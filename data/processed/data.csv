context_3,context_2,context_1,response
,,,"Если не подписывать, что это учебная дз практикума, то проект выглядит, как неплохой отчет о выполненной работе."
,,"Если не подписывать, что это учебная дз практикума, то проект выглядит, как неплохой отчет о выполненной работе.",Всем добрый денек! Занимаюсь задачей QA по корпусу документов. Первым этапом нужно сделать извлечение/ранжирование списка документов в соответствии с заданным вопросом. Какая сейчас сота в этом плане?
,,,"Или не сота, но хотя бы базированное решение, с которого не стыдно начать"
,,"Или не сота, но хотя бы базированное решение, с которого не стыдно начать","Retrieve and rerank sbert, думаю"
,,,"Я был давно на Графиконе, это больше для студентов-аспирантов конференция, а не где большие дяди меряются достижениями. известные люди с ВМК МГУ там были"
,,,"Добрый день, с глупым вопросом возможно залечу. Имеются изображения с архитектурным планом недвижки (черные стены, белый фон). Есть две комнаты, обе прямоугольные, одна очевидно большая и жилая, вторая небольшая и не жилая. Кроме стен ничего нет (ни мебели, ни подписей). Как-то можно разделить такие объекты на два разных класса непосредственно нейронкой? Сверточные нейронки как признаки выделяют только формы, или размеры объекта как-то могут повлиять на результат определения класса?

Использую Yolo для сегментации границ жилых помещений. Думал над разметкой и встал такой вопрос. Может есть мысли и по разметке для такой задаче? Нужно ли выделять отдельно нежилые помещения типа санузлов и кухни, если нужно только жилые помещения определить? (в кухнях и санузлах могут присутствовать бытовая техника и сантехника соответственно)"
,,"Добрый день, с глупым вопросом возможно залечу. Имеются изображения с архитектурным планом недвижки (черные стены, белый фон). Есть две комнаты, обе прямоугольные, одна очевидно большая и жилая, вторая небольшая и не жилая. Кроме стен ничего нет (ни мебели, ни подписей). Как-то можно разделить такие объекты на два разных класса непосредственно нейронкой? Сверточные нейронки как признаки выделяют только формы, или размеры объекта как-то могут повлиять на результат определения класса?

Использую Yolo для сегментации границ жилых помещений. Думал над разметкой и встал такой вопрос. Может есть мысли и по разметке для такой задаче? Нужно ли выделять отдельно нежилые помещения типа санузлов и кухни, если нужно только жилые помещения определить? (в кухнях и санузлах могут присутствовать бытовая техника и сантехника соответственно)","А почему вы решили, что комната поменьше не жилая? Из описания задачи, приведенного вами, этого не следует.
Обычно на плане должны быть хотя бы номера помещений, и экспликация (возможно на другом листе), без этого даже эскиз не имеет смысла. => нужно привязываться к ним, распознавать названия и номера, и на этой основе определять что из себя представляет то или иное помещение. Только по размеру мастерскую например от комнаты отдыха не отличить."
,,,"Базовыми методами opencv типа find_contours не решается задача?  Самый большой - жилая комната, остальные - кухня/санузел.."
,,,"opencv пока не пробовали, но можно.
""Самый большой - жилая комната, остальные - кухня/санузел.."" - Комнат может быть несколько, не всегда самая большая - жилая"
,,"opencv пока не пробовали, но можно.
""Самый большой - жилая комната, остальные - кухня/санузел.."" - Комнат может быть несколько, не всегда самая большая - жилая",В вопросе была именно такая формулировка)
,,,"Всем привет! 
Подскажите, пожалуйста, какие-то недостатки и ограничения LightFM
Вроде вещь популярная, статью прочитал, контрибушены осознал, а вот в каком случае он на практике применим не будет, хочется узнать из вашего личного опыта, для лучшего понимания
Заранее спасибо!"
,,"Всем привет! 
Подскажите, пожалуйста, какие-то недостатки и ограничения LightFM
Вроде вещь популярная, статью прочитал, контрибушены осознал, а вот в каком случае он на практике применим не будет, хочется узнать из вашего личного опыта, для лучшего понимания
Заранее спасибо!",контекстов когда совсем не применим я не могу придумать)
,,,"возможно неправильно выразился. Вопрос скорее в другом. На изображении есть несколько идентичных объектов, одни побольше, другие поменьше. Размер объекта как-то оказывает существенное влияние на предсказания свёрточной сети, если нет прям микрообъектов? Может ли нейросеть на основе размера идентичных объектов разграничить их на разные классы?"
,,"возможно неправильно выразился. Вопрос скорее в другом. На изображении есть несколько идентичных объектов, одни побольше, другие поменьше. Размер объекта как-то оказывает существенное влияние на предсказания свёрточной сети, если нет прям микрообъектов? Может ли нейросеть на основе размера идентичных объектов разграничить их на разные классы?","У вас же чертежи в масштабе, векторизуйте их, вычислите площадь помещения и стройте решение исходя из площади в метрах"
,"возможно неправильно выразился. Вопрос скорее в другом. На изображении есть несколько идентичных объектов, одни побольше, другие поменьше. Размер объекта как-то оказывает существенное влияние на предсказания свёрточной сети, если нет прям микрообъектов? Может ли нейросеть на основе размера идентичных объектов разграничить их на разные классы?","У вас же чертежи в масштабе, векторизуйте их, вычислите площадь помещения и стройте решение исходя из площади в метрах",на большей части изображений отсутствуют масштаб и размеры. По большей части это куча соединенных прямоугольников без надписей
,,,"йоло может различать объекты по размеру, должно завестись из коробки, главное убрать аугментацю с изменением масштаба картинок"
,,,"Это хороший бейзлайн, из минусов
1 медленный в сравнении с имплисит и нейросетками
2 не самая умная обработка мета фичей, только категориальные + просто суммирование векторов"
,,"Это хороший бейзлайн, из минусов
1 медленный в сравнении с имплисит и нейросетками
2 не самая умная обработка мета фичей, только категориальные + просто суммирование векторов","А сори, ещё вопросик, правильно ли я понял, что контентные фичи, которые можно в lightFM использовать - только категориальные

То есть я не смогу заэмбеддить текст и подать как фичи контентные?"
,,,Большое спасибо! А в implicit можно ли контентные фичи учитывать или только коллаборативность?
,,,только коллаборативные насколько помню
,,только коллаборативные насколько помню,Спасибо!
,,,"Всем привет! Посоветуйте, пж, библиотеки для тренировки моделей под instance сегментацию на RGBD данных (RGB + глубина)"
,,"Всем привет! Посоветуйте, пж, библиотеки для тренировки моделей под instance сегментацию на RGBD данных (RGB + глубина)",Попробуй подай 4м каналом в mmdet
,"Всем привет! Посоветуйте, пж, библиотеки для тренировки моделей под instance сегментацию на RGBD данных (RGB + глубина)",Попробуй подай 4м каналом в mmdet,"Тоже думал об этом. Попробую, спасибо)"
,,,"да, там нужно за он-хотить все категории, сконкатенировать и подать в модель, и это кстати вообще не очевидно из документации"
,,"да, там нужно за он-хотить все категории, сконкатенировать и подать в модель, и это кстати вообще не очевидно из документации","более того, если подавать метадату другим образом, модель ее скушает и даже как-то обучится, но будет сильно хуже своего потенциала"
,"да, там нужно за он-хотить все категории, сконкатенировать и подать в модель, и это кстати вообще не очевидно из документации","более того, если подавать метадату другим образом, модель ее скушает и даже как-то обучится, но будет сильно хуже своего потенциала",Большое спасибо за важную инфу)
,,,А цена явно хорошая)
,,,"Всем привет, нужно посчитать 6 квантилей в датасете размером 112 фичей на 3 млн сэмплов. Пандосовский quantile считает вечность, пробовал dask, он тоже это делает очень долго. Кто-нибудь знает какие-то оптимизации для этой задачи?"
,,"Всем привет, нужно посчитать 6 квантилей в датасете размером 112 фичей на 3 млн сэмплов. Пандосовский quantile считает вечность, пробовал dask, он тоже это делает очень долго. Кто-нибудь знает какие-то оптимизации для этой задачи?","Сложить в np.array, например"
,,,"всем привет!
что-то я не очень понимаю для чего FFD нужен, это что-то вроде нормализации временных рядов? если да, то почему не используют CPD?"
,,"всем привет!
что-то я не очень понимаю для чего FFD нужен, это что-то вроде нормализации временных рядов? если да, то почему не используют CPD?",если речь про change point detection то нужно за что-то зацепиться для принятия решения. если о другом - то ¯\_(ツ)_/¯
,,,Polars? Numba jit? Map-reduse на gpu?
,,Polars? Numba jit? Map-reduse на gpu?,"возможно скажу убертупую вещь, но попробуй перевести просто в листы питоновские и посчитать квантили формулами питоновскими. 

У меня была похожая задача, там пандас писал 20 часов эстимейтед тайм, а питон чистый посчитал за 2 минуты."
,,,"Интересно, а совместимость с CUDA или аналог какой-то есть?"
,,"Интересно, а совместимость с CUDA или аналог какой-то есть?","зачем, под такие вещи свой код пишется"
,,,"1) Лично на мой взгляд, в трудовой деятельности очень много информации, которую рекрутер даже если захочет понять, не поймет. Те же детали про петрографический анализ – скорее человек подумает, что это где-то рядом с Петродворцовым районом. Можно рабочий опыт попытаться обернуть в другую оболочку: ""провел анализ того-то, вследствие чего результат стал лучше на сколько-то процентов"", ""составлял датасеты такого-то объема для дальнейшей работы"" и тому подобные фразы, которые будут значительно ближе к той сфере, где идет поиск работы. 

2) Больше раскрыть проекты. В то же время, когда есть любопытный проект, связанный с оттоком клиентов, про него написано полтора предложения, словно за него стыдно. И никакого кринжа нет в проекте в рамках курса: кринж или не кринж – это уже результат проекта, который зависит от его автора, и если даже кринж, то всегда можно доработать.

Если в общих чертах, после прочтения резюме сложилось впечатление, что вам больше по душе работа с камнями в 1С, чем аналитика. Однако, на гите лежат весьма любопытные проекты, которые однозначно стоило бы раскрывать сильнее, убрав из трудового опыта все лишнее.

Насчет гита: ничего плохого нет в том, чтобы держать историю развития на гите, но код, если самому в глаза бросаются заметные ошибки, переработать имеет смысл. Т.е. чтобы не было стыдно за свою же работу."
,,,"По идее это может сделать стейбл диффужен с reference controlnet 
Не самая надежная штука в обращении, впрочем, больше хватает стиль чем объекты."
,,"По идее это может сделать стейбл диффужен с reference controlnet 
Не самая надежная штука в обращении, впрочем, больше хватает стиль чем объекты.","вот да, видел примеры с стейбл, показалось, что будет очень не надежно восстанавливать объекты"
,"По идее это может сделать стейбл диффужен с reference controlnet 
Не самая надежная штука в обращении, впрочем, больше хватает стиль чем объекты.","вот да, видел примеры с стейбл, показалось, что будет очень не надежно восстанавливать объекты","Смотря как подойти к делу, но вряд ли стоит времени 

мб фотошопная сетка лучше причешет если трансформировать слой с платьем на модель"
"По идее это может сделать стейбл диффужен с reference controlnet 
Не самая надежная штука в обращении, впрочем, больше хватает стиль чем объекты.","вот да, видел примеры с стейбл, показалось, что будет очень не надежно восстанавливать объекты","Смотря как подойти к делу, но вряд ли стоит времени 

мб фотошопная сетка лучше причешет если трансформировать слой с платьем на модель","мне кажется, это в первую очередь вопрос, как сделать инъекцию с переносимым объектом, так чтобы было без диких артефактов, некоторые настоящие решения используют походу CLIP чтобы закодировать картинку типо как текстовое представление и это конечно вызывает сомнение"
"вот да, видел примеры с стейбл, показалось, что будет очень не надежно восстанавливать объекты","Смотря как подойти к делу, но вряд ли стоит времени 

мб фотошопная сетка лучше причешет если трансформировать слой с платьем на модель","мне кажется, это в первую очередь вопрос, как сделать инъекцию с переносимым объектом, так чтобы было без диких артефактов, некоторые настоящие решения используют походу CLIP чтобы закодировать картинку типо как текстовое представление и это конечно вызывает сомнение",Контролнет работает поверх клипа с тем на что научена его разновидность. Референс контролнет подсовывает в латент картинку разжеванную энкодером например.
"Смотря как подойти к делу, но вряд ли стоит времени 

мб фотошопная сетка лучше причешет если трансформировать слой с платьем на модель","мне кажется, это в первую очередь вопрос, как сделать инъекцию с переносимым объектом, так чтобы было без диких артефактов, некоторые настоящие решения используют походу CLIP чтобы закодировать картинку типо как текстовое представление и это конечно вызывает сомнение",Контролнет работает поверх клипа с тем на что научена его разновидность. Референс контролнет подсовывает в латент картинку разжеванную энкодером например.,А можешь че-то посоветовать по этой теме почитать?
"мне кажется, это в первую очередь вопрос, как сделать инъекцию с переносимым объектом, так чтобы было без диких артефактов, некоторые настоящие решения используют походу CLIP чтобы закодировать картинку типо как текстовое представление и это конечно вызывает сомнение",Контролнет работает поверх клипа с тем на что научена его разновидность. Референс контролнет подсовывает в латент картинку разжеванную энкодером например.,А можешь че-то посоветовать по этой теме почитать?,https://github.com/lllyasviel/ControlNet-v1-1-nightly
,,,"Всем привет! 
Задача: классифкация на 277 классов, входной тензор размерности 110*9*11. Решать хочется через свертки, но пока архитектуру адекватную подобрать не удалось.

Посоветуйте, пожалуйста, какую архитектуру сверток можно рассмотреть с нестандартного размером каналов входных данных (110 каналов)? 

Идея с добавлением первого слоя к стандартному бекбону для перевода к трехканальному размеру не подходит, так как теряется много инфомрации."
,,"Всем привет! 
Задача: классифкация на 277 классов, входной тензор размерности 110*9*11. Решать хочется через свертки, но пока архитектуру адекватную подобрать не удалось.

Посоветуйте, пожалуйста, какую архитектуру сверток можно рассмотреть с нестандартного размером каналов входных данных (110 каналов)? 

Идея с добавлением первого слоя к стандартному бекбону для перевода к трехканальному размеру не подходит, так как теряется много инфомрации.","В чем проблема с использованием стандартных моделей для этой задачи (например, efficientnet)? Насколько помню, количество каналов можно задать при инициализации модели. Или на таких маленьких картинках плохо себя показывают?"
,"Всем привет! 
Задача: классифкация на 277 классов, входной тензор размерности 110*9*11. Решать хочется через свертки, но пока архитектуру адекватную подобрать не удалось.

Посоветуйте, пожалуйста, какую архитектуру сверток можно рассмотреть с нестандартного размером каналов входных данных (110 каналов)? 

Идея с добавлением первого слоя к стандартному бекбону для перевода к трехканальному размеру не подходит, так как теряется много инфомрации.","В чем проблема с использованием стандартных моделей для этой задачи (например, efficientnet)? Насколько помню, количество каналов можно задать при инициализации модели. Или на таких маленьких картинках плохо себя показывают?","вот кроме efficientnet в голову ничего и не приходит, но хочется еще через что то прогнать, чтобы сравнить. Да, картинка маленькая, смотрел ресерч по этой задаче, необходимо сохранять входную размерность 9*11 до конца выхода сетки, то есть нужно без пулингов обходиться. 

Буду с efficientnet начинать пробовать, спасибо"
"Всем привет! 
Задача: классифкация на 277 классов, входной тензор размерности 110*9*11. Решать хочется через свертки, но пока архитектуру адекватную подобрать не удалось.

Посоветуйте, пожалуйста, какую архитектуру сверток можно рассмотреть с нестандартного размером каналов входных данных (110 каналов)? 

Идея с добавлением первого слоя к стандартному бекбону для перевода к трехканальному размеру не подходит, так как теряется много инфомрации.","В чем проблема с использованием стандартных моделей для этой задачи (например, efficientnet)? Насколько помню, количество каналов можно задать при инициализации модели. Или на таких маленьких картинках плохо себя показывают?","вот кроме efficientnet в голову ничего и не приходит, но хочется еще через что то прогнать, чтобы сравнить. Да, картинка маленькая, смотрел ресерч по этой задаче, необходимо сохранять входную размерность 9*11 до конца выхода сетки, то есть нужно без пулингов обходиться. 

Буду с efficientnet начинать пробовать, спасибо","Если надо сохранять размер картинки, то можно гуглить на тему моделей с dilated convolution (аля тех что испольщуются в DeepLabV3 и древних nlp моделях на свертках).

А по поводу числа входных каналов, главное, чтобы число выходных каналов первого слоя было не слишком мелким (встречаются модели с 32 и 64 каналами на выходе первого слоя).

Также, я бы посмотрел в сторону Visual Transfomer, учитывая размер изображений. Там и проблем с уменьшением размера не будет (все тупо запихнется в один блок растягиваемый в вектор) и взаимосвязи между каналами будут учитываться сильно лучше. Из минусов: потенциально больший размер модели и необходимость иметь довольно большие датасеты"
"В чем проблема с использованием стандартных моделей для этой задачи (например, efficientnet)? Насколько помню, количество каналов можно задать при инициализации модели. Или на таких маленьких картинках плохо себя показывают?","вот кроме efficientnet в голову ничего и не приходит, но хочется еще через что то прогнать, чтобы сравнить. Да, картинка маленькая, смотрел ресерч по этой задаче, необходимо сохранять входную размерность 9*11 до конца выхода сетки, то есть нужно без пулингов обходиться. 

Буду с efficientnet начинать пробовать, спасибо","Если надо сохранять размер картинки, то можно гуглить на тему моделей с dilated convolution (аля тех что испольщуются в DeepLabV3 и древних nlp моделях на свертках).

А по поводу числа входных каналов, главное, чтобы число выходных каналов первого слоя было не слишком мелким (встречаются модели с 32 и 64 каналами на выходе первого слоя).

Также, я бы посмотрел в сторону Visual Transfomer, учитывая размер изображений. Там и проблем с уменьшением размера не будет (все тупо запихнется в один блок растягиваемый в вектор) и взаимосвязи между каналами будут учитываться сильно лучше. Из минусов: потенциально больший размер модели и необходимость иметь довольно большие датасеты",Спасибо
,,,"Слышал мнение, что это то ли утка, то ли переврали журналисты"
,,"Слышал мнение, что это то ли утка, то ли переврали журналисты","Да, там всё странно
https://t.me/theworldisnoteasy/1744"
,,,"Кажется, что смысла нет. Лучше адаптировать Rocm или вообще сделать бэкенд для PyTorch по аналогии с тем, что сделали для чипов Apple"
,,"Кажется, что смысла нет. Лучше адаптировать Rocm или вообще сделать бэкенд для PyTorch по аналогии с тем, что сделали для чипов Apple",пример — гугловские tpu
,"Кажется, что смысла нет. Лучше адаптировать Rocm или вообще сделать бэкенд для PyTorch по аналогии с тем, что сделали для чипов Apple",пример — гугловские tpu,Спасибо большое за рекомендации!
"Кажется, что смысла нет. Лучше адаптировать Rocm или вообще сделать бэкенд для PyTorch по аналогии с тем, что сделали для чипов Apple",пример — гугловские tpu,Спасибо большое за рекомендации!,кто нибудь уже нашел способы: чтобы использовать chat-gpt без апи? и получить доступ в gpt-4 не падая в лист ожидания?
,,,"А что странного? Из описания видна неправильная функция награды: плюсовали только за успешное попадание, хотя 1.обнаружение, 2.поражение и 3.выполнение задания, т. е. два первых пункта плюс запрос на поражение посередине и следование ответу на запрос можно разделить. Они же, похоже, только за пункт 2 плюшками кормили."
,,"А что странного? Из описания видна неправильная функция награды: плюсовали только за успешное попадание, хотя 1.обнаружение, 2.поражение и 3.выполнение задания, т. е. два первых пункта плюс запрос на поражение посередине и следование ответу на запрос можно разделить. Они же, похоже, только за пункт 2 плюшками кормили.","Я больше про то, как новость разошлась. А так более-менее понятно"
,,,"Роботы всех убьют, в т.ч. хозяев!!! Естественно, такое разлетелось моментально."
,,,"Повторю, может кто-то сможет ответить :)"
,,"Повторю, может кто-то сможет ответить :)","так вы провалидируйтесь на своей задаче и будет понятно 👍
параметры выставлены адекватные (но еще уточните, какой размер трейна на всякий)"
,"Повторю, может кто-то сможет ответить :)","так вы провалидируйтесь на своей задаче и будет понятно 👍
параметры выставлены адекватные (но еще уточните, какой размер трейна на всякий)","Вообще ф1 вырос с 77.1 до 77.7
Размер общий около 520к
Ну трейн на млм значит 650к 
Там тексты правда есть и короткие и длинные но паддинг на 256"
,,,"Звучит как лютая хуйня
Чаще всего у таких систем есть свой чужой"
,,"Звучит как лютая хуйня
Чаще всего у таких систем есть свой чужой","Это же симуляция, а не работающий образец из железа, пластика и кремния."
,,,"Так сам собери свертку, без пулингов, а то что 110 каналов, то какая разница? Свертки не захордкожены под 3 канала"
,,"Так сам собери свертку, без пулингов, а то что 110 каналов, то какая разница? Свертки не захордкожены под 3 канала","сам уже собрал, опирась на здраывй смысл. Но хочется посомтреть какие метрики будут именно на архитектурах, которые проверяны временем, а не то что я сам там придумал.
 
>>>Свертки не захордкожены под 3 канала - Если ты про реализацию стандартных архитектур, то в pytorch они сделаны вроде как под три канала. Или предлагаешь  подправить их? Если второй вариант, то так и собираюсь делать. Только пока непонятно с какой скоростью уменьшать входное количество каналов, обычно же все наоборот - увеличваем количество каналов. Думал есть какие то может архитектуры, где прям из коробки можно менять входное количество слоев"
,"Так сам собери свертку, без пулингов, а то что 110 каналов, то какая разница? Свертки не захордкожены под 3 канала","сам уже собрал, опирась на здраывй смысл. Но хочется посомтреть какие метрики будут именно на архитектурах, которые проверяны временем, а не то что я сам там придумал.
 
>>>Свертки не захордкожены под 3 канала - Если ты про реализацию стандартных архитектур, то в pytorch они сделаны вроде как под три канала. Или предлагаешь  подправить их? Если второй вариант, то так и собираюсь делать. Только пока непонятно с какой скоростью уменьшать входное количество каналов, обычно же все наоборот - увеличваем количество каналов. Думал есть какие то может архитектуры, где прям из коробки можно менять входное количество слоев","nn.Conv2d(in_channels, out_channels, kernel_size)"
,,,"спасибо, попробую)"
,,"спасибо, попробую)","Жена у меня биолог, после новости о том что дрон замочил оператора, говорит, всё, Скайнет? ИИ пороботит человеков?

Говорю нет. 

Во-первых, ИИ - это гуманитарный термин. Интеллект - это обозначение непонимания работы мозга. Пока гуманитарии философствуют, математики занимаются машинным обучением.

Во-вторых. Из сегодняшней истории вывод можно сделать такой. Модель от ситуации + потенциальное действие не штрафовали за ущерб. В оценке инвестиционных проектов, например, финансы, уже сто как подобное просчитывают. А тут просто недодумали... И уже сенсация.

А потом имеем волну этики и прочей эстетики, эротики с моделями на грани физических извращений, лишь бы чего не вышло.

И вот это как бы чего неэтичного не вышло - не то чтобы останавливает прогресс, нет. Душит продукты, но это проблема маркетологов. Как раз матан это развивает - как дополнительные условия в лагранжиане. Как +1 пункт в ТЗ.

Но когда это начнет останавливать матан, это будет беда. Потенциала правда к этому я лично пока не вижу."
,"спасибо, попробую)","Жена у меня биолог, после новости о том что дрон замочил оператора, говорит, всё, Скайнет? ИИ пороботит человеков?

Говорю нет. 

Во-первых, ИИ - это гуманитарный термин. Интеллект - это обозначение непонимания работы мозга. Пока гуманитарии философствуют, математики занимаются машинным обучением.

Во-вторых. Из сегодняшней истории вывод можно сделать такой. Модель от ситуации + потенциальное действие не штрафовали за ущерб. В оценке инвестиционных проектов, например, финансы, уже сто как подобное просчитывают. А тут просто недодумали... И уже сенсация.

А потом имеем волну этики и прочей эстетики, эротики с моделями на грани физических извращений, лишь бы чего не вышло.

И вот это как бы чего неэтичного не вышло - не то чтобы останавливает прогресс, нет. Душит продукты, но это проблема маркетологов. Как раз матан это развивает - как дополнительные условия в лагранжиане. Как +1 пункт в ТЗ.

Но когда это начнет останавливать матан, это будет беда. Потенциала правда к этому я лично пока не вижу.","Интересные вопросы от conjecture, да😅"
"спасибо, попробую)","Жена у меня биолог, после новости о том что дрон замочил оператора, говорит, всё, Скайнет? ИИ пороботит человеков?

Говорю нет. 

Во-первых, ИИ - это гуманитарный термин. Интеллект - это обозначение непонимания работы мозга. Пока гуманитарии философствуют, математики занимаются машинным обучением.

Во-вторых. Из сегодняшней истории вывод можно сделать такой. Модель от ситуации + потенциальное действие не штрафовали за ущерб. В оценке инвестиционных проектов, например, финансы, уже сто как подобное просчитывают. А тут просто недодумали... И уже сенсация.

А потом имеем волну этики и прочей эстетики, эротики с моделями на грани физических извращений, лишь бы чего не вышло.

И вот это как бы чего неэтичного не вышло - не то чтобы останавливает прогресс, нет. Душит продукты, но это проблема маркетологов. Как раз матан это развивает - как дополнительные условия в лагранжиане. Как +1 пункт в ТЗ.

Но когда это начнет останавливать матан, это будет беда. Потенциала правда к этому я лично пока не вижу.","Интересные вопросы от conjecture, да😅","А есть какие ресерчи, как без итеративных оптимизаций сразу в оптимум весов попасть?

На AI Talks 2020 небезызвестный Ветров говорил, что работы в направлении ведутся.

Я думал-думал как такое возможно вообще. Ну там лосс обсчитывать в разных местах, бутстрапом может, ну как-то глупо все равно.

Вот мысль есть, может где описана (я хз?). Равновесие по Нэшу (в случае взаимодействия весов) при связанной с лоссом функцией награды каждого, в принципе должно давать оптимум (ну как каждый вес не шатай - лосс хуже). Как специфицировать награду, отдельная история, но известно что в непрерывном случае финальный вес каждого пропорционален x' - x, где x' производная по времени ""игры"". В дискретном случае все это очень напоминает SGD.

При некоторых условиях на модуль производной по весам вышеупомянутой разницы (< 1 - eps), равновесие даже существует.

Я не думаю что кто-то это не описал. Но совсем этими автоградами - решение вроде должно быть технически. Что мешает?.."
,,,"Про почитать не скажу, но если есть желание, могу рассказать"
,,"Про почитать не скажу, но если есть желание, могу рассказать","распишите тут, интересно!"
,"Про почитать не скажу, но если есть желание, могу рассказать","распишите тут, интересно!","Алгоритмической частью не занимался, скажу сразу. 

Торговал на календарных спредах в компании OSTC, они на пару с Атоном предприятие делали. 

Календарные спреды были на фьючерсах, т.е. берём два фьючерса лонговый и шортовый на разные даты - получается новый продукт - календарный спред"
,,,"Привет! А посоветуйте статьи/рабочие инструменты для такой задачи: хочется скормить текст модели и задавать по нему ей вопросы, она соответственно должна отвечать. Скармливание текста динамическое, то есть можно его дополнять и хочется, чтобы она ""дообучалась"" на новом куске, а не обучалась заново.

Понимаю, что с такой задачей может справиться условный чат гпт с хорошим промпт инжинирингом, но интерсно посмотреть более основательные подходы. Или все-таки чат гпт вполне рабочий вариант?

Если вдруг видели статейки на архиве/medium или модели на hugging face под эту задачу или просто есть какие-то мысли, буду благодарен, если поделитесь)"
,,"Привет! А посоветуйте статьи/рабочие инструменты для такой задачи: хочется скормить текст модели и задавать по нему ей вопросы, она соответственно должна отвечать. Скармливание текста динамическое, то есть можно его дополнять и хочется, чтобы она ""дообучалась"" на новом куске, а не обучалась заново.

Понимаю, что с такой задачей может справиться условный чат гпт с хорошим промпт инжинирингом, но интерсно посмотреть более основательные подходы. Или все-таки чат гпт вполне рабочий вариант?

Если вдруг видели статейки на архиве/medium или модели на hugging face под эту задачу или просто есть какие-то мысли, буду благодарен, если поделитесь)",Вы можете использовать langchain и например FRED-T5-LARGE_text_qa. Будет работать хорошо и быстро
,,,"Сырой чат гпт смущает, так как текст может быть довольно длинным, а насколько знаю, ему свойственно забывать информацию"
,,"Сырой чат гпт смущает, так как текст может быть довольно длинным, а насколько знаю, ему свойственно забывать информацию","Выше по чату есть такое
Штука интересная, но мне не зашло в моих задачах"
,,,"Обучаю классификатор текста с бертом, сначала инициализировал модельку с hf и пробовал учить с обычным трейн лупом, потом попробовал заюзать simpletransformers. Я совсем поехавший или почему моделька не учится? На полном датасете не учится, решил протестить, сможет ли переобучиться на 5 примерах, и она ПРОСТО не учится. Лосс не падает (в торче падает до какого то уровня и останавливается, на метрики не влияет, а должен бы быть уже около 0). Да там же даже с рандомными данными модель должна была эти жалкие 5 примеров запомнить, но нет

На первом скрине simpletransformers, на втором со своим трейн лупом в торче"
,,"Обучаю классификатор текста с бертом, сначала инициализировал модельку с hf и пробовал учить с обычным трейн лупом, потом попробовал заюзать simpletransformers. Я совсем поехавший или почему моделька не учится? На полном датасете не учится, решил протестить, сможет ли переобучиться на 5 примерах, и она ПРОСТО не учится. Лосс не падает (в торче падает до какого то уровня и останавливается, на метрики не влияет, а должен бы быть уже около 0). Да там же даже с рандомными данными модель должна была эти жалкие 5 примеров запомнить, но нет

На первом скрине simpletransformers, на втором со своим трейн лупом в торче",у тебя train df точно не один и тот же семпл прокидывает?
,,,"Соответственно, если лонговый фьючерс эксперируется раньше - считаем спред лонговый, шортовый спред экспирируется раньше - считаем спред шортовым
Соответственно, если брать лонговый и шортовый спред одновременно - получается хедж-конструкция (""бабочка"" или ""кондор"") из хедж-конструкция, в свою очередь можно ещё более сложные темы собирать
Для чего весь сыр-бор? Суть в том, что если мы торгуем непосредственно на фьючерсах обычных - у нас цена скачет очень сильно и трудно делать предсказуемый трейдинг с понятными стопами. Идут проскальзывания. Если же берём календарный спред - его волатильность намного ниже.
Дальше больше, если берётся хедж-конструкция, то у неё волатильность ещё меньше. То есть получается, что незначительные рыночные колебания не оказывают влияние, что позволяет зарабатывать на сезонных изменениях
С учётом того, что это хедж, можно наращивать очень большой объем и исследовать сезонные изменения тех или иных конструкций или торговать ренж на них же
Так как это хедж, боковик там встречается намного чаще, чем в обычных фьючерсах, то есть повышается предсказательная способность трейдера"
,,,"Даётся это, впрочем, за зависимость от комиссии(малая волатильность - низкие прибыли на лот) , необходимость строить графики за несколько лет для исследования сезонности и необходимость держать большой объем (что повышает уязвимость от чёрных лебедей)"
,,"Даётся это, впрочем, за зависимость от комиссии(малая волатильность - низкие прибыли на лот) , необходимость строить графики за несколько лет для исследования сезонности и необходимость держать большой объем (что повышает уязвимость от чёрных лебедей)",В тему черных лебедей) Вчера только видел Нассима Талеба после его выступления) Затупил книгу подписать
,"Даётся это, впрочем, за зависимость от комиссии(малая волатильность - низкие прибыли на лот) , необходимость строить графики за несколько лет для исследования сезонности и необходимость держать большой объем (что повышает уязвимость от чёрных лебедей)",В тему черных лебедей) Вчера только видел Нассима Талеба после его выступления) Затупил книгу подписать,"Да, читал)"
,,,"Как бы это только одна стратегия, временные фьючерсы, похожие темы можно делать на опционах (гугли опционные конструкции) и, самая традиционная тема - сравнение переоцененных и недооценённых товаров/компаний (спред WTI-Brent или, я не знаю Tesla-Ford)"
,,,"Можно эту штуку собирать руками, например, на bitmex делать лонг спота и шорт ближайшего фьюча и зарабатывать на временной разнице, разница в ценах и есть максимальная прибыль к экспирации фьюча"
,,"Можно эту штуку собирать руками, например, на bitmex делать лонг спота и шорт ближайшего фьюча и зарабатывать на временной разнице, разница в ценах и есть максимальная прибыль к экспирации фьюча",А какие тут есть варианты развития событий и выходы? Пока не супер хорошо знаком с непосредственно с работой с несколькими инструментами
,"Можно эту штуку собирать руками, например, на bitmex делать лонг спота и шорт ближайшего фьюча и зарабатывать на временной разнице, разница в ценах и есть максимальная прибыль к экспирации фьюча",А какие тут есть варианты развития событий и выходы? Пока не супер хорошо знаком с непосредственно с работой с несколькими инструментами,"Ну смотрите, разница в ценах и есть наша прибыль. Но в моменте из-за рыночных флуктуаций спред может сильно меняться, а гарантийное обеспечение не бесконечное. В целом, к экспирации спред всё равно сойдётся, что бы ни произошло, но надо учитывать, окупит ли оно комиссию, курс биткоина или другой валюты (если мы говорим о валютах, а не о сырьё, скажем, мы можем получить прибыль в биткоинах, но убыток в долларах из-за разницы цен на начало и конец сделки)"
,,,"Да, ещё про минус не расписал - не очень понятно, как эту историю стопить в случае чего. LTCM примерно на такой же фигне прогорели, как и писал выше - есть уязвимость к чёрным лебедяи
Спреды на фьючерсы никогда не сходятся, здесь надо учитывать только спред спот-фьючерс
А, да, ещё, желательно на поставку/экспирацию не выходить, разбалансируется вся конструкция)
На рынке МосБиржи особо эту тему не провернешь, потому что там гарантийное обеспечение считается за каждый фьючерс пока что, а не на конструкцию в целом, то есть объемы не сделаешь достаточно большие
Впрочем, можно этой темой баловаться - например, стопить без фиксации убытка: потеряли на Лонге си, продаем соседний фьючерс и можем прибылью со второго фьючерса перекрыть частично убытки с первого, а потом закрыть тот или иной фьючерс в зависимости от развития событий
Какие если есть вопросы - задавайте
По сути, весь рыночно-нейтральный трейдинг создаёт новые инструменты, со своими графиками, тех-анализом, сезонностью и прочими приколами. Очень похоже на переход в другое пространство в ML"
,,,"Можно  еще про торговлю волатильностью почитать. 
Тоже про один из видов маркет нейтральных стратегий."
,,"Можно  еще про торговлю волатильностью почитать. 
Тоже про один из видов маркет нейтральных стратегий.",Ну по факту это оно и есть
,,,"По поводу ГО на MOEX откуда информация? Если честно, такого не замечал, но возможно ситуация поменялась. По остальному всё так
Почитал по ГО на мосбирже: ГО выставляется по наибольшему ГО на фьючерс, то есть оно на 40-50% меньше, чем на два фьючерса. Также вроде как реализовали синтетический сбор спреда. Возможно стоит попробовать посмотреть, что с этим на Отечественной бирже можно сделать"
,,,"Я не могу найти подвоха, выглядит слишком хорошо"
,,"Я не могу найти подвоха, выглядит слишком хорошо","Это не дипфейк. У нее на сайте есть функция видеообращения и если это не реклама какойто коммерческой штуки то стоит около 100-200$ 

Когда эты выложили на канале курса, то видео так разлетелось что пришлось закрыть комменты и канал сделать непубличным"
,"Я не могу найти подвоха, выглядит слишком хорошо","Это не дипфейк. У нее на сайте есть функция видеообращения и если это не реклама какойто коммерческой штуки то стоит около 100-200$ 

Когда эты выложили на канале курса, то видео так разлетелось что пришлось закрыть комменты и канал сделать непубличным",Блин скиньте пожалуйста сайт найти не могк
"Я не могу найти подвоха, выглядит слишком хорошо","Это не дипфейк. У нее на сайте есть функция видеообращения и если это не реклама какойто коммерческой штуки то стоит около 100-200$ 

Когда эты выложили на канале курса, то видео так разлетелось что пришлось закрыть комменты и канал сделать непубличным",Блин скиньте пожалуйста сайт найти не могк,Я тогда вроде просто в гугле и нашел
,,,А лернинг рейт батч сайз менялся?
,,,Это шедеврально
,,Это шедеврально,Это элфи?
,Это шедеврально,Это элфи?,Да
,,,перемешать
,,перемешать,"Ну это вроде не рабочий вариант, тест обычно фиксированный (соревнования/заказчик напикал реальных примеров), а трейн мы сами где-нить нафармили"
,перемешать,"Ну это вроде не рабочий вариант, тест обычно фиксированный (соревнования/заказчик напикал реальных примеров), а трейн мы сами где-нить нафармили","Сместите искусственно распределение своего трейна к тесту, нормальная практика. Вот если тест и валид отличаются и валид держится в секрете, это скверно."
перемешать,"Ну это вроде не рабочий вариант, тест обычно фиксированный (соревнования/заказчик напикал реальных примеров), а трейн мы сами где-нить нафармили","Сместите искусственно распределение своего трейна к тесту, нормальная практика. Вот если тест и валид отличаются и валид держится в секрете, это скверно.","А как при этом таргет определять на train?  У меня были мысли на этот вопрос по типу бутстрепа, но все бьется что таргет под значения из новых распределений не подогнать же"
"Ну это вроде не рабочий вариант, тест обычно фиксированный (соревнования/заказчик напикал реальных примеров), а трейн мы сами где-нить нафармили","Сместите искусственно распределение своего трейна к тесту, нормальная практика. Вот если тест и валид отличаются и валид держится в секрете, это скверно.","А как при этом таргет определять на train?  У меня были мысли на этот вопрос по типу бутстрепа, но все бьется что таргет под значения из новых распределений не подогнать же","1) Selection bias - вы выбираете в трейн не все сэмплы, которые сумели нафармить, а только избранные так, чтобы распределение совпадало с тестом. 2) генерация искусственных данных. Есть два сэмпла, генерирует третий в каком-то промежутке между ними. 3) кроссинговер - берется два сэмпла с близким таргетом и генерируется новый сэмпл где часть фич берется из одного первого сэмпла, а часть из второго. Комбинируя эти способы, можно сместить распределение теста в сторону трейна"
,,,"а потом поделить обратно
Нерепрезентативный трейн это грустно
ну ладно"
,,"а потом поделить обратно
Нерепрезентативный трейн это грустно
ну ладно","Нет, шедулеров не юзал, батч сайз одинаковый везде"
,"а потом поделить обратно
Нерепрезентативный трейн это грустно
ну ладно","Нет, шедулеров не юзал, батч сайз одинаковый везде",Ну попробуй констант лр наверное прописать и снизить количество нулей (повысить)
"а потом поделить обратно
Нерепрезентативный трейн это грустно
ну ладно","Нет, шедулеров не юзал, батч сайз одинаковый везде",Ну попробуй констант лр наверное прописать и снизить количество нулей (повысить),"Блин, вот бы хоть часть тех же функций в fusionbrain"
"Нет, шедулеров не юзал, батч сайз одинаковый везде",Ну попробуй констант лр наверное прописать и снизить количество нулей (повысить),"Блин, вот бы хоть часть тех же функций в fusionbrain","Всем привет, есть заказ на создание сайта (очень простой, можно шаблон)
Что нужно:
1. Регистрация, можно самое простое через fire base
2. Стандартная оплата (подписка)
3. Страница дэшборда на каждого пользователя с простым контентом
4. Доп страница для размещения неких react компонентов 

Если кому интересно (или знаете кому бы было), подробности и ожидания по оплате в лс, срок до одного месяца"
,,,"Эх, парни, когда вы long ближний фьюч, и short дальний, то у вас не маркет-нейтральная позиция, а поза на вид кривой. Почитайте про curve flatteners & curve steepeners. Причины изменения угла наклона кривой могут быть, например, изменения процентных ставок или изменения в ожиданиях по дивидендам, для commodities - погуглите про supercontango и причины возникновения.

Рыночно нейтральная стратегия - это когда у вас одновременно long apple + short spy (или short qqq) * beta of apple. А календарный спред - это не про ""рыночную нейтральность"" и тем более, не в том случае, когда одна из ног выходит на экспирацию!

Очень рекомендую не забывать основы и прочитать Hull ""Options, Futures and other derivatives"". Можно выписать формулу для фьючей, посмотреть на производные pnl от факторов и подумать про то, на что же у какой конструкции получается ставка, а к каким факторам иммунитет."
,,"Эх, парни, когда вы long ближний фьюч, и short дальний, то у вас не маркет-нейтральная позиция, а поза на вид кривой. Почитайте про curve flatteners & curve steepeners. Причины изменения угла наклона кривой могут быть, например, изменения процентных ставок или изменения в ожиданиях по дивидендам, для commodities - погуглите про supercontango и причины возникновения.

Рыночно нейтральная стратегия - это когда у вас одновременно long apple + short spy (или short qqq) * beta of apple. А календарный спред - это не про ""рыночную нейтральность"" и тем более, не в том случае, когда одна из ног выходит на экспирацию!

Очень рекомендую не забывать основы и прочитать Hull ""Options, Futures and other derivatives"". Можно выписать формулу для фьючей, посмотреть на производные pnl от факторов и подумать про то, на что же у какой конструкции получается ставка, а к каким факторам иммунитет.",По факту это всё виды статистического арбитража.
,"Эх, парни, когда вы long ближний фьюч, и short дальний, то у вас не маркет-нейтральная позиция, а поза на вид кривой. Почитайте про curve flatteners & curve steepeners. Причины изменения угла наклона кривой могут быть, например, изменения процентных ставок или изменения в ожиданиях по дивидендам, для commodities - погуглите про supercontango и причины возникновения.

Рыночно нейтральная стратегия - это когда у вас одновременно long apple + short spy (или short qqq) * beta of apple. А календарный спред - это не про ""рыночную нейтральность"" и тем более, не в том случае, когда одна из ног выходит на экспирацию!

Очень рекомендую не забывать основы и прочитать Hull ""Options, Futures and other derivatives"". Можно выписать формулу для фьючей, посмотреть на производные pnl от факторов и подумать про то, на что же у какой конструкции получается ставка, а к каким факторам иммунитет.",По факту это всё виды статистического арбитража.,"Лол, по факту стоило бы за время работы ознакомиться с предметной областью"
"Эх, парни, когда вы long ближний фьюч, и short дальний, то у вас не маркет-нейтральная позиция, а поза на вид кривой. Почитайте про curve flatteners & curve steepeners. Причины изменения угла наклона кривой могут быть, например, изменения процентных ставок или изменения в ожиданиях по дивидендам, для commodities - погуглите про supercontango и причины возникновения.

Рыночно нейтральная стратегия - это когда у вас одновременно long apple + short spy (или short qqq) * beta of apple. А календарный спред - это не про ""рыночную нейтральность"" и тем более, не в том случае, когда одна из ног выходит на экспирацию!

Очень рекомендую не забывать основы и прочитать Hull ""Options, Futures and other derivatives"". Можно выписать формулу для фьючей, посмотреть на производные pnl от факторов и подумать про то, на что же у какой конструкции получается ставка, а к каким факторам иммунитет.",По факту это всё виды статистического арбитража.,"Лол, по факту стоило бы за время работы ознакомиться с предметной областью","Так он изначально сказал, что не скажет где почитать, видимо действительно не читал. А вот рассказать можно что угодно, вот и говорит  🙃"
По факту это всё виды статистического арбитража.,"Лол, по факту стоило бы за время работы ознакомиться с предметной областью","Так он изначально сказал, что не скажет где почитать, видимо действительно не читал. А вот рассказать можно что угодно, вот и говорит  🙃","В мою защиту, я спрашивал у руководства, где можно про сабж почитать, руководство само не читало ничего."
,,,Никто не даёт советов как заработать деньги
,,Никто не даёт советов как заработать деньги,Никто и не даст. Книжки - это про как не просрать денег на базовых принципах.
,,,"А как ознакомиться, не скачивая"
,,"А как ознакомиться, не скачивая",теперь вам известен вес книжки в МБ
,,,а чем вы торгуете?
,,,токсично)
,,токсично),"Дружеский подкол, мы просто знакомы 🤓"
,,,это же карта из каэсочки 1.6
,,,"Всем привет. Занимаюсь разработкой проекта для анализа расположения объектов по алгоритму. Не подскажите какие модели существуют для такой задачи (вид сверху,мб разделённый сетка ) заранее спасибо"
,,"Всем привет. Занимаюсь разработкой проекта для анализа расположения объектов по алгоритму. Не подскажите какие модели существуют для такой задачи (вид сверху,мб разделённый сетка ) заранее спасибо","если расположение на кадре - https://habr.com/ru/post/718106/

если расположение на плане здания с одной камеры - мы такое сходу не нашли, поэтому написали собственный алгоритм. 

но в теории можно завести стерео камеры и воспользоваться этим туториалом:
https://docs.opencv.org/3.4/d9/db7/tutorial_py_table_of_contents_calib3d.html
вот к чему придешь: https://docs.opencv.org/3.4/dd/d53/tutorial_py_depthmap.html"
,,,Для какой именно задачи? Детекции объектов? Сравнения расположения объектов с о схемой?
,,Для какой именно задачи? Детекции объектов? Сравнения расположения объектов с о схемой?,Мне нужно разработать оптимальное расположение объектов по параметрам.(выделить фичи окружающей среды)
,,,"Все хеллоу. Хотел узнать, есть ли смысл искать удаленную работу на зарубежный сайтах по типу Wellfound? Опыта работы еще нет, но можно немного приукрасить. Есть пару учебный проектов, а так же небольшой проект по кластеризации постов в Тинькофф пульс, не совсем успешный, но, соответствующие выводы сделаны."
,,"Все хеллоу. Хотел узнать, есть ли смысл искать удаленную работу на зарубежный сайтах по типу Wellfound? Опыта работы еще нет, но можно немного приукрасить. Есть пару учебный проектов, а так же небольшой проект по кластеризации постов в Тинькофф пульс, не совсем успешный, но, соответствующие выводы сделаны.",кластеризация это с dano чтоли?
,"Все хеллоу. Хотел узнать, есть ли смысл искать удаленную работу на зарубежный сайтах по типу Wellfound? Опыта работы еще нет, но можно немного приукрасить. Есть пару учебный проектов, а так же небольшой проект по кластеризации постов в Тинькофф пульс, не совсем успешный, но, соответствующие выводы сделаны.",кластеризация это с dano чтоли?,"Нет, просто пет проект ради пет проекта"
,,,"Привет всем!
Кто-нибудь сталкивался с распознаванием смазанных штрихкодов?"
,,"Привет всем!
Кто-нибудь сталкивался с распознаванием смазанных штрихкодов?",Я когда-то похожую штуку для ценников делал.
,,,Смысл точно есть. Но шанс найти эту работу намного ниже чем на домашнем рынке.
,,,"pyzbar такое уже не читает. Копаем пока в сторону методов деблюринга, чтобы потом pyzbar натянуть, тк это проще, чем набирать большую выборку и тренить нейронку с нуля на чтение штрихкода"
,,"pyzbar такое уже не читает. Копаем пока в сторону методов деблюринга, чтобы потом pyzbar натянуть, тк это проще, чем набирать большую выборку и тренить нейронку с нуля на чтение штрихкода","Если смаз линейный( аппроксимируется прямой), то можно через кепстральный анализ сделать. Если что-то более сложное,  то искать по тегу image deblur, deconvolution."
,"pyzbar такое уже не читает. Копаем пока в сторону методов деблюринга, чтобы потом pyzbar натянуть, тк это проще, чем набирать большую выборку и тренить нейронку с нуля на чтение штрихкода","Если смаз линейный( аппроксимируется прямой), то можно через кепстральный анализ сделать. Если что-то более сложное,  то искать по тегу image deblur, deconvolution.","Про кепстральный анализ не слышал, спасибо, почитаю)"
"pyzbar такое уже не читает. Копаем пока в сторону методов деблюринга, чтобы потом pyzbar натянуть, тк это проще, чем набирать большую выборку и тренить нейронку с нуля на чтение штрихкода","Если смаз линейный( аппроксимируется прямой), то можно через кепстральный анализ сделать. Если что-то более сложное,  то искать по тегу image deblur, deconvolution.","Про кепстральный анализ не слышал, спасибо, почитаю)","Стандарт для аудио... Не думал что может зайти, но думаю что может зайти)"
,,,bilateral filter должен смочь... Но деблюр толщину скорее всего испортит. Но попробовать недолго
,,bilateral filter должен смочь... Но деблюр толщину скорее всего испортит. Но попробовать недолго,"Я бы выделил границы, развернул в плоскость, вырезал и посчитал статистику по длинной оси. Скорее всего там будут широкие и узкие пики, которые уже можно распознать"
,bilateral filter должен смочь... Но деблюр толщину скорее всего испортит. Но попробовать недолго,"Я бы выделил границы, развернул в плоскость, вырезал и посчитал статистику по длинной оси. Скорее всего там будут широкие и узкие пики, которые уже можно распознать","И еще тупая идея на попробовать - отрескайэлить вниз, через nearest и/или поэкспериментировать - если время позволяет."
,,,"Слева - восстановленное изображение, справа - исходное"
,,"Слева - восстановленное изображение, справа - исходное",Сетучки?
,"Слева - восстановленное изображение, справа - исходное",Сетучки?,Да
"Слева - восстановленное изображение, справа - исходное",Сетучки?,Да,На синтетике?)))
Сетучки?,Да,На синтетике?))),"Имеешь в виду, что смаз моделировался ?"
,,,"Я делал штрихкоды, маленький бинарник на плюсах. Не через pyzbar. Работало огонь... Хз про смазанные. Щяс ссылку скину, постараюсь найти. Что-то из opencv-contrib dnn"
,,"Я делал штрихкоды, маленький бинарник на плюсах. Не через pyzbar. Работало огонь... Хз про смазанные. Щяс ссылку скину, постараюсь найти. Что-то из opencv-contrib dnn","Что за штука, на чем работает?"
,"Я делал штрихкоды, маленький бинарник на плюсах. Не через pyzbar. Работало огонь... Хз про смазанные. Щяс ссылку скину, постараюсь найти. Что-то из opencv-contrib dnn","Что за штука, на чем работает?","И на смазанных должен работать
Да. Есть же аугментации"
"Я делал штрихкоды, маленький бинарник на плюсах. Не через pyzbar. Работало огонь... Хз про смазанные. Щяс ссылку скину, постараюсь найти. Что-то из opencv-contrib dnn","Что за штука, на чем работает?","И на смазанных должен работать
Да. Есть же аугментации","Нет, это реальные изображения, сделанные людьми :)
Смаз не моделировался"
"Что за штука, на чем работает?","И на смазанных должен работать
Да. Есть же аугментации","Нет, это реальные изображения, сделанные людьми :)
Смаз не моделировался","Ну.. Значит denoising ae какой
Хотя ему датасет нужен"
,,,Тут вы специально датасет собирали для обучения нейронки? Или есть готовый какой-то?
,,Тут вы специально датасет собирали для обучения нейронки? Или есть готовый какой-то?,"Датасет тут не собирался. Если неизвестно ничего об операторе смаза или нет исходного изображения, то не совсем понимаю, как вы хотите обучать. Для image debluring есть готовые датасеты"
,,,Какие-то я видел кстати. Но не мучился с ними
,,Какие-то я видел кстати. Но не мучился с ними,"кто-нибудь знает достойные открытые датасеты в мире рекомендательных систем, ранжирования, CTR prediction и подобного? чтобы мне, как академическому исследователю, был смысл изучать/улучшать производительность на них, и чтобы это хоть как-то транслировалось в жизнь
вот типичная подборка бенчмарков из статьи из мира CTR prediction и рекомендаций.
максимум 9 фичей и (почти) полное отсутствие некатегориальных фичей — это кажется не очень реалистичным сетапом)"
,,,Тоже интересует этот вопрос. Вот на кегле разве нету?)
,,Тоже интересует этот вопрос. Вот на кегле разве нету?),"вот такой ссылкой поделились пока что
https://github.com/RUCAIBox/RecSysDatasets"
,,,"Когда я искала, все хотели разрешение на работу в сша 🥲"
,,,"Всем привет!

Подскажите, пожалуйста, какие лучше всего модели ocr на сегодняшний день подходят для распознавания паспортов в проме? С чем можно поэкспериментировать?"
,,"Всем привет!

Подскажите, пожалуйста, какие лучше всего модели ocr на сегодняшний день подходят для распознавания паспортов в проме? С чем можно поэкспериментировать?","Плюс к вопросу, тоже интересно, чем другие документы распознают.

Сам пробовал tesseract и easyocr. Первый быстрее, может работать на CPU за адекватное время, но для качественных сканов только нормально подходит. Если всякая срань на входе, то второй лучше, но тут уже GPU, и даже на нем не шибко быстро (где-то 3-4 секунды на 1080 Ti)"
,,,"Всем привет! 
Могли бы вы скинуть продуктовые статьи по рек системам. То есть научные статьи, которые описывают принцип действия реальной системы, работающей в проде. Заранее спасибо!"
,,"Всем привет! 
Могли бы вы скинуть продуктовые статьи по рек системам. То есть научные статьи, которые описывают принцип действия реальной системы, работающей в проде. Заранее спасибо!","обычно по всей системе не пишут статей, потому что рексистема строится из кубиков, на каждый из которых нужен свой ресерч, но может быть какой-нибудь блогпостик, объединяющий все в одну картину. Есть список здесь https://github.com/eugeneyan/applied-ml#recommendation, тут 2/3 ссылок как раз такие посты"
,"Всем привет! 
Могли бы вы скинуть продуктовые статьи по рек системам. То есть научные статьи, которые описывают принцип действия реальной системы, работающей в проде. Заранее спасибо!","обычно по всей системе не пишут статей, потому что рексистема строится из кубиков, на каждый из которых нужен свой ресерч, но может быть какой-нибудь блогпостик, объединяющий все в одну картину. Есть список здесь https://github.com/eugeneyan/applied-ml#recommendation, тут 2/3 ссылок как раз такие посты",Большое спасибо!
,,,"коллеги, можете скинуть хороший cheatsheet по всем архитектурам нейросетей. Например в виде кода на keras или просто в виде картинок."
,,,"Если только паспорта, то можно запилить предобработку изображения и взять tesseract, в целом. Просто у меня пул довольно разных доков, для всего настраивать предобработку это жуткая трата времени"
,,"Если только паспорта, то можно запилить предобработку изображения и взять tesseract, в целом. Просто у меня пул довольно разных доков, для всего настраивать предобработку это жуткая трата времени",Что подразумевается под предобработкой?
,"Если только паспорта, то можно запилить предобработку изображения и взять tesseract, в целом. Просто у меня пул довольно разных доков, для всего настраивать предобработку это жуткая трата времени",Что подразумевается под предобработкой?,"контрастность, яркость"
"Если только паспорта, то можно запилить предобработку изображения и взять tesseract, в целом. Просто у меня пул довольно разных доков, для всего настраивать предобработку это жуткая трата времени",Что подразумевается под предобработкой?,"контрастность, яркость","И выравнивание, да"
,,,"А если паспорт фотографируют на телефон с большой вариацией фона внешнего, в таких случаях выравнивание по контрольным точкам работает?"
,,"А если паспорт фотографируют на телефон с большой вариацией фона внешнего, в таких случаях выравнивание по контрольным точкам работает?",Ну эти контрольные точки сначала найти надо) Со сложным фоном традиционные методы выделения и коррекции перспективы будут часто ломаться
,"А если паспорт фотографируют на телефон с большой вариацией фона внешнего, в таких случаях выравнивание по контрольным точкам работает?",Ну эти контрольные точки сначала найти надо) Со сложным фоном традиционные методы выделения и коррекции перспективы будут часто ломаться,"глупый вопрос у меня) перед тем как трансформеры использовать для окр, нужно модельки на детекцию текста использовать? Или они могут и так распознавать?"
"А если паспорт фотографируют на телефон с большой вариацией фона внешнего, в таких случаях выравнивание по контрольным точкам работает?",Ну эти контрольные точки сначала найти надо) Со сложным фоном традиционные методы выделения и коррекции перспективы будут часто ломаться,"глупый вопрос у меня) перед тем как трансформеры использовать для окр, нужно модельки на детекцию текста использовать? Или они могут и так распознавать?",От модели зависит. И упомянутые мной это и не трансформеры вовсе
Ну эти контрольные точки сначала найти надо) Со сложным фоном традиционные методы выделения и коррекции перспективы будут часто ломаться,"глупый вопрос у меня) перед тем как трансформеры использовать для окр, нужно модельки на детекцию текста использовать? Или они могут и так распознавать?",От модели зависит. И упомянутые мной это и не трансформеры вовсе,"Да, это знаю, просто вопрос именно про подачу данных для всяких trOCR. Вообще стоит ли их пытаться для такой задачи в пром запускать или тяжело оптимизировать и есть более подходящие решения"
"глупый вопрос у меня) перед тем как трансформеры использовать для окр, нужно модельки на детекцию текста использовать? Или они могут и так распознавать?",От модели зависит. И упомянутые мной это и не трансформеры вовсе,"Да, это знаю, просто вопрос именно про подачу данных для всяких trOCR. Вообще стоит ли их пытаться для такой задачи в пром запускать или тяжело оптимизировать и есть более подходящие решения","Я слишком не углублядся, но на первый взгляд не увидел толком пркдобученных для русского языка трансформеров"
,,,"Можно взять отдельно детектор текста от другой модели ещё. А в тессеракт только найденные блоки изображения подавать. Но тут тоже многие модели ресурсоемкие, а мелкие модели многое могут пропустить или найти лишнего, надо проверять на вашем потоке"
,,"Можно взять отдельно детектор текста от другой модели ещё. А в тессеракт только найденные блоки изображения подавать. Но тут тоже многие модели ресурсоемкие, а мелкие модели многое могут пропустить или найти лишнего, надо проверять на вашем потоке","Ага, вот ответ.
Как я понимаю, могут. Но лучше детектировать"
,"Можно взять отдельно детектор текста от другой модели ещё. А в тессеракт только найденные блоки изображения подавать. Но тут тоже многие модели ресурсоемкие, а мелкие модели многое могут пропустить или найти лишнего, надо проверять на вашем потоке","Ага, вот ответ.
Как я понимаю, могут. Но лучше детектировать",Ну у тессеракта именно детекцию это вроде набор традиционных методов
,,,"Из быстрых есть классика в виде east
Craft это если хочется прям качества ценой скорости. В том же easyocr он под капотом
Нейронки там чисто распознают
Easyocr это комбинация из craft для детекции и ещё одной модели (yolor вроде?) для распознавания"
,,,У нас хорошо Differentiable Binarization (DB) для детекции себя показывает
,,У нас хорошо Differentiable Binarization (DB) для детекции себя показывает,Но его квантизовать еще нужно для прома
,,,"Наверняка есть модели, у которые детекция и распознавания вместе происходят, но я с ними не работал. Какие-то трансформеры так могут небось"
,,,Dbnet который?
,,Dbnet который?,Да
,,,"В easyocr его можно включать вместо craft)
Но у меня он пропускал маленькие куски текста сильно"
,,,"Номер месяца в таблице, например"
,,"Номер месяца в таблице, например",А какая моделька с этим справилась?
,"Номер месяца в таблице, например",А какая моделька с этим справилась?,"Craft лучше работает, хоть и тоже иногда пропускает"
"Номер месяца в таблице, например",А какая моделька с этим справилась?,"Craft лучше работает, хоть и тоже иногда пропускает","ещё вопрос, детектор обучаете построчный или по словам?"
А какая моделька с этим справилась?,"Craft лучше работает, хоть и тоже иногда пропускает","ещё вопрос, детектор обучаете построчный или по словам?","Предрбученный использую, он по словам даёт результат, но библиотека может за меня слова объединять в более крупные блоки, там много параметров для этого"
,,,Спасибо
,,Спасибо,"Ну там по факту целый heatmap на выходе у самого детектора
Но в итоге результат больше на слова ориентирован"
,,,полностью оправдан!
,,полностью оправдан!,"Но так-то да, принцип везде, с оговорками, один и тот же - возвращение к средним значением. Это работает как на календарных спредах (частные случаи вроде Mar-Apr в газе не берём), так и на активах, не являющихся срочными. Принципы везде одни и те же: большие объёмы, построение синтетических конструкций, исследование сезонностей, возвращение к среднему. В некоторых случаях (спреды на фьючерсы в сырье, в основном) и трендовые стратегии. И да, принцип возвращения к среднему, сезонность и прочее работает и на межпродуктовых спредах. У календарных спредов на фьючерсы есть свои особенности, вроде временной деградации и, соответственно, повышение непредсказуемости спредов ближе к экспирации, но, в целом, одни и те же принципы везде.

Пример повышения непредсказуемости - недавняя история с отрицательными ценами на WTI. Если бы кто-то торговал дальними спредами на эту нефть, то особенно сильных движений может и не заметил бы, что не скажешь о тех, кто торговал фронтальный спред."
,,,Проблемы с нелепой челкой
,,,"Привет ! подскажите пожалуйста пытаюсь сжать модель видв pt в onnx

model = YOLO("".pt"")  
success = model.export(imgsz = 320, format=""onnx"")
применяю ошибка одна и та же
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320"
,,"Привет ! подскажите пожалуйста пытаюсь сжать модель видв pt в onnx

model = YOLO("".pt"")  
success = model.export(imgsz = 320, format=""onnx"")
применяю ошибка одна и та же
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320",python3 export.py --weights models/yolov5s.pt --include onnx --dynamic
,"Привет ! подскажите пожалуйста пытаюсь сжать модель видв pt в onnx

model = YOLO("".pt"")  
success = model.export(imgsz = 320, format=""onnx"")
применяю ошибка одна и та же
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320",python3 export.py --weights models/yolov5s.pt --include onnx --dynamic,"У нее не 5 версия, судя по коду"
"Привет ! подскажите пожалуйста пытаюсь сжать модель видв pt в onnx

model = YOLO("".pt"")  
success = model.export(imgsz = 320, format=""onnx"")
применяю ошибка одна и та же
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320",python3 export.py --weights models/yolov5s.pt --include onnx --dynamic,"У нее не 5 версия, судя по коду",8
,,,"imgsz =(320, 320) пробовали ?)"
,,"imgsz =(320, 320) пробовали ?)","да проверила, то же самое("
,,,Какая версия пакета?
,,Какая версия пакета?,"yolo 8,  при обучении тоже использовала параметр imgsz=320"
,,,"Похоже, стоит обновить пакет ultralytics: в их репо сейчас явным образом прописана корректировка, если размер стороны отличается от дефолтного конфига при экспорте. Подозреваю, что иначе конфиг не обновляется.))"
,,"Похоже, стоит обновить пакет ultralytics: в их репо сейчас явным образом прописана корректировка, если размер стороны отличается от дефолтного конфига при экспорте. Подозреваю, что иначе конфиг не обновляется.))",спасибо попробую
,,,"Всем привет. Есть проблема - defect detection. Данные - pointcloud (rgb + depth) объекта, есть референсный объект/данные с недефектными объектами.
Есть какие-либо рекомендации для решения такой проблемы? Не уверен насколько наивный способ сравнения pointcloud’ов будет хорош (и robust), буду благодарен за любой совет"
,,"Всем привет. Есть проблема - defect detection. Данные - pointcloud (rgb + depth) объекта, есть референсный объект/данные с недефектными объектами.
Есть какие-либо рекомендации для решения такой проблемы? Не уверен насколько наивный способ сравнения pointcloud’ов будет хорош (и robust), буду благодарен за любой совет","Это не совсем поинт клауд. В поинт клаудах не ргб, а координаты точек x, y, z ну и может быть ещё один канал - интенсивность. Поэтому вряд-ли и модели для поинтклаудов пойдут (надо конечно пробовать). Скорее нужно посмотреть модельки, для детекции дефектов на обычных картинках и просто добавить один канал для глубины. Также не понятно на сколько лучше будет с глубиной. Наверное, если какие-нибудь трещины, то глубина трещины должна отличаться от глубины соседних пикселей (и то зависит от того сможет ли стерео камера или камера глубины увидеть такую разницу) , для царапин скорее всего глубина не сильно поможет в распознавании дефектов. А вот для вмятин должно в теории сработать."
,"Всем привет. Есть проблема - defect detection. Данные - pointcloud (rgb + depth) объекта, есть референсный объект/данные с недефектными объектами.
Есть какие-либо рекомендации для решения такой проблемы? Не уверен насколько наивный способ сравнения pointcloud’ов будет хорош (и robust), буду благодарен за любой совет","Это не совсем поинт клауд. В поинт клаудах не ргб, а координаты точек x, y, z ну и может быть ещё один канал - интенсивность. Поэтому вряд-ли и модели для поинтклаудов пойдут (надо конечно пробовать). Скорее нужно посмотреть модельки, для детекции дефектов на обычных картинках и просто добавить один канал для глубины. Также не понятно на сколько лучше будет с глубиной. Наверное, если какие-нибудь трещины, то глубина трещины должна отличаться от глубины соседних пикселей (и то зависит от того сможет ли стерео камера или камера глубины увидеть такую разницу) , для царапин скорее всего глубина не сильно поможет в распознавании дефектов. А вот для вмятин должно в теории сработать.","Формально вы правы, а по сути из rgbd достаточно просто получить point cloud"
"Всем привет. Есть проблема - defect detection. Данные - pointcloud (rgb + depth) объекта, есть референсный объект/данные с недефектными объектами.
Есть какие-либо рекомендации для решения такой проблемы? Не уверен насколько наивный способ сравнения pointcloud’ов будет хорош (и robust), буду благодарен за любой совет","Это не совсем поинт клауд. В поинт клаудах не ргб, а координаты точек x, y, z ну и может быть ещё один канал - интенсивность. Поэтому вряд-ли и модели для поинтклаудов пойдут (надо конечно пробовать). Скорее нужно посмотреть модельки, для детекции дефектов на обычных картинках и просто добавить один канал для глубины. Также не понятно на сколько лучше будет с глубиной. Наверное, если какие-нибудь трещины, то глубина трещины должна отличаться от глубины соседних пикселей (и то зависит от того сможет ли стерео камера или камера глубины увидеть такую разницу) , для царапин скорее всего глубина не сильно поможет в распознавании дефектов. А вот для вмятин должно в теории сработать.","Формально вы правы, а по сути из rgbd достаточно просто получить point cloud","Вообще, да нужно знать интристик характеристики камеры. Если не секрет, чем получали такие изображения? Какой-нибудь кинект?"
"Это не совсем поинт клауд. В поинт клаудах не ргб, а координаты точек x, y, z ну и может быть ещё один канал - интенсивность. Поэтому вряд-ли и модели для поинтклаудов пойдут (надо конечно пробовать). Скорее нужно посмотреть модельки, для детекции дефектов на обычных картинках и просто добавить один канал для глубины. Также не понятно на сколько лучше будет с глубиной. Наверное, если какие-нибудь трещины, то глубина трещины должна отличаться от глубины соседних пикселей (и то зависит от того сможет ли стерео камера или камера глубины увидеть такую разницу) , для царапин скорее всего глубина не сильно поможет в распознавании дефектов. А вот для вмятин должно в теории сработать.","Формально вы правы, а по сути из rgbd достаточно просто получить point cloud","Вообще, да нужно знать интристик характеристики камеры. Если не секрет, чем получали такие изображения? Какой-нибудь кинект?",Внутрение параметры камеры знаю (сами камеры от фирмы luxonis)
,,,"Всем привет!
На месяц уезжаю от интернета в леса и хочу взять что-то почитать)
Посоветуйте пж,  что можно почитать по NLP (знаю, что не всем такой формат заходит, но в лесу выбора нет🌳)"
,,"Всем привет!
На месяц уезжаю от интернета в леса и хочу взять что-то почитать)
Посоветуйте пж,  что можно почитать по NLP (знаю, что не всем такой формат заходит, но в лесу выбора нет🌳)","А по своей воле уезжаешь? А какой смыл уезжать, если книжку по ИИ с собой брать?😁  лучше бери Бертрана Рассела."
,,,Я те написал уже в одс)
,,Я те написал уже в одс),"сори, не увидел) А можно подробнее, не понял что за книга"
,Я те написал уже в одс),"сори, не увидел) А можно подробнее, не понял что за книга",Гугли Войта NLP
,,,спасибо!
,,спасибо!,Ну ты извращенец
,спасибо!,Ну ты извращенец,ETNA ещё от Тинька
спасибо!,Ну ты извращенец,ETNA ещё от Тинька,😂
,,,Посмотрите PointNet++
,,,"это не я вопрос задавал) в своих проектах я пытаюсь интринсики восстанавливать, с переменным успехом, +/- от зоопарка камер"
,,"это не я вопрос задавал) в своих проектах я пытаюсь интринсики восстанавливать, с переменным успехом, +/- от зоопарка камер","А, не посмотрел автора 😃"
,,,Привет! Не пробовали. Это же именно аудио?
,,Привет! Не пробовали. Это же именно аудио?,"привет, да, именно аудио, но они давно уже не обновлялись"
,,,"Никто не знает, где MIDI можно достать?"
,,"Никто не знает, где MIDI можно достать?","Поскрапить сайты типа midiworld, freemidi, bitmidi и т.д.

Есть еще много открытых монофонических баз вроде adl piano midi"
,"Никто не знает, где MIDI можно достать?","Поскрапить сайты типа midiworld, freemidi, bitmidi и т.д.

Есть еще много открытых монофонических баз вроде adl piano midi","Но я пойду этой дорожкой, спасибо!"
,,,Мне кажется Lakh наверное все поскрапил уже
,,Мне кажется Lakh наверное все поскрапил уже,"В Yolo8 по-моему есть сегментация, а так же конверт боксов в сегментацию. но я не пробовал"
,Мне кажется Lakh наверное все поскрапил уже,"В Yolo8 по-моему есть сегментация, а так же конверт боксов в сегментацию. но я не пробовал","Уже же спрашивали
И уже сегментацию советовали)"
Мне кажется Lakh наверное все поскрапил уже,"В Yolo8 по-моему есть сегментация, а так же конверт боксов в сегментацию. но я не пробовал","Уже же спрашивали
И уже сегментацию советовали)","К вас де обджект декшн на фото. 
Таск detect 
Йоле можно передать таск segment"
"В Yolo8 по-моему есть сегментация, а так же конверт боксов в сегментацию. но я не пробовал","Уже же спрашивали
И уже сегментацию советовали)","К вас де обджект декшн на фото. 
Таск detect 
Йоле можно передать таск segment","Я бы применил классический CV после YOLO: детекция границ, детекция прямоугольника (хинт, соотношение сторон не произвольное) и афинное преобразование"
,,,мне очень нравится)
,,мне очень нравится),"На самом деле, выглядит как quiche, но на минималках)"
,,,я все равно не понимаю как мне решить ошибку
,,я все равно не понимаю как мне решить ошибку,бывает
,я все равно не понимаю как мне решить ошибку,бывает,"уверена и у вас ""бывает"""
я все равно не понимаю как мне решить ошибку,бывает,"уверена и у вас ""бывает""","У всех бывает, потеть == норма"
,,,ля кринж
,,ля кринж,"Я Джуна намедни заставил после опостылевшего мне ""я не понимаю"" рассказать мне смысл теоремы Байеса, час дал на подготовку.

А потом задачу, рассчитать P(успех проекта | не понял 5 пунктов из 12)

Ну там получилось 4 раза на миллион, при локально-местечковых приорах"
,,,"Касаемо YOLOv8, интересен опыт перехода с v5. У меня на обоих задачах (вообще далеких друг от друга) v5 по метрикам всегда выше v8, есть сейм?"
,,"Касаемо YOLOv8, интересен опыт перехода с v5. У меня на обоих задачах (вообще далеких друг от друга) v5 по метрикам всегда выше v8, есть сейм?",Я тоже сомневаюсь с переходом
,,,"ну просто я не очень понимаю как тут внутренний код поможет про task я поняла что его там нет 
это же из warning ответ"
,,,"да он отрабатывает но потом не применяется для инференса из-за ошибки размерности как будто 
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320
хотя первоначальная модель pt (обученная с imgsz =320) работает"
,,"да он отрабатывает но потом не применяется для инференса из-за ошибки размерности как будто 
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320
хотя первоначальная модель pt (обученная с imgsz =320) работает","Т.е. это ошибка при инференсе? Может, вы 640-е картинки пытаетесь запихнуть?"
,"да он отрабатывает но потом не применяется для инференса из-за ошибки размерности как будто 
 index: 2 Got: 640 Expected: 320
 index: 3 Got: 640 Expected: 320
хотя первоначальная модель pt (обученная с imgsz =320) работает","Т.е. это ошибка при инференсе? Может, вы 640-е картинки пытаетесь запихнуть?",Нет данные те же как и для pt
,,,тоже ultralytics 8.0.114 да
,,тоже ultralytics 8.0.114 да,"Вероятно надо смотреть в сторону dynamic аттрибутов, а параметр imgsz видимо нужен не для обозначения динамических ширины и высоты на вход. Вобщем как выше сказали уже, нужно копаться в исходниках"
,тоже ultralytics 8.0.114 да,"Вероятно надо смотреть в сторону dynamic аттрибутов, а параметр imgsz видимо нужен не для обозначения динамических ширины и высоты на вход. Вобщем как выше сказали уже, нужно копаться в исходниках",Инференс как делаете?
,,,"Так исходники же есть. Казалось бы, почему не разобраться прямо по месту. Например, посмотреть на ""dynamic"": есть он или нет. Если есть, то работать будет исключительно на CPU. Ну и т.д."
,,"Так исходники же есть. Казалось бы, почему не разобраться прямо по месту. Например, посмотреть на ""dynamic"": есть он или нет. Если есть, то работать будет исключительно на CPU. Ну и т.д.","поставила dynamic= True (по умолчанию он False)  и проблема с 640 кажется ушла но вот теперь это:
 log_string += f""{n} {self.names[int(c)]}{'s' * (n > 1)}, ""
KeyError: 16

на гитхабе у человека была подобная ошибка для
python detect.py --weights ~/Downloads/yolov5s-seg.pt 
и решением было segment.py"
,"Так исходники же есть. Казалось бы, почему не разобраться прямо по месту. Например, посмотреть на ""dynamic"": есть он или нет. Если есть, то работать будет исключительно на CPU. Ну и т.д.","поставила dynamic= True (по умолчанию он False)  и проблема с 640 кажется ушла но вот теперь это:
 log_string += f""{n} {self.names[int(c)]}{'s' * (n > 1)}, ""
KeyError: 16

на гитхабе у человека была подобная ошибка для
python detect.py --weights ~/Downloads/yolov5s-seg.pt 
и решением было segment.py",У них проблемы в экспортном коде с лохматой версии тянутся. В итоге все работает?
"Так исходники же есть. Казалось бы, почему не разобраться прямо по месту. Например, посмотреть на ""dynamic"": есть он или нет. Если есть, то работать будет исключительно на CPU. Ну и т.д.","поставила dynamic= True (по умолчанию он False)  и проблема с 640 кажется ушла но вот теперь это:
 log_string += f""{n} {self.names[int(c)]}{'s' * (n > 1)}, ""
KeyError: 16

на гитхабе у человека была подобная ошибка для
python detect.py --weights ~/Downloads/yolov5s-seg.pt 
и решением было segment.py",У них проблемы в экспортном коде с лохматой версии тянутся. В итоге все работает?,нет( зависла с этой ошибкой последней
"поставила dynamic= True (по умолчанию он False)  и проблема с 640 кажется ушла но вот теперь это:
 log_string += f""{n} {self.names[int(c)]}{'s' * (n > 1)}, ""
KeyError: 16

на гитхабе у человека была подобная ошибка для
python detect.py --weights ~/Downloads/yolov5s-seg.pt 
и решением было segment.py",У них проблемы в экспортном коде с лохматой версии тянутся. В итоге все работает?,нет( зависла с этой ошибкой последней,"А модель от самих ultralytics? Ошибка на вид в том, что каких-то классов не хватает из конфига, в отличие от того числа что выдаёт модель. Это предположение"
У них проблемы в экспортном коде с лохматой версии тянутся. В итоге все работает?,нет( зависла с этой ошибкой последней,"А модель от самих ultralytics? Ошибка на вид в том, что каких-то классов не хватает из конфига, в отличие от того числа что выдаёт модель. Это предположение","у меня видео, модель  ultralutics.YOLO () для каждого фрейма
я применяю вот такой код (почти)
https://docs.ultralytics.com/modes/predict/#streaming-source-for-loop
достаю labels из result"
,,,Нужно для cpu
,,,"Исходные данные: вкатываюсь в DL(""ознакомился""  с классификацией, сегментацией,  еще не трогал детекцию, ганы и тд).  Пощупал модельки в рамках курса DLS.  Понимаю, что  гнать вперед  быстро не хочу, почва слабая. Решение сделать работы по  классификации  и сегментации, не в рамках курсов.  Цель - убить двух зайцев:  1) углубиться, закрепиться 2) не стыдно было оставить  линк на работу в CV на позицию джуна).  Говоря прямо - идей нет. Лезу в гитхаб - либо это далеко от моих возможностей, либо  это типичный зашквар ( датасет с кеггла и решение в лоб).  Единственное что пришло в голову:  задача мультиклассовой классификации( дорожные знаки), построить сравнительный анализ  N моделей Lenet - Resnet, бахнуть что-то вроде бы экспериментальной части  влияния видов аугментации на результат, но опять же на этот случай есть уже статья ""Traffic sign classification with dataset augmentation and convolutional neural network"". Но и это тот же самый зашквар с моей стороны. Запросы большие,  ресурсов (знаний, железа, опыта) нет. Рад критике и совету, сенк"
,,"Исходные данные: вкатываюсь в DL(""ознакомился""  с классификацией, сегментацией,  еще не трогал детекцию, ганы и тд).  Пощупал модельки в рамках курса DLS.  Понимаю, что  гнать вперед  быстро не хочу, почва слабая. Решение сделать работы по  классификации  и сегментации, не в рамках курсов.  Цель - убить двух зайцев:  1) углубиться, закрепиться 2) не стыдно было оставить  линк на работу в CV на позицию джуна).  Говоря прямо - идей нет. Лезу в гитхаб - либо это далеко от моих возможностей, либо  это типичный зашквар ( датасет с кеггла и решение в лоб).  Единственное что пришло в голову:  задача мультиклассовой классификации( дорожные знаки), построить сравнительный анализ  N моделей Lenet - Resnet, бахнуть что-то вроде бы экспериментальной части  влияния видов аугментации на результат, но опять же на этот случай есть уже статья ""Traffic sign classification with dataset augmentation and convolutional neural network"". Но и это тот же самый зашквар с моей стороны. Запросы большие,  ресурсов (знаний, железа, опыта) нет. Рад критике и совету, сенк","На самом деле, лучший мотиватор – придумать задачу, которую потом реально применить в своей жизни. Попробуйте подумать о своих сферах интересов – игры, спорт, домашний быт, что-нибудь вдруг может и всплыть"
,,,"А что мешает по готовому туториалу пойти? 
Дата с каггла или готовые модели вполне себе норм. Если мало - можно самому собрать немного данных и  дообучить модель. 
А гонять трансфер лернинг на лёгкие нейронки можно даже на колабе или каггле"
,,"А что мешает по готовому туториалу пойти? 
Дата с каггла или готовые модели вполне себе норм. Если мало - можно самому собрать немного данных и  дообучить модель. 
А гонять трансфер лернинг на лёгкие нейронки можно даже на колабе или каггле","Сделай то, что написал. Как раз проверишь от себя данную статью. Редко бывает  сразу хорошо и круто. Оформи главное хорошо, с выводом каким-то от себя, с презентацией. Если  еще развернешь модель,  будет на порядок лучше других"
,"А что мешает по готовому туториалу пойти? 
Дата с каггла или готовые модели вполне себе норм. Если мало - можно самому собрать немного данных и  дообучить модель. 
А гонять трансфер лернинг на лёгкие нейронки можно даже на колабе или каггле","Сделай то, что написал. Как раз проверишь от себя данную статью. Редко бывает  сразу хорошо и круто. Оформи главное хорошо, с выводом каким-то от себя, с презентацией. Если  еще развернешь модель,  будет на порядок лучше других","Если хочется чтобы и полезное и в резюме смотрелось, сделайте какое-нибудь end2end решение. 

Например счетчик сколько каждый человек сходил покурить :) torchreid. Или детектор незнакомых для домофона.

Еще, у самого руки не доходят. Соседи по даче воду воруют. Человек в зоне - пошла видеофиксация... А натпроизводствах такое дело называется промбез)"
,,,Доброго времени суток. Подскажите пожалуйста открытые датасеты с артами для text2image с арт-изображениями.
,,Доброго времени суток. Подскажите пожалуйста открытые датасеты с артами для text2image с арт-изображениями.,"Тут есть соседний чат text 2image, скорее там подскажут... 

Я лично могу предложить профильтровать laion классификатором текстов) ну или хотя бы наличием art в нем"
,,,"Вот смотрю, что в профильных ветках говорят, и думаю «какие же они все непостижимо умные», да так, что аж ротик прикрыть хочется и не писать"
,,,В пятой версии была возможность экспорта не всех классов например. Надо разбираться с кодом внутри. Ошибка возникает только при запуске экспортировкнной модели? Если в колабе запускаете петоначим загрузчиком ошибка так же сохряняется?
,,В пятой версии была возможность экспорта не всех классов например. Надо разбираться с кодом внутри. Ошибка возникает только при запуске экспортировкнной модели? Если в колабе запускаете петоначим загрузчиком ошибка так же сохряняется?,"я запускаю локально на компе через cmd)
да ошибка только для onnx
для pt все было норм"
,,Доброго времени суток. Подскажите пожалуйста открытые датасеты с артами для text2image с арт-изображениями.,полуиронично упомяну danbooru.donmai.us
,,,вообще мне не принципиально использование onnx просто нужно ускорить модель как то
,,вообще мне не принципиально использование onnx просто нужно ускорить модель как то,Попробуйте использовать TensorRT
,вообще мне не принципиально использование onnx просто нужно ускорить модель как то,Попробуйте использовать TensorRT,есть условие что без gpu
,,,Onnx неплохо вариант. На гитхабе есть yolo-nas onnx готовый репо. Правда для плюсов вроде
,,Onnx неплохо вариант. На гитхабе есть yolo-nas onnx готовый репо. Правда для плюсов вроде,"надо ускорить раза в 4-5 
а yolo-nas кажется не так эффективен (я читала про ускорение на 10-20% и лучшую точность)"
,Onnx неплохо вариант. На гитхабе есть yolo-nas onnx готовый репо. Правда для плюсов вроде,"надо ускорить раза в 4-5 
а yolo-nas кажется не так эффективен (я читала про ускорение на 10-20% и лучшую точность)","попробуйте в openvino экспортировать, и разрешение подрезать"
Onnx неплохо вариант. На гитхабе есть yolo-nas onnx готовый репо. Правда для плюсов вроде,"надо ускорить раза в 4-5 
а yolo-nas кажется не так эффективен (я читала про ускорение на 10-20% и лучшую точность)","попробуйте в openvino экспортировать, и разрешение подрезать",спасибо😊
"надо ускорить раза в 4-5 
а yolo-nas кажется не так эффективен (я читала про ускорение на 10-20% и лучшую точность)","попробуйте в openvino экспортировать, и разрешение подрезать",спасибо😊,"По багам, попробуйте запустить модель в колабе (туториал есть на сайте торча), если проблема не повторяется, причина в локальных библиотеках (у меня была такая проблема с экспортированной v5). Если проблема повторяется, причина в экспорте, надо копаться в коде, начиная с export .py (или как там он называется в v8) и по нисходящей к классам самой модели.
У v5 была проблема с тем, что jit просто не экспортировал некоторые сущности, использовавшиеся разработчиками. Пришлось их заменять."
"попробуйте в openvino экспортировать, и разрешение подрезать",спасибо😊,"По багам, попробуйте запустить модель в колабе (туториал есть на сайте торча), если проблема не повторяется, причина в локальных библиотеках (у меня была такая проблема с экспортированной v5). Если проблема повторяется, причина в экспорте, надо копаться в коде, начиная с export .py (или как там он называется в v8) и по нисходящей к классам самой модели.
У v5 была проблема с тем, что jit просто не экспортировал некоторые сущности, использовавшиеся разработчиками. Пришлось их заменять.",Спасибо попробую
,,,Мысль в том что стоит поискать уже сконвертированные
,,,"Всем привет!
Какие есть способы сжать эмбеддинги для текста для их последующего хранения?
Сейчас есть схема эмбеддинги - хранятся в монго дб как получены из выхода моделей - далее используется кастомная оболочка над faiss с уже квантизацией и т.д.
Вопрос состоит в оптимизации хранения до faiss. 
Из идей:
1) обучить автоэнкодер и, если он не сильно портит качество, сжимать/разжимать с его помощью
2) Сжимать сам формат, так как модель возвращает float32 - перевести в float16/bfloat16
3) Что-то ещё есть?)"
,,"Всем привет!
Какие есть способы сжать эмбеддинги для текста для их последующего хранения?
Сейчас есть схема эмбеддинги - хранятся в монго дб как получены из выхода моделей - далее используется кастомная оболочка над faiss с уже квантизацией и т.д.
Вопрос состоит в оптимизации хранения до faiss. 
Из идей:
1) обучить автоэнкодер и, если он не сильно портит качество, сжимать/разжимать с его помощью
2) Сжимать сам формат, так как модель возвращает float32 - перевести в float16/bfloat16
3) Что-то ещё есть?)","А уж извините, но для сжатия текстов попробуйте архиваторы. Я без шуток

Интересный факт: война и мир такая длинная, потому что Толстому платили за длину, он выпускал ее частями.

Автоэнкодеры, парафразеры, сжимают хорошо, еслиь сам размер эмбеддинга весьма приличный. Что его приближает к тому же словарному zip'у.

Пардон за банальную идею"
,,,Иметь сразу модель с пожимающей головой
,,Иметь сразу модель с пожимающей головой,В 4-5...?... Без GPU?.. onnx так-то не панацея... Чот хз
,Иметь сразу модель с пожимающей головой,В 4-5...?... Без GPU?.. onnx так-то не панацея... Чот хз,Самый лучший способ получить знания в Интернете - задать вопрос и неправильно на него ответить...
,,,"ребят, мб кто-то знает хорошие модели для сегментации частей тела? ниче подходящего не могу найти"
,,"ребят, мб кто-то знает хорошие модели для сегментации частей тела? ниче подходящего не могу найти",Open pose не подходит ?
,"ребят, мб кто-то знает хорошие модели для сегментации частей тела? ниче подходящего не могу найти",Open pose не подходит ?,Не.
,,,"Segment Anything? (Она не конкретно для частей тела, но можно обучить на своем датасете)"
,,"Segment Anything? (Она не конкретно для частей тела, но можно обучить на своем датасете)",если проблема в нагрузке на cpu то можно хранить пожатыми и распаковывать на gpu см. nvcomp kvikio
,,,"Кто-то сталкивался с задачей генерации слайдов презентации по текстовому описанию слайда?
Мб где-то есть датасеты на эту тему или готовые модели/сервисы?"
,,"Кто-то сталкивался с задачей генерации слайдов презентации по текстовому описанию слайда?
Мб где-то есть датасеты на эту тему или готовые модели/сервисы?","1)Это XLM который можно распарсить
2) парсишь пачки презентаций, парсишь из них текст чистый учишь text2text/gpt чтобы генеровать размер шрифта/положение на слайду
have fun!"
,"Кто-то сталкивался с задачей генерации слайдов презентации по текстовому описанию слайда?
Мб где-то есть датасеты на эту тему или готовые модели/сервисы?","1)Это XLM который можно распарсить
2) парсишь пачки презентаций, парсишь из них текст чистый учишь text2text/gpt чтобы генеровать размер шрифта/положение на слайду
have fun!",А диаграммами как быть тогда? Основная суть норм през в них
"Кто-то сталкивался с задачей генерации слайдов презентации по текстовому описанию слайда?
Мб где-то есть датасеты на эту тему или готовые модели/сервисы?","1)Это XLM который можно распарсить
2) парсишь пачки презентаций, парсишь из них текст чистый учишь text2text/gpt чтобы генеровать размер шрифта/положение на слайду
have fun!",А диаграммами как быть тогда? Основная суть норм през в них,точно так же строиться из кода
"1)Это XLM который можно распарсить
2) парсишь пачки презентаций, парсишь из них текст чистый учишь text2text/gpt чтобы генеровать размер шрифта/положение на слайду
have fun!",А диаграммами как быть тогда? Основная суть норм през в них,точно так же строиться из кода,В большинстве случаях в готовых презах - это картинки
А диаграммами как быть тогда? Основная суть норм през в них,точно так же строиться из кода,В большинстве случаях в готовых презах - это картинки,https://huggingface.co/google/matcha-chartqa и они тоже парсяться
,,,"Просто есть ощущение, что стандартный подход, который применяется для подготовки датасетов для диффузионок не будет работать из-за того, что CLIP не справится с генерацией корректного подробного описания слайда"
,,"Просто есть ощущение, что стандартный подход, который применяется для подготовки датасетов для диффузионок не будет работать из-за того, что CLIP не справится с генерацией корректного подробного описания слайда",генерить сразу слайды в latex
,"Просто есть ощущение, что стандартный подход, который применяется для подготовки датасетов для диффузионок не будет работать из-за того, что CLIP не справится с генерацией корректного подробного описания слайда",генерить сразу слайды в latex,"Понял, это уже выглядит как план"
"Просто есть ощущение, что стандартный подход, который применяется для подготовки датасетов для диффузионок не будет работать из-за того, что CLIP не справится с генерацией корректного подробного описания слайда",генерить сразу слайды в latex,"Понял, это уже выглядит как план","Привет, интересно, смог продвинуться куда нибудь в сторону хороших результатов? Расскажи как работает на твоем домене система?"
генерить сразу слайды в latex,"Понял, это уже выглядит как план","Привет, интересно, смог продвинуться куда нибудь в сторону хороших результатов? Расскажи как работает на твоем домене система?","Всем привет! Не подскажите датасеты пригодные для обнаружения спама, фишинга да и вообще фрода в текстовом контенте?"
,,,"Всем привет, кто-нибудь знает, где можно ознакомиться со типичными пайплайнами препроцессинга кадров для наиболее устойчивой детекции объектов на видео с условного видеорегистратора?
Имеется ввиду применение, размытия по Гауссу, улучшения контрастности или чего-то подобного для повышения стабильности готовой модели на инференсе."
,,"Всем привет, кто-нибудь знает, где можно ознакомиться со типичными пайплайнами препроцессинга кадров для наиболее устойчивой детекции объектов на видео с условного видеорегистратора?
Имеется ввиду применение, размытия по Гауссу, улучшения контрастности или чего-то подобного для повышения стабильности готовой модели на инференсе.","Я делал выравнивание яркости по полю изображения и нормализацию цвета. Но вообще, это зависит от модели, можно повысить устойчивость добавив соответствующие аугментации при тренировке модели"
,,,"Привет! Оцените резюме, пожалуйста. У меня относительно странный карьерный путь, включающий анализ пространственных данных и антифрод, а последний год я вообще занимался не-аналитической благотворительной деятельностью."
,,"Привет! Оцените резюме, пожалуйста. У меня относительно странный карьерный путь, включающий анализ пространственных данных и антифрод, а последний год я вообще занимался не-аналитической благотворительной деятельностью.","Я бы цель более явно указал: работать в NGO, заниматься антифродом или анализом геоданных?"
,"Привет! Оцените резюме, пожалуйста. У меня относительно странный карьерный путь, включающий анализ пространственных данных и антифрод, а последний год я вообще занимался не-аналитической благотворительной деятельностью.","Я бы цель более явно указал: работать в NGO, заниматься антифродом или анализом геоданных?","я подрихтовываю его под каждую вакансию, удаляя лишние части

в идеале я бы вернулся к геоданным, но таких вакансий не то чтобы очень много"
"Привет! Оцените резюме, пожалуйста. У меня относительно странный карьерный путь, включающий анализ пространственных данных и антифрод, а последний год я вообще занимался не-аналитической благотворительной деятельностью.","Я бы цель более явно указал: работать в NGO, заниматься антифродом или анализом геоданных?","я подрихтовываю его под каждую вакансию, удаляя лишние части

в идеале я бы вернулся к геоданным, но таких вакансий не то чтобы очень много","Сам в смежной области работаю, ИМХО, это умирающий рынок. Можно попробовать постучаться в kontur который io. Они периодически ищут людей, которые умеют работать с геоданными в PostGIS. Там не ML, а чистая дата аналитика. Занимаются disaster management, типа прошло цунами и нужно посчитать сколько квадратных метров жилья разрушено и куда направлять спасателей в первую очередь."
"Я бы цель более явно указал: работать в NGO, заниматься антифродом или анализом геоданных?","я подрихтовываю его под каждую вакансию, удаляя лишние части

в идеале я бы вернулся к геоданным, но таких вакансий не то чтобы очень много","Сам в смежной области работаю, ИМХО, это умирающий рынок. Можно попробовать постучаться в kontur который io. Они периодически ищут людей, которые умеют работать с геоданными в PostGIS. Там не ML, а чистая дата аналитика. Занимаются disaster management, типа прошло цунами и нужно посчитать сколько квадратных метров жилья разрушено и куда направлять спасателей в первую очередь.","там давно ничего подходящего не было, по-моему, я даже Дорофею писал:) почему умирающая?"
"я подрихтовываю его под каждую вакансию, удаляя лишние части

в идеале я бы вернулся к геоданным, но таких вакансий не то чтобы очень много","Сам в смежной области работаю, ИМХО, это умирающий рынок. Можно попробовать постучаться в kontur который io. Они периодически ищут людей, которые умеют работать с геоданными в PostGIS. Там не ML, а чистая дата аналитика. Занимаются disaster management, типа прошло цунами и нужно посчитать сколько квадратных метров жилья разрушено и куда направлять спасателей в первую очередь.","там давно ничего подходящего не было, по-моему, я даже Дорофею писал:) почему умирающая?","Хайп прошел. Новые проекты почти не стартуют, а раз нет новых проектов, то нет и вакансий"
"Сам в смежной области работаю, ИМХО, это умирающий рынок. Можно попробовать постучаться в kontur который io. Они периодически ищут людей, которые умеют работать с геоданными в PostGIS. Там не ML, а чистая дата аналитика. Занимаются disaster management, типа прошло цунами и нужно посчитать сколько квадратных метров жилья разрушено и куда направлять спасателей в первую очередь.","там давно ничего подходящего не было, по-моему, я даже Дорофею писал:) почему умирающая?","Хайп прошел. Новые проекты почти не стартуют, а раз нет новых проектов, то нет и вакансий","Да стартуют... да правда и там уже ниши подзаняты. Но сама геоаналитика ни у кого не пропала, у крупняка так уж точно"
,,,"Не пропала, но аналитика у крупняка делается в ArcGIS мышкой выпускником ГИС колледжа. Если где-то ArcGIS не хватает, ему дают в помощь программиста, который умеет вытаскивать данные из DWH."
,,,"Есть вопрос про OCR: что сейчас SOTA для определения лэйаута страницы? Обрабатываю сканы архивных документов. Лэйаут у страниц довольно сложный: текстовые блоки, фотографии с подписями, местами рукописными, и, главное, таблицы в том числе таблицы без рамки и стеки. Проблема в том, что нужные мне данные это топонимы, имена и фамилии, которые часто содержатся именно в таблицах, причем с переносами. Наивный подход засунуть изображение в tesseract или easyocr как есть не прошел."
,,"Есть вопрос про OCR: что сейчас SOTA для определения лэйаута страницы? Обрабатываю сканы архивных документов. Лэйаут у страниц довольно сложный: текстовые блоки, фотографии с подписями, местами рукописными, и, главное, таблицы в том числе таблицы без рамки и стеки. Проблема в том, что нужные мне данные это топонимы, имена и фамилии, которые часто содержатся именно в таблицах, причем с переносами. Наивный подход засунуть изображение в tesseract или easyocr как есть не прошел.","Могу поделиться вот такими ссылками:
https://github.com/shabie/docformer
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main
https://github.com/hikopensource/DAVAR-Lab-OCR/tree/main/demo/text_layout/VSR

Сам все не тестил, но большая часть довольно свежая. Естественно, для русского языка ничего нет. Можешь также поискать по датасету PubLayNet https://paperswithcode.com/paper/190807836"
,,,"Думаю, сперва прогнать изображение через модель для опредления лэйаута, вырезать отдельные блоки и уже их подвавть на вход tesseract"
,,"Думаю, сперва прогнать изображение через модель для опредления лэйаута, вырезать отдельные блоки и уже их подвавть на вход tesseract","Чат, а кто то занимался мержем SMP токенайзеров?
768-> 512"
,,,что за модель юзаеться ?
,,что за модель юзаеться ?,Chilloutmix/ cyberrealistic / pornvision
,,,"Привет. Есть вопрос про то как Conv2d работает на RGB изображении в torch. Вот пример. Создал батч из двадцать ргб изображений размеров 100 на 100. Конволюционный слой принимает 3 канала(РГБ) и создаёт одно ядро размеров 3 для генерации одного канала на выходе. Это ядро применяется к каждому каналу входного изображения и должно выдавать 3 карты признаков, но в отпуте только один. Как я понимаю, торч объединят их как-то, но как? Складывает? Перемножает?"
,,"Привет. Есть вопрос про то как Conv2d работает на RGB изображении в torch. Вот пример. Создал батч из двадцать ргб изображений размеров 100 на 100. Конволюционный слой принимает 3 канала(РГБ) и создаёт одно ядро размеров 3 для генерации одного канала на выходе. Это ядро применяется к каждому каналу входного изображения и должно выдавать 3 карты признаков, но в отпуте только один. Как я понимаю, торч объединят их как-то, но как? Складывает? Перемножает?",
,,,"Всем привет, вопрос по поводу GAN-ов. Есть ли какая то возможность, чтобы моделька генерировала большое количество зависимых фоток? То есть то, что было сгенерировано на предыдущей, влияет на следующую? Как пример: генерация мрт-срезов мозга."
,,"Всем привет, вопрос по поводу GAN-ов. Есть ли какая то возможность, чтобы моделька генерировала большое количество зависимых фоток? То есть то, что было сгенерировано на предыдущей, влияет на следующую? Как пример: генерация мрт-срезов мозга.","Если ганом сжимать фото, то на вход, при разжатии, можно еще добавлять сжатое предыдущее фото"
,,,то есть генератору вместе с шумом подавать вектор фотки?
,,то есть генератору вместе с шумом подавать вектор фотки?,как вариант
,то есть генератору вместе с шумом подавать вектор фотки?,как вариант,спасибо большое)
,,,"Если коротко — да, складывает."
,,"Если коротко — да, складывает.","Как я понял, генерится 5 кубов(ядер) размерностью 3х7х7 и они свёртываются на изображении?"
,"Если коротко — да, складывает.","Как я понял, генерится 5 кубов(ядер) размерностью 3х7х7 и они свёртываются на изображении?",да
,,,"А есть какая-та хорошая модель OCR, которая хороша работает из коробки для русского языка при распознавании текста на уличных объектах? (попробовал EasyOCR, очень так себе, см.скрин)"
,,"А есть какая-та хорошая модель OCR, которая хороша работает из коробки для русского языка при распознавании текста на уличных объектах? (попробовал EasyOCR, очень так себе, см.скрин)","PaddleOCR
Только парадокс в том, что eng модели лучше чем rus работают на русских словах"
,,,Пробовали Tesseract?
,,Пробовали Tesseract?,"Неа
tesseract это же вообще древность по ощущениям"
,,,"Для русского хз...
Для англ, просто для инфо, MMOCR хорошо работает в подобных сценах"
,,,А на идеальном примере она вообще работает? Выглядит как будто с настройками что-то не то
,,А на идеальном примере она вообще работает? Выглядит как будто с настройками что-то не то,"На некоторых ракурсах работает, но на процентах 10 только"
,,,сюда ^
,,сюда ^,Тритон какой-то гемор. Пишут как на заборе о 🚀 перфоманс. Но хз как его запинать
,сюда ^,Тритон какой-то гемор. Пишут как на заборе о 🚀 перфоманс. Но хз как его запинать,"Да меня даже не столько перформанс привлекает, сколько четкая структура для выделения моделей в отдельные модули и протокол взаимодействия между ними, на самом деле"
,,,"Чтобы свой костыль не придумывать
Из похожего еще BentoML часто упоминается в интернетах, мб с ним кто-то работал, расскажете, насколько норм?"
,,,"Коллеги привет. Подскажите в какую сторону мыслить: задача - из корпоративной документации по запросам пользователей выдавать релевантный ответ. Док оч много, в основном инструкции. Собираю цепочку с ретривером на лангчейне. Схема классическая -LLM  Сайга, мультиязычный векторизатор и Faiss (векторная БД). На тестах пока корпус документов был маленький всё было ок. Как расширил корпус - Faiss  начал выдавать нерелевантные документы. Не знаю куда копать... Посоветуйте куда смотреть что изучать..."
,,"Коллеги привет. Подскажите в какую сторону мыслить: задача - из корпоративной документации по запросам пользователей выдавать релевантный ответ. Док оч много, в основном инструкции. Собираю цепочку с ретривером на лангчейне. Схема классическая -LLM  Сайга, мультиязычный векторизатор и Faiss (векторная БД). На тестах пока корпус документов был маленький всё было ок. Как расширил корпус - Faiss  начал выдавать нерелевантные документы. Не знаю куда копать... Посоветуйте куда смотреть что изучать...","Нерелеватные документы?...)

Ну это проблема что в пространствах размерностью 512 или там 768, по косинусу валяется рядом всякий мусор. Чтобы решить это есть два пути:
1. google ""sbert retrieve and rerank"". Будете находить релевантные куски текста.
2. Всякие суммаризаторы от retrieve, генеративные.

Я лично пока в п. 2. не могу, боюсь и не буду. 

Пример. В доке есть текст про ""котировка X в Турции Y лир"". Спрашиваю про ""цена Х в Турции"", генеративные отвечают нормально. Спрашиваю тоже самое 1в1 с заменой Турции на Индию... 

Первый вариант ничего не находит, второй отвечает то же, с заменой Турции на Индию. Y. 

Вот какая-то такая галлюцинирующая история пока в прод не зайдет.

Ждемс WorldGPT по заветам Шолле с учетом географии"
,"Коллеги привет. Подскажите в какую сторону мыслить: задача - из корпоративной документации по запросам пользователей выдавать релевантный ответ. Док оч много, в основном инструкции. Собираю цепочку с ретривером на лангчейне. Схема классическая -LLM  Сайга, мультиязычный векторизатор и Faiss (векторная БД). На тестах пока корпус документов был маленький всё было ок. Как расширил корпус - Faiss  начал выдавать нерелевантные документы. Не знаю куда копать... Посоветуйте куда смотреть что изучать...","Нерелеватные документы?...)

Ну это проблема что в пространствах размерностью 512 или там 768, по косинусу валяется рядом всякий мусор. Чтобы решить это есть два пути:
1. google ""sbert retrieve and rerank"". Будете находить релевантные куски текста.
2. Всякие суммаризаторы от retrieve, генеративные.

Я лично пока в п. 2. не могу, боюсь и не буду. 

Пример. В доке есть текст про ""котировка X в Турции Y лир"". Спрашиваю про ""цена Х в Турции"", генеративные отвечают нормально. Спрашиваю тоже самое 1в1 с заменой Турции на Индию... 

Первый вариант ничего не находит, второй отвечает то же, с заменой Турции на Индию. Y. 

Вот какая-то такая галлюцинирующая история пока в прод не зайдет.

Ждемс WorldGPT по заветам Шолле с учетом географии","Добрый день! Вы предлагали использовать sbert для задач Q&A. Я щас приступила к изучению вопроса. То есть получается, что в цепочке ""переводим знания в вектора, сохраняем их в векторную БД, запрос пользователя тоже вереводим в вектор, ищем похожие по семантике на запрос пользователя вектора в БД, из них формируем тектовый контекст, составляем промт для LLM (контекст + вопрос пользователя) и получаем ответ"" SBERT заменит поиск по векторной БД? С помощью такой модели можно получить более релевантные результаты поиска по базе знаний?"
"Коллеги привет. Подскажите в какую сторону мыслить: задача - из корпоративной документации по запросам пользователей выдавать релевантный ответ. Док оч много, в основном инструкции. Собираю цепочку с ретривером на лангчейне. Схема классическая -LLM  Сайга, мультиязычный векторизатор и Faiss (векторная БД). На тестах пока корпус документов был маленький всё было ок. Как расширил корпус - Faiss  начал выдавать нерелевантные документы. Не знаю куда копать... Посоветуйте куда смотреть что изучать...","Нерелеватные документы?...)

Ну это проблема что в пространствах размерностью 512 или там 768, по косинусу валяется рядом всякий мусор. Чтобы решить это есть два пути:
1. google ""sbert retrieve and rerank"". Будете находить релевантные куски текста.
2. Всякие суммаризаторы от retrieve, генеративные.

Я лично пока в п. 2. не могу, боюсь и не буду. 

Пример. В доке есть текст про ""котировка X в Турции Y лир"". Спрашиваю про ""цена Х в Турции"", генеративные отвечают нормально. Спрашиваю тоже самое 1в1 с заменой Турции на Индию... 

Первый вариант ничего не находит, второй отвечает то же, с заменой Турции на Индию. Y. 

Вот какая-то такая галлюцинирующая история пока в прод не зайдет.

Ждемс WorldGPT по заветам Шолле с учетом географии","Добрый день! Вы предлагали использовать sbert для задач Q&A. Я щас приступила к изучению вопроса. То есть получается, что в цепочке ""переводим знания в вектора, сохраняем их в векторную БД, запрос пользователя тоже вереводим в вектор, ищем похожие по семантике на запрос пользователя вектора в БД, из них формируем тектовый контекст, составляем промт для LLM (контекст + вопрос пользователя) и получаем ответ"" SBERT заменит поиск по векторной БД? С помощью такой модели можно получить более релевантные результаты поиска по базе знаний?",Он будет лучше отвечать с тч зрения фактологии
,,,Андрей спасибо! Гляну чекаво там с реранком..
,,Андрей спасибо! Гляну чекаво там с реранком..,"Модели на mmarco для реранк смотрите. Msmarco для реранк на английском, mmarco - переведённый msmarco"
,Андрей спасибо! Гляну чекаво там с реранком..,"Модели на mmarco для реранк смотрите. Msmarco для реранк на английском, mmarco - переведённый msmarco",Mmraco это репа с моделями?
Андрей спасибо! Гляну чекаво там с реранком..,"Модели на mmarco для реранк смотрите. Msmarco для реранк на английском, mmarco - переведённый msmarco",Mmraco это репа с моделями?,датасет
,,,"Всем привет! Сейчас я развиваюсь в сфере продуктовой аналитики. В связи с этим вопрос: есть ли у вас какой-то курс лекций, по которому можно углубиться в основные задачи аналитика? (A/B тесты, метрики, параметрические и непараметрические методы)"
,,"Всем привет! Сейчас я развиваюсь в сфере продуктовой аналитики. В связи с этим вопрос: есть ли у вас какой-то курс лекций, по которому можно углубиться в основные задачи аналитика? (A/B тесты, метрики, параметрические и непараметрические методы)","Еще желательно бесплатных 🙏🏼🙏🏼🙏🏼
Можно на английском если есть"
,,,"Можешь попробовать отнаследоваться от докер-образа triton-server'a, доставить туда неободимые библиотеки и разрабатывать прямо в нем, чтобы все зависимости были видны"
,,"Можешь попробовать отнаследоваться от докер-образа triton-server'a, доставить туда неободимые библиотеки и разрабатывать прямо в нем, чтобы все зависимости были видны","Неа, датасет запросов msmarco, только мультиязычный - mmarco"
,,,Привет! Запись вебинара будет?
,,Привет! Запись вебинара будет?,Будет
,Привет! Запись вебинара будет?,Будет,Оч ждём!
,,,"Всем доброго времени суток, если кто-то пробовал квантовать модели yolo подскажите пожалуйста как вы это делали, какие подводные?"
,,"Всем доброго времени суток, если кто-то пробовал квантовать модели yolo подскажите пожалуйста как вы это делали, какие подводные?","У YOLOv6 есть раздел по квантизации. Все последние йоло в той или иной мере родственники, так что можно попробовать применить и на других."
,,,TensorRT или tkDNN
,,TensorRT или tkDNN,"я пробовал TensorRT, но получил ускорение всего на 10%.
это видимо сильно зависит от аппаратной части?"
,TensorRT или tkDNN,"я пробовал TensorRT, но получил ускорение всего на 10%.
это видимо сильно зависит от аппаратной части?","Если у вас не оч. большой входной тензор, то ускорение в 2-8 раз, в зависимости от размера батча и типа квантизации вы получите, скорее всего.
Для больших тензоров типа 1280*1280*3, и архитектур типа p6, эффект действительно становится не так заметен, я в таких случаях видел 10-30%."
,,,а 10% это throughput или latency?
,,,"Зависит. Если оборудование позволяет, то при batch size = 1 замена float32 на float16 даёт ускорение в 2 раза практически без потери точности, а квантизация в int8 в 4 раза при потере точности на 2-4%"
,,"Зависит. Если оборудование позволяет, то при batch size = 1 замена float32 на float16 даёт ускорение в 2 раза практически без потери точности, а квантизация в int8 в 4 раза при потере точности на 2-4%","А вот это ещё интереснее, спасибо большое"
,,,в self promo пж
,,,чат а кто то учил модели для паралельной генерации дорожек? есть работы вообще?
,,чат а кто то учил модели для паралельной генерации дорожек? есть работы вообще?,"Musegan, правда оно 2016го года"
,,,"Если оставить тот же текст, но без пересылки, то так будет ок?"
,,"Если оставить тот же текст, но без пересылки, то так будет ок?",да как хочешь
,,,Понятно спасибо
,,,"Видел где-то диссер, в котором чел обучил mvae+lstm 

Сурс сейчас не найду"
,,"Видел где-то диссер, в котором чел обучил mvae+lstm 

Сурс сейчас не найду",Vae оч не хочется
,,,"всем привет, кто-нибудь работал с cvat-sdk? хочу поменять organization для создания таски, но не понимаю как"
,,,"Всем привет! Есть ли какие статьи по последним исследованиям asr? Те же сота модели и их сравнение. Вдруг у кого имеются ссылочки под рукой, поделитесь, пожалуйста 🙏"
,,"Всем привет! Есть ли какие статьи по последним исследованиям asr? Те же сота модели и их сравнение. Вдруг у кого имеются ссылочки под рукой, поделитесь, пожалуйста 🙏",papers with code
,,,"Вообще, вещи не взаимозаменяемые. Сильно.

Дропаут он регуляризует. Большие дропауты, более тех же 0.2 в принципе не нужны - лучше сетку уменьшать. И дропаут обучение сильно замедляет.

Батчнорм же ускоряет - но не регуляризует. Ускоряет потому что сетка процесс обучения адаптируется к данным. Но на инференс это не влияет (читай на предикт).

В вашем случае если дропаут мешает, а батчнорм помогает - то это значит что в архитектуре фичи обустроены так, что слои много впитывают из данных полезного сразу, и пространство фич (каждого слоя) не избыточно, вполне структурировано.

—
Если нужен ""гайд"", то лучше Гудфеллоу ничего нет в этом плане."
,,"Вообще, вещи не взаимозаменяемые. Сильно.

Дропаут он регуляризует. Большие дропауты, более тех же 0.2 в принципе не нужны - лучше сетку уменьшать. И дропаут обучение сильно замедляет.

Батчнорм же ускоряет - но не регуляризует. Ускоряет потому что сетка процесс обучения адаптируется к данным. Но на инференс это не влияет (читай на предикт).

В вашем случае если дропаут мешает, а батчнорм помогает - то это значит что в архитектуре фичи обустроены так, что слои много впитывают из данных полезного сразу, и пространство фич (каждого слоя) не избыточно, вполне структурировано.

—
Если нужен ""гайд"", то лучше Гудфеллоу ничего нет в этом плане.","Интересно, спасибо)
Может, есть какие-то конкретные его работы? Или в целом в GAN-ах много про регуляризацию, и можно читать любую?"
,,,Я про эту книгу
,,Я про эту книгу,"батчнорм можно считать легкой регуляризацией за счёт шума в статистиках батчей и авторы заявляли, что потребность дропаута снижается. На практике дропаут после батчнорма норм работает"
,Я про эту книгу,"батчнорм можно считать легкой регуляризацией за счёт шума в статистиках батчей и авторы заявляли, что потребность дропаута снижается. На практике дропаут после батчнорма норм работает","Спасибо, почитаю)"
,,,всем привет как можно посчитать вклад входных разных каналов в предикт сетки и их условную важность?
,,всем привет как можно посчитать вклад входных разных каналов в предикт сетки и их условную важность?,"Оу... две идеи. gradcam и в его духе методы, и другой вариант - рассмотреть 8 вариантов зануления каналов (и смотреть на скор).

Надо отдать должное, идея нетривиальная - RGB это некоторое упрощение домена"
,всем привет как можно посчитать вклад входных разных каналов в предикт сетки и их условную важность?,"Оу... две идеи. gradcam и в его духе методы, и другой вариант - рассмотреть 8 вариантов зануления каналов (и смотреть на скор).

Надо отдать должное, идея нетривиальная - RGB это некоторое упрощение домена",спасибо
,,,"прошу прощения
просто классика)"
,,"прошу прощения
просто классика)","Всем привет, пришла в голову такая идея, собираемся в чатике толпой и делаем созвон раз в неделю, где обсуждаем рандомные папиры в основном по DL/CV/NLP, одна голова хорошо а 10-20 еще лучше формат локальный, но для меня тупого идеально с кем-то обсудить, формат коллективного разума некий

если интересно попробовать - напишите мне в личку"
,"прошу прощения
просто классика)","Всем привет, пришла в голову такая идея, собираемся в чатике толпой и делаем созвон раз в неделю, где обсуждаем рандомные папиры в основном по DL/CV/NLP, одна голова хорошо а 10-20 еще лучше формат локальный, но для меня тупого идеально с кем-то обсудить, формат коллективного разума некий

если интересно попробовать - напишите мне в личку",Спасибо)
"прошу прощения
просто классика)","Всем привет, пришла в голову такая идея, собираемся в чатике толпой и делаем созвон раз в неделю, где обсуждаем рандомные папиры в основном по DL/CV/NLP, одна голова хорошо а 10-20 еще лучше формат локальный, но для меня тупого идеально с кем-то обсудить, формат коллективного разума некий

если интересно попробовать - напишите мне в личку",Спасибо),"Даже очень длинные видео работают, очень интересно"
,,,"По FreqTrade вопрос - поддерживаются ли уже частичные сделки? Например, входим в лонг-позицию на $1000 и потом половину закрываем.
Смотрел год назад - такого не было из коробки."
,,"По FreqTrade вопрос - поддерживаются ли уже частичные сделки? Например, входим в лонг-позицию на $1000 и потом половину закрываем.
Смотрел год назад - такого не было из коробки.","можно, вроде давно поддерживает
https://www.freqtrade.io/en/stable/strategy-callbacks/#adjust-trade-position"
,"По FreqTrade вопрос - поддерживаются ли уже частичные сделки? Например, входим в лонг-позицию на $1000 и потом половину закрываем.
Смотрел год назад - такого не было из коробки.","можно, вроде давно поддерживает
https://www.freqtrade.io/en/stable/strategy-callbacks/#adjust-trade-position","О, спасибо! 
Судя по коммитам, где-то апреле-мае прошлого года в девелоп ветке эту фичу запилили. 

Вообще, конечно, далековато эту логику упрятали! КМК логично было бы прямо в сигналах указывать, на какой процент от stake_amount из конфига нужно совершать сделку (года полтора назад такая подпилка заработала, для сеточной стратегии, но код выглядел грязновато)."
"По FreqTrade вопрос - поддерживаются ли уже частичные сделки? Например, входим в лонг-позицию на $1000 и потом половину закрываем.
Смотрел год назад - такого не было из коробки.","можно, вроде давно поддерживает
https://www.freqtrade.io/en/stable/strategy-callbacks/#adjust-trade-position","О, спасибо! 
Судя по коммитам, где-то апреле-мае прошлого года в девелоп ветке эту фичу запилили. 

Вообще, конечно, далековато эту логику упрятали! КМК логично было бы прямо в сигналах указывать, на какой процент от stake_amount из конфига нужно совершать сделку (года полтора назад такая подпилка заработала, для сеточной стратегии, но код выглядел грязновато).","Freetrade Уже более в стабильной версии конечно, но многие вещи не поддерживает из коробки, а правки тока усложняют изначально не предназначенного для них бота"
,,,"ля, один матан все собесят, как скучно. Никакой интуиции к real data"
,,"ля, один матан все собесят, как скучно. Никакой интуиции к real data",ну типо спрашивают материал dl/ml курсов
,,,"А что можно спросить, чтобы проверить интуцию real data?"
,,"А что можно спросить, чтобы проверить интуцию real data?","Вот домен, вот задача. Какие фичи будешь извлекать? Каким образом? Какие проблемы возникнут? Как будешь их решать? Если тренировать модель, то на каком датасете? Откуда будешь брать датасет? Какого размера датасет нужен? Как поймешь что датасет разбалансирован? Как будешь балансировать? Как определишь куда балансировать? Какие аугментации применишь? Какую функцию потерь используешь? Как оценишь перфрманс модели?"
,,,"Дать посмотреть картинок 20 одного домена, и спросить что потенциально лучше сперформит по скору или по времени инференса в задаче сегментации например.

А не эти ряды один делить на цэ из N по K"
,,"Дать посмотреть картинок 20 одного домена, и спросить что потенциально лучше сперформит по скору или по времени инференса в задаче сегментации например.

А не эти ряды один делить на цэ из N по K",Звучит как дизайн
,"Дать посмотреть картинок 20 одного домена, и спросить что потенциально лучше сперформит по скору или по времени инференса в задаче сегментации например.

А не эти ряды один делить на цэ из N по K",Звучит как дизайн,По крайней мере это ближе к работе...
,,,"хм, ну вообще да, это было бы классно. Можно потом завести разговор про архитектуры"
,,"хм, ну вообще да, это было бы классно. Можно потом завести разговор про архитектуры","Мне кажется такое из опыта работы выцепляют больше на финалах. Команда уже знает какую задачу хочет человеку дать и ищет похожую экспертизу. Потому что в одной задаче у человека может быть интуиция, а в другой нет (даже сегментация/детекция те же)"
,,,"А тут прямо любые анонсы можно? Могу про свой запуск на producthunt рассказать, когда он будет?)"
,,"А тут прямо любые анонсы можно? Могу про свой запуск на producthunt рассказать, когда он будет?)",ага
,,,В свое время мне оказалось проще своего бота с 0 написать чем допиливать freetrade под свою стратегию)
,,В свое время мне оказалось проще своего бота с 0 написать чем допиливать freetrade под свою стратегию),"Офигенная работа, спасибо!"
,В свое время мне оказалось проще своего бота с 0 написать чем допиливать freetrade под свою стратегию),"Офигенная работа, спасибо!","Соответственно, если вы изъявите желание добавить свой собес, напиши мне в личные сообщения, я вам раздам редактирование"
В свое время мне оказалось проще своего бота с 0 написать чем допиливать freetrade под свою стратегию),"Офигенная работа, спасибо!","Соответственно, если вы изъявите желание добавить свой собес, напиши мне в личные сообщения, я вам раздам редактирование","Спасибо! Навскидку сразу бросается в глаза плюс - поддержка stocks.
Из минусов - последний коммит в конце марта.
Ещё попалась на глаза их функция вычисления коэф. Шарпа:
def sharpe(returns, n=252, risk_free_rate=None):
    returns = pd.Series(returns)
    if risk_free_rate:
        mean = returns.mean() * n - risk_free_rate
    else:
        mean = returns.mean() * n
    std = returns.std() * np.sqrt(n)
    if std == 0.0:
        return 0.0
    return mean / std

Такой подход через усреднение returns может давать  ошибки в случае больших разнонаправленных движений, вплоть до неверного знака результата."
"Офигенная работа, спасибо!","Соответственно, если вы изъявите желание добавить свой собес, напиши мне в личные сообщения, я вам раздам редактирование","Спасибо! Навскидку сразу бросается в глаза плюс - поддержка stocks.
Из минусов - последний коммит в конце марта.
Ещё попалась на глаза их функция вычисления коэф. Шарпа:
def sharpe(returns, n=252, risk_free_rate=None):
    returns = pd.Series(returns)
    if risk_free_rate:
        mean = returns.mean() * n - risk_free_rate
    else:
        mean = returns.mean() * n
    std = returns.std() * np.sqrt(n)
    if std == 0.0:
        return 0.0
    return mean / std

Такой подход через усреднение returns может давать  ошибки в случае больших разнонаправленных движений, вплоть до неверного знака результата.","Привет. Не очень понятен вопрос, если тебе надо sql over pandas dataframe то есть библиотечка pandasql. Если вопрос как перехватывать запросы от bi, то тут нужны детали в какие СУБД и как эта bi ходит, т. к. интерфейсы у них разные. Ну и не очень понятно чем не подходит СУБД (можно сделать stage  базенку) и нужно именно api юзать
Если иначе никак, то в постгре есть поддержка python. Пишешь хранимую процедуру которая request ом дёргает твой API. В эту сторону я оберток не писал ещё но по идее должно работать)"
"Соответственно, если вы изъявите желание добавить свой собес, напиши мне в личные сообщения, я вам раздам редактирование","Спасибо! Навскидку сразу бросается в глаза плюс - поддержка stocks.
Из минусов - последний коммит в конце марта.
Ещё попалась на глаза их функция вычисления коэф. Шарпа:
def sharpe(returns, n=252, risk_free_rate=None):
    returns = pd.Series(returns)
    if risk_free_rate:
        mean = returns.mean() * n - risk_free_rate
    else:
        mean = returns.mean() * n
    std = returns.std() * np.sqrt(n)
    if std == 0.0:
        return 0.0
    return mean / std

Такой подход через усреднение returns может давать  ошибки в случае больших разнонаправленных движений, вплоть до неверного знака результата.","Привет. Не очень понятен вопрос, если тебе надо sql over pandas dataframe то есть библиотечка pandasql. Если вопрос как перехватывать запросы от bi, то тут нужны детали в какие СУБД и как эта bi ходит, т. к. интерфейсы у них разные. Ну и не очень понятно чем не подходит СУБД (можно сделать stage  базенку) и нужно именно api юзать
Если иначе никак, то в постгре есть поддержка python. Пишешь хранимую процедуру которая request ом дёргает твой API. В эту сторону я оберток не писал ещё но по идее должно работать)",sqlite может открывать memory://. Встроен в python)
"Спасибо! Навскидку сразу бросается в глаза плюс - поддержка stocks.
Из минусов - последний коммит в конце марта.
Ещё попалась на глаза их функция вычисления коэф. Шарпа:
def sharpe(returns, n=252, risk_free_rate=None):
    returns = pd.Series(returns)
    if risk_free_rate:
        mean = returns.mean() * n - risk_free_rate
    else:
        mean = returns.mean() * n
    std = returns.std() * np.sqrt(n)
    if std == 0.0:
        return 0.0
    return mean / std

Такой подход через усреднение returns может давать  ошибки в случае больших разнонаправленных движений, вплоть до неверного знака результата.","Привет. Не очень понятен вопрос, если тебе надо sql over pandas dataframe то есть библиотечка pandasql. Если вопрос как перехватывать запросы от bi, то тут нужны детали в какие СУБД и как эта bi ходит, т. к. интерфейсы у них разные. Ну и не очень понятно чем не подходит СУБД (можно сделать stage  базенку) и нужно именно api юзать
Если иначе никак, то в постгре есть поддержка python. Пишешь хранимую процедуру которая request ом дёргает твой API. В эту сторону я оберток не писал ещё но по идее должно работать)",sqlite может открывать memory://. Встроен в python),Работает в AIRI у нас делал KGQA
,,,"Может ли быть такое, что на сбалансированном датасете на валидации метрики хорошие (f1), а если взять несбалансированный то сразу хреновые становятся? Для меня это какая то магия, на сбалансированном сете выходят по каждому классу пресижн и рекол адекватные.

Причем нет такого, что модель переобучилась предсказывать какой то один класс, кажется. 

Вообще, нормальная же стратегия, если у тебя есть дисбаланс в датасете, и чтоб это компенсировать делаешь undersampling?
(пробовал взвешенный лосс, и взвешенный семплер, не помогло)"
,,"Может ли быть такое, что на сбалансированном датасете на валидации метрики хорошие (f1), а если взять несбалансированный то сразу хреновые становятся? Для меня это какая то магия, на сбалансированном сете выходят по каждому классу пресижн и рекол адекватные.

Причем нет такого, что модель переобучилась предсказывать какой то один класс, кажется. 

Вообще, нормальная же стратегия, если у тебя есть дисбаланс в датасете, и чтоб это компенсировать делаешь undersampling?
(пробовал взвешенный лосс, и взвешенный семплер, не помогло)","Никакой магии тут нет. Если ты в валидационном датасете изменишь распределение классов, то пресижн класса, доля которого стала больше - увеличиться, а другого класса, доял которого стала меньше - уменьшится. Рикол при этом не изменится."
,,,На сбалансированном сете
,,,На несбалансированном
,,На несбалансированном,Пороги подбираешь?
,,,"Пробовал разные подвыборки случайно выбирать, результат один"
,,,Ещё можно юзать focal loss
,,Ещё можно юзать focal loss,Может завестись лучше взвешенного кроссентропи лосса?
,Ещё можно юзать focal loss,Может завестись лучше взвешенного кроссентропи лосса?,"Можно и так и так, выбрать лучшее. И для бинарки оч советую порог подбирать тк f1 от него зависит"
,,,Помогает
,,Помогает,Выбираю метку аргмаксом
,,,Не пробовал пороги
,,Не пробовал пороги,"Когда у меня несбалансированная бинарная классификация, я обычно при разработке моделей меряю качество по ROC AUC (ибо эта метрика мало чувствительна к балансу классов, теоретически вообще не чувствительно). 

А потом, когда выбрал модель с наилучшим ROC AUC и она меня устраивает, я отдельно подбираю пороги для классификации, хорошо решающие ту конечную задачу, ради которой мы классифицируем (часто в случае бинарной классификации ложноположительные и ложнноотрицательные ошибки обладают разными последствиями, поэтому порог приходится выбирать кастомный)."
,Не пробовал пороги,"Когда у меня несбалансированная бинарная классификация, я обычно при разработке моделей меряю качество по ROC AUC (ибо эта метрика мало чувствительна к балансу классов, теоретически вообще не чувствительно). 

А потом, когда выбрал модель с наилучшим ROC AUC и она меня устраивает, я отдельно подбираю пороги для классификации, хорошо решающие ту конечную задачу, ради которой мы классифицируем (часто в случае бинарной классификации ложноположительные и ложнноотрицательные ошибки обладают разными последствиями, поэтому порог приходится выбирать кастомный).","Эм, roc auc как раз таки теоретически чувствительна к имбалансу классов, precision-recall тогда уж надо (auc-pr)"
Не пробовал пороги,"Когда у меня несбалансированная бинарная классификация, я обычно при разработке моделей меряю качество по ROC AUC (ибо эта метрика мало чувствительна к балансу классов, теоретически вообще не чувствительно). 

А потом, когда выбрал модель с наилучшим ROC AUC и она меня устраивает, я отдельно подбираю пороги для классификации, хорошо решающие ту конечную задачу, ради которой мы классифицируем (часто в случае бинарной классификации ложноположительные и ложнноотрицательные ошибки обладают разными последствиями, поэтому порог приходится выбирать кастомный).","Эм, roc auc как раз таки теоретически чувствительна к имбалансу классов, precision-recall тогда уж надо (auc-pr)","Почему чувствительна?

Допустим, в старой, сбалансированной валидационной выборке у нас было N положительных и N отрицательных примеров. ROC-AUC на ней вычислялся как доля пар примеров из разных классов (таких примеров всего N*N), где модель предсказала больший скор для положительного, чем для отрицательного примера.

Теперь разбалансируем эту выборку: продублируем каждый отрицательный пример M раз (то есть теперь у нас N положительных и MN отрицательных примеров). Тогда все N*N пар примеров с разными метками тоже продублируются M раз, и доля тех из них, которые модель упорядочила верно, не изменится."
"Когда у меня несбалансированная бинарная классификация, я обычно при разработке моделей меряю качество по ROC AUC (ибо эта метрика мало чувствительна к балансу классов, теоретически вообще не чувствительно). 

А потом, когда выбрал модель с наилучшим ROC AUC и она меня устраивает, я отдельно подбираю пороги для классификации, хорошо решающие ту конечную задачу, ради которой мы классифицируем (часто в случае бинарной классификации ложноположительные и ложнноотрицательные ошибки обладают разными последствиями, поэтому порог приходится выбирать кастомный).","Эм, roc auc как раз таки теоретически чувствительна к имбалансу классов, precision-recall тогда уж надо (auc-pr)","Почему чувствительна?

Допустим, в старой, сбалансированной валидационной выборке у нас было N положительных и N отрицательных примеров. ROC-AUC на ней вычислялся как доля пар примеров из разных классов (таких примеров всего N*N), где модель предсказала больший скор для положительного, чем для отрицательного примера.

Теперь разбалансируем эту выборку: продублируем каждый отрицательный пример M раз (то есть теперь у нас N положительных и MN отрицательных примеров). Тогда все N*N пар примеров с разными метками тоже продублируются M раз, и доля тех из них, которые модель упорядочила верно, не изменится.","По определению) потому что она считает положительный и отрицательный классы равноценными. Если положительных  очень мало, но они в топе среди процента отрицательных, которых очень много, то рок аук будет большой, а классификация плохая.
Precision recall кривая как раз оценивает по положительному классу, что требуется в большинстве задач, тоже забивая на пороги"
"Эм, roc auc как раз таки теоретически чувствительна к имбалансу классов, precision-recall тогда уж надо (auc-pr)","Почему чувствительна?

Допустим, в старой, сбалансированной валидационной выборке у нас было N положительных и N отрицательных примеров. ROC-AUC на ней вычислялся как доля пар примеров из разных классов (таких примеров всего N*N), где модель предсказала больший скор для положительного, чем для отрицательного примера.

Теперь разбалансируем эту выборку: продублируем каждый отрицательный пример M раз (то есть теперь у нас N положительных и MN отрицательных примеров). Тогда все N*N пар примеров с разными метками тоже продублируются M раз, и доля тех из них, которые модель упорядочила верно, не изменится.","По определению) потому что она считает положительный и отрицательный классы равноценными. Если положительных  очень мало, но они в топе среди процента отрицательных, которых очень много, то рок аук будет большой, а классификация плохая.
Precision recall кривая как раз оценивает по положительному классу, что требуется в большинстве задач, тоже забивая на пороги","""Если положительных  очень мало, но они в топе среди процента отрицательных, которых очень много, то рок аук будет большой, а классификация плохая.""
Почему такой вывод? Если из 1000 заявок на кредиты 3 мошеннических, и они все вошли в топ 10 самых подозрительных заявок, то модель, измеряющая подозрительность, кажется весьма неплохой, и ROC AUC это как раз и отразит."
,,,"У меня получается предикшн на два класса идет, выход из двух чисел
Поэтому так"
,,"У меня получается предикшн на два класса идет, выход из двух чисел
Поэтому так","чтобы меньше зависело от выборки можно юзать поправленные критерии типа Heidke skill score HSS / Gilbert skill score (GSS, ETS)"
,"У меня получается предикшн на два класса идет, выход из двух чисел
Поэтому так","чтобы меньше зависело от выборки можно юзать поправленные критерии типа Heidke skill score HSS / Gilbert skill score (GSS, ETS)",Спасибо за советы! Буду копать
,,,"Не в контексте спрашиваемой задачи, просто зацепила фраза, что рок аук нечувствителен к имбалансу"
,,"Не в контексте спрашиваемой задачи, просто зацепила фраза, что рок аук нечувствителен к имбалансу","Но рок аук действительно не очень чувствителен к балансу)
Можете на своей выборке какой-нибудь проверить: достаточно выбросить какую-то большУю долю положительного или отрицательного класса и сравнить метрику до и после)"
,,,"Под ""нечувствительный к имбалансу"" я имею в виду ""для двух выборок, которые отличаются друг от друга только балансом классов, но не отличаются распределением внутри каждого класса, метрика выдаст одно и то же значение"".
А что под нечувствительностью понимаешь ты?"
,,,"То, что я выше написал. Не хочу излишне в детали вдаваться, можете почитать в каких случаях используют roc а когда pr и почему. Но может в вопросе выше положительный класс важен как и отрицательный"
,,"То, что я выше написал. Не хочу излишне в детали вдаваться, можете почитать в каких случаях используют roc а когда pr и почему. Но может в вопросе выше положительный класс важен как и отрицательный","Ну нет уж, если ты начал спорить и вдаваться в детали, то объясни нормально - с определениями и примерами - что ты понимаешь под чувствительностью. А не соскакивай)"
,,,"Я не собирался тут спорить, просто указал людям на дизинфу, а то мало ли.
Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то классификатор плохой. По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают. F1 (precision и recall) же люди как раз считают потому они в отличии от accuracy нормально позволяют оценить качество при имбалансе"
,,"Я не собирался тут спорить, просто указал людям на дизинфу, а то мало ли.
Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то классификатор плохой. По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают. F1 (precision и recall) же люди как раз считают потому они в отличии от accuracy нормально позволяют оценить качество при имбалансе","По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают.
Именно поэтому я и назвал ROC AUC нечувствительным к имбалансу 🙂
""Нечувствительный"" - означает, что ROC AUC зависит не от того, сколько примеров в каждом классе, а только от того, насколько хорошо модель их разделяет друг от друга.

Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то ROC AUC будет примерно 90%.
Если из 5000000 заявок 100 мошеннических попадут  с 500000 по 500100, то ROC AUC будет тоже 90%.
Если из 10000 заявок 100 мошеннических попадут  с 1000 по 1100, то ROC AUC будет опять-таки 90%.

Где здесь дезинформация?"
,"Я не собирался тут спорить, просто указал людям на дизинфу, а то мало ли.
Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то классификатор плохой. По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают. F1 (precision и recall) же люди как раз считают потому они в отличии от accuracy нормально позволяют оценить качество при имбалансе","По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают.
Именно поэтому я и назвал ROC AUC нечувствительным к имбалансу 🙂
""Нечувствительный"" - означает, что ROC AUC зависит не от того, сколько примеров в каждом классе, а только от того, насколько хорошо модель их разделяет друг от друга.

Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то ROC AUC будет примерно 90%.
Если из 5000000 заявок 100 мошеннических попадут  с 500000 по 500100, то ROC AUC будет тоже 90%.
Если из 10000 заявок 100 мошеннических попадут  с 1000 по 1100, то ROC AUC будет опять-таки 90%.

Где здесь дезинформация?","Нигде)
Вот ещё и контрпример (с корявым наскоро состряпанным кодом, но всё же):"
"Я не собирался тут спорить, просто указал людям на дизинфу, а то мало ли.
Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то классификатор плохой. По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают. F1 (precision и recall) же люди как раз считают потому они в отличии от accuracy нормально позволяют оценить качество при имбалансе","По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают.
Именно поэтому я и назвал ROC AUC нечувствительным к имбалансу 🙂
""Нечувствительный"" - означает, что ROC AUC зависит не от того, сколько примеров в каждом классе, а только от того, насколько хорошо модель их разделяет друг от друга.

Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то ROC AUC будет примерно 90%.
Если из 5000000 заявок 100 мошеннических попадут  с 500000 по 500100, то ROC AUC будет тоже 90%.
Если из 10000 заявок 100 мошеннических попадут  с 1000 по 1100, то ROC AUC будет опять-таки 90%.

Где здесь дезинформация?","Нигде)
Вот ещё и контрпример (с корявым наскоро состряпанным кодом, но всё же):","и что?
то что численное значение почти не меняется не значит, что оптимальные модели совпадают (или хотя бы близки)"
"По определению в рок ауке считаются tpr и в fpr, которые имбаланс вообще не учитывают.
Именно поэтому я и назвал ROC AUC нечувствительным к имбалансу 🙂
""Нечувствительный"" - означает, что ROC AUC зависит не от того, сколько примеров в каждом классе, а только от того, насколько хорошо модель их разделяет друг от друга.

Если из 1000000 заявок 100 мошеннических попадут  с 100000 по 100100, то ROC AUC будет примерно 90%.
Если из 5000000 заявок 100 мошеннических попадут  с 500000 по 500100, то ROC AUC будет тоже 90%.
Если из 10000 заявок 100 мошеннических попадут  с 1000 по 1100, то ROC AUC будет опять-таки 90%.

Где здесь дезинформация?","Нигде)
Вот ещё и контрпример (с корявым наскоро состряпанным кодом, но всё же):","и что?
то что численное значение почти не меняется не значит, что оптимальные модели совпадают (или хотя бы близки)","Напрямую не значит
Но значит, что рокаук слабочувствителен к балансу
А из этого следует что если модель А имела метрику 0.91, а модель B метрику 0.92, то после ухудшения баланса их метрики останутся ±такими же (std действительно маленький, сами видите) -> с большой вероятностью метрика модели B даже при дисбалансе будет лучше чем у А"
,,,"подскажите название тг бота который голосовухи в текст переводит (чище, чем сам телеграм), недавно мелькал в разных каналах и новостях. ему еще пересылать из вотсапа можно было сбщ. спаисбо"
,,,"Я имел в виду не учитывается примерно в том же смысле, как и accuracy по сравнению с f1. И повторюсь, я не хотел начинать этот бесконечный спор. Но если кто-то прочитает мой первый коммент и не будет бездумно юзать рок аук при имбалансе, то я своей исходной цели достиг"
,,"Я имел в виду не учитывается примерно в том же смысле, как и accuracy по сравнению с f1. И повторюсь, я не хотел начинать этот бесконечный спор. Но если кто-то прочитает мой первый коммент и не будет бездумно юзать рок аук при имбалансе, то я своей исходной цели достиг","Так в чем вред-то от использования ROC AUC?
Можешь привести пример, когда ROC AUC выбирает из двух моделей более плохую?

Я не наезжаю, я честно хочу разобраться)"
,"Я имел в виду не учитывается примерно в том же смысле, как и accuracy по сравнению с f1. И повторюсь, я не хотел начинать этот бесконечный спор. Но если кто-то прочитает мой первый коммент и не будет бездумно юзать рок аук при имбалансе, то я своей исходной цели достиг","Так в чем вред-то от использования ROC AUC?
Можешь привести пример, когда ROC AUC выбирает из двух моделей более плохую?

Я не наезжаю, я честно хочу разобраться)","Нет, тут не про выбор моделей. А про то что по факту у обоих кривых одно измерение совпадает, а в качестве второй у pr кривой используется precision вместо FPR. FPR при большом дисбалассе линейная по fp получается."
,,,"кажется у Александра действительно какое-то альтернативное понимание ""чувствительности"""
,,"кажется у Александра действительно какое-то альтернативное понимание ""чувствительности""","Если кто-нибудь найдёт контрпример, где рокаук неправильно ранкает модели именно из-за дисбаланса классов, а какой-нибудь f1/pr auc/... делает это лучше — скиньте, пожалуйста
Правда было бы очень интересно разобрать"
,"кажется у Александра действительно какое-то альтернативное понимание ""чувствительности""","Если кто-нибудь найдёт контрпример, где рокаук неправильно ранкает модели именно из-за дисбаланса классов, а какой-нибудь f1/pr auc/... делает это лучше — скиньте, пожалуйста
Правда было бы очень интересно разобрать",Те при высоком рок ауке на самом деле модель может оказаться не очень. Ранжирующая способность ни куда не уходит
,,,"Да, мой пойнт был в том, что при имбалансе рок аук неадекватно оценивает хорошесть модели, и лучше сразу брать метрику, которая для этого предназначена"
,,"Да, мой пойнт был в том, что при имбалансе рок аук неадекватно оценивает хорошесть модели, и лучше сразу брать метрику, которая для этого предназначена","А, то есть ты критиковал ROC AUC не для принятия решений типа ""какая из моделей лучше, A или B?"", а для принятия решений типа ""достаточно ли модель А хороша, чтобы катить её в прод?"", верно?

Мне кажется, что для второго вида решений ни ROC-AUC, ни F1, ни PR-AUC не подходят, а подходят только бизнес-метрики, оценивающие последствия решений, принимаемых на основе модели."
,"Да, мой пойнт был в том, что при имбалансе рок аук неадекватно оценивает хорошесть модели, и лучше сразу брать метрику, которая для этого предназначена","А, то есть ты критиковал ROC AUC не для принятия решений типа ""какая из моделей лучше, A или B?"", а для принятия решений типа ""достаточно ли модель А хороша, чтобы катить её в прод?"", верно?

Мне кажется, что для второго вида решений ни ROC-AUC, ни F1, ни PR-AUC не подходят, а подходят только бизнес-метрики, оценивающие последствия решений, принимаемых на основе модели.","Меня цепанула фраза со словами рок аук и имбаланс в одном предложении, про пример кейса я тоже выше написал, и ты его как будто в этом же смысле попытался сначала оспорить. Про бизнес метрики согласен, но все-таки обычно, если выбирают какие-то промежуточные скоры, то выбирают наиболее подходящие"
,,,"так про то что рок аук нечувствителен к имбалансу все корректно сказано
чувствительность метрики к имбалансу это если бы ее колбасило от смещения баланса классов"
,,"так про то что рок аук нечувствителен к имбалансу все корректно сказано
чувствительность метрики к имбалансу это если бы ее колбасило от смещения баланса классов","Да я понял, что под словом чувствительность другое имелось в виду, я с этим и не спорил ни разу, я про другой аспект писал сразу"
,,,Кто подскажет статья/книги/методы по поиску инсайтов в данных(табличных)?
,,Кто подскажет статья/книги/методы по поиску инсайтов в данных(табличных)?,"Тоже не спец) Можно действовать также как и в любой естественной науке: строишь гипотезу, проверяешь ее на данных. Если обнаруживается расхождение, либо отбрасываешь гипотезу, либо дорабатываешь гипотезу, либо дорабатываешь проверку. После того как у тебя собрался набор гипотез, строишь из них предиктивную модель предметной области in silico. И уже играясь с этой моделью получаешь инсайты и планируешь эксперименты in vivo. Почитать можно любую книгу по философии науки. Классика: The Logic of Scientific Discovery by Karl Popper."
,,,"Не спец в этом деле, но однозначно можно посоветовать смотреть ноутбуки с соревнований на каггле. Раскручивать анализ от общей информации к более специфичной (та, что нам нужна), задавая вопросы ко всему, что не понятно в данных. Самый базовый пример -  находишь пропуски в каких-то колонках, выводишь строки с ними - и, возможно, в этих пропусках есть какая-то закономерность. Что-то в этом духе. Если обучаешь модель, можно также выводить примеры из тренировочного датасета,  на которых ошибка очень большая - возможно, в них тоже есть какая-то особенность"
,,,А ты в токенайзер долил спец токены
,,А ты в токенайзер долил спец токены,"Ребят, как в DALL-E 2 ребята делали инверсию из изображения initial noise."
,,,"Добрый день, какие есть метрики для Image Alignment/Image registration? Масок нет, так что iou не пойдет. Можно конечно просто разницу посчитать но есть ощущение что так не делается."
,,"Добрый день, какие есть метрики для Image Alignment/Image registration? Масок нет, так что iou не пойдет. Можно конечно просто разницу посчитать но есть ощущение что так не делается.",Контраст по границе склейки?
,"Добрый день, какие есть метрики для Image Alignment/Image registration? Масок нет, так что iou не пойдет. Можно конечно просто разницу посчитать но есть ощущение что так не делается.",Контраст по границе склейки?,Это же про image stiching если я правильно понимаю?
"Добрый день, какие есть метрики для Image Alignment/Image registration? Масок нет, так что iou не пойдет. Можно конечно просто разницу посчитать но есть ощущение что так не делается.",Контраст по границе склейки?,Это же про image stiching если я правильно понимаю?,"Да, идея оттуда."
,,,"Мне кажется, для image alignment тоже может подойти, но это от домена зависит"
,,"Мне кажется, для image alignment тоже может подойти, но это от домена зависит","Там с изображениями с микроскопа сваязанно и одно изображение может быть небаольшим сегментом другого. Так что врядли подойдет, но спасибо большое!"
,"Мне кажется, для image alignment тоже может подойти, но это от домена зависит","Там с изображениями с микроскопа сваязанно и одно изображение может быть небаольшим сегментом другого. Так что врядли подойдет, но спасибо большое!","Image stitching обычно как раз с перекрытием и делается. Тут больше вопрос, насколько изменяется само изображение между соседними сдвигами. Если сильно (оптическая ось не перпендикулярна плоскости подвижки, объектив плохой и на краях поля зрения хроматические абберации, образцы совсем разные), то локальные метрики не сработают."
,,,А нет тут треда где спросить какую LLM модель можно поставить на GPU6 GB или CPU 16 GB?
,,А нет тут треда где спросить какую LLM модель можно поставить на GPU6 GB или CPU 16 GB?,"спомощью Llama.cpp можно часть выгрузить в GPU, часть в RAM. Так что у вас 13B спокойно запустится квантованная. А может даже 30B"
,,,"Если хочется именно сравнить изображения по всей области перекрытия, можно попробовать прогнать изображения через DoG, LoG или любое другое преобразование, выделяющее фичи, а потом посчитать разницу. Я бы еще дополнительно попробовал даунсэмплить изображения и считать взвешенную разницу в зависимости от масштаба."
,,"Если хочется именно сравнить изображения по всей области перекрытия, можно попробовать прогнать изображения через DoG, LoG или любое другое преобразование, выделяющее фичи, а потом посчитать разницу. Я бы еще дополнительно попробовал даунсэмплить изображения и считать взвешенную разницу в зависимости от масштаба.","Спасибо, пойду попробую!"
,,,"Всем привет!

Имею 0 опыт внедрения мл моделей на телефоны.

Подскажите, пожалуйста, на сегодняшний день средняя мобилка способна на инференс rl бота в играх?"
,,,"Всем привет, конкуренты подсказали, что они используют как фичу для Штатов зип код  (почтовый индекс). Зип коды класетризованы по вэлфэре, ну типо какой-то район более благосостоятельный и дорогой по недвижке, какой-то меньше

Вопрос: мб кто-то знает источник с размеченными (по среднему достатку/цене кв метра/ и тд) зип кодам США?)"
,,"Всем привет, конкуренты подсказали, что они используют как фичу для Штатов зип код  (почтовый индекс). Зип коды класетризованы по вэлфэре, ну типо какой-то район более благосостоятельный и дорогой по недвижке, какой-то меньше

Вопрос: мб кто-то знает источник с размеченными (по среднему достатку/цене кв метра/ и тд) зип кодам США?)","Попробуйте здесь фразой ""by zip code""

https://datasetsearch.research.google.com/"
,,,а какая там модель в rl?
,,а какая там модель в rl?,"пока никакой) 
Поставили задачу пока разработать rl бота для мобильной игры, при этом моделька будет крутиться на устройстве клиента. Игра чем то похожа на agario, где дейсвтия нужно совершать постоянно и нет времени на подумать. 

Перед тем как перейти к разработке, хочется узнать, реально ли это вообще запускать локально у пользователя или можно даже не пытаться."
,,,"ну вот mobilenet  крутится на айфон 8 и дальше в реалтайме, можно дальше прикинуть по флопсам
а в rl вроде разные штуки могут быть, как две линейки так и трансформеры"
,,"ну вот mobilenet  крутится на айфон 8 и дальше в реалтайме, можно дальше прикинуть по флопсам
а в rl вроде разные штуки могут быть, как две линейки так и трансформеры","да, кажется что без конкретной модели на руках трудно что-то сказать"
,,,"Штука классная, но как cправедливо заметили на хабре, кто будет это поддерживать?"
,,"Штука классная, но как cправедливо заметили на хабре, кто будет это поддерживать?","Сообщество. Кому надо, тот будет поддерживать"
,,,а че не контрибутишь в opencv напрямую?
,,а че не контрибутишь в opencv напрямую?,Пропихнуть рефакторинг в большой опенсорс проект практически нереально
,а че не контрибутишь в opencv напрямую?,Пропихнуть рефакторинг в большой опенсорс проект практически нереально,"но команду хорошо бы найти, это да"
а че не контрибутишь в opencv напрямую?,Пропихнуть рефакторинг в большой опенсорс проект практически нереально,"но команду хорошо бы найти, это да","Интересно, насколько разные проблемы у людей. Я использую OpenCV из С++, там есть проблема в том, что у многих функций есть своё внутреннее состояние. Это замедляет работу итогового пайплайна, приходится смотреть исходники и переписывать у себя их функции с уменьшением числа выделения памяти и всяческого копирования. При этом само по себе написание кода не является узким местом в разработке, он тестируется намного дольше, продумывается дольше.
А тут цена скорости разработки оказывается выше, а скорость работы конечного пайплайна даже замедляют.
P.S. При этом согласен, что cv2 неудобна и надо сделать лучше."
,,,"Кстати, а как дела с UMat и gpuMat?"
,,"Кстати, а как дела с UMat и gpuMat?",вот сюда пока не углублялся
,,,Не могу установить СУДА кто может помочь у меня 2060 супер видеокарта
,,Не могу установить СУДА кто может помочь у меня 2060 супер видеокарта,"В общем, могу сказать пару вещей, которые, возможно, покажутся несколько неочевидным решением многих подобных проблем на краткосрок (далеко не только вашей конкретной), но они сэкономят вам много нервов в будущем и это даст очень много плюшек в долгосрок.

1. Посмотрите в сторону линуксов на десктопе (например, убунту) (это самое важное)
2. Познакомьтесь с контейнерами (можно погуглить что-то типа docker для ml)
3. Попробуйте запускать jupyter из контейнера"
,Не могу установить СУДА кто может помочь у меня 2060 супер видеокарта,"В общем, могу сказать пару вещей, которые, возможно, покажутся несколько неочевидным решением многих подобных проблем на краткосрок (далеко не только вашей конкретной), но они сэкономят вам много нервов в будущем и это даст очень много плюшек в долгосрок.

1. Посмотрите в сторону линуксов на десктопе (например, убунту) (это самое важное)
2. Познакомьтесь с контейнерами (можно погуглить что-то типа docker для ml)
3. Попробуйте запускать jupyter из контейнера","nvidia-docker называектся проект. Да, в него можно завернуть python c необходимыми библиотеками и взаимодействовать с ним снаружи через jupyter. Мы так делали, но работать так не совсем удобно"
Не могу установить СУДА кто может помочь у меня 2060 супер видеокарта,"В общем, могу сказать пару вещей, которые, возможно, покажутся несколько неочевидным решением многих подобных проблем на краткосрок (далеко не только вашей конкретной), но они сэкономят вам много нервов в будущем и это даст очень много плюшек в долгосрок.

1. Посмотрите в сторону линуксов на десктопе (например, убунту) (это самое важное)
2. Познакомьтесь с контейнерами (можно погуглить что-то типа docker для ml)
3. Попробуйте запускать jupyter из контейнера","nvidia-docker называектся проект. Да, в него можно завернуть python c необходимыми библиотеками и взаимодействовать с ним снаружи через jupyter. Мы так делали, но работать так не совсем удобно","А почему не очень удобно? Для меня чистый кайф, мб не натолкнулся ещё на что-то"
"В общем, могу сказать пару вещей, которые, возможно, покажутся несколько неочевидным решением многих подобных проблем на краткосрок (далеко не только вашей конкретной), но они сэкономят вам много нервов в будущем и это даст очень много плюшек в долгосрок.

1. Посмотрите в сторону линуксов на десктопе (например, убунту) (это самое важное)
2. Познакомьтесь с контейнерами (можно погуглить что-то типа docker для ml)
3. Попробуйте запускать jupyter из контейнера","nvidia-docker называектся проект. Да, в него можно завернуть python c необходимыми библиотеками и взаимодействовать с ним снаружи через jupyter. Мы так делали, но работать так не совсем удобно","А почему не очень удобно? Для меня чистый кайф, мб не натолкнулся ещё на что-то","пока не нужно что-либо самому пересобирать из исходников - все норм, да"
,,,Тогда попробуй ТУДА поставить
,,Тогда попробуй ТУДА поставить,В этом и проблема – КУДА поставить
,,,Тебе для руторча?
,,Тебе для руторча?,Tensorflow и pytorch
,Тебе для руторча?,Tensorflow и pytorch,"Без конкретной ошибки тебе ничем конкретным не помочь, возьми текст ошибки, прочитай, и загугли его. а потом скинь сюда, если не найдешь"
Тебе для руторча?,Tensorflow и pytorch,"Без конкретной ошибки тебе ничем конкретным не помочь, возьми текст ошибки, прочитай, и загугли его. а потом скинь сюда, если не найдешь","Я установил все: CUDA, Visual studio, cudnn но не могу подключить GPU у меня 2060 супер видеокарта"
Tensorflow и pytorch,"Без конкретной ошибки тебе ничем конкретным не помочь, возьми текст ошибки, прочитай, и загугли его. а потом скинь сюда, если не найдешь","Я установил все: CUDA, Visual studio, cudnn но не могу подключить GPU у меня 2060 супер видеокарта","exit code 0 - это завершение скрипта без ошибок.
(впрочем чек ничего не чекает)"
,,,мб для тенсорфлоша
,,мб для тенсорфлоша,"а где ошибка то
так а если эксепшн все равно ж будет 0"
,мб для тенсорфлоша,"а где ошибка то
так а если эксепшн все равно ж будет 0","Я установил все: CUDA, Visual studio, cudnn но не могу подключить GPU у меня 2060 супер видеокарта"
мб для тенсорфлоша,"а где ошибка то
так а если эксепшн все равно ж будет 0","Я установил все: CUDA, Visual studio, cudnn но не могу подключить GPU у меня 2060 супер видеокарта","Есть стойкое ощущение, что человек просто толстый вброс делает на ночь глядя"
,,,"можешь сделать так
import torch
print(torch.cuda.is_available())

если напишет True значит все ок"
,,"можешь сделать так
import torch
print(torch.cuda.is_available())

если напишет True значит все ок",
,,,"ну все, не подключается супервидеокарта(("
,,,A nvidia-smi в shell что показывает?
,,A nvidia-smi в shell что показывает?,Как это сделать
,,,Открой cmd
,,,И напиши nvidia-smi
,,И напиши nvidia-smi,
,И напиши nvidia-smi,,"Ну стоит 12, как ты тут можешь прочитать"
,,,"Ты уверен, что CUDA 12.2 поддерживается? Я недавно 11.8 накатывал и на tf, и на pytorch"
,,"Ты уверен, что CUDA 12.2 поддерживается? Я недавно 11.8 накатывал и на tf, и на pytorch",У меня сейчас установлено 11.8 12 не установил эшо
,,,Проверь по табличке
,,Проверь по табличке,Axa
,,,"А вообще, видеокарта-то, наверняка супер, но с 8 гб видеопамяти зачем именно на ней учить? Google colab дает v100 с 16gb"
,,"А вообще, видеокарта-то, наверняка супер, но с 8 гб видеопамяти зачем именно на ней учить? Google colab дает v100 с 16gb","Я вот делал учебный проект, у меня ресурс быстро исчерпался, хотя задача была простенькая"
,"А вообще, видеокарта-то, наверняка супер, но с 8 гб видеопамяти зачем именно на ней учить? Google colab дает v100 с 16gb","Я вот делал учебный проект, у меня ресурс быстро исчерпался, хотя задача была простенькая","Заводишь 3 почты, шаришь папку в гугл драйве между ними всеми"
"А вообще, видеокарта-то, наверняка супер, но с 8 гб видеопамяти зачем именно на ней учить? Google colab дает v100 с 16gb","Я вот делал учебный проект, у меня ресурс быстро исчерпался, хотя задача была простенькая","Заводишь 3 почты, шаришь папку в гугл драйве между ними всеми","В такой ситуации уже проще просто на 3070 гонять своей

Так-то понятно, что голь на выдумки хитра: я в свое время на pythonanywhere, чтобы параллелить работу, завел три сервера и связующий четвертый, который им команды отдавал, кто какой запрос обрабатывает))"
"Я вот делал учебный проект, у меня ресурс быстро исчерпался, хотя задача была простенькая","Заводишь 3 почты, шаришь папку в гугл драйве между ними всеми","В такой ситуации уже проще просто на 3070 гонять своей

Так-то понятно, что голь на выдумки хитра: я в свое время на pythonanywhere, чтобы параллелить работу, завел три сервера и связующий четвертый, который им команды отдавал, кто какой запрос обрабатывает))","Бля, еще проще на своей А100 тогда уж)"
,,,"Хотя поебаться с торчем и кудой это наверное сродне обряду инициации
Там ведь их два даже, торч для цпу и торч для гпу)"
,,,2060 super это модель видюхи что доебались-то)
,,2060 super это модель видюхи что доебались-то),Так просто кеково написано)
,,,"В nvidia-smi отображается, что 12.2 стоит.

Инструкции все вполне исчерпывающие, пройдись по ним внимательно, посмотри на установленные версии и затем задай вопросы

Забей пока на tensorflow, его вообще на винде щас ставить тяжко, но torch с полпинка заводится при правильных движениях"
,,"В nvidia-smi отображается, что 12.2 стоит.

Инструкции все вполне исчерпывающие, пройдись по ним внимательно, посмотри на установленные версии и затем задай вопросы

Забей пока на tensorflow, его вообще на винде щас ставить тяжко, но torch с полпинка заводится при правильных движениях",Нужно сейчас нагуглить как снести нахуй все куды какие понаставились и по табличке совместимости выбрать расово верную
,,,Да я знаю
,,Да я знаю,Prosto klass
,Да я знаю,Prosto klass,не отнять
,,,В днс консультанты 1050ti называют супервидеокартой для AI
,,В днс консультанты 1050ti называют супервидеокартой для AI,Ну они-то конечно шарят
,,,"Монтируешь драйв, работаешь в папке
Как послали на одном аккаунте - продолжаешь с чекпоинта на другом
Можно еще сторожа там же спросить
Я думаю люди на колаб не от хорошей жизни лезут"
,,"Монтируешь драйв, работаешь в папке
Как послали на одном аккаунте - продолжаешь с чекпоинта на другом
Можно еще сторожа там же спросить
Я думаю люди на колаб не от хорошей жизни лезут",Ну с 2060 супер видеокартой можно и сразиться с версиями куды))
,"Монтируешь драйв, работаешь в папке
Как послали на одном аккаунте - продолжаешь с чекпоинта на другом
Можно еще сторожа там же спросить
Я думаю люди на колаб не от хорошей жизни лезут",Ну с 2060 супер видеокартой можно и сразиться с версиями куды)),"8гб, я особо за цв не слежу сейчас, но в нлп соты в такое уже не влезут"
,,,Когда ничерта не заводится (и ты виндузятник) лезть пробовать еще один способ как можно все сделать – разумное конечное решение.
,,Когда ничерта не заводится (и ты виндузятник) лезть пробовать еще один способ как можно все сделать – разумное конечное решение.,А что не так с виндой-то? WSL вроде ± справляется
,,,"Нормальная карта, у меня в девбоксе до сих пор 1080Ti для CV крутятся."
,,,"Ну да. И торч пересобрать можно и тф, и в чатах почти не глумятся."
,,"Ну да. И торч пересобрать можно и тф, и в чатах почти не глумятся.","Насчет глумятся это уже вопрос интеллекта. Есть инструмент, есть его плюсы и минусы, все остальное уже не по существу)

А что подразумевается под лучшим пониманием?"
,"Ну да. И торч пересобрать можно и тф, и в чатах почти не глумятся.","Насчет глумятся это уже вопрос интеллекта. Есть инструмент, есть его плюсы и минусы, все остальное уже не по существу)

А что подразумевается под лучшим пониманием?",И как же формулируется вопрос интеллекта?
,,,"Для WSL нужно немножко лучше понимать что делаешь, кмк."
,,"Для WSL нужно немножко лучше понимать что делаешь, кмк.",Поржали но помогли
,,,"1. Человек пришел с техническим вопросом без трейсбека, объяснения ситуации и даже не сказал что у него за ОС.
2. nvidia-smi - это как?
3. Exit code 0
Да много деталей. 

Я не глумлюсь, я просто удивлен что зеленому новичку еще никто убунту поставить не посоветовал
Хотя говорить что под WSL все можно сделать примерно того же уровня совет"
,,"1. Человек пришел с техническим вопросом без трейсбека, объяснения ситуации и даже не сказал что у него за ОС.
2. nvidia-smi - это как?
3. Exit code 0
Да много деталей. 

Я не глумлюсь, я просто удивлен что зеленому новичку еще никто убунту поставить не посоветовал
Хотя говорить что под WSL все можно сделать примерно того же уровня совет",Спасибо за поддержку. 👍
,"1. Человек пришел с техническим вопросом без трейсбека, объяснения ситуации и даже не сказал что у него за ОС.
2. nvidia-smi - это как?
3. Exit code 0
Да много деталей. 

Я не глумлюсь, я просто удивлен что зеленому новичку еще никто убунту поставить не посоветовал
Хотя говорить что под WSL все можно сделать примерно того же уровня совет",Спасибо за поддержку. 👍,"Не, правда. Если у тебя какие-то проектики небольшие и горят сроки, то попробуй гугл колаб или каггловские ноутбуки. 
Там все бесплатно и онлайн, но ограничения по времени. 
Просто установка куды и на линуксе немного заморочная, особенно для новичка. 
Все через это проходили."
"1. Человек пришел с техническим вопросом без трейсбека, объяснения ситуации и даже не сказал что у него за ОС.
2. nvidia-smi - это как?
3. Exit code 0
Да много деталей. 

Я не глумлюсь, я просто удивлен что зеленому новичку еще никто убунту поставить не посоветовал
Хотя говорить что под WSL все можно сделать примерно того же уровня совет",Спасибо за поддержку. 👍,"Не, правда. Если у тебя какие-то проектики небольшие и горят сроки, то попробуй гугл колаб или каггловские ноутбуки. 
Там все бесплатно и онлайн, но ограничения по времени. 
Просто установка куды и на линуксе немного заморочная, особенно для новичка. 
Все через это проходили.","tf, кстати, плюсую. Я двое суток пытался его к винде с WSL прикрутить, в итоге по issues гитхаба по крупицам собирал решения десятка проблем, вылезших друг за другом, даже решил их, чтобы узнать, что YOLOv8 оказывается на pytorch переехал"
,,,"Уровень интеллекта - это вроде про нас было, не про автора вопроса
А стопэ, это вобще про другое."
,,"Уровень интеллекта - это вроде про нас было, не про автора вопроса
А стопэ, это вобще про другое.","Блин, я запутался кто тут за а кто против подъебов"
,"Уровень интеллекта - это вроде про нас было, не про автора вопроса
А стопэ, это вобще про другое.","Блин, я запутался кто тут за а кто против подъебов","Опять же, не хочу разводить оффтоп, в обеих ОС работал с различной степени паршивости проблемами, и с линуксом наелся очень прилично, когда при ругани на что-то из-за процессора Intel в логах они до 20 Гб+ разжирались за долю секунды, и система не запускалась, или же драйвер видеокарты, который фризил монитор через 2 минуты, и нужно было за эти две минуты заспидранить установку стороннего, официального драйвера nvidia"
,,,И это делает из тебя очень опытного юзера.
,,И это делает из тебя очень опытного юзера.,А арч вообще в зверя нахуй превращает
,И это делает из тебя очень опытного юзера.,А арч вообще в зверя нахуй превращает,
,,,"То есть, я понимаю, что если нативно сделано под линукс, это лучше, чем через WSL пристраиваться к линуксу сзади, но с ним даже как-то по ощущениям проблем поменьше)"
,,"То есть, я понимаю, что если нативно сделано под линукс, это лучше, чем через WSL пристраиваться к линуксу сзади, но с ним даже как-то по ощущениям проблем поменьше)","с wsl просто есть момент, что если возникает какая-то проблема, то зачастую дело швах потому что она слишком обскурная и никто в интернете не знает как ее фиксить"
,"То есть, я понимаю, что если нативно сделано под линукс, это лучше, чем через WSL пристраиваться к линуксу сзади, но с ним даже как-то по ощущениям проблем поменьше)","с wsl просто есть момент, что если возникает какая-то проблема, то зачастую дело швах потому что она слишком обскурная и никто в интернете не знает как ее фиксить","Тут понял, благодарю"
,,,"И это тоже ставил ради интереса, но в сущности это мало что меняет, просто лучше понимаешь, как организуется система хранения файлов, какие действия в убунту или в винде делаются за нас автоматически"
,,"И это тоже ставил ради интереса, но в сущности это мало что меняет, просто лучше понимаешь, как организуется система хранения файлов, какие действия в убунту или в винде делаются за нас автоматически",в обычных линуксах с этим веселее
,,,"Но в действительности мой вопрос в том, реально ли WSL заменить линукс полностью, потому что мне Win11 по всем штукам очень зашла, а ставить две ОС рядом – это смерть, я пытался, даже сервер времени навернулся и никакими действиями вернуть его не удалось"
,,"Но в действительности мой вопрос в том, реально ли WSL заменить линукс полностью, потому что мне Win11 по всем штукам очень зашла, а ставить две ОС рядом – это смерть, я пытался, даже сервер времени навернулся и никакими действиями вернуть его не удалось",Только эта единственная проблема с двумя ос и была - часы сбивались ибо винда и линух разные стандарты времени используют (привет начало всех времён в 70-х)
,,,Аха 👍
,,Аха 👍,Но и это фиксится вроде
,Аха 👍,Но и это фиксится вроде,у тензорфлоу все печально в целом
,,,"Нинужон, проиграл в конкурентной борьбе"
,,"Нинужон, проиграл в конкурентной борьбе","это неправда, к сожалению нужон еще много где"
,"Нинужон, проиграл в конкурентной борьбе","это неправда, к сожалению нужон еще много где",Например?
"Нинужон, проиграл в конкурентной борьбе","это неправда, к сожалению нужон еще много где",Например?,"прод много где и в отечественном, и в зарубежном бигтехе крутится на тензорфлоу"
,,,еще отдельная дисциплина специальной олимпиады это поставить рядом торч и тензорфлоу и чтоб оба работали на гпу
,,еще отдельная дисциплина специальной олимпиады это поставить рядом торч и тензорфлоу и чтоб оба работали на гпу,"У меня была такая перспектива, как раз хорошая реализация YOLO на pytorch, а DeepSort на tf

Но я подумал, что это будет извращением и породит только больше проблем

И увидев, насколько pytorch удобнее и тупо с двух-трех команд работает, прибился к нему"
,,,Одновременно
,,Одновременно,именно
,,,"для инференса под мобилки тензорфлоу лайт все еще одно из лучших решений, торч мобайл в плане перфа сильно позади"
,,"для инференса под мобилки тензорфлоу лайт все еще одно из лучших решений, торч мобайл в плане перфа сильно позади","Ну про мобилки может и да, гугел вроде в своих пикселях специально тензор-оптимизированные процессы пихает"
,,,"ну я бы тоже с удовольствием пользовался только торчем, но жизнь есть жизнь
была ситуация когда надо было запустить репу, использующую одновременно торч и тензорфлоу 1.х, один из худших опытов в моей жизни"
,,,А почему pytorch  через conda не посоветовали поставить? Там автоматом правильные версии подбираются
,,А почему pytorch  через conda не посоветовали поставить? Там автоматом правильные версии подбираются,"Я так и не понял, как там все точно работает, но часть ставится через pypi, часть через конду и в совокупности все пашет"
,,,Конда куду не поставит
,,Конда куду не поставит,торч сейчас сам все тянет
,,,Если поставит то я охуею
,,Если поставит то я охуею,"Под линухом кстати ставит
Не советовал, потому что не знаю что под виндой творится."
,Если поставит то я охуею,"Под линухом кстати ставит
Не советовал, потому что не знаю что под виндой творится.",Да ставит
Если поставит то я охуею,"Под линухом кстати ставит
Не советовал, потому что не знаю что под виндой творится.",Да ставит,До чего дошел прогресс!
"Под линухом кстати ставит
Не советовал, потому что не знаю что под виндой творится.",Да ставит,До чего дошел прогресс!,"с собой
куду руками для него ставить не надо"
Да ставит,До чего дошел прогресс!,"с собой
куду руками для него ставить не надо","Но куда это же не питоновский пакет, а конда ставит только их?"
До чего дошел прогресс!,"с собой
куду руками для него ставить не надо","Но куда это же не питоновский пакет, а конда ставит только их?","Если правильно помню, у меня конда все сама поставила с pytorch, когда аналогичные проблемы были. На убунте правда"
"с собой
куду руками для него ставить не надо","Но куда это же не питоновский пакет, а конда ставит только их?","Если правильно помню, у меня конда все сама поставила с pytorch, когда аналогичные проблемы были. На убунте правда","conda же, она либы ставить умеет (и если заглянешь в коробку делает это).
Но тут проблема, у человека на скринах venv, и плодить сущности дело такоэ"
,,,Падажщи. Ты хочешь сказать что я могу поставить себе 5 conda env с 5 разными кудами и это все будет работать?
,,Падажщи. Ты хочешь сказать что я могу поставить себе 5 conda env с 5 разными кудами и это все будет работать?,
,,,Да)
,,,А почему нет?)
,,А почему нет?),"Да по тысяче причин. Раньше ж почему-то ставить cuda/cudnn было очень больно: качай с оффсайта и логинься.
Это не опенсорс, черт его знает что там с лицензиями на распространение."
,,,"Ну, я полагал потому что куда на уровне драйверов обитает"
,,"Ну, я полагал потому что куда на уровне драйверов обитает","У меня одна куда, но разные cudnn.
Nope, куды ты можешь N штук поставить и рулить версией при запуске скриптов через LD_LIBRARY_PATH/CUDA_PATH и т.д"
,"Ну, я полагал потому что куда на уровне драйверов обитает","У меня одна куда, но разные cudnn.
Nope, куды ты можешь N штук поставить и рулить версией при запуске скриптов через LD_LIBRARY_PATH/CUDA_PATH и т.д","Справедливости ради скажу, что после установки через конду действительно для решения какой-то из проблем нужно было лезть в файлы, лежащие в системных папках, примерно lib что-то там 8, уже забыл. И это было не в конде и не где-либо еще"
"Ну, я полагал потому что куда на уровне драйверов обитает","У меня одна куда, но разные cudnn.
Nope, куды ты можешь N штук поставить и рулить версией при запуске скриптов через LD_LIBRARY_PATH/CUDA_PATH и т.д","Справедливости ради скажу, что после установки через конду действительно для решения какой-то из проблем нужно было лезть в файлы, лежащие в системных папках, примерно lib что-то там 8, уже забыл. И это было не в конде и не где-либо еще","Прикольно. У меня тут одна выебистая библиотека только с 9 кудой работает и я в виртуальную машину всё это пихал
A в PATH из этих 5 кто запишется?"
,,,Если я без конды потом просто позову nvidia-smi будет command not found?
,,Если я без конды потом просто позову nvidia-smi будет command not found?,nvidia-smi может приехать и с каким-то другим пакетом
,,,"Nope, в Path ничего не пишется.
Наружу не торчит
У меня есть тачка без установленной системно куды. LD_LIBRARY_PATH пустой.
Но в торче в нужном окружении gpu есть."
,,,"Бывает что нужно доставить либу. Надо пересобирать контейнер. Если команда, то этих контейнров разводится зоопарк с разными версиями и комбинациями либ. И не всегда удобно через jupyter работать, иногда нужно уметь какие-то CLI инструменты запускать, например, конвертировать файлы через ffmpeg."
,,"Бывает что нужно доставить либу. Надо пересобирать контейнер. Если команда, то этих контейнров разводится зоопарк с разными версиями и комбинациями либ. И не всегда удобно через jupyter работать, иногда нужно уметь какие-то CLI инструменты запускать, например, конвертировать файлы через ffmpeg.","а, ну это понятно. Тут у кого какая боль. Мне вот нравится, когда вся эта шелуха рассована по контейнерам, а не по ОС.
Что касается работы через jupyter, так это я просто предложил позапускать, можно ж в контейнер и через терминал залезть и кайфовать опять же, почти как на голой ОС. А вообще, седьмая степень балдежа (наивысшая), это подключать IDE к докеру, чтоб и скрипты писать, и Jupyter. Вот сейчас пишу это всё и слюна выделяется"
,,,"У меня прямо полно граблей с docker/nvidia-docker'ом собрано.
1. надо уметь сильно больше чем docker run чтобы то что создается из-под докера имела того же овнера, что в системе живет
2. бесконтрольно растущий /var/lib/docker в какой-то момент уронит сервер или какие-нибудь сервисы (или не даст залогиниться, если система стоит на том же SSD что и хомяк)
3. Если ты умник, который перекинул докерную папку в конфиге на большой HDD, лови неконтролируемые просадки IO перфа
4. related to 1: на коммунальных серверах карточки будут заняты root'ами, и поди догадайся где чье.

Чтобы писать сами докер-файлы надо иметь гораздо более продвинутую модель линукса в голове, чем при жизни в обычной убунте.
Имхо на каком-то этапе развития просто отказываешься от этого всего и нормально настраиваешь окружение."
,,"У меня прямо полно граблей с docker/nvidia-docker'ом собрано.
1. надо уметь сильно больше чем docker run чтобы то что создается из-под докера имела того же овнера, что в системе живет
2. бесконтрольно растущий /var/lib/docker в какой-то момент уронит сервер или какие-нибудь сервисы (или не даст залогиниться, если система стоит на том же SSD что и хомяк)
3. Если ты умник, который перекинул докерную папку в конфиге на большой HDD, лови неконтролируемые просадки IO перфа
4. related to 1: на коммунальных серверах карточки будут заняты root'ами, и поди догадайся где чье.

Чтобы писать сами докер-файлы надо иметь гораздо более продвинутую модель линукса в голове, чем при жизни в обычной убунте.
Имхо на каком-то этапе развития просто отказываешься от этого всего и нормально настраиваешь окружение.","@Alex, а можешь развить тему ""Если ты умник, который перекинул докерную папку в конфиге на большой HDD, лови неконтролируемые просадки IO перфа""? Какую папку куда не следует прокидывать? А то я, похоже, ловлю ""просадки IO перфа"" и не понимаю почему."
,"У меня прямо полно граблей с docker/nvidia-docker'ом собрано.
1. надо уметь сильно больше чем docker run чтобы то что создается из-под докера имела того же овнера, что в системе живет
2. бесконтрольно растущий /var/lib/docker в какой-то момент уронит сервер или какие-нибудь сервисы (или не даст залогиниться, если система стоит на том же SSD что и хомяк)
3. Если ты умник, который перекинул докерную папку в конфиге на большой HDD, лови неконтролируемые просадки IO перфа
4. related to 1: на коммунальных серверах карточки будут заняты root'ами, и поди догадайся где чье.

Чтобы писать сами докер-файлы надо иметь гораздо более продвинутую модель линукса в голове, чем при жизни в обычной убунте.
Имхо на каком-то этапе развития просто отказываешься от этого всего и нормально настраиваешь окружение.","@Alex, а можешь развить тему ""Если ты умник, который перекинул докерную папку в конфиге на большой HDD, лови неконтролируемые просадки IO перфа""? Какую папку куда не следует прокидывать? А то я, похоже, ловлю ""просадки IO перфа"" и не понимаю почему.","У меня была тачка на которой в какой-то момент вынесли содержимое /var/lib/docker на большой HDD, а то SSD с системой и хомяками забивался и что-нибудь неприятно падало.
И я стал эпизодически ловить фризы, глазами это выглядело как внезапно долгий отклик nvidia-smi или даже ls (в баше в докере)
А так во время обучения ловили просадки steps per second. Глубоко лезть не стали и как-то обошли.

Совсем недавно у меня был сервак с похожими симптомами, только без докера. После обновлений обращение к некоторым дискам стало долго откликаться - похоже на режим энергосбережения для дисков. Но я не знаю связанны ли эти истории."
,,,"Я человеку выше обозначил, что это не на краткосрок, но и превращать докер в священную технологию из темной эры тоже не стоит. Хотя я уже понял, что следовало пояснить, что самым важным я считаю знакомство с линуксами, а то у меня уже сложилось впечатление, что я порекомендовал человеку стать senior mlops, чтоб запустить что-то на 2060s"
,,,"Есть много вариантов как продвинуться: ubuntu, docker, conda, пересесть на облака. 
Разные решения прячут разные сложности, но порог входа все равно есть.
Можно дотолкать уже запуск под виндой. Пересесть на докер – это все начинать сначала, только с новыми правилами"
,,"Есть много вариантов как продвинуться: ubuntu, docker, conda, пересесть на облака. 
Разные решения прячут разные сложности, но порог входа все равно есть.
Можно дотолкать уже запуск под виндой. Пересесть на докер – это все начинать сначала, только с новыми правилами","лучше начинать всё сначала, чем продолжать путь в никуда, имхо"
,,,"*когда ждешь, что админ прекратит срачи про установку зависимостей и cuda в разделе про CV и сделает отдельный раздел, куда все умники скинут свои туториалы*"
,,"*когда ждешь, что админ прекратит срачи про установку зависимостей и cuda в разделе про CV и сделает отдельный раздел, куда все умники скинут свои туториалы*",пингуйте хоть
,,,"в общем, я придумал мем. Потраченного времени, конечно, жаль"
,,"в общем, я придумал мем. Потраченного времени, конечно, жаль","Сижу на винде чтобы в игоры играть хоть иногда, работа на серваке с подключением через VS code"
,"в общем, я придумал мем. Потраченного времени, конечно, жаль","Сижу на винде чтобы в игоры играть хоть иногда, работа на серваке с подключением через VS code","Тоже иногда так делаю)
На одном монике игра, на другом vscode с ssh/колаб"
,,,(ubuntu(16))
,,(ubuntu(16)),"Брат жив, зависимости нету"
,,,"Привет, где почитать про Tacotron и какие-нибудь ноутбуки для него. У меня задача по практике поменять там 1 слой и посмотреть что будет"
,,"Привет, где почитать про Tacotron и какие-нибудь ноутбуки для него. У меня задача по практике поменять там 1 слой и посмотреть что будет",https://github.com/uberduck-ai/uberduck-ml-dev
,,,На основе знания в LLM
,,,"пока не понимаю, что на практике надо сделать. вроде BERT не учится отвечать и продолжать текст. Он обучается для MLM и NSP"
,,"пока не понимаю, что на практике надо сделать. вроде BERT не учится отвечать и продолжать текст. Он обучается для MLM и NSP",На практике над взять и почитать retrieval+llm
,,,мне надо дообучить SBERT на задачу NSP для моего корпуса знаний?
,,мне надо дообучить SBERT на задачу NSP для моего корпуса знаний?,"И тогда понимание придет
Гуглите сударь"
,мне надо дообучить SBERT на задачу NSP для моего корпуса знаний?,"И тогда понимание придет
Гуглите сударь","спасибо)
ну в любом случае из вариантов с langchain+embeddings, использования sbert и классического fine-tune обычной LLM на своих знаниях - третий вариант вообще не катит?"
мне надо дообучить SBERT на задачу NSP для моего корпуса знаний?,"И тогда понимание придет
Гуглите сударь","спасибо)
ну в любом случае из вариантов с langchain+embeddings, использования sbert и классического fine-tune обычной LLM на своих знаниях - третий вариант вообще не катит?","А зачем тебе langchain тут, достаточно просто prompt нормального"
"И тогда понимание придет
Гуглите сударь","спасибо)
ну в любом случае из вариантов с langchain+embeddings, использования sbert и классического fine-tune обычной LLM на своих знаниях - третий вариант вообще не катит?","А зачем тебе langchain тут, достаточно просто prompt нормального",Это я к своему старому вопросу
,,,"Если в претрене не было этой датки
Alignment не поможет
Останется тогда делать файнтюн разве что"
,,,"Про то, что есть в модели Сбера над смотреть по статьям Сбера и данным которые они юзали для обучения"
,,"Про то, что есть в модели Сбера над смотреть по статьям Сбера и данным которые они юзали для обучения",сберовский гигачат точно не знает о нашем CAD)
,"Про то, что есть в модели Сбера над смотреть по статьям Сбера и данным которые они юзали для обучения",сберовский гигачат точно не знает о нашем CAD),Дык в статье о претрене и не было такого источника указано
,,,"да, про это вопрос. взять русскую модельку, зафайнтюнить ее на справку по нашей CAD системе. И ребята с чата отвечали, что будут галюцинации в таком случае"
,,"да, про это вопрос. взять русскую модельку, зафайнтюнить ее на справку по нашей CAD системе. И ребята с чата отвечали, что будут галюцинации в таком случае","Я бы лучше делал retrieval + LLM по документации, чтобы модель не выдумывала. Так и LLM нужна меньше и надежность выше"
,"да, про это вопрос. взять русскую модельку, зафайнтюнить ее на справку по нашей CAD системе. И ребята с чата отвечали, что будут галюцинации в таком случае","Я бы лучше делал retrieval + LLM по документации, чтобы модель не выдумывала. Так и LLM нужна меньше и надежность выше",Все равно выдумает
"да, про это вопрос. взять русскую модельку, зафайнтюнить ее на справку по нашей CAD системе. И ребята с чата отвечали, что будут галюцинации в таком случае","Я бы лучше делал retrieval + LLM по документации, чтобы модель не выдумывала. Так и LLM нужна меньше и надежность выше",Все равно выдумает,"Да но надежность выше, т.к. можно узнать на какой документ модель ссылается (или даже на какую его часть, если они индексируются). У сбера видел также прям указанние после работы LLM куда смотреть, чтобы проверять результат, но как они это сделали не в курсе."
"Я бы лучше делал retrieval + LLM по документации, чтобы модель не выдумывала. Так и LLM нужна меньше и надежность выше",Все равно выдумает,"Да но надежность выше, т.к. можно узнать на какой документ модель ссылается (или даже на какую его часть, если они индексируются). У сбера видел также прям указанние после работы LLM куда смотреть, чтобы проверять результат, но как они это сделали не в курсе.",Оно и без ЛЛМ так работало
,,,"Поэтому посоветовали ещё и БД рядом положить видимо
И к ней ретривить"
,,"Поэтому посоветовали ещё и БД рядом положить видимо
И к ней ретривить","Это о-енно здорово, надеюсь скоро смогу выбросить весь зелёный хлам на помойку (где ему и место)"
,"Поэтому посоветовали ещё и БД рядом положить видимо
И к ней ретривить","Это о-енно здорово, надеюсь скоро смогу выбросить весь зелёный хлам на помойку (где ему и место)",Пример retrieve + llm есть в чате выше space от Ильи Гусева
,,,"да, уже смотрю. пока что-то нерелевантные куски pfd находит"
,,"да, уже смотрю. пока что-то нерелевантные куски pfd находит","Она и будет их находить. Чтобы завести ретривер этот, нужно сильно постараться и там будет далеко не 10 строчек"
,,,"а не проще тут без всяких нейросетей просто в коде проанализировать. если есть какие-то ответы от retrieve - составляем промт для llm, если нет - пишем пользователю, что данных не найдено"
,,"а не проще тут без всяких нейросетей просто в коде проанализировать. если есть какие-то ответы от retrieve - составляем промт для llm, если нет - пишем пользователю, что данных не найдено","А как понять, есть он или нет :("
,,,От retrieve всегда есть. С разными cosine similarity
,,От retrieve всегда есть. С разными cosine similarity,"а, поняла"
,,,"реализовать retrieve+rerank сможет 1 человек, который вот только щас начнет учиться ML?)))"
,,"реализовать retrieve+rerank сможет 1 человек, который вот только щас начнет учиться ML?)))","Да... Там пример есть на sbert.net, можно адаптировать. Модели поиском по чату выше можно найти. По ""mmarco"""
,,,Солнечный зайчик захотел ртх….
,,,"и так смотрю, модельки не очень прям большие. средняя компания на своей инфраструктуре потянет"
,,"и так смотрю, модельки не очень прям большие. средняя компания на своей инфраструктуре потянет","Вы учитите что reasoning не будет. То есть найдете документы +/-, но на ответ ""почему"" будет найдено предложение, а не ответ.

То есть условно ""кот запрыгнул на диван чтобы его погладили"", по запросу ""почему кот на диване"" - будет в лучшем случае исходное предложение. С LLM - полноценный ответ"
,,,и нам нужен полноценный ответ
,,и нам нужен полноценный ответ,Ну... успехов... Rerank - это не про генерацию...
,,,ну на первый взгляд проблему можно решить промтом для LLM
,,ну на первый взгляд проблему можно решить промтом для LLM,"Еали пользователи обычные люди, то проект они закопают"
,,,"или через few-shot learning
инженеры-проектировщики"
,,,так а если тогда все же прям fine-tune для большой модели сделать на своем большом корпусе знаний? все равно будут галюцинации?
,,так а если тогда все же прям fine-tune для большой модели сделать на своем большом корпусе знаний? все равно будут галюцинации?,Да не будет такого что прям 100% генеративная станет надёжной офк
,,,"Да, будут"
,,"Да, будут",спасибо всем за ответы!
,,,"Чат, а кто то считал насколько выгоднее 30б чем 7б? Ну типа, там реально так докидывает качество что выгодно держать 30б в проде?"
,,"Чат, а кто то считал насколько выгоднее 30б чем 7б? Ну типа, там реально так докидывает качество что выгодно держать 30б в проде?",А задача какая?
,,,де_генеративные чат боты
,,де_генеративные чат боты,"Если как болталка, то выше 7В нет смысла. Если как ассистент типа сайги, то 30В будет лучше в плане фактологичности и языка"
,,,"Господа, вопрос.

Нужно собрать вопросно-ответный сервис на собственном домене.
Плюс хочется из «официального канцеляризма» преобразовывать ответ в нормальный человеческий. 

Полагаю, что архитектурно это должно быть так:

Пользователь ввел вопрос,
По эмбеддингам я нашел ответ (вот тут, как по мне - самые большие трудности. Тут, как я понимаю, я должен использовать BERT)
Передал в LLM для суммаризации (видимо, я ее дообучаб тоже?).

Подскажите, где я чего верхнеуровнево не учел плюс ткните в хорошую русскую LLM. T5? 

Заранее спасибо. 


P.S. Забугорные модельки использовать нельзя ("
,,"Господа, вопрос.

Нужно собрать вопросно-ответный сервис на собственном домене.
Плюс хочется из «официального канцеляризма» преобразовывать ответ в нормальный человеческий. 

Полагаю, что архитектурно это должно быть так:

Пользователь ввел вопрос,
По эмбеддингам я нашел ответ (вот тут, как по мне - самые большие трудности. Тут, как я понимаю, я должен использовать BERT)
Передал в LLM для суммаризации (видимо, я ее дообучаб тоже?).

Подскажите, где я чего верхнеуровнево не учел плюс ткните в хорошую русскую LLM. T5? 

Заранее спасибо. 


P.S. Забугорные модельки использовать нельзя (","Для начала гляньте
https://t.me/betterdatacommunity/202/20356"
,,,"Теорию я сам знаю, практика цифры"
,,"Теорию я сам знаю, практика цифры","Но мой эксперимент с Анфисой показал, что поиск в интернете улучшает все кардинально"
,,,бизнес метрики
,,бизнес метрики,"Тут модель щас доучится, сделаю замеры качества с и без интернета"
,бизнес метрики,"Тут модель щас доучится, сделаю замеры качества с и без интернета",ну у тебя нет метрик на юзерах
,,,Все будет)
,,Все будет),нет ARPU и вот это все
,,,условно у тебя все убыточно по дефолтку
,,условно у тебя все убыточно по дефолтку,Проект же опенсурс...
,условно у тебя все убыточно по дефолтку,Проект же опенсурс...,ну у меня речь о не опенсурс
,,,"ТЗ (не только благодаря PS) выглядит если не противоречивым, то уже уровня hard вполне"
,,,"Без r', и слэш в другую сторону)"
,,"Без r', и слэш в другую сторону)","есть еще какие-нибудь варианты попробовать?

подсказка - стандартный хак с чтением через нампай работает без танцев со слешем"
,,,Ну... Походу not working. Остается жить с этим
,,Ну... Походу not working. Остается жить с этим,"дык еслиж новая либа - может и имрид починить?
(тем более если рабочее решение прямо на скрине))
проблема-то известная лет надцать как
причем с видеоридером такой проблемы нет - другие люди видимо писали
а тут - тяжелое наследие царского режима"
,Ну... Походу not working. Остается жить с этим,"дык еслиж новая либа - может и имрид починить?
(тем более если рабочее решение прямо на скрине))
проблема-то известная лет надцать как
причем с видеоридером такой проблемы нет - другие люди видимо писали
а тут - тяжелое наследие царского режима",
,,,"согласен, совсем забыл про этот бред. Скоро добавим"
,,"согласен, совсем забыл про этот бред. Скоро добавим","Пользуясь моментом, хотел бы поинтересоваться, есть ли ребята с опытом создания и поддержки библиотек? Ищу человека, который бы мог проконсультировать с этим. Знаю, что не относится к тематики данного чата - единичный запрос. Но уверен, здесь могут быть заинтересованные люди, готовые помочь."
,"согласен, совсем забыл про этот бред. Скоро добавим","Пользуясь моментом, хотел бы поинтересоваться, есть ли ребята с опытом создания и поддержки библиотек? Ищу человека, который бы мог проконсультировать с этим. Знаю, что не относится к тематики данного чата - единичный запрос. Но уверен, здесь могут быть заинтересованные люди, готовые помочь.","Прям вот помочь миль пардон... Где бы время найти на хорошее начинание.

В целом при написании библиотек основное правило - максимум ООП, что есть в языке. Это залог расширяемости и поддерживаемости.

Хороший пример scikit learn"
,,,"хмм, интересно, обычно проблем с этим не возникало, в том же колабе
давайте создам чат, туда можно задавать вопросы по библе
чтобы тут не засорять"
,,,"Гайз, а есть кто во Вьетнаме/тае сейчас? Завтра лечу визаранить в Бали, и хотел бы спросить пару вопросов в духе как там дела с визами на случай если не выйдет обратно влететь"
,,"Гайз, а есть кто во Вьетнаме/тае сейчас? Завтра лечу визаранить в Бали, и хотел бы спросить пару вопросов в духе как там дела с визами на случай если не выйдет обратно влететь","В Тае иззи студенческая виза. 60к бат в год, зависит от школы"
,,,"Т.е. основной смысл в том, чтобы сначала выполнять классический поиск для локализации источника инфы, а потом его и вопрос закидывать в prompt"
,,,"Привет всем! Извиняюсь, если уже спрашивали, но у меня такой вопрос: знаете модель (или скрипт) для русского языка, которая определяет текст на соответствие правилам приличия, законам ? Грубо говоря фильтр. Здесь речь не совсем про токсичность. Нужно  чтобы определяла, есть ли в тексте разговоры о Гитлере, матершинные слова,  сексуальный подтекст, расы, политика и др."
,,"Привет всем! Извиняюсь, если уже спрашивали, но у меня такой вопрос: знаете модель (или скрипт) для русского языка, которая определяет текст на соответствие правилам приличия, законам ? Грубо говоря фильтр. Здесь речь не совсем про токсичность. Нужно  чтобы определяла, есть ли в тексте разговоры о Гитлере, матершинные слова,  сексуальный подтекст, расы, политика и др.","Вот тут есть две модели, одна выделяет разные потенциально опасные темы, другая - определяет бинарно, является ли даннный текст неприемлемым (ибо не любой текст на опасную тему сам по себе плох).
https://github.com/s-nlp/inappropriate-sensitive-topics"
,,,"Привет всем)

Может кто знает, 
Какие есть способы быстро разметить датасэты такого вида?"
,,"Привет всем)

Может кто знает, 
Какие есть способы быстро разметить датасэты такого вида?",if x > 2e4 -> class = 2 elif x > 1e4 -> class = 1 else 0?
,"Привет всем)

Может кто знает, 
Какие есть способы быстро разметить датасэты такого вида?",if x > 2e4 -> class = 2 elif x > 1e4 -> class = 1 else 0?,"Я хочу сделать функционал для разметчиков, чтоб  мышкой выбирать разные кластера, группы и назначать им метки."
,,,Спасибо)
,,,а где у сбера? можешь ссылку дать глянуть?
,,а где у сбера? можешь ссылку дать глянуть?,"Ссылки нет, ходили в сбер с тех. визитом. То, о чем я говорю - это подсистема SberIDP"
,а где у сбера? можешь ссылку дать глянуть?,"Ссылки нет, ходили в сбер с тех. визитом. То, о чем я говорю - это подсистема SberIDP",Ну там надо понимать очень серьёзно сделана система поиска
,,,"А ЛЛМ ток занимается сублимацией того, что нашёл ретривер"
,,"А ЛЛМ ток занимается сублимацией того, что нашёл ретривер","Именно так, да. По сути там LLM работает только с содержанием найденного дока (или его части) как с промтом для формирования ответа на вопрос."
,"А ЛЛМ ток занимается сублимацией того, что нашёл ретривер","Именно так, да. По сути там LLM работает только с содержанием найденного дока (или его части) как с промтом для формирования ответа на вопрос.","Но всё равно, без этого да ЛЛМ хуже по фактологии, но даже с подсказкой оно не гарантирует 100% достоверности"
"А ЛЛМ ток занимается сублимацией того, что нашёл ретривер","Именно так, да. По сути там LLM работает только с содержанием найденного дока (или его части) как с промтом для формирования ответа на вопрос.","Но всё равно, без этого да ЛЛМ хуже по фактологии, но даже с подсказкой оно не гарантирует 100% достоверности","Ну это понятно, но тут вопрос бизнес-процесса уже. Надежнее в смысле, что пользак может перепроверить результаты модели"
"Именно так, да. По сути там LLM работает только с содержанием найденного дока (или его части) как с промтом для формирования ответа на вопрос.","Но всё равно, без этого да ЛЛМ хуже по фактологии, но даже с подсказкой оно не гарантирует 100% достоверности","Ну это понятно, но тут вопрос бизнес-процесса уже. Надежнее в смысле, что пользак может перепроверить результаты модели","Пользак это делать не хочет, пользак хочет сразу дай мне надёжный ответ, я его не проверяя пойду использовать"
"Но всё равно, без этого да ЛЛМ хуже по фактологии, но даже с подсказкой оно не гарантирует 100% достоверности","Ну это понятно, но тут вопрос бизнес-процесса уже. Надежнее в смысле, что пользак может перепроверить результаты модели","Пользак это делать не хочет, пользак хочет сразу дай мне надёжный ответ, я его не проверяя пойду использовать",Тогда это не про LLM в текущем виде вообще ни разу
"Ну это понятно, но тут вопрос бизнес-процесса уже. Надежнее в смысле, что пользак может перепроверить результаты модели","Пользак это делать не хочет, пользак хочет сразу дай мне надёжный ответ, я его не проверяя пойду использовать",Тогда это не про LLM в текущем виде вообще ни разу,Или про систему поддержки принятия решений
"Пользак это делать не хочет, пользак хочет сразу дай мне надёжный ответ, я его не проверяя пойду использовать",Тогда это не про LLM в текущем виде вообще ни разу,Или про систему поддержки принятия решений,"Да. Ну ML - это впринципе либо поддержка принятия решений, либо работа в бизнес процессе не дающем сломать что-либо ML-алгоритму своей ошибкой"
,,,"И там всё равно есть вероятность ошибки глюков и тп
Сингл система поиска по  докам у IDP работает надежнее
Смотрим доклад с SberAIDay
Никто не задумывался почему Яндекс не использует свой YAlM в местах где требуется надёжность ответа) а это важный вопрос. Даже почитав пост про YALM на Хабре с примерам где они её юзают , понимаешь, что она подсобна иным алго более детерминированным в Алисе. И новые УаГПт ака Ялм2.0 даже навык вызывает через ""давай придумаем""
Если это не система поддержки принятия решений"
,,,"На таком же принципе работает поисковик. Да решение конечное за тобой, но много ли вы перепроверяете выдачу?)"
,,"На таком же принципе работает поисковик. Да решение конечное за тобой, но много ли вы перепроверяете выдачу?)",много)
,,,"вообще с галюцинациями все ОК в HUMATA, например"
,,"вообще с галюцинациями все ОК в HUMATA, например","Это система, а не сингл ллм"
,,,"если там задать вопрос, ответа на который нет в документах, сервис так и ответит, что в предоставленных документах информации не нашел"
,,"если там задать вопрос, ответа на который нет в документах, сервис так и ответит, что в предоставленных документах информации не нашел",Кстати если нет инфо в доке отвечает не ллм
,"если там задать вопрос, ответа на который нет в документах, сервис так и ответит, что в предоставленных документах информации не нашел",Кстати если нет инфо в доке отвечает не ллм,"Точнее так. Идёт поиск через условный ретривал, если не нашёл идёт промт в ЛЛМ - скажи что нет ничего"
,,,и используется там GPT3.5
,,и используется там GPT3.5,А значит вокруг есть куча моделек и правил на проверку
,и используется там GPT3.5,А значит вокруг есть куча моделек и правил на проверку,"да не важно, смысл в том, что это реализуемо вполне. про сингл llm и нет речи
можно вообще поизвращаться и сначала зафайнтюнить свою LLM на нужные знания, а потом эту зафайнтюненную модель еще и в цепочке retrieval+LLM использовать)))"
,,,или retrieval+rerank+fine-tunedLLM) :D
,,или retrieval+rerank+fine-tunedLLM) :D,ЛЛМ какую бы надёжную вырезку бы ей не дал может её переврать
,,,"всем привет) поделитесь, пожалуйста, вашими способами, как фильтруете тарабарщину по типу уойипйуипйоаы йоимойий и тд? 

- делала доп классификатор на них 
- фильтровала через вхождения в общий словарь 
- пробовала фильтр по частям слова"
,,"всем привет) поделитесь, пожалуйста, вашими способами, как фильтруете тарабарщину по типу уойипйуипйоаы йоимойий и тд? 

- делала доп классификатор на них 
- фильтровала через вхождения в общий словарь 
- пробовала фильтр по частям слова","Взяли сет из сокращений, аббревиатур и тарабарщины и поверх фриз Роберты обучили mlp"
,,,"Я не фильтрую, но по идее прогнать bert и получить confidence каждого слова. Наверняка их можно будет оттресхолдить"
,,"Я не фильтрую, но по идее прогнать bert и получить confidence каждого слова. Наверняка их можно будет оттресхолдить",Берт для классификации тарабарщина или нет или для другой какой-то задачи и потом по токенам на скоры смотреть?
,,,Аннотатор обучаем
,,,Вот что за люди ищут золотую пулю в ллм
,,Вот что за люди ищут золотую пулю в ллм,по вашему такую задачу вообще не стоит делать?
,Вот что за люди ищут золотую пулю в ллм,по вашему такую задачу вообще не стоит делать?,"Стоит, но сделать правильно архитектуру системы"
Вот что за люди ищут золотую пулю в ллм,по вашему такую задачу вообще не стоит делать?,"Стоит, но сделать правильно архитектуру системы","это понятно. нам для продакшена... и на коленке делать это мы не будем. у меня пока цель просто оценить возможность реализации такой фичи. грубо говоря ответить на вопрос, а стоит ли вообще начинать? и сколько будет стоить, что еще не мало важно"
,,,В нашем собеседнике норм работает
,,В нашем собеседнике норм работает,"интересные 1 и 3 подходы, по перпрлексии не фильтровала,  спасибо)"
,В нашем собеседнике норм работает,"интересные 1 и 3 подходы, по перпрлексии не фильтровала,  спасибо)",подскажите пожалуйста подходы по клонированию поведения личности путем обучения на текстовых данных. Какие сейчас модели для этого лучше подходят и в целом SOTA подходы для этого. Заранее благодарю
В нашем собеседнике норм работает,"интересные 1 и 3 подходы, по перпрлексии не фильтровала,  спасибо)",подскажите пожалуйста подходы по клонированию поведения личности путем обучения на текстовых данных. Какие сейчас модели для этого лучше подходят и в целом SOTA подходы для этого. Заранее благодарю,"Хай. 
Есть кто-нибудь с опытом работы Dash? 
 Интерфейс пишу, глюки ловлю)
Если подробнее, то PIL Image не отрисовывается через plotly.express.imshow() хотя должно, вроде"
,,,"Всем привет!
Делаю распознавание штрихкодов на нейронке и делаю по голове для каждой цифры кода вот так:"
,,"Всем привет!
Делаю распознавание штрихкодов на нейронке и делаю по голове для каждой цифры кода вот так:",Просто у меня при инференсе баг вылазит очень странный
,,,"Это правильно, или я что-то делаю не так?"
,,"Это правильно, или я что-то делаю не так?","Ты делаешь прямо много супер-странных вещей.
1. Что такое ctrl_code?
2. Что у тебя за лосс?
3. Почему голов 10?.. в штрихкоде не 10 же цифр.
...

> Ответ модели зависит от размера батча почему-то
где-то ошибаешься с размерностями, но это проще простого если мешать туплы и тензоры"
,"Это правильно, или я что-то делаю не так?","Ты делаешь прямо много супер-странных вещей.
1. Что такое ctrl_code?
2. Что у тебя за лосс?
3. Почему голов 10?.. в штрихкоде не 10 же цифр.
...

> Ответ модели зависит от размера батча почему-то
где-то ошибаешься с размерностями, но это проще простого если мешать туплы и тензоры",А как не через tuple вернуть ответы голов?
"Это правильно, или я что-то делаю не так?","Ты делаешь прямо много супер-странных вещей.
1. Что такое ctrl_code?
2. Что у тебя за лосс?
3. Почему голов 10?.. в штрихкоде не 10 же цифр.
...

> Ответ модели зависит от размера батча почему-то
где-то ошибаешься с размерностями, но это проще простого если мешать туплы и тензоры",А как не через tuple вернуть ответы голов?,Сконкатенировать тензор?
,,,Обучаю вот так:
,,Обучаю вот так:,Замечание чисто по коду: было бы лучше использовать nn.ModuleList в этом случае
,,,Ответ модели зависит от размера батча почему-то
,,Ответ модели зависит от размера батча почему-то,"Вот это не понятно все равно.
А когда предикт делаешь модельку в eval переключаешь?"
,Ответ модели зависит от размера батча почему-то,"Вот это не понятно все равно.
А когда предикт делаешь модельку в eval переключаешь?","Я дурак, извиняюсь, за такое. Переключил, теперь всё норм работает"
Ответ модели зависит от размера батча почему-то,"Вот это не понятно все равно.
А когда предикт делаешь модельку в eval переключаешь?","Я дурак, извиняюсь, за такое. Переключил, теперь всё норм работает","Да ну, хорошо что так легко разрешилось)
Искать перепутанные размерности в тензорах из туплов то еще удовольствие)"
,,,"1. Это контрольная цифра (т.е там 10 основных цифр и одна контрольная)
2. К каждой голове применяю CrossEntropyLoss
3. В данных штрихкодах всегда 10 цифр"
,,"1. Это контрольная цифра (т.е там 10 основных цифр и одна контрольная)
2. К каждой голове применяю CrossEntropyLoss
3. В данных штрихкодах всегда 10 цифр",а у контрольной цифры точно 103 допустимых значения?
,"1. Это контрольная цифра (т.е там 10 основных цифр и одна контрольная)
2. К каждой голове применяю CrossEntropyLoss
3. В данных штрихкодах всегда 10 цифр",а у контрольной цифры точно 103 допустимых значения?,Да
,,,Там взвешенная на позицию элемента контрольная сумма считается и контрольная цифра - это остаток от деления на 103
,,Там взвешенная на позицию элемента контрольная сумма считается и контрольная цифра - это остаток от деления на 103,"Ты же сам пишешь, это не мултикласс. Тебе важно чтобы i-ая голова правильно предсказала i-ую по счету цифру, а не абстрактное наличие цифр"
,,,Поэтому там их может быть 103 допустимых значения
,,,"Замени все головы на ОДНУ суммарной размерности (10 * 10 + 103), полученный тензор рейшейпь/распиливай на отдельные предикты. 
Скажем первые 100 превратить в [bs, classes, digits], остальные в [bs, possible_values], сложи в словарь, возвращай словарь.
> так у тебя будет и код читабельные и тензора
Алсо, покажи подсчет лосса, а то выглядит сомнительно."
,,"Замени все головы на ОДНУ суммарной размерности (10 * 10 + 103), полученный тензор рейшейпь/распиливай на отдельные предикты. 
Скажем первые 100 превратить в [bs, classes, digits], остальные в [bs, possible_values], сложи в словарь, возвращай словарь.
> так у тебя будет и код читабельные и тензора
Алсо, покажи подсчет лосса, а то выглядит сомнительно.","Окей, попробую, спасибо"
,,,"Что еще странно: self.backbone = ...
avgpool выбросит всю пространственную информацию, а она важна в твоей задаче"
,,"Что еще странно: self.backbone = ...
avgpool выбросит всю пространственную информацию, а она важна в твоей задаче",Это от EffNet оставил
,,,"Так там небось классификацию решали (в которой пространственная информация в глубоких слоях уже не важна), а ты хочешь последовательность цифр доставать"
,,"Так там небось классификацию решали (в которой пространственная информация в глубоких слоях уже не важна), а ты хочешь последовательность цифр доставать","Да, но тут то я как бы цифры независимо предсказываю"
,,,Что похоже на мультиклассовую классификацию
,,Что похоже на мультиклассовую классификацию,Так что adaptive avg pool (чтобы фиксированного размера выход получался) + flatten(чтобы порядок не терять)
,,,"Если это действительно сетка с имаджнета,  интересно было бы узнать, какая интуиция для выбора этой сетки в качестве экстрактора фичей для штрихкодов"
,,"Если это действительно сетка с имаджнета,  интересно было бы узнать, какая интуиция для выбора этой сетки в качестве экстрактора фичей для штрихкодов",https://arxiv.org/pdf/2004.06297.pdf
,"Если это действительно сетка с имаджнета,  интересно было бы узнать, какая интуиция для выбора этой сетки в качестве экстрактора фичей для штрихкодов",https://arxiv.org/pdf/2004.06297.pdf,"я не сомневаюсь, что оно может заработать, даже уверен, что это можно сделать существенно лучше рандома, но почему-то кажется, что могут быть варианты получше, чем выход последней свертки сетки с имаджнета (ну или глобал пулинга) учитывая специфику вашей задачи и т.к. свертка там обучалась так, чтобы работала классификация на имаджнете.
Например, что вы думаете насчёт того, чтобы не брать всю сетку, а только первые k слоев, заморозить их и дообучить не только линейный классификатор, но и свой сверточный блок? Более того, как выше справедливо заметили, вам действительно нужна пространственная информация, вы сможете написать что-то, что вам больше подходит, чем  global average pooling. Но, конечно, сначала есть смысл попробовать то, что сделать быстрее всего)"
"Если это действительно сетка с имаджнета,  интересно было бы узнать, какая интуиция для выбора этой сетки в качестве экстрактора фичей для штрихкодов",https://arxiv.org/pdf/2004.06297.pdf,"я не сомневаюсь, что оно может заработать, даже уверен, что это можно сделать существенно лучше рандома, но почему-то кажется, что могут быть варианты получше, чем выход последней свертки сетки с имаджнета (ну или глобал пулинга) учитывая специфику вашей задачи и т.к. свертка там обучалась так, чтобы работала классификация на имаджнете.
Например, что вы думаете насчёт того, чтобы не брать всю сетку, а только первые k слоев, заморозить их и дообучить не только линейный классификатор, но и свой сверточный блок? Более того, как выше справедливо заметили, вам действительно нужна пространственная информация, вы сможете написать что-то, что вам больше подходит, чем  global average pooling. Но, конечно, сначала есть смысл попробовать то, что сделать быстрее всего)",А есть ли смысл брать предобученные первые слои?
https://arxiv.org/pdf/2004.06297.pdf,"я не сомневаюсь, что оно может заработать, даже уверен, что это можно сделать существенно лучше рандома, но почему-то кажется, что могут быть варианты получше, чем выход последней свертки сетки с имаджнета (ну или глобал пулинга) учитывая специфику вашей задачи и т.к. свертка там обучалась так, чтобы работала классификация на имаджнете.
Например, что вы думаете насчёт того, чтобы не брать всю сетку, а только первые k слоев, заморозить их и дообучить не только линейный классификатор, но и свой сверточный блок? Более того, как выше справедливо заметили, вам действительно нужна пространственная информация, вы сможете написать что-то, что вам больше подходит, чем  global average pooling. Но, конечно, сначала есть смысл попробовать то, что сделать быстрее всего)",А есть ли смысл брать предобученные первые слои?,Просто сейчас мы с нуля её всю обучаем
,,,Тут авторы говорили о любом экстракторе
,,,Иначе сделал бы всего одну голову с 10 выходами и решал бы бинарную классификацию == есть такая цифра в ответе или нет.
,,Иначе сделал бы всего одну голову с 10 выходами и решал бы бинарную классификацию == есть такая цифра в ответе или нет.,Так тут каждая голова об этом и будет заботиться
,,,Чтобы предсказывать свою цифру
,,Чтобы предсказывать свою цифру,а разве при это подходе не нужно ОЧЕНЬ сильно балансить датасет ?
,Чтобы предсказывать свою цифру,а разве при это подходе не нужно ОЧЕНЬ сильно балансить датасет ?,У меня синтетика
Чтобы предсказывать свою цифру,а разве при это подходе не нужно ОЧЕНЬ сильно балансить датасет ?,У меня синтетика,"Предобучаемся на этом, а потом реальные данные загрузим"
,,,На своей позиции
,,,И входные фичи этих голов не_содержат_пространственной_информации
,,И входные фичи этих голов не_содержат_пространственной_информации,"Да, думаю, что тут я неправильно сделал"
,И входные фичи этих голов не_содержат_пространственной_информации,"Да, думаю, что тут я неправильно сделал","Я думал, что эта информация накопится в каналах, и оттуда каждая голова сделает вывод"
И входные фичи этих голов не_содержат_пространственной_информации,"Да, думаю, что тут я неправильно сделал","Я думал, что эта информация накопится в каналах, и оттуда каждая голова сделает вывод",Это возможно. Хотя честная детекция тут была бы уместнее и не требовала бы большой датасет.
,,,"Global Average Pooling -- это взятие среднего по пространственным осям, не надо так делать, если по фичам потом надо предсказывать что-то spatial-related"
,,"Global Average Pooling -- это взятие среднего по пространственным осям, не надо так делать, если по фичам потом надо предсказывать что-то spatial-related","Но понял, что идея такая себе
В этом вы правы, пока effnet как baseline, и надо будет проверить оставить только первые несколько слоёв"
,,,"собственно, к тому, о чём я говорю, можно подвести этой картинкой"
,,"собственно, к тому, о чём я говорю, можно подвести этой картинкой","Да, я так и понял)"
,"собственно, к тому, о чём я говорю, можно подвести этой картинкой","Да, я так и понял)","очень вероятно, что да. Например, первые слои сеток с имаджнета используются как экстрактор фичей для лоссов сеток, которые делают супер резолюшн, и они работают для большого класса очень разных текстур. Они очень информативны. Это одно соображение.

Второе, первые слои обычно содержат мало сверток, что делает их очень общими, они не так ""переобучены"" на конкретный датасет, как последние"
"собственно, к тому, о чём я говорю, можно подвести этой картинкой","Да, я так и понял)","очень вероятно, что да. Например, первые слои сеток с имаджнета используются как экстрактор фичей для лоссов сеток, которые делают супер резолюшн, и они работают для большого класса очень разных текстур. Они очень информативны. Это одно соображение.

Второе, первые слои обычно содержат мало сверток, что делает их очень общими, они не так ""переобучены"" на конкретный датасет, как последние","Думаю, что вы правы. Тогда буду экспериментировать с архитектурой. Спасибо вам большое)"
,,,"А если не делать AveragePooling, то просто через flatten на линейный слой подавать?"
,,"А если не делать AveragePooling, то просто через flatten на линейный слой подавать?",Это может быть тяжело вычислительно
,"А если не делать AveragePooling, то просто через flatten на линейный слой подавать?",Это может быть тяжело вычислительно,А как тогда связать поумнее?
"А если не делать AveragePooling, то просто через flatten на линейный слой подавать?",Это может быть тяжело вычислительно,А как тогда связать поумнее?,А вам уже Alex написал)
,,,"Зависит от того насколько там большая фичемапа.
Если большая, то сначала adaptive avg pooling до разумного размера"
,,"Зависит от того насколько там большая фичемапа.
Если большая, то сначала adaptive avg pooling до разумного размера",Спасибо😊
,,,"Ага, окей"
,,"Ага, окей",Я в Дублине проездом. С удовольствием бы сходил в паб если есть тут кто
,"Ага, окей",Я в Дублине проездом. С удовольствием бы сходил в паб если есть тут кто,А ещё скажите куда ещё я могу закинуть
,,,"В label studio есть инструмент для разметки интервалов.
Для точек можно свой плагин написать."
,,"В label studio есть инструмент для разметки интервалов.
Для точек можно свой плагин написать.","раз всплыло это название, насколько удобный инструмент? в двух словах"
,"В label studio есть инструмент для разметки интервалов.
Для точек можно свой плагин написать.","раз всплыло это название, насколько удобный инструмент? в двух словах","Покликай https://labelstud.io/playground/

> и есть ли аналоги лучше?
Для разметки рядов интервалами я не видел."
,,,и есть ли аналоги лучше?
,,,"Привет. Можете, пожалуйста, посоветовать алгоритмы для сравнения человеческих лиц по наборам лендмарков? То есть по набору лендмарков лица нужно построить векторное представление с хорошими дискриминационными свойствами. Насколько я понял, это что-то из категории geometry-based face recognition"
,,"Привет. Можете, пожалуйста, посоветовать алгоритмы для сравнения человеческих лиц по наборам лендмарков? То есть по набору лендмарков лица нужно построить векторное представление с хорошими дискриминационными свойствами. Насколько я понял, это что-то из категории geometry-based face recognition",Но зачем это делать именно по лендмаркам? Обычные вектора-дескрипторы чем не подходят?
,"Привет. Можете, пожалуйста, посоветовать алгоритмы для сравнения человеческих лиц по наборам лендмарков? То есть по набору лендмарков лица нужно построить векторное представление с хорошими дискриминационными свойствами. Насколько я понял, это что-то из категории geometry-based face recognition",Но зачем это делать именно по лендмаркам? Обычные вектора-дескрипторы чем не подходят?,"Потому что задача распознавания лиц тут как showcase для системы векторного поиска. Индекс будет большой, и построить векторы для всей выборки сеткой будет дорого"
"Привет. Можете, пожалуйста, посоветовать алгоритмы для сравнения человеческих лиц по наборам лендмарков? То есть по набору лендмарков лица нужно построить векторное представление с хорошими дискриминационными свойствами. Насколько я понял, это что-то из категории geometry-based face recognition",Но зачем это делать именно по лендмаркам? Обычные вектора-дескрипторы чем не подходят?,"Потому что задача распознавания лиц тут как showcase для системы векторного поиска. Индекс будет большой, и построить векторы для всей выборки сеткой будет дорого","Есть лёгкие и быстрые модели, если проблема только в скорости. Но их дескрипторы хуже."
,,,"Не понятно.
А лендмарки откуда берутся тогда?
Задетектить лицо и предсказать N точек не дешевле чем задетектить лицо и посчитать дескриптор."
,,"Не понятно.
А лендмарки откуда берутся тогда?
Задетектить лицо и предсказать N точек не дешевле чем задетектить лицо и посчитать дескриптор.","можем быть и так, подумаю над этим. Спасибо"
,,,"ИМХО, используя только ландмарки, мы теряем много информации об объекте.  и ""хорошие дискриминационные свойства"" будут касаться исключительно ландмарок, а не лица в целом."
,,"ИМХО, используя только ландмарки, мы теряем много информации об объекте.  и ""хорошие дискриминационные свойства"" будут касаться исключительно ландмарок, а не лица в целом.","Просто сами лендмарки обычно не слишком консистентны:
- под них сложно собрать большой датасет, в отличие от простой идентичности
- их гораздо сложнее размечать, чем bbox'ы

Так что я бы ожидал качество самих ленмарок довольно плохим.
Handcrafted дескрипторы собрать то можно, но вот чтобы хорошие и проучить нужна будет разметка.

Сами лендмарки от разных [предобученных] детекторов сильно различаются."
,"ИМХО, используя только ландмарки, мы теряем много информации об объекте.  и ""хорошие дискриминационные свойства"" будут касаться исключительно ландмарок, а не лица в целом.","Просто сами лендмарки обычно не слишком консистентны:
- под них сложно собрать большой датасет, в отличие от простой идентичности
- их гораздо сложнее размечать, чем bbox'ы

Так что я бы ожидал качество самих ленмарок довольно плохим.
Handcrafted дескрипторы собрать то можно, но вот чтобы хорошие и проучить нужна будет разметка.

Сами лендмарки от разных [предобученных] детекторов сильно различаются.","Какими инструментами пользуются для разметки  данных в NLP ? В частности, интересует задача NER. Какую лучше модель брать для решения этой задачи? Как много данных нужно +- ?"
,,,"привет всем! имеется карта глубины конвейера с углем, которая в срезе имеет такую форму (скрин). есть мысли как можно измерить глубину горки? есть идея апроксимировать под ней основание (что-то типо параболой), но как реализовать непонятно"
,,"привет всем! имеется карта глубины конвейера с углем, которая в срезе имеет такую форму (скрин). есть мысли как можно измерить глубину горки? есть идея апроксимировать под ней основание (что-то типо параболой), но как реализовать непонятно",scipy find peaks
,"привет всем! имеется карта глубины конвейера с углем, которая в срезе имеет такую форму (скрин). есть мысли как можно измерить глубину горки? есть идея апроксимировать под ней основание (что-то типо параболой), но как реализовать непонятно",scipy find peaks,Сделал с этим алгоритм посмотрим насколько его точность допустимо
"привет всем! имеется карта глубины конвейера с углем, которая в срезе имеет такую форму (скрин). есть мысли как можно измерить глубину горки? есть идея апроксимировать под ней основание (что-то типо параболой), но как реализовать непонятно",scipy find peaks,Сделал с этим алгоритм посмотрим насколько его точность допустимо,"Точность будет норм, если либо лента в середине имеет плоскую форму, либо она имеет (ввиду упругости материала ленты) постоянную величину от краев провалов и пика.

Подогнать параболу можно. Но там скорее какая-нибудь лемниската или резольвента... Хз, что-то по типу.

Поэтому берете всю кривульку, заряжаете pipeline PolynomialFeatures => Ridge, вполне возможно в реалтайме. Площадь будет определенным интегралом, который можно или через scipy или через sympy (но скорее scipy) считать.

Я хотя на обогатительных угольных фабриках был, чот глядя в график тупанул, подумал про расстояние до плоскоской основы, но лента-то выгибается 😀

Ну и насыпь может быть несимметричной. Поэтому pipeline наверное самое рабочее дело"
,,,"Первым делом проверь что тебя не устраивает OpenAIApi
Оно очень дешевое быстрое и отлично делает NER"
,,"Первым делом проверь что тебя не устраивает OpenAIApi
Оно очень дешевое быстрое и отлично делает NER","Можете объяснить за ласт часть?
ICT, BFS и WLP
Это все ещё сота в информейшн ретривал: доставать наиболее актуальные параграфы по query пользователя?"
,,,Особенно интересно за Wiki Link Prediction
,,Особенно интересно за Wiki Link Prediction,"Прочту, расскажу"
,,,Но по абстракту схема неубиваемая
,,Но по абстракту схема неубиваемая,"https://link.springer.com/chapter/10.1007/978-3-031-28241-6_3

The use of clarifying questions within a search system can have a key role in improving retrieval effectiveness. The generation and exploitation of clarifying questions is an emerging area of research in information retrieval, especially in the context of conversational search.

Вот эта штука ещё очень интересна"
,,,"Чат, подкиньте sbert finetuning вот чтобы все было"
,,"Чат, подкиньте sbert finetuning вот чтобы все было","А на какой задаче и датасете хочется файнтюнить?

0) Вот тут у меня, например, есть supervised finetuning: берём параллельный корпус предложений и дообучаем на нём LaBSE сближать пары эмбеддингов для синонимичных предложений.

А если такого размеченного корпуса нет, то сформулировать хорошую unsupervised задачу для sentence encoder'а сложно. Но некоторые всё равно пытаются:
1) Можно дообучаться в формате SimCSE, то есть использовать в качестве положительной пары одно и то же предложение (вся вариация только за счет дропаута), но нет гарантии, что это улучшит качество энкодера, а не порушит его.
2) Можно дообучаться в формате автоэнкодера (восстанавливать предложение обратно из эмбеддинга, как в LASER или в моих экспериментах с LaBSE и T5), но если нет предобученного декодера, совместимого с твоим энкодером, то от этого тоже может быть больше вреда, чем пользы."
,"Чат, подкиньте sbert finetuning вот чтобы все было","А на какой задаче и датасете хочется файнтюнить?

0) Вот тут у меня, например, есть supervised finetuning: берём параллельный корпус предложений и дообучаем на нём LaBSE сближать пары эмбеддингов для синонимичных предложений.

А если такого размеченного корпуса нет, то сформулировать хорошую unsupervised задачу для sentence encoder'а сложно. Но некоторые всё равно пытаются:
1) Можно дообучаться в формате SimCSE, то есть использовать в качестве положительной пары одно и то же предложение (вся вариация только за счет дропаута), но нет гарантии, что это улучшит качество энкодера, а не порушит его.
2) Можно дообучаться в формате автоэнкодера (восстанавливать предложение обратно из эмбеддинга, как в LASER или в моих экспериментах с LaBSE и T5), но если нет предобученного декодера, совместимого с твоим энкодером, то от этого тоже может быть больше вреда, чем пользы.","Хочу попробовать сделать поиск по докуменатации, спасибо за ссылки"
,,,что имеется ввиду про схема неубиваемая?
,,,Для ru или eng?
,,Для ru или eng?,ru
,Для ru или eng?,ru,https://huggingface.co/ai-forever/sbert_large_nlu_ru
,,,И как тебе требования нужно удовлетворить?
,,И как тебе требования нужно удовлетворить?,поисковик натюнить
,И как тебе требования нужно удовлетворить?,поисковик натюнить,Или laBSE
,,,Но я думаю ты его уже дергал
,,,мне файнтюн))
,,мне файнтюн)),Мои файнтюн
,,,а код файнтюна
,,а код файнтюна,"Код тебе, ща."
,,,"Есть ли возможносять связать подход sentence document embeddings (cohere/openai) с графами знаний, для умного поиска?"
,,"Есть ли возможносять связать подход sentence document embeddings (cohere/openai) с графами знаний, для умного поиска?","Сори ребят, почистил флуд"
,"Есть ли возможносять связать подход sentence document embeddings (cohere/openai) с графами знаний, для умного поиска?","Сори ребят, почистил флуд",Я кстати кинул твой код из п0 Саше в лс
,,,А почему не рассматриваете contrastive learning для файнтюнинга ? Пара соседних предложений и рандомное предложение из другого текста в противовес?
,,А почему не рассматриваете contrastive learning для файнтюнинга ? Пара соседних предложений и рандомное предложение из другого текста в противовес?,"Так это как раз случай (0), когда есть примеры этих самых пар схожих предложений."
,,,"Можно так, но сет вообще не имеет пар, там придется повозиться с датой"
,,"Можно так, но сет вообще не имеет пар, там придется повозиться с датой","Просто не обязательно иметь параллельный корпус для этого. Достаточно просто текстов.
Соседние предложения как правило логически связаны"
,,,Кто работал с mmaction2?
,,Кто работал с mmaction2?,Начинаю работать сейчас)
,,,А известно насколько это быстрее / медленнее demucs-a?
,,А известно насколько это быстрее / медленнее demucs-a?,Не знаю 🤷🏻‍♀️
,,,"Кто знает, подскажите пожалуйста модели по численной оценке любых рус текстов. Задача: есть несколько маленьких текстов (вопросов или утверждений), и из них нужно выбрать какой-нибудь, желательно, наилучший, путем поиска наиболее качественного. Если таких моделей нет, то было бы неплохо узнать вариант с определением общей темы текста (по типу политика, наука, образование и т.д.)."
,,"Кто знает, подскажите пожалуйста модели по численной оценке любых рус текстов. Задача: есть несколько маленьких текстов (вопросов или утверждений), и из них нужно выбрать какой-нибудь, желательно, наилучший, путем поиска наиболее качественного. Если таких моделей нет, то было бы неплохо узнать вариант с определением общей темы текста (по типу политика, наука, образование и т.д.).",А что значит релевантность коротких текстов?
,"Кто знает, подскажите пожалуйста модели по численной оценке любых рус текстов. Задача: есть несколько маленьких текстов (вопросов или утверждений), и из них нужно выбрать какой-нибудь, желательно, наилучший, путем поиска наиболее качественного. Если таких моделей нет, то было бы неплохо узнать вариант с определением общей темы текста (по типу политика, наука, образование и т.д.).",А что значит релевантность коротких текстов?,"Ой, да, извиняюсь. Тут не релевантность. Скорее значимость, качество текста, что-то в этом роде"
"Кто знает, подскажите пожалуйста модели по численной оценке любых рус текстов. Задача: есть несколько маленьких текстов (вопросов или утверждений), и из них нужно выбрать какой-нибудь, желательно, наилучший, путем поиска наиболее качественного. Если таких моделей нет, то было бы неплохо узнать вариант с определением общей темы текста (по типу политика, наука, образование и т.д.).",А что значит релевантность коротких текстов?,"Ой, да, извиняюсь. Тут не релевантность. Скорее значимость, качество текста, что-то в этом роде",Для классификации текстов можно использовать это: https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway
А что значит релевантность коротких текстов?,"Ой, да, извиняюсь. Тут не релевантность. Скорее значимость, качество текста, что-то в этом роде",Для классификации текстов можно использовать это: https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway,Точность не проверял
,,,Спасибо большое)
,,,"Господа, есть задача: на вход - скриншот экрана/фото ноутбука с экраном, на выход - область содержимого экрана (то есть в случае со скриншотом ничего не надо делать). Есть ли решения, которые понимают что перед ними скриншот и не сегментируют область экрана?"
,,"Господа, есть задача: на вход - скриншот экрана/фото ноутбука с экраном, на выход - область содержимого экрана (то есть в случае со скриншотом ничего не надо делать). Есть ли решения, которые понимают что перед ними скриншот и не сегментируют область экрана?",А контент на скриншоте и экране ноутбука произвольный?
,"Господа, есть задача: на вход - скриншот экрана/фото ноутбука с экраном, на выход - область содержимого экрана (то есть в случае со скриншотом ничего не надо делать). Есть ли решения, которые понимают что перед ними скриншот и не сегментируют область экрана?",А контент на скриншоте и экране ноутбука произвольный?,да
,,,"Поставить в пайплайне классификатор (скриншот или не очень)?
Из палок из скотча можно на CLIP собрать"
,,"Поставить в пайплайне классификатор (скриншот или не очень)?
Из палок из скотча можно на CLIP собрать",а есть на это уже датасет какой-нибудь?
,,,"Не, в том-то и дело, CLIP - это image-text модель делающая два типа дескрипторрв, на этом можно делать zero-shot классификатор: пишешь пачку фраз соответствующих тому что тебе надо, эмбеддишь и сравнивать image-дескрипторы с этими векторами.
Как раз удобно для прототипов и сбора датасетов"
,,"Не, в том-то и дело, CLIP - это image-text модель делающая два типа дескрипторрв, на этом можно делать zero-shot классификатор: пишешь пачку фраз соответствующих тому что тебе надо, эмбеддишь и сравнивать image-дескрипторы с этими векторами.
Как раз удобно для прототипов и сбора датасетов","уххх, как мощно, попробую, спасибо огромное"
,"Не, в том-то и дело, CLIP - это image-text модель делающая два типа дескрипторрв, на этом можно делать zero-shot классификатор: пишешь пачку фраз соответствующих тому что тебе надо, эмбеддишь и сравнивать image-дескрипторы с этими векторами.
Как раз удобно для прототипов и сбора датасетов","уххх, как мощно, попробую, спасибо огромное","Это работает не так хорошо, как fine-tune на датасете. Но это тот молоток который прямо точно стоит заботать.
Может быть не CLIP, а что-нибудь по-свежее, но image-text модельки для начала очень удобны, если на входе обычные картинки (а не гиперспектральные какие-нибудь."
,,,"Проблема решается использованием нормального плеера (например elmedia) QuickTime слишком много всего не поддерживает, чтобы с ним возиться."
,,"Проблема решается использованием нормального плеера (например elmedia) QuickTime слишком много всего не поддерживает, чтобы с ним возиться.",А что с VLC? он кажется умеет дебаг-лог показывать
,"Проблема решается использованием нормального плеера (например elmedia) QuickTime слишком много всего не поддерживает, чтобы с ним возиться.",А что с VLC? он кажется умеет дебаг-лог показывать,"В VLC все нормально показывает
На Ubuntu видео плеер дефолтный тоже не показывает ни одно видео
Хотя в VLC все нормально"
,,,"Тебе нужно чтобы в любом QuickTime проигрывалось?
И ты готов перекодировать? Так перекодировай"
,,"Тебе нужно чтобы в любом QuickTime проигрывалось?
И ты готов перекодировать? Так перекодировай",Хотя бы в новых версиях макоси
,,,"Желательно без перекодировки
Клиент просто просит, чтобы в QuickTime работало
И нигде спецификации нету даже, что QuickTime нормально поддерживает😕"
,,"Желательно без перекодировки
Клиент просто просит, чтобы в QuickTime работало
И нигде спецификации нету даже, что QuickTime нормально поддерживает😕",Потому что почти ничего
,"Желательно без перекодировки
Клиент просто просит, чтобы в QuickTime работало
И нигде спецификации нету даже, что QuickTime нормально поддерживает😕",Потому что почти ничего,"Понял, спасибо. Вообще странно, что дефолтные плееры на убунту/macOS такие отстойные - ничего не поддерживают"
,,,кто учил свой tts?
,,кто учил свой tts?,Ну было
,кто учил свой tts?,Ну было,"а что использовали,если не секрет? coqui-tts?"
кто учил свой tts?,Ну было,"а что использовали,если не секрет? coqui-tts?","из такого vits могу посоветовать, с полпинка залетает"
Ну было,"а что использовали,если не секрет? coqui-tts?","из такого vits могу посоветовать, с полпинка залетает",есть код для обучения для русского?я просто уже несколько дней вожусь и максимум что видел про vits так это какой то японский
"а что использовали,если не секрет? coqui-tts?","из такого vits могу посоветовать, с полпинка залетает",есть код для обучения для русского?я просто уже несколько дней вожусь и максимум что видел про vits так это какой то японский,"готовым кодом поделиться не могу, к сожалению, потому что сейчас пилим коммерческое решение. но для русского ничего специфического кроме предобработки типа е/ё, простановки ударений и нормализации обычно нет — это самая тяжелая часть, потому что готового и открытого практически нет, а то, что есть — надо собирать в кучу и допиливать ручками"
,,,ща закину репу релевантную
,,ща закину репу релевантную,"я пока гуглил про vits нашел вот какой вопрос https://github.com/coqui-ai/TTS/discussions/1998. тут обсуждается плохое качество, они пришли к выводу что gruut плох для русского, и там есть примеры кода которые я модифицировал для использования espeak просто добавив в конфиг phonemizer=""espeak"" и изменив phoneme_language с ""ru-ru"" на ""ru"". Можете посмотреть если интересует."
,,,буду благодарен
,,буду благодарен,"https://github.com/rhasspy/piper вот это для разгона достаточно, хотя тут и пайторч лайтнинг. сама имплементация на базе оригинальной репы VITS. для старта вам будет достаточно использовать чистые, нормализованные тексты и с фонемайзером espeak, который там и используется — а как только дойдете до или упретесь качеством в ударения, произношение и прочее, тогда уже можно что-то свое пилить для предобработки и g2p"
,буду благодарен,"https://github.com/rhasspy/piper вот это для разгона достаточно, хотя тут и пайторч лайтнинг. сама имплементация на базе оригинальной репы VITS. для старта вам будет достаточно использовать чистые, нормализованные тексты и с фонемайзером espeak, который там и используется — а как только дойдете до или упретесь качеством в ударения, произношение и прочее, тогда уже можно что-то свое пилить для предобработки и g2p",спасибо большое
буду благодарен,"https://github.com/rhasspy/piper вот это для разгона достаточно, хотя тут и пайторч лайтнинг. сама имплементация на базе оригинальной репы VITS. для старта вам будет достаточно использовать чистые, нормализованные тексты и с фонемайзером espeak, который там и используется — а как только дойдете до или упретесь качеством в ударения, произношение и прочее, тогда уже можно что-то свое пилить для предобработки и g2p",спасибо большое,"Ещё может быть полезно:

https://github.com/alphacep/awesome-russian-speech

Там же вроде указан vosk-tts — это VITS, обученный на открытых русских датасетах типа NATASHA. Можете поиграться с ним и посмотреть, устроит ли вас нечто подобное по качеству. Но имейте в виду, что все в ваши данные упирается преимущественно, а открытые датасеты — не самого хорошего качества на русском"
"https://github.com/rhasspy/piper вот это для разгона достаточно, хотя тут и пайторч лайтнинг. сама имплементация на базе оригинальной репы VITS. для старта вам будет достаточно использовать чистые, нормализованные тексты и с фонемайзером espeak, который там и используется — а как только дойдете до или упретесь качеством в ударения, произношение и прочее, тогда уже можно что-то свое пилить для предобработки и g2p",спасибо большое,"Ещё может быть полезно:

https://github.com/alphacep/awesome-russian-speech

Там же вроде указан vosk-tts — это VITS, обученный на открытых русских датасетах типа NATASHA. Можете поиграться с ним и посмотреть, устроит ли вас нечто подобное по качеству. Но имейте в виду, что все в ваши данные упирается преимущественно, а открытые датасеты — не самого хорошего качества на русском",спасибо
,,,если будут хорошие чекпоинты поделюсь весами)
,,,Кто-то решал задачу wake word detection?
,,Кто-то решал задачу wake word detection?,"если это тоже самое что keyword spotting, то может быть полезной эта лекция https://www.youtube.com/watch?v=mNkwO8f3Edk"
,Кто-то решал задачу wake word detection?,"если это тоже самое что keyword spotting, то может быть полезной эта лекция https://www.youtube.com/watch?v=mNkwO8f3Edk","а нет ли ссылок на сами ноутбуки, про которых говорят лекторы?"
Кто-то решал задачу wake word detection?,"если это тоже самое что keyword spotting, то может быть полезной эта лекция https://www.youtube.com/watch?v=mNkwO8f3Edk","а нет ли ссылок на сами ноутбуки, про которых говорят лекторы?",https://github.com/markovka17/dla
"если это тоже самое что keyword spotting, то может быть полезной эта лекция https://www.youtube.com/watch?v=mNkwO8f3Edk","а нет ли ссылок на сами ноутбуки, про которых говорят лекторы?",https://github.com/markovka17/dla,спасибо огромное
"а нет ли ссылок на сами ноутбуки, про которых говорят лекторы?",https://github.com/markovka17/dla,спасибо огромное,пожалуйста
,,,"Какие инструменты лучше всего использовать для аннотации текстов ? В CV часто используют CVAT, а что используют в NLP?"
,,"Какие инструменты лучше всего использовать для аннотации текстов ? В CV часто используют CVAT, а что используют в NLP?","Labelstudio имхо хорош для такого https://labelstud.io/playground/ покликай шаблонные штуки классификация, сегментация (NER) там есть"
,"Какие инструменты лучше всего использовать для аннотации текстов ? В CV часто используют CVAT, а что используют в NLP?","Labelstudio имхо хорош для такого https://labelstud.io/playground/ покликай шаблонные штуки классификация, сегментация (NER) там есть",спасибо!
,,,А существует задача супер резолюшн для звука?
,,А существует задача супер резолюшн для звука?,"Ага, чет такое есть"
,,,"Ребят, привет, а кто может подсказать как находится минимум функции потери в Catboost при MultiClass функции потери ?"
,,"Ребят, привет, а кто может подсказать как находится минимум функции потери в Catboost при MultiClass функции потери ?","Можешь как-то переформулировать вопрос?
Ты хочешь какую-то формулу найти, или реализацию в коде или название функции в трейнере или что?
Образ результата то какой?
На картинках обычная кросс-энтропия."
,"Ребят, привет, а кто может подсказать как находится минимум функции потери в Catboost при MultiClass функции потери ?","Можешь как-то переформулировать вопрос?
Ты хочешь какую-то формулу найти, или реализацию в коде или название функции в трейнере или что?
Образ результата то какой?
На картинках обычная кросс-энтропия.","Я бы хотел понять, как рассчитывается первое предсказание в случае MultiClass функции потерь. 

Вот например для задачи регрессии с квадратичной функции потерь в алгоритме градиентного бустинга первым шагом это подсчет среднего значения всех имеющихся предсказаний (это и есть минимум для в этой ситуации)."
"Ребят, привет, а кто может подсказать как находится минимум функции потери в Catboost при MultiClass функции потери ?","Можешь как-то переформулировать вопрос?
Ты хочешь какую-то формулу найти, или реализацию в коде или название функции в трейнере или что?
Образ результата то какой?
На картинках обычная кросс-энтропия.","Я бы хотел понять, как рассчитывается первое предсказание в случае MultiClass функции потерь. 

Вот например для задачи регрессии с квадратичной функции потерь в алгоритме градиентного бустинга первым шагом это подсчет среднего значения всех имеющихся предсказаний (это и есть минимум для в этой ситуации).","Среднее -- это не минимум, это тривиальное решение (в смысле можно выбить больше, но придется использовать входные данные).
В случае с кросс-энтропией такая же история, тривиальное решение -- это доли классов в выборке."
"Можешь как-то переформулировать вопрос?
Ты хочешь какую-то формулу найти, или реализацию в коде или название функции в трейнере или что?
Образ результата то какой?
На картинках обычная кросс-энтропия.","Я бы хотел понять, как рассчитывается первое предсказание в случае MultiClass функции потерь. 

Вот например для задачи регрессии с квадратичной функции потерь в алгоритме градиентного бустинга первым шагом это подсчет среднего значения всех имеющихся предсказаний (это и есть минимум для в этой ситуации).","Среднее -- это не минимум, это тривиальное решение (в смысле можно выбить больше, но придется использовать входные данные).
В случае с кросс-энтропией такая же история, тривиальное решение -- это доли классов в выборке.","Принял, вот я так и знал, спасибо! 

А можете, пожалуйста, подсказать правильно ли я понимаю, как работает алгоритм для решения задач многоклассвоой классификации. 

1. Ищется доля классов выборке log((количество событий когда произошло А)/(количество событий когда НЕ произошло А) 

2. С помощью логистической функции находим вероятность происхождения каждого класса. 

3. После вот не мне не понятно, как я должен посчитать pseudo residuals, у меня же в таблице номер класса, как я буду искать разность с найденной первой вероятностью ?"
"Я бы хотел понять, как рассчитывается первое предсказание в случае MultiClass функции потерь. 

Вот например для задачи регрессии с квадратичной функции потерь в алгоритме градиентного бустинга первым шагом это подсчет среднего значения всех имеющихся предсказаний (это и есть минимум для в этой ситуации).","Среднее -- это не минимум, это тривиальное решение (в смысле можно выбить больше, но придется использовать входные данные).
В случае с кросс-энтропией такая же история, тривиальное решение -- это доли классов в выборке.","Принял, вот я так и знал, спасибо! 

А можете, пожалуйста, подсказать правильно ли я понимаю, как работает алгоритм для решения задач многоклассвоой классификации. 

1. Ищется доля классов выборке log((количество событий когда произошло А)/(количество событий когда НЕ произошло А) 

2. С помощью логистической функции находим вероятность происхождения каждого класса. 

3. После вот не мне не понятно, как я должен посчитать pseudo residuals, у меня же в таблице номер класса, как я буду искать разность с найденной первой вероятностью ?","А поищите книгу Николенко, в первых главах хорошо раскрыт вопрос"
,,,"Согласно алгоритму, первый шаг вот такой, а функция потери вот так выглядит, как это добро найти )"
,,"Согласно алгоритму, первый шаг вот такой, а функция потери вот так выглядит, как это добро найти )",Как будто бы вид функции потерь намекает на MLE
,,,"Всем привет, для решения задачи (замена номера машины на логотип сайта) нужна модель, способная выдавать все 4 ключевые точки параллелограмма, который ограничивает участок номера машины. Пробовал использовать различные версии YOLO, но проблема в том, что  в данной модели на выходе ограничивающий прямоугольник, который не подстраивается под геометрию номера. 

Существуют ли претрейн модели для нахождения ключевых точек или есть другой способ решения задачи"
,,"Всем привет, для решения задачи (замена номера машины на логотип сайта) нужна модель, способная выдавать все 4 ключевые точки параллелограмма, который ограничивает участок номера машины. Пробовал использовать различные версии YOLO, но проблема в том, что  в данной модели на выходе ограничивающий прямоугольник, который не подстраивается под геометрию номера. 

Существуют ли претрейн модели для нахождения ключевых точек или есть другой способ решения задачи",Загугли YOLOv5-OBB
,"Всем привет, для решения задачи (замена номера машины на логотип сайта) нужна модель, способная выдавать все 4 ключевые точки параллелограмма, который ограничивает участок номера машины. Пробовал использовать различные версии YOLO, но проблема в том, что  в данной модели на выходе ограничивающий прямоугольник, который не подстраивается под геометрию номера. 

Существуют ли претрейн модели для нахождения ключевых точек или есть другой способ решения задачи",Загугли YOLOv5-OBB,Выглядит очень похоже на то что я ищу. Спасибо большое
,,,"Натрень свою.
Если категорически не хочется ничего размечать и хочется приключений, из наколеночного можно взять сегментацию (на SAM например), а потом пост-процессить рамки без нейронок."
,,"Натрень свою.
Если категорически не хочется ничего размечать и хочется приключений, из наколеночного можно взять сегментацию (на SAM например), а потом пост-процессить рамки без нейронок.","один вечер разметки, тренишь свою регрессию, постпроцессинг для аккуратного параллелограмма (если надо), профит"
,,,Ещё можно посмотреть на ARCH/GARCH/VAR/BATS+T-BATS
,,Ещё можно посмотреть на ARCH/GARCH/VAR/BATS+T-BATS,"Первые два это про регрессию сигма квадратов. Не дженерал перпос, нужно скорее в очень специфических задачах."
,Ещё можно посмотреть на ARCH/GARCH/VAR/BATS+T-BATS,"Первые два это про регрессию сигма квадратов. Не дженерал перпос, нужно скорее в очень специфических задачах.","Ну если захочется делать предикты по ряду, то без этого уже сложно куда-то продвинуться
По крайней мере принципы работы етна и профет без авторегрессий тяжко понять"
,,,"Но это уже не программа минимум, мне кажется)"
,,,"На то что стоит под логарифмом можно смотреть как на вероятности (они неотрицательные и суммируются в единичку).
Минимум лосса достигается когда эти вероятности совпадают с нормализованными w_i"
,,"На то что стоит под логарифмом можно смотреть как на вероятности (они неотрицательные и суммируются в единичку).
Минимум лосса достигается когда эти вероятности совпадают с нормализованными w_i","факт, у меня этот параметр 1, всех классов я собрал равное количество"
,,,"Да просто почитать для начала что такое автокорреляция, что такое стационарность, какие есть статистические способы раскрыть суть автокорреляции (ARMA, etc), как можно раскрыть нелинейность которая за ней стоит. Вообще про подход Бокса-Дженкинса, это так или иначе хребет анализа таймсериес вообще."
,,,"Коллеги, посоветуйте бэктестер, который умеет по тикам прогонять, под рынок фьючерсов (крипта)."
,,"Коллеги, посоветуйте бэктестер, который умеет по тикам прогонять, под рынок фьючерсов (крипта).",https://hftbacktest.readthedocs.io/en/latest/data.html
,"Коллеги, посоветуйте бэктестер, который умеет по тикам прогонять, под рынок фьючерсов (крипта).",https://hftbacktest.readthedocs.io/en/latest/data.html,"стоит понимать, что когда на хфт уровень спускаешься, там уже гораздо более софистикейтед в плане бэктеста, тут сделано неплохо с поправкой, что это опенсорс"
"Коллеги, посоветуйте бэктестер, который умеет по тикам прогонять, под рынок фьючерсов (крипта).",https://hftbacktest.readthedocs.io/en/latest/data.html,"стоит понимать, что когда на хфт уровень спускаешься, там уже гораздо более софистикейтед в плане бэктеста, тут сделано неплохо с поправкой, что это опенсорс",но опять же максимально топорно все аспекты реализованы
,,,"Ну мне hft не нужно. Мне нужно прогнать стратегию, которая изначально была сделана на свечах. Чтоб проверить, как например тралл отрабатывает.
Так например в freqtrade тралл считает не корректно. И его нормально не протестить. Зато можно легко получить Грааль по бэктесту)))"
,,"Ну мне hft не нужно. Мне нужно прогнать стратегию, которая изначально была сделана на свечах. Чтоб проверить, как например тралл отрабатывает.
Так например в freqtrade тралл считает не корректно. И его нормально не протестить. Зато можно легко получить Грааль по бэктесту)))",тралл— это?
,,,trailling stop
,,trailling stop,"а, оке"
,,,ну там есть position adjustments
,,,у меня получалось переписать фректрейд чтобы честно входы были + стопы как раз
,,у меня получалось переписать фректрейд чтобы честно входы были + стопы как раз,Код правил или как-то через настройки?
,у меня получалось переписать фректрейд чтобы честно входы были + стопы как раз,Код правил или как-то через настройки?,код
,,,"А что правил, если не секрет. А то я что-то совсем пригораю, столько лет проекту, и столько косяков на самой важной его части - бэктестеру"
,,"А что правил, если не секрет. А то я что-то совсем пригораю, столько лет проекту, и столько косяков на самой важной его части - бэктестеру","ну саму логику датафидов и обработки открытия позиций, честн о берутся bbo и по ним смотрится, что открытие, что закрытие и так далее (чтобы не было мидфрика зарабатывающего меньше спреда :))"
,"А что правил, если не секрет. А то я что-то совсем пригораю, столько лет проекту, и столько косяков на самой важной его части - бэктестеру","ну саму логику датафидов и обработки открытия позиций, честн о берутся bbo и по ним смотрится, что открытие, что закрытие и так далее (чтобы не было мидфрика зарабатывающего меньше спреда :))","Ага, там как раз оптимизации скатываются в минимальный стоп и тейк к уровню спреда и показывают граальный доход. А почему они сами не исправили?) Или авторы не спускаются ниже часовых свечей? 😄"
"А что правил, если не секрет. А то я что-то совсем пригораю, столько лет проекту, и столько косяков на самой важной его части - бэктестеру","ну саму логику датафидов и обработки открытия позиций, честн о берутся bbo и по ним смотрится, что открытие, что закрытие и так далее (чтобы не было мидфрика зарабатывающего меньше спреда :))","Ага, там как раз оптимизации скатываются в минимальный стоп и тейк к уровню спреда и показывают граальный доход. А почему они сами не исправили?) Или авторы не спускаются ниже часовых свечей? 😄","поняти не имею,  но из того что видел там обычно просто ниже 15 минут стратегии не делают и терновер процентов 10 там, с целевым rpt > 3%, там это уже действительно не так важно"
"ну саму логику датафидов и обработки открытия позиций, честн о берутся bbo и по ним смотрится, что открытие, что закрытие и так далее (чтобы не было мидфрика зарабатывающего меньше спреда :))","Ага, там как раз оптимизации скатываются в минимальный стоп и тейк к уровню спреда и показывают граальный доход. А почему они сами не исправили?) Или авторы не спускаются ниже часовых свечей? 😄","поняти не имею,  но из того что видел там обычно просто ниже 15 минут стратегии не делают и терновер процентов 10 там, с целевым rpt > 3%, там это уже действительно не так важно","я тестил стратегию на часовиках, из-за не верных подсчетов тралла, рои, и стопа, разница в итоговом баланcе была в 2 раза относительно бэктеста на 1h и на 1m (благо хоть на 1м дают подробнее прогнать)"
,,,"""терновер"" это что?"
,,"""терновер"" это что?",ratio ротации портфеля
,,,"Всем привет! Подскажите про dvc. Вот если использовать его для версионирования данных и делать даги для создания фичей. То вот появилась гипотеза, она включает в себя создание новых фичей. Написали для этого даг для DVC. Здорово. Появилась другая гипотеза, там другие фичи. Тут тоже даг надо писать. И получается под каждый эксперимент по файлу. Не много ли их получается и как ими всеми управлять?"
,,,"всем привет! Для задачи распознавания 2-3 страницы паспорта необходимо извлекать только фио, дату и место выдачи.


Была идея, что можно просто ориентироваться на пиксельное взаиморасположение боксов и вытаскивать так нужные атрибуты. Но столкнулся с проблемой, что где-то добавляется еще распознавание слов на печати и подписи, что полностью смещает алгоритм поиска. Как это можно решить?"
,,"всем привет! Для задачи распознавания 2-3 страницы паспорта необходимо извлекать только фио, дату и место выдачи.


Была идея, что можно просто ориентироваться на пиксельное взаиморасположение боксов и вытаскивать так нужные атрибуты. Но столкнулся с проблемой, что где-то добавляется еще распознавание слов на печати и подписи, что полностью смещает алгоритм поиска. Как это можно решить?","https://habr.com/ru/companies/enterra/articles/219535/
Была захватывающая статья про подводные камни.
Кажется проблем с паспортами настолько дофига, что надо экспериментировать и смотреть в каком проценте случаев ломается и почему."
,"всем привет! Для задачи распознавания 2-3 страницы паспорта необходимо извлекать только фио, дату и место выдачи.


Была идея, что можно просто ориентироваться на пиксельное взаиморасположение боксов и вытаскивать так нужные атрибуты. Но столкнулся с проблемой, что где-то добавляется еще распознавание слов на печати и подписи, что полностью смещает алгоритм поиска. Как это можно решить?","https://habr.com/ru/companies/enterra/articles/219535/
Была захватывающая статья про подводные камни.
Кажется проблем с паспортами настолько дофига, что надо экспериментировать и смотреть в каком проценте случаев ломается и почему.",Спасибо)
,,,"А для чего нужен именно параллелограмм? Распознавание текста номера в данном случае решается разметкой (есть готовы сеты на робофлоу). Если надо картинку выровнять и куда-то дальше передать, то openCV с такой задачей справляется хорошо, т.к. номер сам по себе прямоугольный и разница в цвете между номером и остальной машиной велика."
,,"А для чего нужен именно параллелограмм? Распознавание текста номера в данном случае решается разметкой (есть готовы сеты на робофлоу). Если надо картинку выровнять и куда-то дальше передать, то openCV с такой задачей справляется хорошо, т.к. номер сам по себе прямоугольный и разница в цвете между номером и остальной машиной велика.","Наверное проблема не «выровнять» в плоскости, а чтобы это выглядело как будто логотип сайта вместо номера, типа проекции на 3д модель"
,,,Я в начале видимо наискосок прочитал
,,,"Добрый день.
нужен совет по деплою. П
Разворачиваю свой проект в докере, но он получается невероятно тяжелый.
Питоновский образ вкупе с torch весят больно много. Сам проект на диске полтора гига, из них около гига - торч.
Образ собирался полчаса и так и не собрался - грохнул от греха.

Вопрос: это я криво собираю образ, или такое поведение нормально для образов с торчем внутри?
И если да, есть ли облегченные версии торча с минимальным функционалом, как в целом версии для деплоя оптимизировать?"
,,"Добрый день.
нужен совет по деплою. П
Разворачиваю свой проект в докере, но он получается невероятно тяжелый.
Питоновский образ вкупе с torch весят больно много. Сам проект на диске полтора гига, из них около гига - торч.
Образ собирался полчаса и так и не собрался - грохнул от греха.

Вопрос: это я криво собираю образ, или такое поведение нормально для образов с торчем внутри?
И если да, есть ли облегченные версии торча с минимальным функционалом, как в целом версии для деплоя оптимизировать?","Можно на плюсах написать инференс, но весить будет все равно торч (если с кудой) много, либы"
,,,export onnx/triton/torchserve/etc
,,export onnx/triton/torchserve/etc,"Всем привет! Интересно мнение, какой таргет лучше подходит для трендовых стратегий? Пробовал trend scanning, но как-то неактуально учить машину, когда у тебя и начало тренда и конец - это один и тот же класс."
,export onnx/triton/torchserve/etc,"Всем привет! Интересно мнение, какой таргет лучше подходит для трендовых стратегий? Пробовал trend scanning, но как-то неактуально учить машину, когда у тебя и начало тренда и конец - это один и тот же класс.","mmrotate еще есть, но не заводится с полтычка, как китайская yolov5obb"
export onnx/triton/torchserve/etc,"Всем привет! Интересно мнение, какой таргет лучше подходит для трендовых стратегий? Пробовал trend scanning, но как-то неактуально учить машину, когда у тебя и начало тренда и конец - это один и тот же класс.","mmrotate еще есть, но не заводится с полтычка, как китайская yolov5obb","ребят, если ли пример данных которые есть у продавцов маркетплецсов?"
,,,"Всем привет, в какой категории я могу задать вопрос по обычной регрессионной задаче?"
,,"Всем привет, в какой категории я могу задать вопрос по обычной регрессионной задаче?",Classic ml?
,"Всем привет, в какой категории я могу задать вопрос по обычной регрессионной задаче?",Classic ml?,Да
,,,"Спасибо
Всем привет, решаю обычную регрессионную задачу с предсказанием целевой переменной. Провёл Feature engineering, использую CatBoost регрессию, прогнал через RandomizedSearch, но вот проблема мои конкуренты опережают меня на 1-7 (условно у меня 198,4 у них 198, 8). Может кто подсказать способ, как увеличить точность или какую-нибудь интересную модель? Спасибо заранее"
,,"Спасибо
Всем привет, решаю обычную регрессионную задачу с предсказанием целевой переменной. Провёл Feature engineering, использую CatBoost регрессию, прогнал через RandomizedSearch, но вот проблема мои конкуренты опережают меня на 1-7 (условно у меня 198,4 у них 198, 8). Может кто подсказать способ, как увеличить точность или какую-нибудь интересную модель? Спасибо заранее","попробуй логарифмировать таргет
для регрессии - деревья не всегда хороши, попробуй линейные модели и сетки"
,"Спасибо
Всем привет, решаю обычную регрессионную задачу с предсказанием целевой переменной. Провёл Feature engineering, использую CatBoost регрессию, прогнал через RandomizedSearch, но вот проблема мои конкуренты опережают меня на 1-7 (условно у меня 198,4 у них 198, 8). Может кто подсказать способ, как увеличить точность или какую-нибудь интересную модель? Спасибо заранее","попробуй логарифмировать таргет
для регрессии - деревья не всегда хороши, попробуй линейные модели и сетки","Я пробовал несколько вариантов, деревья показали наилучший результат. Но я попробую, спасибо. Есть какие-нибудь интересные линейные модели?"
"Спасибо
Всем привет, решаю обычную регрессионную задачу с предсказанием целевой переменной. Провёл Feature engineering, использую CatBoost регрессию, прогнал через RandomizedSearch, но вот проблема мои конкуренты опережают меня на 1-7 (условно у меня 198,4 у них 198, 8). Может кто подсказать способ, как увеличить точность или какую-нибудь интересную модель? Спасибо заранее","попробуй логарифмировать таргет
для регрессии - деревья не всегда хороши, попробуй линейные модели и сетки","Я пробовал несколько вариантов, деревья показали наилучший результат. Но я попробую, спасибо. Есть какие-нибудь интересные линейные модели?","Всем приветы!
1. Имеется датасет авиасъемки тюленей на льду
2. Задача - подсчет, сегментация и дальнейший анализ контуров
3. Моделька - YOLOv8, обучил, вроде неплохо уже работает. Ниже - результат (красные метки - центроиды контуров сегментации, найденные через cv2.Moments)."
,,,"Итак, уважаемые знатоки, внимание, вопрос :) Как видно, некоторые тюлени обнаруживаются дважды. Как это побороть? На вскидку думаю такое:
1. Дообучить с аугами по размеру (у самолета +/- 10% по высоте гуляет, м.б. это из-за разных высот)
2. Может какой-то внутренний параметр? Что-то вроде NMS подкрутить в нужную сторону?
Извините если вопрос дурацкий, я в этом всем недавно :)"
,,"Итак, уважаемые знатоки, внимание, вопрос :) Как видно, некоторые тюлени обнаруживаются дважды. Как это побороть? На вскидку думаю такое:
1. Дообучить с аугами по размеру (у самолета +/- 10% по высоте гуляет, м.б. это из-за разных высот)
2. Может какой-то внутренний параметр? Что-то вроде NMS подкрутить в нужную сторону?
Извините если вопрос дурацкий, я в этом всем недавно :)","Да, nms_iou может быть маловат"
,,,"Здравствуйте. Кто-нибудь натыкался на что-то вроде списка контор, занимающихся hft?"
,,"Здравствуйте. Кто-нибудь натыкался на что-то вроде списка контор, занимающихся hft?",Их много
,,,быть может кто-то задавался аналогичным вопросом и проводил небольшой ресерч
,,быть может кто-то задавался аналогичным вопросом и проводил небольшой ресерч,"Пока ничего умнее костыльного постпроцессинга не придумал. Типа задаем максимальное расстояние, которое еще считается дублем и выкидываем из результатов все что <= этому."
,,,А какие конкретно hft интересуют?
,,А какие конкретно hft интересуют?,"Ныне здравствующие) интересует больше существование ресурса, где представлена подобная информация"
,А какие конкретно hft интересуют?,"Ныне здравствующие) интересует больше существование ресурса, где представлена подобная информация",Сайты с поиском вакансий
,,,"CitSec, HRT, XTX, Jump"
,,"CitSec, HRT, XTX, Jump",Самые крупные так найти точно можно
,"CitSec, HRT, XTX, Jump",Самые крупные так найти точно можно,"Да, тогда скорее интересуют те, что несильно стремятся светиться"
,,,Вам для чего?
,,Вам для чего?,иметь представление о рынке и игроках
,,,"Для меня все еще не прозрачны конкретные критерии. 

Если интересует прям всеобъемлющий список, то я бы и сам с радостью его посмотрел, но лично на своем опыте, лучшее что я видел это 
1) сайт с вакансиями, тот же линкедин
2) подборка компаний для стажировки (малоизвестных компаний там не будет точно)

Есть много людей, которые устраивались когда-то на работу и знают пачку разных компаний подходящие под их критерии
Вот такие списки тоже найти не проблема. У меня у самого такой есть"
,,"Для меня все еще не прозрачны конкретные критерии. 

Если интересует прям всеобъемлющий список, то я бы и сам с радостью его посмотрел, но лично на своем опыте, лучшее что я видел это 
1) сайт с вакансиями, тот же линкедин
2) подборка компаний для стажировки (малоизвестных компаний там не будет точно)

Есть много людей, которые устраивались когда-то на работу и знают пачку разных компаний подходящие под их критерии
Вот такие списки тоже найти не проблема. У меня у самого такой есть",Справедливо. Давайте попробуем ограничиться русскими компаниями (не обязательно де юре)
,"Для меня все еще не прозрачны конкретные критерии. 

Если интересует прям всеобъемлющий список, то я бы и сам с радостью его посмотрел, но лично на своем опыте, лучшее что я видел это 
1) сайт с вакансиями, тот же линкедин
2) подборка компаний для стажировки (малоизвестных компаний там не будет точно)

Есть много людей, которые устраивались когда-то на работу и знают пачку разных компаний подходящие под их критерии
Вот такие списки тоже найти не проблема. У меня у самого такой есть",Справедливо. Давайте попробуем ограничиться русскими компаниями (не обязательно де юре),"wunderfund.io
не крупные, но относительно известные"
,,,Русские  hft есть на крипте. РТС может еще остался кто.
,,Русские  hft есть на крипте. РТС может еще остался кто.,На РТС точно никого не осталось:)))) А вот на ФОРТС живые есть:))
,,,Есть не только на крипте
,,,а фортс еще есть?
,,а фортс еще есть?,"Есть призрак отца Гамлета. Но после того, как все западные фонды свалили, стало дышать полегче:)"
,,,"Да знаю я :) Еще с Юнета начинал, как Костя (2-е место) рекомендовал.
В итоге разумная комбинация nms_iou и conf хорошо помогает. Почти все вычищает."
,,,"Всем привет!
Погружаюсь сейчас в мир рекомендашек и столкнулась с проблемой, что данных событий (юзер - айтем) очень много и например lightfm крайне долго обучается и считает метрики, а для каких-то моделей вообще обучение запустить невозможно из-за памяти 
Не подскажите, как такие проблемы решают в индустрии например?
Обязательно ли использовать все данные или можно сэмплировать/брать только последние события/только самых активных юзеров?"
,,"Всем привет!
Погружаюсь сейчас в мир рекомендашек и столкнулась с проблемой, что данных событий (юзер - айтем) очень много и например lightfm крайне долго обучается и считает метрики, а для каких-то моделей вообще обучение запустить невозможно из-за памяти 
Не подскажите, как такие проблемы решают в индустрии например?
Обязательно ли использовать все данные или можно сэмплировать/брать только последние события/только самых активных юзеров?","Привет! Есть реализация lightfm  под pyspark в библиотеке replay, может быть полезно, если есть инфраструктура под парадигму map reduce. С этой либой без пол-литра не разберешься, правда
Я, например, не пью, поэтому отказался от неё и использовал ванильный lightfm, но понизил количество эпох обучения, k лоссе и, самое важное, отфильтровал обучающую выборку, оставив только наиболее активных юзеров.
Общее мнение: предсказание для новых клиентов на lightfm - Голгофа (придётся через lightfm. dataset предсказывать и за индексами следить, приговаривая  ухх бля)"
,"Всем привет!
Погружаюсь сейчас в мир рекомендашек и столкнулась с проблемой, что данных событий (юзер - айтем) очень много и например lightfm крайне долго обучается и считает метрики, а для каких-то моделей вообще обучение запустить невозможно из-за памяти 
Не подскажите, как такие проблемы решают в индустрии например?
Обязательно ли использовать все данные или можно сэмплировать/брать только последние события/только самых активных юзеров?","Привет! Есть реализация lightfm  под pyspark в библиотеке replay, может быть полезно, если есть инфраструктура под парадигму map reduce. С этой либой без пол-литра не разберешься, правда
Я, например, не пью, поэтому отказался от неё и использовал ванильный lightfm, но понизил количество эпох обучения, k лоссе и, самое важное, отфильтровал обучающую выборку, оставив только наиболее активных юзеров.
Общее мнение: предсказание для новых клиентов на lightfm - Голгофа (придётся через lightfm. dataset предсказывать и за индексами следить, приговаривая  ухх бля)","Спасибо 🙏🏻
Поняла 
В общем придется выкручиваться)"
,,,"Всем привет,  передо мной стоит задача  - поиск и подсчет людей на фотографии с камеры в доме. Я читал несколько статей, и я так понял, что лучше всего будет использование какого нибудь yolo, или кто-то знает варианты получше?"
,,"Всем привет,  передо мной стоит задача  - поиск и подсчет людей на фотографии с камеры в доме. Я читал несколько статей, и я так понял, что лучше всего будет использование какого нибудь yolo, или кто-то знает варианты получше?",deepsort + любой детектор
,,,Для бейзлайна на камере yolo отличный вариант
,,Для бейзлайна на камере yolo отличный вариант,"всем привет, хочу для задачи классификации попробовать нагенерить синтетических данных, для нужного класса мало картинок, подскажите, какие есть норм модельки которые можно дообучить на своих данных и сгенерить похожие новые, может ссылки на коллабовские ноутбуки по подобной задачи завалялись у кого?"
,Для бейзлайна на камере yolo отличный вариант,"всем привет, хочу для задачи классификации попробовать нагенерить синтетических данных, для нужного класса мало картинок, подскажите, какие есть норм модельки которые можно дообучить на своих данных и сгенерить похожие новые, может ссылки на коллабовские ноутбуки по подобной задачи завалялись у кого?","попробуй text-to-image (stable diffusion, kandinsky etc)"
Для бейзлайна на камере yolo отличный вариант,"всем привет, хочу для задачи классификации попробовать нагенерить синтетических данных, для нужного класса мало картинок, подскажите, какие есть норм модельки которые можно дообучить на своих данных и сгенерить похожие новые, может ссылки на коллабовские ноутбуки по подобной задачи завалялись у кого?","попробуй text-to-image (stable diffusion, kandinsky etc)",Натюнить можно с dreambooth(в diffusers есть код)
,,,"а вообще, я думаю в России большинство частотников в специальных отделах крупных ib и фондов типо атона, альфы, сбер cib"
,,"а вообще, я думаю в России большинство частотников в специальных отделах крупных ib и фондов типо атона, альфы, сбер cib","Там нет hft, они слишком медленные для этого и с жутким legacy"
,,,"Они не могут привлекать талант когда на 1 кванта по 10+ менеджеров, нет startup mentality. Они по другому зарабатывают деньги"
,,,"в атоне точно есть один как минимум, в cib набирали на валютку в ежегодной программе, в альфе есть директ но там хызы как с этим"
,,"в атоне точно есть один как минимум, в cib набирали на валютку в ежегодной программе, в альфе есть директ но там хызы как с этим",В альфе есть трейдинг отдел
,,,"Высокочастотный
В сбере тоже"
,,"Высокочастотный
В сбере тоже","ну вот это все кванты в России и есть)
ну если серьезно, я думаю на них приходится больше половины частотного объема на российском рынке"
,"Высокочастотный
В сбере тоже","ну вот это все кванты в России и есть)
ну если серьезно, я думаю на них приходится больше половины частотного объема на российском рынке","Используйте только те модели, которые сможете обучить за разумное время на своих данных и своем железе."
"Высокочастотный
В сбере тоже","ну вот это все кванты в России и есть)
ну если серьезно, я думаю на них приходится больше половины частотного объема на российском рынке","Используйте только те модели, которые сможете обучить за разумное время на своих данных и своем железе.",мы начали
"ну вот это все кванты в России и есть)
ну если серьезно, я думаю на них приходится больше половины частотного объема на российском рынке","Используйте только те модели, которые сможете обучить за разумное время на своих данных и своем железе.",мы начали,"Часто решают проблему просто покупая/снимая железо с большим количеством оперативной памяти, не прибегая к супер хитрым хакам. 
RAM год от года дешевеет( ну считается так)"
"Используйте только те модели, которые сможете обучить за разумное время на своих данных и своем железе.",мы начали,"Часто решают проблему просто покупая/снимая железо с большим количеством оперативной памяти, не прибегая к супер хитрым хакам. 
RAM год от года дешевеет( ну считается так)","Всем привет
Кто-нибудь может пожалуйста подсказать хороший коннектор для бинанс фьючерс на базе С++ ?
Пишу свой, хочу понять с чем имею дело)

Спасибо"
мы начали,"Часто решают проблему просто покупая/снимая железо с большим количеством оперативной памяти, не прибегая к супер хитрым хакам. 
RAM год от года дешевеет( ну считается так)","Всем привет
Кто-нибудь может пожалуйста подсказать хороший коннектор для бинанс фьючерс на базе С++ ?
Пишу свой, хочу понять с чем имею дело)

Спасибо","Кто может подсказать хорошие ресурсы в (желательно в текстовом виде), чтобы освежить знания по матстату и аб тестам?

ну тоесть задача не заботать заново а просто пройтись по тому что забыл"
"Часто решают проблему просто покупая/снимая железо с большим количеством оперативной памяти, не прибегая к супер хитрым хакам. 
RAM год от года дешевеет( ну считается так)","Всем привет
Кто-нибудь может пожалуйста подсказать хороший коннектор для бинанс фьючерс на базе С++ ?
Пишу свой, хочу понять с чем имею дело)

Спасибо","Кто может подсказать хорошие ресурсы в (желательно в текстовом виде), чтобы освежить знания по матстату и аб тестам?

ну тоесть задача не заботать заново а просто пройтись по тому что забыл","у lightfm как-то долго работает валидация - ее лучше отключать между эпохами, либо свою написать. Плюс стоит проверить, нормально ли доп фичи препроцессятся - lightfm поддерживает только кат фичи, причем лучше их сразу разряженной матрицей подавать
еще есть implicit, если есть гпу - сильно быстрее, плюс есть als, svd на спарке"
"Всем привет
Кто-нибудь может пожалуйста подсказать хороший коннектор для бинанс фьючерс на базе С++ ?
Пишу свой, хочу понять с чем имею дело)

Спасибо","Кто может подсказать хорошие ресурсы в (желательно в текстовом виде), чтобы освежить знания по матстату и аб тестам?

ну тоесть задача не заботать заново а просто пройтись по тому что забыл","у lightfm как-то долго работает валидация - ее лучше отключать между эпохами, либо свою написать. Плюс стоит проверить, нормально ли доп фичи препроцессятся - lightfm поддерживает только кат фичи, причем лучше их сразу разряженной матрицей подавать
еще есть implicit, если есть гпу - сильно быстрее, плюс есть als, svd на спарке",Спасибо!
"Кто может подсказать хорошие ресурсы в (желательно в текстовом виде), чтобы освежить знания по матстату и аб тестам?

ну тоесть задача не заботать заново а просто пройтись по тому что забыл","у lightfm как-то долго работает валидация - ее лучше отключать между эпохами, либо свою написать. Плюс стоит проверить, нормально ли доп фичи препроцессятся - lightfm поддерживает только кат фичи, причем лучше их сразу разряженной матрицей подавать
еще есть implicit, если есть гпу - сильно быстрее, плюс есть als, svd на спарке",Спасибо!,Всегда брать эмбед последнего токена?
"у lightfm как-то долго работает валидация - ее лучше отключать между эпохами, либо свою написать. Плюс стоит проверить, нормально ли доп фичи препроцессятся - lightfm поддерживает только кат фичи, причем лучше их сразу разряженной матрицей подавать
еще есть implicit, если есть гпу - сильно быстрее, плюс есть als, svd на спарке",Спасибо!,Всегда брать эмбед последнего токена?,"Мега пиздатая книга
Я кстати по этому датасету диплом написал))

Один из самых кайфовых, что я видел. Там даже бизнес метрики можно посчитать если немного помучиться"
Спасибо!,Всегда брать эмбед последнего токена?,"Мега пиздатая книга
Я кстати по этому датасету диплом написал))

Один из самых кайфовых, что я видел. Там даже бизнес метрики можно посчитать если немного помучиться",Или mean pool от sequence embs
Всегда брать эмбед последнего токена?,"Мега пиздатая книга
Я кстати по этому датасету диплом написал))

Один из самых кайфовых, что я видел. Там даже бизнес метрики можно посчитать если немного помучиться",Или mean pool от sequence embs,"Делюсь короче своими подборками для старта, что то уже скидывали даже"
"Мега пиздатая книга
Я кстати по этому датасету диплом написал))

Один из самых кайфовых, что я видел. Там даже бизнес метрики можно посчитать если немного помучиться",Или mean pool от sequence embs,"Делюсь короче своими подборками для старта, что то уже скидывали даже","Еще кстати классная книга есть - practical recommender systems by kim falk, там довольно много про продуктовые и продовые проблемы в сравнении с академическими книгами"
,,,Это работает для энкодеров
,,Это работает для энкодеров,Пуллинг кстати и для RNN ok работал
,,,"Берта, например"
,,,"Для lstm вполне работало, если каждый токен имеет внимание слева от контекста, то каждый токен знает о предыдущем"
,,"Для lstm вполне работало, если каждый токен имеет внимание слева от контекста, то каждый токен знает о предыдущем","Кстати у меня на специфичной задаче mean pool от рекурентки лучше чем last hidden state, что мне покоя никак не даёт)"
,,,Как стейты прям у lstm
,,,"Last hidden state знает всё о предыдущих, да с условием затухания знаний в RNN на sequence, поэтому там врубали би схему. Но тут есть в декодере внимание, поэтому last token embs знает взвешенно предыдущие токены"
,,"Last hidden state знает всё о предыдущих, да с условием затухания знаний в RNN на sequence, поэтому там врубали би схему. Но тут есть в декодере внимание, поэтому last token embs знает взвешенно предыдущие токены","Действительно, в теории архитектурно last token embedding в трансформерном декодере_может_ знать все предыдущие токены. Но интуиция подсказывает, что на практике без специального дообучения этого не будет происходить. Ведь модели на текущем шаге нужно предсказывать только следующий токен, и она будет пихать в текущий эмбеддинг только информацию, необходимую для этого (ведь, в отличие от rnn без внимания, всю остальную информацию она может потом в любой момент заново подглядеть вниманием)."
,"Last hidden state знает всё о предыдущих, да с условием затухания знаний в RNN на sequence, поэтому там врубали би схему. Но тут есть в декодере внимание, поэтому last token embs знает взвешенно предыдущие токены","Действительно, в теории архитектурно last token embedding в трансформерном декодере_может_ знать все предыдущие токены. Но интуиция подсказывает, что на практике без специального дообучения этого не будет происходить. Ведь модели на текущем шаге нужно предсказывать только следующий токен, и она будет пихать в текущий эмбеддинг только информацию, необходимую для этого (ведь, в отличие от rnn без внимания, всю остальную информацию она может потом в любой момент заново подглядеть вниманием).","Поэтому, если вы декодер не дообучаете на специальную задачу извлечения эмбеддингов, я бы ожидал, что средний эмбеддинг всех токенов будет информативнее, чем эмбеддинг последнего токена (но все ещё менее информативным, чем средний эмбеддинг энкодерной модели аналогичного размера, ибо энкодер двухсторонний)"
"Last hidden state знает всё о предыдущих, да с условием затухания знаний в RNN на sequence, поэтому там врубали би схему. Но тут есть в декодере внимание, поэтому last token embs знает взвешенно предыдущие токены","Действительно, в теории архитектурно last token embedding в трансформерном декодере_может_ знать все предыдущие токены. Но интуиция подсказывает, что на практике без специального дообучения этого не будет происходить. Ведь модели на текущем шаге нужно предсказывать только следующий токен, и она будет пихать в текущий эмбеддинг только информацию, необходимую для этого (ведь, в отличие от rnn без внимания, всю остальную информацию она может потом в любой момент заново подглядеть вниманием).","Поэтому, если вы декодер не дообучаете на специальную задачу извлечения эмбеддингов, я бы ожидал, что средний эмбеддинг всех токенов будет информативнее, чем эмбеддинг последнего токена (но все ещё менее информативным, чем средний эмбеддинг энкодерной модели аналогичного размера, ибо энкодер двухсторонний)","Поэтому, предлагаю два стула) или last embs или pool"
,,,"На этой же идее и предсказывают следующий токен
Значит Бери эмб ласт токена фразы"
,,"На этой же идее и предсказывают следующий токен
Значит Бери эмб ласт токена фразы",🧐
,"На этой же идее и предсказывают следующий токен
Значит Бери эмб ласт токена фразы",🧐,"но офк лучше доучить, тк для reward модели OpenAI используют именно decoder эмбеды фраз"
,,,И доучивают на loss а-ля log(sigmoid(ri-rj))
,,И доучивают на loss а-ля log(sigmoid(ri-rj)),"В целом да, еще можно усреднять разности ревордов потокенно, так в дипспидчате сделано"
,И доучивают на loss а-ля log(sigmoid(ri-rj)),"В целом да, еще можно усреднять разности ревордов потокенно, так в дипспидчате сделано","Вопрос бро, как брать эмбеды текста с декодера)"
,,,Откуда дровишки? Где почитать что делает OpenAI для своего эмбеддинг эндпоинта?
,,Откуда дровишки? Где почитать что делает OpenAI для своего эмбеддинг эндпоинта?,Про лосс в блоге
,,,"Как и то, что у них decoder reward
Кстати можно посмотреть trl код или deep speed chat  код где учат reward"
,,"Как и то, что у них decoder reward
Кстати можно посмотреть trl код или deep speed chat  код где учат reward",Помогает от переобучения
,"Как и то, что у них decoder reward
Кстати можно посмотреть trl код или deep speed chat  код где учат reward",Помогает от переобучения,Воть
,,,"Базово варианта 3: ласт токен, мин пул, хитрый минпул, когда мы делаем выравнивание по длине"
,,"Базово варианта 3: ласт токен, мин пул, хитрый минпул, когда мы делаем выравнивание по длине",Выравнивание по длине это как?
,"Базово варианта 3: ласт токен, мин пул, хитрый минпул, когда мы делаем выравнивание по длине",Выравнивание по длине это как?,"это когда в коротком тексте из пары берешь в мин пулинг еще пад токены, чтобы была одинаковая длина"
,,,"Ну последнее уже даже база
Я даже такое и для энкодеров кастом делаю"
,,"Ну последнее уже даже база
Я даже такое и для энкодеров кастом делаю","Есть идеи подергать с разных слоев, но руки еще не дошли"
,"Ну последнее уже даже база
Я даже такое и для энкодеров кастом делаю","Есть идеи подергать с разных слоев, но руки еще не дошли","А-ля как в USE
Тут кста bert как reward
Поэтому лучше тут искать"
"Ну последнее уже даже база
Я даже такое и для энкодеров кастом делаю","Есть идеи подергать с разных слоев, но руки еще не дошли","А-ля как в USE
Тут кста bert как reward
Поэтому лучше тут искать","Огонь, спасибо!"
"Есть идеи подергать с разных слоев, но руки еще не дошли","А-ля как в USE
Тут кста bert как reward
Поэтому лучше тут искать","Огонь, спасибо!",давно тут не было
,,,"Приветствую
Может ли кто подсказать, для задачи идентификации и для задачи верификации человека по лицу одна и та же нейронка одинаково хорошо должна работать, или под каждую задачу лучше отдельную нейронку натренировать? И если разные, то в чем отличие при обучении? Пока ощущение, что одну и ту же можно использовать без проблем."
,,"Приветствую
Может ли кто подсказать, для задачи идентификации и для задачи верификации человека по лицу одна и та же нейронка одинаково хорошо должна работать, или под каждую задачу лучше отдельную нейронку натренировать? И если разные, то в чем отличие при обучении? Пока ощущение, что одну и ту же можно использовать без проблем.","На всякий случай хотел предупредить, если это не учебный проект, а что-то, что пойдёт в прод с реальными лицами людей и на территории РФ, то с 1 июня такая идентификация является противозаконной, нужно либо пользоваться ебс, либо стать аккредитиванной организацией"
,"Приветствую
Может ли кто подсказать, для задачи идентификации и для задачи верификации человека по лицу одна и та же нейронка одинаково хорошо должна работать, или под каждую задачу лучше отдельную нейронку натренировать? И если разные, то в чем отличие при обучении? Пока ощущение, что одну и ту же можно использовать без проблем.","На всякий случай хотел предупредить, если это не учебный проект, а что-то, что пойдёт в прод с реальными лицами людей и на территории РФ, то с 1 июня такая идентификация является противозаконной, нужно либо пользоваться ебс, либо стать аккредитиванной организацией","А это интересно. Расскажите поподробнее?

Это про этот закон речь? Федеральный закон от 29.12.2022 N 572-ФЗ ""Об осуществлении идентификации и (или) аутентификации физических лиц с использованием биометрических персональных данных...""

Для банковской сферы, электронного документооборота вполне обоснованно его введение. Но распространяется ли этот закон, например на FaceID в телефоне? Или на умный дом, который умеет открывать дверь при виде хозяина? А на СКУД на молокозаводе?"
"Приветствую
Может ли кто подсказать, для задачи идентификации и для задачи верификации человека по лицу одна и та же нейронка одинаково хорошо должна работать, или под каждую задачу лучше отдельную нейронку натренировать? И если разные, то в чем отличие при обучении? Пока ощущение, что одну и ту же можно использовать без проблем.","На всякий случай хотел предупредить, если это не учебный проект, а что-то, что пойдёт в прод с реальными лицами людей и на территории РФ, то с 1 июня такая идентификация является противозаконной, нужно либо пользоваться ебс, либо стать аккредитиванной организацией","А это интересно. Расскажите поподробнее?

Это про этот закон речь? Федеральный закон от 29.12.2022 N 572-ФЗ ""Об осуществлении идентификации и (или) аутентификации физических лиц с использованием биометрических персональных данных...""

Для банковской сферы, электронного документооборота вполне обоснованно его введение. Но распространяется ли этот закон, например на FaceID в телефоне? Или на умный дом, который умеет открывать дверь при виде хозяина? А на СКУД на молокозаводе?","Да именно про фз 572. Про фейс айди интересный вопрос, я когда с ними общался (сейчас создали специального федерального оператора ебс - цбт, вот их офф канал в тг https://t.me/biometria_rf), забыл спросить. Скуды точно попадают, про умный дом хз, это если лично для себя делаешь то скорее можно пользоваться, если предоставляешь услуги связанные с распознаванием лица или голоса для умного дома, то попадает.
Чисто формально под закон попадает любая автоматизированная (то есть не человек проверяет личность) индентификация по лицу или голосу. То есть если в магазе трекаешь количество людей, то норм, но если ты их можешь как-то отличить(идентифицировать) по фото/видео, то уже попадаешь под закон. Так мне объяснили спецы из цбт"
,,,"Друзья, делаю мульти инпут берт регрессию, может ли кто-то помочь? ASAP! Заранее большое спасибо"
,,"Друзья, делаю мульти инпут берт регрессию, может ли кто-то помочь? ASAP! Заранее большое спасибо",А что не получается?
,"Друзья, делаю мульти инпут берт регрессию, может ли кто-то помочь? ASAP! Заранее большое спасибо",А что не получается?,Можно в лс напишу?
,,,Угу
,,Угу,"Обычно используют одну и ту же. Просто из-за простоты последующего использования, и сложности обучения специально для идентификации. Для идентификации можно дотюнивать или обучать дополнительный шаг модификации дескрипторов, чтобы вытащенные из базы дескрипторы были более релевантными."
,,,"Вопрос на засыпку...
Есть алгоритм который просто дает примерно 60-70% сделок плюсовых. (  Вроде даже хорошо и можно не заморачиватся оптимизацией. Но хочется поднять выше профитность и выйти на другие таймфреймы что бы  увеличить оборот,

Такая вот не тривиальная задача.
Есть датасет OHLCV + некоторые фичи ( всего примерно 10 столбцов) и сигналы на вход и профит с этой сделки... 

Хочу пойти через класификацию плюсовых сделок пойти. 
В какую сторону лучше пойти думать? И"
,,"Вопрос на засыпку...
Есть алгоритм который просто дает примерно 60-70% сделок плюсовых. (  Вроде даже хорошо и можно не заморачиватся оптимизацией. Но хочется поднять выше профитность и выйти на другие таймфреймы что бы  увеличить оборот,

Такая вот не тривиальная задача.
Есть датасет OHLCV + некоторые фичи ( всего примерно 10 столбцов) и сигналы на вход и профит с этой сделки... 

Хочу пойти через класификацию плюсовых сделок пойти. 
В какую сторону лучше пойти думать? И","не очень понял вопроса тоже, хочется навесить какой-то рискчекер-фильтр, который бы увеличил профитрость за счет уменьшения числа сделок, отбрасывая какие-то как «потенциально непрофитные»?"
,"Вопрос на засыпку...
Есть алгоритм который просто дает примерно 60-70% сделок плюсовых. (  Вроде даже хорошо и можно не заморачиватся оптимизацией. Но хочется поднять выше профитность и выйти на другие таймфреймы что бы  увеличить оборот,

Такая вот не тривиальная задача.
Есть датасет OHLCV + некоторые фичи ( всего примерно 10 столбцов) и сигналы на вход и профит с этой сделки... 

Хочу пойти через класификацию плюсовых сделок пойти. 
В какую сторону лучше пойти думать? И","не очень понял вопроса тоже, хочется навесить какой-то рискчекер-фильтр, который бы увеличил профитрость за счет уменьшения числа сделок, отбрасывая какие-то как «потенциально непрофитные»?",Хорошее желание :)
"Вопрос на засыпку...
Есть алгоритм который просто дает примерно 60-70% сделок плюсовых. (  Вроде даже хорошо и можно не заморачиватся оптимизацией. Но хочется поднять выше профитность и выйти на другие таймфреймы что бы  увеличить оборот,

Такая вот не тривиальная задача.
Есть датасет OHLCV + некоторые фичи ( всего примерно 10 столбцов) и сигналы на вход и профит с этой сделки... 

Хочу пойти через класификацию плюсовых сделок пойти. 
В какую сторону лучше пойти думать? И","не очень понял вопроса тоже, хочется навесить какой-то рискчекер-фильтр, который бы увеличил профитрость за счет уменьшения числа сделок, отбрасывая какие-то как «потенциально непрофитные»?",Хорошее желание :),"ну да, мечта)"
,,,"Всем добрый день!
Подскажите, пожалуйста, как бустинг под капотом обобщается на задачу multiclass и multilabel? 

Я знаю, что можно строить на i-м шаге K деревьев по числу классов, так делает XGBoost (классический OvA). Вроде бы LightGBM тоже для multiclass делает softmax над K бустингами. 

Но есть более продвинутая стратегия (в CatBoost), когда одно дерево может выдавать для наблюдения сразу вектор прогнозов. То есть строится фактически только один бустинг, оценивающий скор каждого класса (или лейбла). Я не совсем понимаю, как это работает: получается, в каждом листе уже не оценка логита происходит.

Очень бы хотел узнать об этом глубже. Может быть, есть какие-то материалы, которые было бы полезно посмотреть? Поправьте, пожалуйста, если где-то ошибся. Заранее спасибо!"
,,,"Всем привет!
Есть задача классификации изображений с микроскопа (клетки, все grayscale, пример приложен) на несколько классов (до 10). Классы различаются взаимным расположением, формой, размерами некоторых клеток. Кол-во изображеий ~ 2 тыс. (есть дисбаланс, 85% - наибольший класс, минимально представленный класс - 25 шт.).
Вопрос, существуют ли для подобных изображений (grayscale, нечеткие границы, однотипная структура) предобученные модели лучше, чем c ImageNet? 
Может быть модели из медицинского домена (тот же ковид по снимкам легких или что то подобное). Т.к. ""кажется"" что большинство фильтров/весов для извлечения фичей актуальных для ImageNet, здесь использоваться не будут (вернее из необходимо будет существенно переучивать)."
,,"Всем привет!
Есть задача классификации изображений с микроскопа (клетки, все grayscale, пример приложен) на несколько классов (до 10). Классы различаются взаимным расположением, формой, размерами некоторых клеток. Кол-во изображеий ~ 2 тыс. (есть дисбаланс, 85% - наибольший класс, минимально представленный класс - 25 шт.).
Вопрос, существуют ли для подобных изображений (grayscale, нечеткие границы, однотипная структура) предобученные модели лучше, чем c ImageNet? 
Может быть модели из медицинского домена (тот же ковид по снимкам легких или что то подобное). Т.к. ""кажется"" что большинство фильтров/весов для извлечения фичей актуальных для ImageNet, здесь использоваться не будут (вернее из необходимо будет существенно переучивать).","Привет. 
Есть различные подходы для сегементации клеток, например: https://github.com/stardist/stardist (вроде у них все на tensorflow, можно найти аналог библиотеки для торча).
Можно взять предобученный  энкодер (например: 2D_versatile_fluo 2D_paper_dsb2018),
навесить свой классификатор
и учить только его.
Ну и кажется вариант с fine-tuning моделей imagenet тоже рабочий"
,,,Хз. Брал серебро на кегле одноканальным претреном с имнгнета.
,,Хз. Брал серебро на кегле одноканальным претреном с имнгнета.,а по количеству изображений сопоставимо было?
,,,"Данных дето на порядок было больше, но они оч шумные были и на глаз сложно было отличить"
,,"Данных дето на порядок было больше, но они оч шумные были и на глаз сложно было отличить","понял, спасибо!"
,,,"ты хочешь бинарно класифицировать и понять вес фичей?
или классификтор вывести?"
,,"ты хочешь бинарно класифицировать и понять вес фичей?
или классификтор вывести?",При дисбалансе классов можно использовать взвешенную кросс-энтропию или focal loss
,"ты хочешь бинарно класифицировать и понять вес фичей?
или классификтор вывести?",При дисбалансе классов можно использовать взвешенную кросс-энтропию или focal loss,"спасибо большое за наводки и ссылки, буду изучать; про дисбаланс хотел попробовать и сравнить взвешенную кросс энтропию и oversampling ""малых"" классов; focal loss не пробовал, добавлю в сравнение"
,,,"Коллеги, нубский вопрос
Учу тсдае из под сберта, уменьшение длины строк позволяет увеличить батч (или раскрутить модель побольше при том же батчсайзе), почему так и работает ли это с другими лоссами?"
,,"Коллеги, нубский вопрос
Учу тсдае из под сберта, уменьшение длины строк позволяет увеличить батч (или раскрутить модель побольше при том же батчсайзе), почему так и работает ли это с другими лоссами?","Чем меньше длина, тем меньше занимает памяти, тем больше влезет батч"
,"Коллеги, нубский вопрос
Учу тсдае из под сберта, уменьшение длины строк позволяет увеличить батч (или раскрутить модель побольше при том же батчсайзе), почему так и работает ли это с другими лоссами?","Чем меньше длина, тем меньше занимает памяти, тем больше влезет батч",Л логично
,,,Так а это разве сформер не фикссайз эмбед выдает
,,Так а это разве сформер не фикссайз эмбед выдает,Их количество не фикс
,Так а это разве сформер не фикссайз эмбед выдает,Их количество не фикс,На самом деле большое спасибо вы мне сделали прозрение
,,,нейронка что ли?
,,нейронка что ли?,да
,,,"А не подскажете, есть готовый пример такого рискчекера фильтра? 👀"
,,"А не подскажете, есть готовый пример такого рискчекера фильтра? 👀","ну у меня есть для около хфт стратегий такие статистические большем, но имхо если это мидфрик, то в проприетарных масштабах и в отсутствии портфеля альф (как я понимаю тут такой случай), это все должно быть частью самого алгоритма, так что «нечего оптимизировать» может быть неправда и можно попробовать запустить баес параметров по шарпу, например"
,,,"есть подозрение, что там будет у объема очень большой вес и все свалится в негативный предикт на крупные объемы"
,,"есть подозрение, что там будет у объема очень большой вес и все свалится в негативный предикт на крупные объемы","+ какой-то постаналис, посмотреть откуда идет НЕпрофитные сделки, это что-то, что часто ловит минревеижн => оптимизируем параметры алгоритма чтобы не иметь экспожура на минревержн, если это высокая волатильность на открытии/закрытии сессий на текущем рынке, или на иных рынках -> добавить просто tag с тем, что за сессия и посчитать статистики по каждой сессии и дальше принять решение о том, как параметризовать на это (меньше позы на открытии/закрытии ny/apac)"
,,,"Сюда можно скинуть ТЗ на модель, связанную с NLP (точнее аудиопотока с речью) и поискать исполнителей для этой истории?"
,,"Сюда можно скинуть ТЗ на модель, связанную с NLP (точнее аудиопотока с речью) и поискать исполнителей для этой истории?","Думаю, можно.
А если внятно прописать условия, можно ещё запостить в канал @nlp_jobs."
,,,"Всем привет, какие альтернативы есть facerig (для обычного пользователя, не для дизайна) в 2023? Подскажите, если знает кто"
,,"Всем привет, какие альтернативы есть facerig (для обычного пользователя, не для дизайна) в 2023? Подскажите, если знает кто",WORD EMBEDDING MUST BE STOPPED
,,,"Баян, но после собесов актуально"
,,"Баян, но после собесов актуально",Это типо ты с тим лидом пьешь?😁
,"Баян, но после собесов актуально",Это типо ты с тим лидом пьешь?😁,Я и есть лид
,,,Есть ли тут чат по генеративным моделям?
,,Есть ли тут чат по генеративным моделям?,nlp?
,Есть ли тут чат по генеративным моделям?,nlp?,"генеративные модели могут применяться и в nlp, и cv, и других доменах 🤔"
Есть ли тут чат по генеративным моделям?,nlp?,"генеративные модели могут применяться и в nlp, и cv, и других доменах 🤔","Генеративные модели это принцип методологии, в каждой сфере свои подходы."
,,,"а, мне почему-то показалось ,что в nlp))"
,,"а, мне почему-то показалось ,что в nlp))","Товарищи, я слепой, где в kaggle включить интернет и устанавливать сторонние пакеты, не нахожу нигде в настройках
ааа, тут нужно номер подтвердить, мелким текстом спрятали эту возможность
спасибо всем)"
,,,"а русские номера нельзя подтверждать, да?"
,,"а русские номера нельзя подтверждать, да?",Можно.
,,,"можно в поддержку написать, вроде так подтверждают"
,,,А записи будут доступны?
,,А записи будут доступны?,"Скорее всего, их вообще не будет"
,,,"В общем всем кто занимается биометрией советую ещё с вашими юристами проконсультироваться. Закон новый и сырой, есть непонятные вещи, например как с фэйс ид. Если раньше занимались биометрией, то сейчас переходный период, до конца года (точно не помню дату то ли 1 декабря или ноября) надо передать данные в цбт, если только начинаете, то без лицензии - это нарушение закона 🤷‍♂🤷‍♂🤷‍♂"
,,,"Спасибо, интересно!
Созрел ещё вопрос. Если подключаться к ебс (придумали же сокращение), то туда фотки отсылаются, или нужно ГОСТовской нейронкой получить вектор и его отсылать?"
,,"Спасибо, интересно!
Созрел ещё вопрос. Если подключаться к ебс (придумали же сокращение), то туда фотки отсылаются, или нужно ГОСТовской нейронкой получить вектор и его отсылать?","Там есть варики. У них какие-то свои нейронки есть. Нужно фотку посылать определённого размера и качества, где-то это есть написано. Да, кстати, это не бесплатно за каждый запрос нужно платить, раньше писали что рублей 60, сейчас все стали возмущаться, что очень дорого сильно снизили. Можно и кастомные (свои нейронки) запускать у них на серваках, но это надо быть аккредитиванной организацией и там хз какая оплата за это. Но, чтоб стать аккредитиванной организацией, нужно сильно упороться. Например, фирме нужно иметь капитал 500 кк рублей"
,"Спасибо, интересно!
Созрел ещё вопрос. Если подключаться к ебс (придумали же сокращение), то туда фотки отсылаются, или нужно ГОСТовской нейронкой получить вектор и его отсылать?","Там есть варики. У них какие-то свои нейронки есть. Нужно фотку посылать определённого размера и качества, где-то это есть написано. Да, кстати, это не бесплатно за каждый запрос нужно платить, раньше писали что рублей 60, сейчас все стали возмущаться, что очень дорого сильно снизили. Можно и кастомные (свои нейронки) запускать у них на серваках, но это надо быть аккредитиванной организацией и там хз какая оплата за это. Но, чтоб стать аккредитиванной организацией, нужно сильно упороться. Например, фирме нужно иметь капитал 500 кк рублей",500кк = 500 миллионов ?
,,,"Про закон - как я понял, нельзя хранить биометрию (ембеды плюс что-то) людей и искать по ним. FaceID сравнивает с одним ембедом, поэтому вроде как можно"
,,"Про закон - как я понял, нельзя хранить биометрию (ембеды плюс что-то) людей и искать по ним. FaceID сравнивает с одним ембедом, поэтому вроде как можно","По закону нельзя ни хранить, ни проводить аутентификацию/идентификацию при помощи алгоритмов, по сути в айфоне все равно хранится 1 эмбдинг. Я конечно, не юрист но какой-то пограничный случай, могут эпл прихватить, при желании"
,,,ну и цены
,,ну и цены,"Судя по всему хотят могополизировать рынок биометрии, потому, что такие ограничения сразу отрезают большой процент контор, которые занимаются/хотели бы заниматься биометрией"
,,,"да, именно так)
Не нравится, не работай с биометрией, или плати в ебс, либо плати другим аккредитованным конторам"
,,,"И еще говорят, что это развитие биометрических систем, скорее это конец развитию, с другой стороны, нужно как-то контролить, а то утечки постоянно случаются. С третьей стороны, если ты хранишь какой-то uuid и embedding, то лицо человека никак не восстановить по нему, даже если знаешь, какая нейронка использовалась с какими весами"
,,"И еще говорят, что это развитие биометрических систем, скорее это конец развитию, с другой стороны, нужно как-то контролить, а то утечки постоянно случаются. С третьей стороны, если ты хранишь какой-то uuid и embedding, то лицо человека никак не восстановить по нему, даже если знаешь, какая нейронка использовалась с какими весами",Чегой то вдруг никак? А автоэнкодеры как работают?
,"И еще говорят, что это развитие биометрических систем, скорее это конец развитию, с другой стороны, нужно как-то контролить, а то утечки постоянно случаются. С третьей стороны, если ты хранишь какой-то uuid и embedding, то лицо человека никак не восстановить по нему, даже если знаешь, какая нейронка использовалась с какими весами",Чегой то вдруг никак? А автоэнкодеры как работают?,"автоэнкодеры строятся так, чтобы можно было восстановить лицо из эмбеддингов
в общем случае это не так"
,,,"Прям реально никак? Мб обратное отображение несколько неоднозначно, но там же далеко не полный рандом"
,,"Прям реально никак? Мб обратное отображение несколько неоднозначно, но там же далеко не полный рандом","Ну да, что-то похожее будет, но не тот самый человек, это если знаешь какой моделью с какими весами их делали, то как-то можно будет натренить. Создать свой датасет и попробовать восстановить, но не зная исходных лиц (из базы), проверить на сколько это хорошо сделано тоже невозможно"
,"Прям реально никак? Мб обратное отображение несколько неоднозначно, но там же далеко не полный рандом","Ну да, что-то похожее будет, но не тот самый человек, это если знаешь какой моделью с какими весами их делали, то как-то можно будет натренить. Создать свой датасет и попробовать восстановить, но не зная исходных лиц (из базы), проверить на сколько это хорошо сделано тоже невозможно",Это да
,,,вроде восстанавливали как то по эмбедингам
,,вроде восстанавливали как то по эмбедингам,"Так если собрать базу лиц аналогичную, со слитой сетью и весами, разве декодер нельзя натренировать для этого latent space?"
,,,"Понятно будут потери информации, не 1 в 1, но узнаваемо то будет"
,,"Понятно будут потери информации, не 1 в 1, но узнаваемо то будет","Ну похожий, может он, а может вообще такого человека не существует, что там декодер найдет в этом латентом пространстве, не знает никто)"
,,,"В общем моя мысль к тому, что очень жесткая регуляция биометрии, в любом случае в бд можно хранить шифрованные эмбединги, тогда ломать систему будет совсем не выгодно материально, даже если ты получишь лица, ты не знаешь ФИО человека. Выглядет сейчас так как-будто кто-то приближенный хочет срубить бабла на этой теме"
,,,"Ну то есть натренировали мы энкодер на 500млн лиц, затем слили сеть и веса, затем взяли другой датасет на других 500млн лиц, натренировали автонэнкодер с замороженным энкодером, где энкодер - слитая сеть, а таргеты - новый датасет. Далее декодим имеющиеся от неизвестной базы эмбеддинги. Интуиция подсказывает, что при хорошей размерности latent space и прочих подобранных гиперпараметрах, должно давать plausible результат"
,,"Ну то есть натренировали мы энкодер на 500млн лиц, затем слили сеть и веса, затем взяли другой датасет на других 500млн лиц, натренировали автонэнкодер с замороженным энкодером, где энкодер - слитая сеть, а таргеты - новый датасет. Далее декодим имеющиеся от неизвестной базы эмбеддинги. Интуиция подсказывает, что при хорошей размерности latent space и прочих подобранных гиперпараметрах, должно давать plausible результат","Эмбединги условно могут быть сжатые с упором на конкретные паттерны, все помимо этого на изображении будет кашей"
,"Ну то есть натренировали мы энкодер на 500млн лиц, затем слили сеть и веса, затем взяли другой датасет на других 500млн лиц, натренировали автонэнкодер с замороженным энкодером, где энкодер - слитая сеть, а таргеты - новый датасет. Далее декодим имеющиеся от неизвестной базы эмбеддинги. Интуиция подсказывает, что при хорошей размерности latent space и прочих подобранных гиперпараметрах, должно давать plausible результат","Эмбединги условно могут быть сжатые с упором на конкретные паттерны, все помимо этого на изображении будет кашей","Зависит от слитой сети. Подогнать декодер всегда можно, имея энкодер и веса на руках"
,,,Few shot fine tuned decoder наверное возможно сделать
,,,"Ну да, может я погорячился с ""никак"" нельзя. С какой-то точностью и большими трудозатратами и денежными ресурсами, что-то более менее вменяемое можно сообразить. Но учитывая такое количество человеко часов и денег (в колабе 500 мл лиц не потренишь), то те, кто этим занимаются должны представлять какая выгода от этого, чтоб покрыла расходы и еще заработать на этом, то видится крайне маловероятным такой исход. 
Тут наверное если по этому эмбеду можно получить доступ к банковским продуктам, но тут надо знать кого искать, а то потратишь на это все несколько сотен долларов, а взломаешь чела с 10 к рублями)"
,,"Ну да, может я погорячился с ""никак"" нельзя. С какой-то точностью и большими трудозатратами и денежными ресурсами, что-то более менее вменяемое можно сообразить. Но учитывая такое количество человеко часов и денег (в колабе 500 мл лиц не потренишь), то те, кто этим занимаются должны представлять какая выгода от этого, чтоб покрыла расходы и еще заработать на этом, то видится крайне маловероятным такой исход. 
Тут наверное если по этому эмбеду можно получить доступ к банковским продуктам, но тут надо знать кого искать, а то потратишь на это все несколько сотен долларов, а взломаешь чела с 10 к рублями)","Вопрос рациональности такого мероприятия, конечно, стоит отдельно и обесценивает затраты, я думаю. Тут согласен)"
,"Ну да, может я погорячился с ""никак"" нельзя. С какой-то точностью и большими трудозатратами и денежными ресурсами, что-то более менее вменяемое можно сообразить. Но учитывая такое количество человеко часов и денег (в колабе 500 мл лиц не потренишь), то те, кто этим занимаются должны представлять какая выгода от этого, чтоб покрыла расходы и еще заработать на этом, то видится крайне маловероятным такой исход. 
Тут наверное если по этому эмбеду можно получить доступ к банковским продуктам, но тут надо знать кого искать, а то потратишь на это все несколько сотен долларов, а взломаешь чела с 10 к рублями)","Вопрос рациональности такого мероприятия, конечно, стоит отдельно и обесценивает затраты, я думаю. Тут согласен)","Ну только если надо срочно попасть на молокозавод по СКУД, тогда усилия точно оправданы)))"
"Ну да, может я погорячился с ""никак"" нельзя. С какой-то точностью и большими трудозатратами и денежными ресурсами, что-то более менее вменяемое можно сообразить. Но учитывая такое количество человеко часов и денег (в колабе 500 мл лиц не потренишь), то те, кто этим занимаются должны представлять какая выгода от этого, чтоб покрыла расходы и еще заработать на этом, то видится крайне маловероятным такой исход. 
Тут наверное если по этому эмбеду можно получить доступ к банковским продуктам, но тут надо знать кого искать, а то потратишь на это все несколько сотен долларов, а взломаешь чела с 10 к рублями)","Вопрос рациональности такого мероприятия, конечно, стоит отдельно и обесценивает затраты, я думаю. Тут согласен)","Ну только если надо срочно попасть на молокозавод по СКУД, тогда усилия точно оправданы)))",Меньше чем за ликеро-водочный даже ноут не откроем!))
,,,"Привет, кому-то доводилось писать кастомные лоссы?

Не занимался этим делом раньше, и не могу понять, надо ли это мне. Хочется узнать ответы на три вопроса: 
1.) Как часто это приходится делать на практике?
2.) Насколько целесообразно это делать? По сложности\прибавка к качеству модели
3.)  Для чего вообще писать кастомный лосс? Какие проблемы он может решить
 

Буду благодарен 🙇‍♂️🙇‍♂️🙇‍♂️"
,,"Привет, кому-то доводилось писать кастомные лоссы?

Не занимался этим делом раньше, и не могу понять, надо ли это мне. Хочется узнать ответы на три вопроса: 
1.) Как часто это приходится делать на практике?
2.) Насколько целесообразно это делать? По сложности\прибавка к качеству модели
3.)  Для чего вообще писать кастомный лосс? Какие проблемы он может решить
 

Буду благодарен 🙇‍♂️🙇‍♂️🙇‍♂️","нейронка выдавала физически невозможное состояние системы, добавил соответствующее слагаемое в лосс и проблема ушла"
,,,"Максимум , что я делал, это сумму нескольких лоссов. А в какой задаче возник такой вопрос ? Написать просто, имхо, возьми квадрат MSE, будет такой кастомный лосс :)"
,,"Максимум , что я делал, это сумму нескольких лоссов. А в какой задаче возник такой вопрос ? Написать просто, имхо, возьми квадрат MSE, будет такой кастомный лосс :)","1. У кого как, от задач зависит. Часто новые статьи требуют кастомной работы (не только лоссы).
2. Субъективно, сложность около нуля. Но нужно некоторое время, в первую очередь, на тесты правильности работы.
3. Когда стандартный не подходит)

Прошу прощения за туманность ответов, но тут по принципу ""каков вопрос""))"
,"Максимум , что я делал, это сумму нескольких лоссов. А в какой задаче возник такой вопрос ? Написать просто, имхо, возьми квадрат MSE, будет такой кастомный лосс :)","1. У кого как, от задач зависит. Часто новые статьи требуют кастомной работы (не только лоссы).
2. Субъективно, сложность около нуля. Но нужно некоторое время, в первую очередь, на тесты правильности работы.
3. Когда стандартный не подходит)

Прошу прощения за туманность ответов, но тут по принципу ""каков вопрос""))","1. Постоянно
2. Иногда без этого никак, иногда чистое позерство
3. Хитрая постановка задачи, дополнительные предположения о функции ошибки. 
Из проблем, например, проблему того, что без него ничего работать не будет))"
,,,А можете написать пример задачи и кастомного лосса ? Мне любопытно
,,А можете написать пример задачи и кастомного лосса ? Мне любопытно,"была любопытная задача по фиту к контуру четырехугольника, с доп. ограничениями на положение сторон
пришлось писать свой велосипед, чтоб быстро проверить гипотезу
задача вообще не про DL, но на торче запрототипировать оказалось удобнее)"
,,,"Wasserstein loss + gradient penalty (генерация)
SwAV loss (self-supervised экстрактор фичей)"
,,"Wasserstein loss + gradient penalty (генерация)
SwAV loss (self-supervised экстрактор фичей)","аааа, ну типа такого я тоже писал :) прошу прощения, я наверное неправильно понял изначальный вопрос. я подумал, что кастомный - это прям свой-свой велосипед."
,"Wasserstein loss + gradient penalty (генерация)
SwAV loss (self-supervised экстрактор фичей)","аааа, ну типа такого я тоже писал :) прошу прощения, я наверное неправильно понял изначальный вопрос. я подумал, что кастомный - это прям свой-свой велосипед.","Ну, я под кастомным понимаю то, чего нет во фреймворках. Т.е. то, что требует написания своей функции"
"Wasserstein loss + gradient penalty (генерация)
SwAV loss (self-supervised экстрактор фичей)","аааа, ну типа такого я тоже писал :) прошу прощения, я наверное неправильно понял изначальный вопрос. я подумал, что кастомный - это прям свой-свой велосипед.","Ну, я под кастомным понимаю то, чего нет во фреймворках. Т.е. то, что требует написания своей функции",в такой постановке задачи вопросов нет. я чето не вкурил сразу :(
"аааа, ну типа такого я тоже писал :) прошу прощения, я наверное неправильно понял изначальный вопрос. я подумал, что кастомный - это прям свой-свой велосипед.","Ну, я под кастомным понимаю то, чего нет во фреймворках. Т.е. то, что требует написания своей функции",в такой постановке задачи вопросов нет. я чето не вкурил сразу :(,"Ну, я и сейчас не уверен правильно ли я понял о чем спрашивают"
,,,"Perceptual loss (Style transfer/super resolution) (не уверен, что ещё актуально, не отслеживал)"
,,,"continuous ranked probability score
достаточно кастомный?"
,,"continuous ranked probability score
достаточно кастомный?","ну то есть считаем кастомным тот, который не библиотечный ? тогда да :)"
,,,"это такой, скорее экзотический пример, с максимально ""кастомным"" (в вашем понимании) лоссом)"
,,"это такой, скорее экзотический пример, с максимально ""кастомным"" (в вашем понимании) лоссом)","всем привет. есть задача разбить текст на логические блоки, в какую сторону копать?"
,,,Что можно почитать про инновации и развитие темы GANов за за последние годы?
,,Что можно почитать про инновации и развитие темы GANов за за последние годы?,Вот канал есть специальный по ганам https://t.me/casual_gan
,Что можно почитать про инновации и развитие темы GANов за за последние годы?,Вот канал есть специальный по ганам https://t.me/casual_gan,"Спасибо.
Автор канала похоже выгорел год назад."
,,,"Ну там чатик есть отдельный можно там поспрашивать
Мне год назад рекомендовали там vqgan, но это аж 2021 года статья так что...))"
,,,"Подскажите, пожалуйста, что сейчас есть из классического NLP помимо NLTK?   Задача: извлекать именованные сущности и отношения из слабоструктурированного текста с кучей опечаток и сокращений, вроде ""уч. пл. 10га в 3км к СЗ от с.Малые Лопари"" При этом сокращения зависят от контекста: ст. Может означать ""станция"", ""станица"", ""столб"" или ""строение"". Данных для обучения нейросетевых моделей мало, а из коробки они такое не едят."
,,"Подскажите, пожалуйста, что сейчас есть из классического NLP помимо NLTK?   Задача: извлекать именованные сущности и отношения из слабоструктурированного текста с кучей опечаток и сокращений, вроде ""уч. пл. 10га в 3км к СЗ от с.Малые Лопари"" При этом сокращения зависят от контекста: ст. Может означать ""станция"", ""станица"", ""столб"" или ""строение"". Данных для обучения нейросетевых моделей мало, а из коробки они такое не едят.",У deeppavlov есть неплохой берт
,"Подскажите, пожалуйста, что сейчас есть из классического NLP помимо NLTK?   Задача: извлекать именованные сущности и отношения из слабоструктурированного текста с кучей опечаток и сокращений, вроде ""уч. пл. 10га в 3км к СЗ от с.Малые Лопари"" При этом сокращения зависят от контекста: ст. Может означать ""станция"", ""станица"", ""столб"" или ""строение"". Данных для обучения нейросетевых моделей мало, а из коробки они такое не едят.",У deeppavlov есть неплохой берт,"В последний раз когда трогал deeppavlov для NER, он пропускал почти любые имена с незаглавное буквы"
,,,Для ру домена Наташа
,,,"Всем привет, может кто подсказать какой-нибудь курс/туториалы по программированию на cuda?"
,,"Всем привет, может кто подсказать какой-нибудь курс/туториалы по программированию на cuda?",https://telegra.ph/Kickstart-in-CUDA-by-ai-newz-04-16
,"Всем привет, может кто подсказать какой-нибудь курс/туториалы по программированию на cuda?",https://telegra.ph/Kickstart-in-CUDA-by-ai-newz-04-16,"О, спасибо!"
"Всем привет, может кто подсказать какой-нибудь курс/туториалы по программированию на cuda?",https://telegra.ph/Kickstart-in-CUDA-by-ai-newz-04-16,"О, спасибо!","Спасибо Артёму, автору @ai_newz
Всём, кто ещё не подписан, рекомендую, оч крутой канал!"
,,,спасибо🙏
,,,"Я бы рекомендовал разметить побольше данных (как вариант, с применением активного обучения), и дообучить какой-нибудь BERT на детекцию ваших сущностей.

Наташа из коробки поддерживает только сущности типа person/location/organization, и только в ""новостном"" формате текстов (с правильной капитализацией и пунктуацией), а дообучить её на новые сущности или домен - сложнее, чем дообучить BERT."
,,"Я бы рекомендовал разметить побольше данных (как вариант, с применением активного обучения), и дообучить какой-нибудь BERT на детекцию ваших сущностей.

Наташа из коробки поддерживает только сущности типа person/location/organization, и только в ""новостном"" формате текстов (с правильной капитализацией и пунктуацией), а дообучить её на новые сущности или домен - сложнее, чем дообучить BERT.","Но если хочется писать правила, а не обучать модели, тогда можно писать их на yargy (на котором работала предыдущая версия наташи, до того, как она стала нейросетевой)"
,"Я бы рекомендовал разметить побольше данных (как вариант, с применением активного обучения), и дообучить какой-нибудь BERT на детекцию ваших сущностей.

Наташа из коробки поддерживает только сущности типа person/location/organization, и только в ""новостном"" формате текстов (с правильной капитализацией и пунктуацией), а дообучить её на новые сущности или домен - сложнее, чем дообучить BERT.","Но если хочется писать правила, а не обучать модели, тогда можно писать их на yargy (на котором работала предыдущая версия наташи, до того, как она стала нейросетевой)",Правила мне кажутся более предсказуемым подходом. Для каждого утверждения можно понять по каким правилам оно было распознано и при необходимости покрутить. А мл модели это штука вероятностная
,,,у кайф
,,у кайф,"Кто-нибудь знаком с экспертами в области Knowledge base population, Knowledge Graph Completion, etc.?"
,у кайф,"Кто-нибудь знаком с экспертами в области Knowledge base population, Knowledge Graph Completion, etc.?","InCommodities A/S, a Danish trading firm backed by Goldman Sachs Group Inc., reported a ninefold increase in profit last year as it benefited from record price volatility triggered by the energy crisis.

The surge in pretax profit to €1.37 billion ($1.5 billion) from €146 million reflects the market turbulence caused by Russia’s invasion of Ukraine, which sent prices for power and gas soaring. Other commodity traders — from Vitol Group to Mercuria Energy Group Ltd. — also posted bumper earnings for 2022.

The market gyrations were a “100-year event” as Covid restrictions, stimulus packages and the war in Ukraine all combined to cause wild price swings, InCommodities Chief Executive Officer Jesper Johanson said in an interview. As such, he doesn’t expect that level of profits to be repeated.

“We’ve seen prices and volatility come down quite significantly across the whole energy spectrum,” Johanson said. “It’s probably true for most companies involved in energy trading that it’s going to be a different year than in 2022.”

InCommodities, founded in 2017 in Aarhus and focused on Europe and the US, will tap some of its earnings to expand in Asia. It’s active in 20 power markets and more than a dozen gas markets, and is developing its first solar park in its home city.

“We’re setting up an office in Singapore as we speak, and we’re looking very intensively at the Japanese market to see how we can apply our skill-set and our way of managing assets there,” Johanson said.

Another Aarhus trader, MFT Energy P/s, said Wednesday it’s looking to sell a stake. But Johanson doesn’t plan to follow suit. Goldman holds just over 5% of the company, while 85% is owned by management and staff."
,,,"коллеги. кто-нибудь шарит за semi-supervised обучение? нужно сегментировать снимки, но размеченный сет маленький. Я знаю, что можно доразмечать данные самой моделью, но не уверен, есть ли уже готовые сборки.
статьи, подходы, репозитории, идеи - накидайте, что в голову придет. Буду признателен"
,,"коллеги. кто-нибудь шарит за semi-supervised обучение? нужно сегментировать снимки, но размеченный сет маленький. Я знаю, что можно доразмечать данные самой моделью, но не уверен, есть ли уже готовые сборки.
статьи, подходы, репозитории, идеи - накидайте, что в голову придет. Буду признателен",https://github.com/HiLab-git/SSL4MIS
,,,Особенно -если есть опыт решения подобной задачи. остальное я так или иначе нагуглю))
,,Особенно -если есть опыт решения подобной задачи. остальное я так или иначе нагуглю)),"недавно для подобного пользовался lightly, очень доступная библиотека"
,,,"а, сорян, прочёл self-supervised вместо semi"
,,"а, сорян, прочёл self-supervised вместо semi",все равно посмотрю
,"а, сорян, прочёл self-supervised вместо semi",все равно посмотрю,"тем не менее, если у тебя много неразмеченных в нужном домене — может пригодиться"
,,,"Я правильно понимаю, что эмпирическая ковариационная матрица всегда положительно полуопределённая?"
,,"Я правильно понимаю, что эмпирическая ковариационная матрица всегда положительно полуопределённая?",всегда неотрицательно определена
,"Я правильно понимаю, что эмпирическая ковариационная матрица всегда положительно полуопределённая?",всегда неотрицательно определена,"Разобрался, спасибо"
,,Спасибо,"огонь
спасибо))"
,Спасибо,"огонь
спасибо))",А я-то уж чуть Sam_b почти в прод не запихал)
Спасибо,"огонь
спасибо))",А я-то уж чуть Sam_b почти в прод не запихал),Запихнуть предобработку и генерацию фичей в код и управлять этим как параметрами эксперимента?
"огонь
спасибо))",А я-то уж чуть Sam_b почти в прод не запихал),Запихнуть предобработку и генерацию фичей в код и управлять этим как параметрами эксперимента?,SD 1.4 и outpainting
А я-то уж чуть Sam_b почти в прод не запихал),Запихнуть предобработку и генерацию фичей в код и управлять этим как параметрами эксперимента?,SD 1.4 и outpainting,а почему это в text2image-то
Запихнуть предобработку и генерацию фичей в код и управлять этим как параметрами эксперимента?,SD 1.4 и outpainting,а почему это в text2image-то,"Я использовал, как text2image
А куда надо было отправить?"
,,,"всем привет, подскажите как можно ускорить инференс модели через onnx, ну и вообще в целом как можно ускорить инференс (модель по классификации видео)"
,,"всем привет, подскажите как можно ускорить инференс модели через onnx, ну и вообще в целом как можно ускорить инференс (модель по классификации видео)","А ты делал замеры что узкое место именно в части инференса? В моем случае огромный прирост скорости дала не его оптимизация, а оптимизация процесса получения входа модели из изображений, прогон батчами вместо одиночного изображения. И параллелизация всех процессов, пока через видеокарту идет инференс подготавливаются следующие данные для следующего прогона."
,"всем привет, подскажите как можно ускорить инференс модели через onnx, ну и вообще в целом как можно ускорить инференс (модель по классификации видео)","А ты делал замеры что узкое место именно в части инференса? В моем случае огромный прирост скорости дала не его оптимизация, а оптимизация процесса получения входа модели из изображений, прогон батчами вместо одиночного изображения. И параллелизация всех процессов, пока через видеокарту идет инференс подготавливаются следующие данные для следующего прогона.",Ну я не знаю как ещё можно ускорить поступление видео в модель
"всем привет, подскажите как можно ускорить инференс модели через onnx, ну и вообще в целом как можно ускорить инференс (модель по классификации видео)","А ты делал замеры что узкое место именно в части инференса? В моем случае огромный прирост скорости дала не его оптимизация, а оптимизация процесса получения входа модели из изображений, прогон батчами вместо одиночного изображения. И параллелизация всех процессов, пока через видеокарту идет инференс подготавливаются следующие данные для следующего прогона.",Ну я не знаю как ещё можно ускорить поступление видео в модель,"Если с видео в модель загоняется фреймами и каждый фрейм под вход модели резайзится, то можно за один проход прогонять батч в 60 фреймов, например (от количества видеопамяти зависит)."
,,,"Конвертируешь из торча в onnx, потом tensorrt/openvino. Это один из вариантов."
,,,"Засунуть onnx в tensorrt и дождаться, когда магия произойдёт"
,,"Засунуть onnx в tensorrt и дождаться, когда магия произойдёт",А магия произойдёт?
,"Засунуть onnx в tensorrt и дождаться, когда магия произойдёт",А магия произойдёт?,"Только для той гпу, на которой гоняешь"
,,,А
,,А,"Ещё можно torch script попробовать, но я не знаю точно, используют ли его для оптимизации инференса в том плане, как используют tensorrt - чтоб он перебирал структуру, склеивал слои и тд"
,,,"Там классификация в реал тайме, не думаю, что так получится, то есть для каждого таймстампа там нужно присвоить класс условно говоря"
,,"Там классификация в реал тайме, не думаю, что так получится, то есть для каждого таймстампа там нужно присвоить класс условно говоря","таймсепы, про которые вы пишите могут быть не обязательно последовательными кадрами видео, можно брать каждый n-тый кадр, также можно батчами обрабатывать, а не гонять модель и данные с гпу на хост на каждый таймстеп. Ну и квантование конечно тоже мастхев"
,,,"можете сдистиллить модель в какую-нибудь маленькую, если задача позволяет, но качество упадет на несколько процентов"
,,"можете сдистиллить модель в какую-нибудь маленькую, если задача позволяет, но качество упадет на несколько процентов","Это да, квантизации там всякие, да"
,,,"Так вполне реально, выход модели после батча будет же так же в виде массива, где одна из размерностей отвечает за каждый элемент батча.
Типа
input = [batchSize, channelsCount, width, height]
output = [batchSize, datas]

Т.е. выход можно будет привязать к конкретному фрейму"
,,"Так вполне реально, выход модели после батча будет же так же в виде массива, где одна из размерностей отвечает за каждый элемент батча.
Типа
input = [batchSize, channelsCount, width, height]
output = [batchSize, datas]

Т.е. выход можно будет привязать к конкретному фрейму","Попробую, спасибо"
,,,"не, это другое чуть-чуть"
,,"не, это другое чуть-чуть","я знаю, но времени на обучение дистилляции нет сейчас
а квантизацию можно провернуть"
,,,"Оцените, пожалуйста, резюме. Опыта работы нет, есть только учебные пет проекты, курсы и т.п"
,,"Оцените, пожалуйста, резюме. Опыта работы нет, есть только учебные пет проекты, курсы и т.п","вам стоит заморочиться над оформлением. 
1. Название файла,
2. Пустая страница два,
3. Лайаут (расположение) текста.

Нечитабельно, неопрятно.

Касательно остального. Это для чего резюме? У каждой бумаги должна быть цель)

Проще всего как сделать, достаточно универсальный совет. 
- изучаете требования в вакансиях,
- смотрите, что в вашем опыте релевантно,
- подсвечиваете в направлении.

Резюме - это затравка к беседе. Главное попасть на беседу туда, где вам будет комфортно, и где с вами тоже будет комфортно, поэтому важно оглянуться"
,"Оцените, пожалуйста, резюме. Опыта работы нет, есть только учебные пет проекты, курсы и т.п","вам стоит заморочиться над оформлением. 
1. Название файла,
2. Пустая страница два,
3. Лайаут (расположение) текста.

Нечитабельно, неопрятно.

Касательно остального. Это для чего резюме? У каждой бумаги должна быть цель)

Проще всего как сделать, достаточно универсальный совет. 
- изучаете требования в вакансиях,
- смотрите, что в вашем опыте релевантно,
- подсвечиваете в направлении.

Резюме - это затравка к беседе. Главное попасть на беседу туда, где вам будет комфортно, и где с вами тоже будет комфортно, поэтому важно оглянуться","Это резюме не в конкретную компанию, просто на вакансию ML-engineer. Под конкретную вакансию буду выделять что-то. Просто собрал и обобщил свой опыт, чтобы человеку было понятно, что я из себя представляю как сотрудник"
,,,"По поводу дизайна, учту, спасибо. А что касается содержимого, есть, что сказать?"
,,"По поводу дизайна, учту, спасибо. А что касается содержимого, есть, что сказать?","До содержимого нужно добраться вследствие оформления, а это и впрямь важно.

Перечисление курсов... Вы представьте себя на месте hr, которым стопки приходят резюме, и все с ключевыми словами. 

Курсы сами по себе не ценность, как и знания, для начинающего спеца. В начинающих всегда поначалу больше вкладывают, чем получают.

Поэтому чтобы паззлы складывались, нужно, еще раз, обозначать направление мечты.

Напишите, ""хочу вертеть докеры с сетками с утра до вечера, испытываю удовольствие когда инфраструктура дает буст в юнит-экономику"", и шанс прирастет значительно"
,,,"В остальном скиллсет для старта неслабый 👍 так скажем под мои вакансии на собес попадание 100%, а там дальше уже как кривая выводить будет"
,,,"И еще, nothing personal only business, на аву тоже смотрят, причём ее вес при принятии решения не последний. Но я этого не рассказывал =)"
,,"И еще, nothing personal only business, на аву тоже смотрят, причём ее вес при принятии решения не последний. Но я этого не рассказывал =)",Так что лучше не ставить?)
,"И еще, nothing personal only business, на аву тоже смотрят, причём ее вес при принятии решения не последний. Но я этого не рассказывал =)",Так что лучше не ставить?),"Да, самое политкорректное лицом не светить. По теореме Байеса так шанс выше

P(приглос на собес|нет отвлекающих персональных факторов)"
,,,"Где можно более подробно почитать про обучение Stable diffusion? Статью не нашел. Я просто пытаюсь сделать аналог classifier guidance и сейчас надо выбрать какую-то часть laion2B для обучения. Меня смущает, что если брать рандомные картинки и промпты, то:
1) промпты бывают очень ""грязные""
2) есть маленькие картинки и их придется ресайзить до 512x512, на выходе получается что-то такое, на чем не хочется учиться.
Кстати, есть советы как отобрать данные?"
,,"Где можно более подробно почитать про обучение Stable diffusion? Статью не нашел. Я просто пытаюсь сделать аналог classifier guidance и сейчас надо выбрать какую-то часть laion2B для обучения. Меня смущает, что если брать рандомные картинки и промпты, то:
1) промпты бывают очень ""грязные""
2) есть маленькие картинки и их придется ресайзить до 512x512, на выходе получается что-то такое, на чем не хочется учиться.
Кстати, есть советы как отобрать данные?",Взять Coyo700m где сделали предобработку
,,,"Добрый вечер. выкатываю свое cv, если кто-то поделится мнением, буду признателен
Работа не совсем по профилю, но опыт есть.
Проекты по computer vision, с зачатками Mlops-а)"
,,,"Как из мед картинок срезов тканей добыть больше инфы? Аугментация, ок. 
0. Поворачивать на 90° и тд нет смысла, считаю, переубедите.
1. Отзеркалить считаю надо обязательно. 
3. Добавить шума в изображения? Зачем?
4. Нарезать (например из 512*512 сделать 4 по 256), и что?
5. Поиграть с фильтрами - выключить по очереди РГБ, сделать ч/б или сепию. Рекомендуют, но я интуитивно думал, что модель это и так «видит».

Ваши комменты."
,,"Как из мед картинок срезов тканей добыть больше инфы? Аугментация, ок. 
0. Поворачивать на 90° и тд нет смысла, считаю, переубедите.
1. Отзеркалить считаю надо обязательно. 
3. Добавить шума в изображения? Зачем?
4. Нарезать (например из 512*512 сделать 4 по 256), и что?
5. Поиграть с фильтрами - выключить по очереди РГБ, сделать ч/б или сепию. Рекомендуют, но я интуитивно думал, что модель это и так «видит».

Ваши комменты.","мое представление 0-4 это для того, что бы модель обощила что нужно на трейне, а не тупо запомнила датасет в стиле очень мелких отличительных особенностей, которые она видит регуляно на протяжении нескольких эпох. Особенно это актуально при малом количестве данных. По 5, интуитивно предполагал так же (что ""видит""), но если совет давался про рандомные преобразования, то скорей всего цель та же (обобщиться, а не переобучиться).
В cv мало опыта, если понимаю не так, поправьте."
,,,"Картинки срезов тканей делаются каким аппаратом ? Чем аппараты конструктивно отличаются ? От конструкции может зависеть шум, яркость, резкость и тд, эти параметры и нужно изменять"
,,"Картинки срезов тканей делаются каким аппаратом ? Чем аппараты конструктивно отличаются ? От конструкции может зависеть шум, яркость, резкость и тд, эти параметры и нужно изменять","Это сорева, публичный датасет весь однообразный. Но спасибо!"
,,,"прежде чем отзеркаливать, посмотри, что там за ""срезы"", а то обучишь модель на сердце справа и печень слева."
,,"прежде чем отзеркаливать, посмотри, что там за ""срезы"", а то обучишь модель на сердце справа и печень слева.","Мысль понял, в моем случае не применимо"
,,,так бывают такие паталогии развития
,,так бывают такие паталогии развития,"в целом моя интуиция грубо следующая, если после аугментации человек (эксперт) способен все так же отнести к нужному классу, то все норм, аугментации допустимы и имеют смысл."
,,,"Всем привет!
Подскажите какое-нибудь решение, чтобы из гугл колаба перенести стратегию на api binance и потестить.
Стратегия на основе LSTM"
,,"Всем привет!
Подскажите какое-нибудь решение, чтобы из гугл колаба перенести стратегию на api binance и потестить.
Стратегия на основе LSTM","FreqTrade-FreqAI, заведется из коробки скорее всего"
,"Всем привет!
Подскажите какое-нибудь решение, чтобы из гугл колаба перенести стратегию на api binance и потестить.
Стратегия на основе LSTM","FreqTrade-FreqAI, заведется из коробки скорее всего","Спасибо, посмотрю"
,,,"Привет! Разбираюсь с эйрфлоу, подскажите, есть ли нормальный способ в ETL пайплайне передавать данные от оператора к оператору? Допустим у меня есть три оператора, считывание, обработка и загрузка, как огранизовать проброс данных между ними?"
,,"Привет! Разбираюсь с эйрфлоу, подскажите, есть ли нормальный способ в ETL пайплайне передавать данные от оператора к оператору? Допустим у меня есть три оператора, считывание, обработка и загрузка, как огранизовать проброс данных между ними?","airflow по дизайну - оркестратор расчетов. Предполагается, что он работает поверх хранилища данных или файловой системы. Напрямую датасеты в нем не нужно передавать"
,,,"у нас больше про DS + вилка маленькая, опять же у вас кажется fullstack"
,,"у нас больше про DS + вилка маленькая, опять же у вас кажется fullstack","Про ДС понятно, но я в правилах не увидел противоречия, поэтому и закинул. По вилке спорно (какие критерии говорят о том, что она маленькая?), ну и вакансия прямо точно на фронтенд, просто близкая к выходам из бэка и нейронкам :)"
,"у нас больше про DS + вилка маленькая, опять же у вас кажется fullstack","Про ДС понятно, но я в правилах не увидел противоречия, поэтому и закинул. По вилке спорно (какие критерии говорят о том, что она маленькая?), ну и вакансия прямо точно на фронтенд, просто близкая к выходам из бэка и нейронкам :)","ограничений нет, просто публика специфичная)"
,,,"Подскажите плиз кто нибудь
Для классификации картинок с помощью нейронок используются дескрипторы типо SIFT или HOG?
Или смысла пробовать нет и можно сразу пихать в сетку"
,,"Подскажите плиз кто нибудь
Для классификации картинок с помощью нейронок используются дескрипторы типо SIFT или HOG?
Или смысла пробовать нет и можно сразу пихать в сетку",На практике практически полностью вытеснены как минимум сверточными
,,,"Они вроде не так сложно запускаются, чтобы не протестить"
,,"Они вроде не так сложно запускаются, чтобы не протестить","учить прост время
думал может кто заранее знает"
,,,"Привет! Какого рода данные хочешь передавать? Небольшие сообщения можно через XCom перебрасывать, файлы - через промежуточное хранилище."
,,"Привет! Какого рода данные хочешь передавать? Небольшие сообщения можно через XCom перебрасывать, файлы - через промежуточное хранилище.","Да, прo XCom прочитал, в моем случае это табличные данные из бд, записей может быть от нескольких десятков строк до нескольких десятков тысяч. Можно пожалуйста пример, как это реализовать через промежуточное хранилище? Пока самое умное что придумал это писать данные в файл, передавать через икском путь к файлу до следующего оператора, и т.д.
(Данные изначально поступают в виде жсона, поэтому можно без костылей просто в файл, но можно и сразу их класть в какую-то ещё бд)"
,"Привет! Какого рода данные хочешь передавать? Небольшие сообщения можно через XCom перебрасывать, файлы - через промежуточное хранилище.","Да, прo XCom прочитал, в моем случае это табличные данные из бд, записей может быть от нескольких десятков строк до нескольких десятков тысяч. Можно пожалуйста пример, как это реализовать через промежуточное хранилище? Пока самое умное что придумал это писать данные в файл, передавать через икском путь к файлу до следующего оператора, и т.д.
(Данные изначально поступают в виде жсона, поэтому можно без костылей просто в файл, но можно и сразу их класть в какую-то ещё бд)","Ну, вы и без примеров почти правильно всё сказали. Единственное - зачем передавать путь через XCom, если можно его передавать прямо в коде? У большинства операторов можно указать выходной путь, и в таком случае его же можно указать как входной для следующего оператора. :)"
"Привет! Какого рода данные хочешь передавать? Небольшие сообщения можно через XCom перебрасывать, файлы - через промежуточное хранилище.","Да, прo XCom прочитал, в моем случае это табличные данные из бд, записей может быть от нескольких десятков строк до нескольких десятков тысяч. Можно пожалуйста пример, как это реализовать через промежуточное хранилище? Пока самое умное что придумал это писать данные в файл, передавать через икском путь к файлу до следующего оператора, и т.д.
(Данные изначально поступают в виде жсона, поэтому можно без костылей просто в файл, но можно и сразу их класть в какую-то ещё бд)","Ну, вы и без примеров почти правильно всё сказали. Единственное - зачем передавать путь через XCom, если можно его передавать прямо в коде? У большинства операторов можно указать выходной путь, и в таком случае его же можно указать как входной для следующего оператора. :)","Окей, спасибо!"
,,,"Сетки сами могут в feature engineering под задачу, в этом их магия

Дедушкины методы замечательны в условиях ограниченного вычислительного бюджета, но распадаются на части при выходе влево/вправо от домена
Тем не менее sift hog могут внести inductive bias в сетки - приблизить их к решению. Но это весьма частный случай
В двух словах: релевантны задаче sift hog могут быть, могут не быть, могут быть немного и выгодно/невыгодно.

Какой домен?"
,,"Сетки сами могут в feature engineering под задачу, в этом их магия

Дедушкины методы замечательны в условиях ограниченного вычислительного бюджета, но распадаются на части при выходе влево/вправо от домена
Тем не менее sift hog могут внести inductive bias в сетки - приблизить их к решению. Но это весьма частный случай
В двух словах: релевантны задаче sift hog могут быть, могут не быть, могут быть немного и выгодно/невыгодно.

Какой домен?","cifar-10, но взято 30% от общего числа"
,"Сетки сами могут в feature engineering под задачу, в этом их магия

Дедушкины методы замечательны в условиях ограниченного вычислительного бюджета, но распадаются на части при выходе влево/вправо от домена
Тем не менее sift hog могут внести inductive bias в сетки - приблизить их к решению. Но это весьма частный случай
В двух словах: релевантны задаче sift hog могут быть, могут не быть, могут быть немного и выгодно/невыгодно.

Какой домен?","cifar-10, но взято 30% от общего числа",Предмет экспериментов... Сильно разнообразно
,,,ну вообще 10 классов вроде всего
,,ну вообще 10 классов вроде всего,"Нету количестве дело. Даже два класса.

Человек без каски и в каске, или человек и автомобиль"
,,,"или многовато уже
а, понял, спасибо)
придется видимо экспериментировать"
,,"или многовато уже
а, понял, спасибо)
придется видимо экспериментировать","Мысль в том что разделимость - это наличие в feature maps каких-то хорошо разделяющих признаков.

Пять углов - машина, сложный контур - человек, что-то около"
,"или многовато уже
а, понял, спасибо)
придется видимо экспериментировать","Мысль в том что разделимость - это наличие в feature maps каких-то хорошо разделяющих признаков.

Пять углов - машина, сложный контур - человек, что-то около","На цифаре бесполезно.
А так в kornia можешь удобчные сифты взять."
"или многовато уже
а, понял, спасибо)
придется видимо экспериментировать","Мысль в том что разделимость - это наличие в feature maps каких-то хорошо разделяющих признаков.

Пять углов - машина, сложный контур - человек, что-то около","На цифаре бесполезно.
А так в kornia можешь удобчные сифты взять.","Frontend конечно не матан, но и не последний зашквар. Svelte слишком аномальный правда фремворк"
"Мысль в том что разделимость - это наличие в feature maps каких-то хорошо разделяющих признаков.

Пять углов - машина, сложный контур - человек, что-то около","На цифаре бесполезно.
А так в kornia можешь удобчные сифты взять.","Frontend конечно не матан, но и не последний зашквар. Svelte слишком аномальный правда фремворк","спасибо, буду пробовать)"
"На цифаре бесполезно.
А так в kornia можешь удобчные сифты взять.","Frontend конечно не матан, но и не последний зашквар. Svelte слишком аномальный правда фремворк","спасибо, буду пробовать)",А какие хранилища можно юзать?
"Frontend конечно не матан, но и не последний зашквар. Svelte слишком аномальный правда фремворк","спасибо, буду пробовать)",А какие хранилища можно юзать?,Если коротко - любые. :)
"спасибо, буду пробовать)",А какие хранилища можно юзать?,Если коротко - любые. :),"Ну всё, благодарность"
,,,"Добрый вечер! Подскажите пожалуйста, есть ли какое-то готовое решение в Python, которое позволяет работать одновременно с explicit и implicit рейтингами? Нашла SVD++ в библиотеке Surprise, но хоть у них в документации и указано, что этот алгоритм способен работать с implicit оценками, в FAQ сказано, что в целом библиотека Surprise подобную проблему не решает."
,,"Добрый вечер! Подскажите пожалуйста, есть ли какое-то готовое решение в Python, которое позволяет работать одновременно с explicit и implicit рейтингами? Нашла SVD++ в библиотеке Surprise, но хоть у них в документации и указано, что этот алгоритм способен работать с implicit оценками, в FAQ сказано, что в целом библиотека Surprise подобную проблему не решает.","Интересная задача, чтобы поправить под себя существующие решения. Мб тот же implicit. А как так вышло, если не секрет? Мб в целом не стоит объединять эти два источника данных в одну матрицу? Те делать две модели?"
,"Добрый вечер! Подскажите пожалуйста, есть ли какое-то готовое решение в Python, которое позволяет работать одновременно с explicit и implicit рейтингами? Нашла SVD++ в библиотеке Surprise, но хоть у них в документации и указано, что этот алгоритм способен работать с implicit оценками, в FAQ сказано, что в целом библиотека Surprise подобную проблему не решает.","Интересная задача, чтобы поправить под себя существующие решения. Мб тот же implicit. А как так вышло, если не секрет? Мб в целом не стоит объединять эти два источника данных в одну матрицу? Те делать две модели?","Вообще это на самом деле игрушечное задание, чтоб основные принципы recsys изучить. Датасет, который нам дали, содержит как раз implicit и explicit оценки вместе. Причем странно то, что нет совсем missing values. То есть либо непосредственно оценка 1-10, либо 0, что соответствует implicit rating. Получается каждый пользователь якобы взаимодействовал с ~300к товаров, что даже у очень активных пользователей мне кажется сомнительным 😅"
"Добрый вечер! Подскажите пожалуйста, есть ли какое-то готовое решение в Python, которое позволяет работать одновременно с explicit и implicit рейтингами? Нашла SVD++ в библиотеке Surprise, но хоть у них в документации и указано, что этот алгоритм способен работать с implicit оценками, в FAQ сказано, что в целом библиотека Surprise подобную проблему не решает.","Интересная задача, чтобы поправить под себя существующие решения. Мб тот же implicit. А как так вышло, если не секрет? Мб в целом не стоит объединять эти два источника данных в одну матрицу? Те делать две модели?","Вообще это на самом деле игрушечное задание, чтоб основные принципы recsys изучить. Датасет, который нам дали, содержит как раз implicit и explicit оценки вместе. Причем странно то, что нет совсем missing values. То есть либо непосредственно оценка 1-10, либо 0, что соответствует implicit rating. Получается каждый пользователь якобы взаимодействовал с ~300к товаров, что даже у очень активных пользователей мне кажется сомнительным 😅",Это скорее всего класс пользователя 300к контактов делал.
,,,чем это отличается от классической разреженной матрицы?
,,чем это отличается от классической разреженной матрицы?,"Насколько я понимаю, в классической матрице 0 бы означал, что пользователь не взаимодействовал с товаром. В этом же случае 0 - тоже оценка, как и 1-10, то есть каждый пользователь так или иначе взаимодействовал с каждым существующим товаром"
,чем это отличается от классической разреженной матрицы?,"Насколько я понимаю, в классической матрице 0 бы означал, что пользователь не взаимодействовал с товаром. В этом же случае 0 - тоже оценка, как и 1-10, то есть каждый пользователь так или иначе взаимодействовал с каждым существующим товаром",так для этого вроде же есть уверенность. типа коэффициента альфа или как там для als.
чем это отличается от классической разреженной матрицы?,"Насколько я понимаю, в классической матрице 0 бы означал, что пользователь не взаимодействовал с товаром. В этом же случае 0 - тоже оценка, как и 1-10, то есть каждый пользователь так или иначе взаимодействовал с каждым существующим товаром",так для этого вроде же есть уверенность. типа коэффициента альфа или как там для als.,"Да, абсолютно верно. В классическом имплисит (не про статью, а про библиотечные реализации) на входе ты подаёшь матрицу положительны чисел - свою уверенность в том, что человеку нравится товар. Те в лоссе идёт ошибка от предикта единицы, но с весом - это поданное на вход число уверенности. Для нулей работает так: если на входе в «матрице уверенности» стоит ноль или отрицательное число, то модель будет считать это нулём с весом альфа (параметром модели)."
,,,О о О Денис нашёл крутую вещь!
,,О о О Денис нашёл крутую вещь!,"Всем привет! 
Может кто подскажет, жизнеспособен ли подход [детектор по наиболее общим признакам] -> [классификаторы частных вариаций] В инете не нашел определенного его названия.
Домен: дорожные знаки (>300 наименований по гост)
Может есть более эффективные/легковесные пайплайны для решения такой задачи?"
,О о О Денис нашёл крутую вещь!,"Всем привет! 
Может кто подскажет, жизнеспособен ли подход [детектор по наиболее общим признакам] -> [классификаторы частных вариаций] В инете не нашел определенного его названия.
Домен: дорожные знаки (>300 наименований по гост)
Может есть более эффективные/легковесные пайплайны для решения такой задачи?","Более чем работоспособен. Обычно так и делают: легковесный object detection, нормализация (разворот в плоскость и унификация масштаба), а затем классификация."
О о О Денис нашёл крутую вещь!,"Всем привет! 
Может кто подскажет, жизнеспособен ли подход [детектор по наиболее общим признакам] -> [классификаторы частных вариаций] В инете не нашел определенного его названия.
Домен: дорожные знаки (>300 наименований по гост)
Может есть более эффективные/легковесные пайплайны для решения такой задачи?","Более чем работоспособен. Обычно так и делают: легковесный object detection, нормализация (разворот в плоскость и унификация масштаба), а затем классификация.",Очень плохо было
"Всем привет! 
Может кто подскажет, жизнеспособен ли подход [детектор по наиболее общим признакам] -> [классификаторы частных вариаций] В инете не нашел определенного его названия.
Домен: дорожные знаки (>300 наименований по гост)
Может есть более эффективные/легковесные пайплайны для решения такой задачи?","Более чем работоспособен. Обычно так и делают: легковесный object detection, нормализация (разворот в плоскость и унификация масштаба), а затем классификация.",Очень плохо было,"Ну по сравнению с Наташей, он на топонимы сильно лучше работал (трогал их больше года назад)"
"Более чем работоспособен. Обычно так и делают: легковесный object detection, нормализация (разворот в плоскость и унификация масштаба), а затем классификация.",Очень плохо было,"Ну по сравнению с Наташей, он на топонимы сильно лучше работал (трогал их больше года назад)","подскажите пожалуйста, какую модель лучше всего файнтьюнить на русских текстах? Для адекватной генерации текста (значит предобучена должна быть на русских токенах?). Тип обучить на книге автора и тд. Чтоб отвечать в его стиле и по книге? 
Заранее благодарю"
Очень плохо было,"Ну по сравнению с Наташей, он на топонимы сильно лучше работал (трогал их больше года назад)","подскажите пожалуйста, какую модель лучше всего файнтьюнить на русских текстах? Для адекватной генерации текста (значит предобучена должна быть на русских токенах?). Тип обучить на книге автора и тд. Чтоб отвечать в его стиле и по книге? 
Заранее благодарю","Подскажите, пожалуйста, тутор/пример файнтюна falcon7b без квантизации и адаптеров (все веса)?"
"Ну по сравнению с Наташей, он на топонимы сильно лучше работал (трогал их больше года назад)","подскажите пожалуйста, какую модель лучше всего файнтьюнить на русских текстах? Для адекватной генерации текста (значит предобучена должна быть на русских токенах?). Тип обучить на книге автора и тд. Чтоб отвечать в его стиле и по книге? 
Заранее благодарю","Подскажите, пожалуйста, тутор/пример файнтюна falcon7b без квантизации и адаптеров (все веса)?","titan.csv
для тех кто не смог осилить titanic.csv"
,,,"Всем привет, тоже выкатываю резюме, буду оч признателен, если дадите какой-то фидбек, что можно улучшить"
,,"Всем привет, тоже выкатываю резюме, буду оч признателен, если дадите какой-то фидбек, что можно улучшить","Небольшое уточнение: какой смысл оставлять ссылку на кагл, если там ничего нет?"
,"Всем привет, тоже выкатываю резюме, буду оч признателен, если дадите какой-то фидбек, что можно улучшить","Небольшое уточнение: какой смысл оставлять ссылку на кагл, если там ничего нет?","Спасибо, просто забыл кучу блокнотов сделать публичными. Или если нет в профиле каких то хороших мест в соревнованиях, думаете лучше убрать? В целом я ее добавил как ещё одно место, где можно посмотреть как выглядит код, который я писал"
"Всем привет, тоже выкатываю резюме, буду оч признателен, если дадите какой-то фидбек, что можно улучшить","Небольшое уточнение: какой смысл оставлять ссылку на кагл, если там ничего нет?","Спасибо, просто забыл кучу блокнотов сделать публичными. Или если нет в профиле каких то хороших мест в соревнованиях, думаете лучше убрать? В целом я ее добавил как ещё одно место, где можно посмотреть как выглядит код, который я писал","Ни разу слышал, чтобы качество кода смотрели в кагле, а не на гите. На мой взгляд, кагл нужно указывать если в соревнованиях чего либо добились / большой вклад в ноутбуки или датасеты внесли"
,,,"привет. а кто какими инструментами пользуется для исправления орфографиских ошибок в текстах? хочу перед получением эмбеддингов исправлять орфографические ошибки, добавлять пробелы там где пропущено итд. нашел на хаггине несколько моделей для spell check, мб еще какие-нибудь посоветуйте"
,,"привет. а кто какими инструментами пользуется для исправления орфографиских ошибок в текстах? хочу перед получением эмбеддингов исправлять орфографические ошибки, добавлять пробелы там где пропущено итд. нашел на хаггине несколько моделей для spell check, мб еще какие-нибудь посоветуйте",попробуй обучить Т5
,,,"перепиши рабочий опыт в формате: сделал А, получил Б это прерастило С, в остальном очень неплохло"
,,,"Яндекс предоставляет апи спел-чекера.
Опечатки можно править с помощью symspell, например."
,,"Яндекс предоставляет апи спел-чекера.
Опечатки можно править с помощью symspell, например.",мне бы решение более продуктовое
,,,"Подзатрахался в два дня, но пихается в браузер. Не сказать что прямо вот офигенная штука на все 💯, но в некоторых кейсах вполне рабочая"
,,,"symspell чекну, спс))"
,,"symspell чекну, спс))","jamspell многие хвалили, ноту меня до прода так и не дошел. Для speech2text есть отдельные решения на huggingface, если это релевантно"
,,,"Польша, Краков"
,,,Токенайзер?
,,Токенайзер?,Токенайзер + эмбеддер + на чем учили.
,,,"Привет!

- Мб, названия самих образовательных программ добавитъ? Ещё можно выделить релеватные предметы (типо матеши) + практики, стипендии.

- Раз опыта работы не так много я б писала в такой последовательности: education, work experience, projects, skills (у себя именно так делаю, вроде работает).

- В skills можно добавить языки.

- Ещё если ориентировано на англоязычную аудиторию, не дурно сделать LinkedIn и прикрепить ссылку вверху, но он может банить без впн, так что аккуратно."
,,"Привет!

- Мб, названия самих образовательных программ добавитъ? Ещё можно выделить релеватные предметы (типо матеши) + практики, стипендии.

- Раз опыта работы не так много я б писала в такой последовательности: education, work experience, projects, skills (у себя именно так делаю, вроде работает).

- В skills можно добавить языки.

- Ещё если ориентировано на англоязычную аудиторию, не дурно сделать LinkedIn и прикрепить ссылку вверху, но он может банить без впн, так что аккуратно.","Спасибо за совет, я названия программ не указывал, ибо они не технические совершенно (гму и политология), пытался больше сконцентрировать внимание на том шо я рил умею делать, поэтому такая очередность. 

Про языки вы имеете в виду натуральные языки?

Ещё я думал стоит ли добавлять шото типа lua, если все что я с ним делал - конфиг неовима

Про линкедин тоже спс, там изначально в шаблоне он и был, я прост каггл вместо него поставил, потому шо акк не сделал пока"
,,,мы начали
,,мы начали,"Да, про натуральные языки, раз резюме на АЯ, мб прям уровень написать, типо:
- English: B2 (например)
- Russian: C2 / native
…

Образование у меня тоже 1 непрофильное, но я пишу, хотяб конвенций ради + чтоб полная картина была. Но можно тогда их действительно внизу указать.

Про lua не знаю, я не такой технический специалист (пока), но в принципе можно. Ты ж вряд ли на вакансии по этой теме подаёшься + git / bash же ты пишешь…"
,мы начали,"Да, про натуральные языки, раз резюме на АЯ, мб прям уровень написать, типо:
- English: B2 (например)
- Russian: C2 / native
…

Образование у меня тоже 1 непрофильное, но я пишу, хотяб конвенций ради + чтоб полная картина была. Но можно тогда их действительно внизу указать.

Про lua не знаю, я не такой технический специалист (пока), но в принципе можно. Ты ж вряд ли на вакансии по этой теме подаёшься + git / bash же ты пишешь…",Репостнул и удалил
,,,"Подскажите, а насколько адекватно использовать обычные линейные модели поверх скоров, полученных с помощью bert-like моделей? 

К примеру у меня задача, в которой надо из текстовых данных построить на бинарный таргет. Есть ли смысл натренировать 5 разных русскоязычных моделей и построить на этих скорах регрессию?"
,,"Подскажите, а насколько адекватно использовать обычные линейные модели поверх скоров, полученных с помощью bert-like моделей? 

К примеру у меня задача, в которой надо из текстовых данных построить на бинарный таргет. Есть ли смысл натренировать 5 разных русскоязычных моделей и построить на этих скорах регрессию?",Посмотри на решающие пни
,,,Или же использовать усреднение скоров
,,Или же использовать усреднение скоров,У кого-нибудь есть способы максимально быстро (без всяких установок скриптов и аккаунтов) и бесплатно выкачать архив с baidu ?
,,,"Добрый день! Необходимо произвести кластеризацию датасета изображений (скорее даже растровых иконок) по визуальному сходству с целью выделения множества классов для детектора. Пока думал сделать kmeans по фичам какой-нибудь сетки, но может есть уже готовые решения из коробки? Поискал на гите по image clusterization, пока все выглядит слишком избыточным и тяжелым. Может кто сталкивался с похожей задачей?"
,,"Добрый день! Необходимо произвести кластеризацию датасета изображений (скорее даже растровых иконок) по визуальному сходству с целью выделения множества классов для детектора. Пока думал сделать kmeans по фичам какой-нибудь сетки, но может есть уже готовые решения из коробки? Поискал на гите по image clusterization, пока все выглядит слишком избыточным и тяжелым. Может кто сталкивался с похожей задачей?",https://github.com/peterlevi/image-clustering
,,,"если там размерность произведения +/- < 3000-8000, попробуйте umap бахнуть сначала.

С fashion mnist проканывает)"
,,"если там размерность произведения +/- < 3000-8000, попробуйте umap бахнуть сначала.

С fashion mnist проканывает)","Я бы в качестве бейзлайна взял предобученный EffifientNet, Resnet или лоюбой другой сверточный классификатор. Оторвал от него последний полносвязный слой чтобы получить эмбеддинги, а затем засунул их в DBSCAN. Это точно рабочая схема."
,,,"Ага, попробую, а модель какую использовали?"
,,"Ага, попробую, а модель какую использовали?","Как я понял, надо кластеризовать? Umap понизит размерность, а кластеризовывать можно хоть hdscan в связке неплох"
,,,"Ок, благодарю, буду пробовать 👍"
,,"Ок, благодарю, буду пробовать 👍","Линейные модели можно поверх чего угодно обучать) Не факт, что получится сильно лучше, чем просто усреднение с разными весами, но если обученные модели уже есть, не вижу причин не попробовать."
,,,"Товарищи, есть идеи, как из полигона >4 углов получить полигон из 4 углов"
,,"Товарищи, есть идеи, как из полигона >4 углов получить полигон из 4 углов",OpenCV contour approximation
,"Товарищи, есть идеи, как из полигона >4 углов получить полигон из 4 углов",OpenCV contour approximation,Спасибо!!!
,,,"Привет, кто-нибудь может посоветовать мне дешёвые решения с GPU (perhaps serverless) для студентов, где я могу задеплоить мою AI model, это будет использоваться для inference по запросу? (На каждый запрос это занимает 3-10 минуты с A100 в collab)
I've requested for access to some serverless solutions, but I am in a waiting list."
,,"Привет, кто-нибудь может посоветовать мне дешёвые решения с GPU (perhaps serverless) для студентов, где я могу задеплоить мою AI model, это будет использоваться для inference по запросу? (На каждый запрос это занимает 3-10 минуты с A100 в collab)
I've requested for access to some serverless solutions, but I am in a waiting list.","Угу, спасибо, читаю как раз)"
,"Привет, кто-нибудь может посоветовать мне дешёвые решения с GPU (perhaps serverless) для студентов, где я могу задеплоить мою AI model, это будет использоваться для inference по запросу? (На каждый запрос это занимает 3-10 минуты с A100 в collab)
I've requested for access to some serverless solutions, but I am in a waiting list.","Угу, спасибо, читаю как раз)",На runpod не дают возможность лимиты поднять?
"Привет, кто-нибудь может посоветовать мне дешёвые решения с GPU (perhaps serverless) для студентов, где я могу задеплоить мою AI model, это будет использоваться для inference по запросу? (На каждый запрос это занимает 3-10 минуты с A100 в collab)
I've requested for access to some serverless solutions, but I am in a waiting list.","Угу, спасибо, читаю как раз)",На runpod не дают возможность лимиты поднять?,да вот вроде как там х8 максимум
"Угу, спасибо, читаю как раз)",На runpod не дают возможность лимиты поднять?,да вот вроде как там х8 максимум,"Lambda, corewave, fluidstack"
На runpod не дают возможность лимиты поднять?,да вот вроде как там х8 максимум,"Lambda, corewave, fluidstack",Всем привет! У кого-нибудь есть электронная версия книги Статистика для всех Сары Бослаф ? Можно на английском)
да вот вроде как там х8 максимум,"Lambda, corewave, fluidstack",Всем привет! У кого-нибудь есть электронная версия книги Статистика для всех Сары Бослаф ? Можно на английском),на либгене закончилась?
"Lambda, corewave, fluidstack",Всем привет! У кого-нибудь есть электронная версия книги Статистика для всех Сары Бослаф ? Можно на английском),на либгене закончилась?,"1. blip, blip-2"
,,,"всем привет, 

есть кто-то, кто бы занимался моделями в парадигме «train from events” для каких-нибудь НЕ ultra-hft альф(хотя бы на горизонт дальше чем минута, в идеале на прямо БОЛЬШОЙ горизонт, типа дня)? было бы интересно обсудить подходы (опыт если у кого-то в проде крутится уже), не призываю и сам не буду раскрывать секреты конкретных пайплайнов, просто общую парадигму; может кто-то, кто таким занимается, в лондоне сидит, тогда рад был бы пересечься оффлайн, с меня кофе :)"
,,"всем привет, 

есть кто-то, кто бы занимался моделями в парадигме «train from events” для каких-нибудь НЕ ultra-hft альф(хотя бы на горизонт дальше чем минута, в идеале на прямо БОЛЬШОЙ горизонт, типа дня)? было бы интересно обсудить подходы (опыт если у кого-то в проде крутится уже), не призываю и сам не буду раскрывать секреты конкретных пайплайнов, просто общую парадигму; может кто-то, кто таким занимается, в лондоне сидит, тогда рад был бы пересечься оффлайн, с меня кофе :)","под такой парадигмой я подразумеваю что в модель подаются например просто трейды (каким-то образом фичеризованные), по одной или в совокупности"
,"всем привет, 

есть кто-то, кто бы занимался моделями в парадигме «train from events” для каких-нибудь НЕ ultra-hft альф(хотя бы на горизонт дальше чем минута, в идеале на прямо БОЛЬШОЙ горизонт, типа дня)? было бы интересно обсудить подходы (опыт если у кого-то в проде крутится уже), не призываю и сам не буду раскрывать секреты конкретных пайплайнов, просто общую парадигму; может кто-то, кто таким занимается, в лондоне сидит, тогда рад был бы пересечься оффлайн, с меня кофе :)","под такой парадигмой я подразумеваю что в модель подаются например просто трейды (каким-то образом фичеризованные), по одной или в совокупности","пока тут оживление, повторю вопрос 

как пример таких алгоритмов могу привести условно предсказание нормализованного ретерна сделки (side*asset_return) далее это предсказание агрегируются для создания tomeframe based сигнала (5 минут, час, день, неделя). агрегироваться может как и просто статически (взвешенное по размеру трейдов среднее/имбалансы и так далее), но интересно конечно про обучаемое (нейронка с 1д сверкой которая смотрит на несколько предсказаний по трейдам и продуцируют аггрегированное на таймфрейм)"
,,,Только восточное побережье :)
,,Только восточное побережье :),буду кстати в NY и бостоне ближе к сентябрю :)
,,,"всем привет подскажите как удалить мусор на заднем фоне в меше nerfstudio?  (кусок неба синий)
пытался удалить точки из colmap не получилось"
,,,"Привет!
А чем сейчас пользуются для наиболее эффективной дедупликации изображений (из алгоритмов sota)? Вдруг чего-то не нашел"
,,"Привет!
А чем сейчас пользуются для наиболее эффективной дедупликации изображений (из алгоритмов sota)? Вдруг чего-то не нашел",https://github.com/idealo/imagededup
,"Привет!
А чем сейчас пользуются для наиболее эффективной дедупликации изображений (из алгоритмов sota)? Вдруг чего-то не нашел",https://github.com/idealo/imagededup,"Спасибо! Это видел). Думал, вдруг есть еще что-то)."
"Привет!
А чем сейчас пользуются для наиболее эффективной дедупликации изображений (из алгоритмов sota)? Вдруг чего-то не нашел",https://github.com/idealo/imagededup,"Спасибо! Это видел). Думал, вдруг есть еще что-то).",а чего не хватает?
https://github.com/idealo/imagededup,"Спасибо! Это видел). Думал, вдруг есть еще что-то).",а чего не хватает?,"находит не все дубликаты, на моих примерах c небольшими сдвигами бывает, что фейлится"
,,,"Товарищи, а есть платформы типа колаба (необязательно юпитер) где можно выбрать версию питона (нужна 3.6) и запустить проект ? UPD : у яндекс клауда как раз есть 3.6"
,,"Товарищи, а есть платформы типа колаба (необязательно юпитер) где можно выбрать версию питона (нужна 3.6) и запустить проект ? UPD : у яндекс клауда как раз есть 3.6","Я не хочу все снова переписывать 😭
Но по-моему, это в браузер не запихать"
,,,"Привет, Федя :)
меня зовут Дима. подскажи пожалуйста, на что может рассчитывать CV-ресерчер/инженер русский по национальности в Израиле ?"
,,"Привет, Федя :)
меня зовут Дима. подскажи пожалуйста, на что может рассчитывать CV-ресерчер/инженер русский по национальности в Израиле ?","Вопрос как будто чуть с подвохом: в Израиле не так важна национальность, как гражданство. 
Если человек гражданин Израиля, то, как и любой гражданин (не важно откуда он репатриировался из рф, беларуси, украины) может легко апплаиться на разные вакансии. Если не гражданин, то виза сильно привязана к работе и вообще все сложно (вроде беспилотники из Я как-то команду перевезли, но подробностей я не знаю).

При этом рынок чуть-чуть перенасыщен здесь кандидатами, а вакансий качественных меньше, поэтому местные hr тонут в резюме.

Знание иврита будет плюсом, но сейчас есть возможности и при хорошем английском без иврите)

Более подробно могу в лс посоветовать пару чатиков!"
,"Привет, Федя :)
меня зовут Дима. подскажи пожалуйста, на что может рассчитывать CV-ресерчер/инженер русский по национальности в Израиле ?","Вопрос как будто чуть с подвохом: в Израиле не так важна национальность, как гражданство. 
Если человек гражданин Израиля, то, как и любой гражданин (не важно откуда он репатриировался из рф, беларуси, украины) может легко апплаиться на разные вакансии. Если не гражданин, то виза сильно привязана к работе и вообще все сложно (вроде беспилотники из Я как-то команду перевезли, но подробностей я не знаю).

При этом рынок чуть-чуть перенасыщен здесь кандидатами, а вакансий качественных меньше, поэтому местные hr тонут в резюме.

Знание иврита будет плюсом, но сейчас есть возможности и при хорошем английском без иврите)

Более подробно могу в лс посоветовать пару чатиков!","Мне Яндекс в своё время выдавал временную рабочую визу в Израиль (ездил туда на несколько месяцев в командировку).
Кажется, им и постоянную сделать не очень сложно.
Ну и если ты шаришь в CV и Яндексом не гнушаешься, то в команде беспилотников или медиасервисов тебе наверняка будут рады."
"Привет, Федя :)
меня зовут Дима. подскажи пожалуйста, на что может рассчитывать CV-ресерчер/инженер русский по национальности в Израиле ?","Вопрос как будто чуть с подвохом: в Израиле не так важна национальность, как гражданство. 
Если человек гражданин Израиля, то, как и любой гражданин (не важно откуда он репатриировался из рф, беларуси, украины) может легко апплаиться на разные вакансии. Если не гражданин, то виза сильно привязана к работе и вообще все сложно (вроде беспилотники из Я как-то команду перевезли, но подробностей я не знаю).

При этом рынок чуть-чуть перенасыщен здесь кандидатами, а вакансий качественных меньше, поэтому местные hr тонут в резюме.

Знание иврита будет плюсом, но сейчас есть возможности и при хорошем английском без иврите)

Более подробно могу в лс посоветовать пару чатиков!","Мне Яндекс в своё время выдавал временную рабочую визу в Израиль (ездил туда на несколько месяцев в командировку).
Кажется, им и постоянную сделать не очень сложно.
Ну и если ты шаришь в CV и Яндексом не гнушаешься, то в команде беспилотников или медиасервисов тебе наверняка будут рады.","Я счас в Яндексе работаю в РФ, к сожалению не в CV. Иногда попадаются задачки, но очень простые. Думаю, что не получится перейти."
,,,"да нет никаких подвохов. просто Израиль нравится, как страна. есть друзья, родственники, но нет нужной крови :) ну и гражданства соответственно. английский В2, иврит без потенциального гражданства учить неохота.
про рынок понял, спасибо, Федя :)"
,,"да нет никаких подвохов. просто Израиль нравится, как страна. есть друзья, родственники, но нет нужной крови :) ну и гражданства соответственно. английский В2, иврит без потенциального гражданства учить неохота.
про рынок понял, спасибо, Федя :)","Ааа, тогда не с подвохом, а чуть не хватило контекта! Сорри)

Если нет возможности для гражданства, то нужно искать места, которые будут готовы заморочиться. Слышал что в израильский офис Небиуса ищут разных спецов"
,,,"Всем привет)
Такой вопрос: какие есть адекватные подходы к realtime трекингу на CPU?

Есть банальная ситуация: детекция движущихся объектов на yolov7 с последующим трекингом SORT.
Качество трекинга зависит от количества fps. Поэтому кажется логичным ускорение инференса для детекции.
1. Какие есть способы ускорить детекцию именно на CPU (помимо использования лёгкой архитектуры сети или применения ONNX, OpenVINO)?
2. Может быть где-то уже есть такой же быстрый трекинг, как SORT, но лучше справляющийся со сложными ситуациями (например когда одновременно много разных объектов) и остающийся realtime?"
,,"Всем привет)
Такой вопрос: какие есть адекватные подходы к realtime трекингу на CPU?

Есть банальная ситуация: детекция движущихся объектов на yolov7 с последующим трекингом SORT.
Качество трекинга зависит от количества fps. Поэтому кажется логичным ускорение инференса для детекции.
1. Какие есть способы ускорить детекцию именно на CPU (помимо использования лёгкой архитектуры сети или применения ONNX, OpenVINO)?
2. Может быть где-то уже есть такой же быстрый трекинг, как SORT, но лучше справляющийся со сложными ситуациями (например когда одновременно много разных объектов) и остающийся realtime?","еще как вариант, можно вынести пре/постпроцессинг в один поток, инференс в другой (в OpenVino это можно довольно просто через async request сделать)"
,,,"Можешь Yolov8 попробовать, там сразу в коробке два трекера запихнули"
,,"Можешь Yolov8 попробовать, там сразу в коробке два трекера запихнули","Судя по результатам MOT17 и MOT20, самый лучший по скорости/качеству сейчас MAATrack. Кода на него не видел, только статью. Он быстрее и лучше, чем SORT"
,,,Опять же можно распознавать и трекать не все кадры
,,Опять же можно распознавать и трекать не все кадры,"Можно детектировать не на всех, а трекать на всех"
,,,"попробуй OC-SORT
Насколько я понял из статьи там основная идея в том, что современные детекторы дают очень хорошие детекции и теперь для трекинга можно использовать не скрытое состояния из фильтра калмана, а сами детекшены. А фильтр как вспомогательный инструмент.

На практике у меня он работал лучше чем сорт и по перформансу он примерно такой же"
,,"попробуй OC-SORT
Насколько я понял из статьи там основная идея в том, что современные детекторы дают очень хорошие детекции и теперь для трекинга можно использовать не скрытое состояния из фильтра калмана, а сами детекшены. А фильтр как вспомогательный инструмент.

На практике у меня он работал лучше чем сорт и по перформансу он примерно такой же","Спасибо большое всем)
Буду пробовать эти варианты"
,"попробуй OC-SORT
Насколько я понял из статьи там основная идея в том, что современные детекторы дают очень хорошие детекции и теперь для трекинга можно использовать не скрытое состояния из фильтра калмана, а сами детекшены. А фильтр как вспомогательный инструмент.

На практике у меня он работал лучше чем сорт и по перформансу он примерно такой же","Спасибо большое всем)
Буду пробовать эти варианты","Давид, Яндексом ""гнушаться"" чтобы, надо до тебя допрыгнуть)"
"попробуй OC-SORT
Насколько я понял из статьи там основная идея в том, что современные детекторы дают очень хорошие детекции и теперь для трекинга можно использовать не скрытое состояния из фильтра калмана, а сами детекшены. А фильтр как вспомогательный инструмент.

На практике у меня он работал лучше чем сорт и по перформансу он примерно такой же","Спасибо большое всем)
Буду пробовать эти варианты","Давид, Яндексом ""гнушаться"" чтобы, надо до тебя допрыгнуть)","Не уверена, что правильный канал
Мне нужна модель (gan скорее всего), которая может из текста и звуковой дорожки сделать говорящую голову. Стартапы тоже подойдут. Нужно максимальное качество"
,,,"Всем здравствуйте. Есть опыт в классическом МЛ. Хочу погрузиться в тему алгоритмического трейдинга и использования алгоритмов МЛ в трейдинга. Хочу с ребятами оформить пет проект в виде торгового бота, потыкаться, на первое время написать что-нибудь простенькое и запустить, посмотреть как уходят денюжки нормальным трейдерам)). Можете посоветовать материалы для изучения?"
,,"Всем здравствуйте. Есть опыт в классическом МЛ. Хочу погрузиться в тему алгоритмического трейдинга и использования алгоритмов МЛ в трейдинга. Хочу с ребятами оформить пет проект в виде торгового бота, потыкаться, на первое время написать что-нибудь простенькое и запустить, посмотреть как уходят денюжки нормальным трейдерам)). Можете посоветовать материалы для изучения?",https://t.me/betterdatacommunity/3/15803
,,,"Еще хочется узнать про языки программирования и технологии, которое будут наиболее удобными для написания такого учебного проекта. То есть предполагается, что бот будет совершать реальные сделки на криптобирже"
,,"Еще хочется узнать про языки программирования и технологии, которое будут наиболее удобными для написания такого учебного проекта. То есть предполагается, что бот будет совершать реальные сделки на криптобирже","Как вариант начать с питона, тем более если у тебя опыт в мле есть"
,,,"Все технологии необходимые можно взять готовые, самые популярные на гитхабе

Коннекторы к биржам, бэктест и тулы для рисерча
К пример, в чате как помню упоминали ccxt, freqtrade, blankly
Также полезно посмотреть историю чата, ссылки и не только"
,,,"Привет! Хотела узнать, есть ли какие-то решения, которые умеют дорисовывать детали в рисунок ?:)
При этом не меняя сам рисунок, только дорисовывая что нужно"
,,"Привет! Хотела узнать, есть ли какие-то решения, которые умеют дорисовывать детали в рисунок ?:)
При этом не меняя сам рисунок, только дорисовывая что нужно","inpainting, в том же автоматике, хорошо справляется, на основе stable-diffusion. Вносил правки через него в реальные фотографии"
,"Привет! Хотела узнать, есть ли какие-то решения, которые умеют дорисовывать детали в рисунок ?:)
При этом не меняя сам рисунок, только дорисовывая что нужно","inpainting, в том же автоматике, хорошо справляется, на основе stable-diffusion. Вносил правки через него в реальные фотографии",Дорисовать предметы получалось?
"Привет! Хотела узнать, есть ли какие-то решения, которые умеют дорисовывать детали в рисунок ?:)
При этом не меняя сам рисунок, только дорисовывая что нужно","inpainting, в том же автоматике, хорошо справляется, на основе stable-diffusion. Вносил правки через него в реальные фотографии",Дорисовать предметы получалось?,"Да, и неплохо"
,,,pix2pix ганы
,,,Есть ли какие-нибудь решения для генерации синтетики для object detection путем выставки маски искомого объекта в изображения фона?
,,Есть ли какие-нибудь решения для генерации синтетики для object detection путем выставки маски искомого объекта в изображения фона?,"https://blog.unity.com/engine-platform/perception-open-source-toolbox-for-synthetic-data

ну и сам можешь накатать"
,,,"Как вообще в целом выполняется oversampling&undersampling классов, если их bbox'ы присутствуют одновременно на одних кадрах?"
,,"Как вообще в целом выполняется oversampling&undersampling классов, если их bbox'ы присутствуют одновременно на одних кадрах?",вырезанием картинки вокруг боксов нуного класса
,"Как вообще в целом выполняется oversampling&undersampling классов, если их bbox'ы присутствуют одновременно на одних кадрах?",вырезанием картинки вокруг боксов нуного класса,"Не совсем понял, тип просто вырезать макс область с этим боксом? А потом не возникнет проблем с размерами anchor боксов во время обучения?"
"Как вообще в целом выполняется oversampling&undersampling классов, если их bbox'ы присутствуют одновременно на одних кадрах?",вырезанием картинки вокруг боксов нуного класса,"Не совсем понял, тип просто вырезать макс область с этим боксом? А потом не возникнет проблем с размерами anchor боксов во время обучения?",можешь по сег маскам если есть (или получить их)
вырезанием картинки вокруг боксов нуного класса,"Не совсем понял, тип просто вырезать макс область с этим боксом? А потом не возникнет проблем с размерами anchor боксов во время обучения?",можешь по сег маскам если есть (или получить их),"Не, масок нет, только bbox'ы"
"Не совсем понял, тип просто вырезать макс область с этим боксом? А потом не возникнет проблем с размерами anchor боксов во время обучения?",можешь по сег маскам если есть (или получить их),"Не, масок нет, только bbox'ы",попробуй segment anything
можешь по сег маскам если есть (или получить их),"Не, масок нет, только bbox'ы",попробуй segment anything,"Пробовал, но у меня 70к кадров, мало того, что эмбеддинги будет долго считать, но и результат нормально не оценить..."
"Не, масок нет, только bbox'ы",попробуй segment anything,"Пробовал, но у меня 70к кадров, мало того, что эмбеддинги будет долго считать, но и результат нормально не оценить...","недавно видел, что релизнули статью и код FastSAM, говорят что в 50 раз быстрее при небольших просадках по качеству, сам пока не смотрел, по качеству не скажу, на картинку пишут, что уходит 40 ms.

https://github.com/CASIA-IVA-Lab/FastSAM"
попробуй segment anything,"Пробовал, но у меня 70к кадров, мало того, что эмбеддинги будет долго считать, но и результат нормально не оценить...","недавно видел, что релизнули статью и код FastSAM, говорят что в 50 раз быстрее при небольших просадках по качеству, сам пока не смотрел, по качеству не скажу, на картинку пишут, что уходит 40 ms.

https://github.com/CASIA-IVA-Lab/FastSAM",с TRT так вообще 12 ms
,,,"У меня довольно мелкие объекты, при этом зачастую расположенные рядом"
,,"У меня довольно мелкие объекты, при этом зачастую расположенные рядом","Возникнет, конечно. Можно оставлять исходного размера, делая паддинги. Ещё можно заливать другие классы."
,"У меня довольно мелкие объекты, при этом зачастую расположенные рядом","Возникнет, конечно. Можно оставлять исходного размера, делая паддинги. Ещё можно заливать другие классы.","Ага, спасибо, попробую эти трансформы. По заливке, просто лить, к примеру, черным?"
"У меня довольно мелкие объекты, при этом зачастую расположенные рядом","Возникнет, конечно. Можно оставлять исходного размера, делая паддинги. Ещё можно заливать другие классы.","Ага, спасибо, попробую эти трансформы. По заливке, просто лить, к примеру, черным?","можно частями того же изображения, но это может быть сложно, если другие объекты рядом"
"Возникнет, конечно. Можно оставлять исходного размера, делая паддинги. Ещё можно заливать другие классы.","Ага, спасибо, попробую эти трансформы. По заливке, просто лить, к примеру, черным?","можно частями того же изображения, но это может быть сложно, если другие объекты рядом","Спасибо, гляну, мб что-нибудь придумаю"
,,,Порекомендуйте антиспам бота для телеграм сообществ?
,,Порекомендуйте антиспам бота для телеграм сообществ?,Можешь своего написать
,,,"Раньше Shady или как-то так неплохо справлялся, но теперь нет"
,,,В Karpov.Courses/simulator-ml такое делают как пет проект на вечер
,,В Karpov.Courses/simulator-ml такое делают как пет проект на вечер,)
,,,"Всем привет!
Может быть, есть люди, которые учатся в маге мфти по блокчейну или знакомы с такими и готовы прокомментировать?
Коллега спрашивает, у него сын бакалавриат нгу закончил, по блокчейну я.профи олимпиаду выиграл и диплом тоже по блокчейну писал, интересуется насколько в мфти возможно поступить из нск и насколько эта мага котируется в мире потом?"
,,"Всем привет!
Может быть, есть люди, которые учатся в маге мфти по блокчейну или знакомы с такими и готовы прокомментировать?
Коллега спрашивает, у него сын бакалавриат нгу закончил, по блокчейну я.профи олимпиаду выиграл и диплом тоже по блокчейну писал, интересуется насколько в мфти возможно поступить из нск и насколько эта мага котируется в мире потом?","Привет! Сам не учился в этой маге, знакомых нет, но поступить точно реально, особенно если олимпиаду профильную выиграл. Сам по себе МФТИ котируется, насчёт конкретно маги не знаю, но если уже есть профильные знания и интерес, то значит, что проще будет найти хорошего научника и сделать сильный проект на дипломе, который сам по себе даст много знаний"
,,,В Talib наверняка есть.
,,,"это похоже Fear and Greed не для BTC, а для рынка акций"
,,"это похоже Fear and Greed не для BTC, а для рынка акций","The data include:

Current volume: measured against historical data to indicate the current level of greediness or fearfulness in the market.
Open interest: also compared to historical data, with high open interest indicating more greed in the market
Social media sentiment from Reddit and Twitter: can reveal shifts in sentiment
Search data from Google and Bing: search volume and trends for cryptocurrency terms can also indicate changing sentiment"
,,,"ну вот подобного рода “текстовые” описания и бывают. думал, может кто в курсе где именно более формализованное, чтобы можно было самим считать и числа бились."
,,"ну вот подобного рода “текстовые” описания и бывают. думал, может кто в курсе где именно более формализованное, чтобы можно было самим считать и числа бились.","Я делал свою реализацию для российского рынка. По аналогии с CNN индексом, тут почти все данные есть в открытых источниках. Единственная проблема это получить сбалансированные коэффициенты для каждого компонента."
,,,"В этом описании 1, 2 и 4 компоненты достать легко, 3 не скажу сходу, надо искать. А дальше брутфорсить коэффициенты по историческим данным оригинального индекса."
,,"В этом описании 1, 2 и 4 компоненты достать легко, 3 не скажу сходу, надо искать. А дальше брутфорсить коэффициенты по историческим данным оригинального индекса.","по идее можно регрессию делать, раз компоненты посчитаны и результат есть.
тем самым, вытащить коэффициенты."
,,,смысл идти все равно скоро закроется
,,смысл идти все равно скоро закроется,Хахахахахахах
,,,"Спасибо, посмотрю!
Спасибо, видимо формат видео лекции и правда самый лучший"
,,"Спасибо, посмотрю!
Спасибо, видимо формат видео лекции и правда самый лучший","Тут формулировка бизнес требования от 9 2 мне кажется лучше, чем стандартный подход. Те в некоторых нулях ты тоже уверен. Но скорее всего на практике это решается тем, что нули, в которых уверен, не рекомендуешь клиенту."
,"Спасибо, посмотрю!
Спасибо, видимо формат видео лекции и правда самый лучший","Тут формулировка бизнес требования от 9 2 мне кажется лучше, чем стандартный подход. Те в некоторых нулях ты тоже уверен. Но скорее всего на практике это решается тем, что нули, в которых уверен, не рекомендуешь клиенту.","подскажите плиз как добавить сферу в меш в ply файле через питон?
Спасибо!"
,,,А есть сетка для определения является ли текст вопросом? Ченить простое)
,,А есть сетка для определения является ли текст вопросом? Ченить простое),"Так это же решается просто поиском вопросительных слов. Типа где, когда и т.д"
,А есть сетка для определения является ли текст вопросом? Ченить простое),"Так это же решается просто поиском вопросительных слов. Типа где, когда и т.д",Ты че угораешь? Или проблема сеть натренить ?)
,,,Существуют вопросы без вопросительных слов? ;)
,,Существуют вопросы без вопросительных слов? ;),Да. Например: Ты человек?
,Существуют вопросы без вопросительных слов? ;),Да. Например: Ты человек?,Знак вопроса найденный обычной регуляркой '?' и если нет то вопросительные слова.
,,,Это может быть и утверждением и вопросом
,,,"О чем и речь, одних маркерных слов недостаточно"
,,"О чем и речь, одних маркерных слов недостаточно",Но и нейросеть не даст 100% точность. Тут уже человеку самому решать
,,,"А если в фразе ""ты человек"" нет вопросительного знака, то и человек не поймёт что это."
,,,"Есть еще проблема с тем, что не все предложения с вопросительными словами – вопросительные

""Когда я был молод, трава была зеленее"""
,,"Есть еще проблема с тем, что не все предложения с вопросительными словами – вопросительные

""Когда я был молод, трава была зеленее""","Да, кстати"
,,,"Только по контексту, то есть простенькое не подойдёт, нужна сетка"
,,"Только по контексту, то есть простенькое не подойдёт, нужна сетка","Да, без контекста никуда. Хотя и есть какие-то априорные вероятности для некоторых конструкций, что они чаще употребляются в вопросительных или же повествовательных предложениях"
,,,"Доброго времени суток.
Какие решения сейчас наиболее актуальны для генерации для генерации видео, по набору фотографий/видео? Желательно real-time, в идеале, учитывающие при генерации мимику из образца видео (такие вообще есть?)"
,,"Доброго времени суток.
Какие решения сейчас наиболее актуальны для генерации для генерации видео, по набору фотографий/видео? Желательно real-time, в идеале, учитывающие при генерации мимику из образца видео (такие вообще есть?)","зачем тренить сетку на таску которая решается и без неё
regex на вопросительный знак
пофильтровать вопросительными словами 100%ые кейсы

ну и как будто достаточно вопросительным знаком фильтровать (и чтобы восклицательным знаки не были рядом)"
,"Доброго времени суток.
Какие решения сейчас наиболее актуальны для генерации для генерации видео, по набору фотографий/видео? Желательно real-time, в идеале, учитывающие при генерации мимику из образца видео (такие вообще есть?)","зачем тренить сетку на таску которая решается и без неё
regex на вопросительный знак
пофильтровать вопросительными словами 100%ые кейсы

ну и как будто достаточно вопросительным знаком фильтровать (и чтобы восклицательным знаки не были рядом)","Добрый день.
Подскажите пожалуйста, какие сейчас наиболее актуальные решения в построении вопросно-ответных систем?
Что взять как baseline?"
"Доброго времени суток.
Какие решения сейчас наиболее актуальны для генерации для генерации видео, по набору фотографий/видео? Желательно real-time, в идеале, учитывающие при генерации мимику из образца видео (такие вообще есть?)","зачем тренить сетку на таску которая решается и без неё
regex на вопросительный знак
пофильтровать вопросительными словами 100%ые кейсы

ну и как будто достаточно вопросительным знаком фильтровать (и чтобы восклицательным знаки не были рядом)","Добрый день.
Подскажите пожалуйста, какие сейчас наиболее актуальные решения в построении вопросно-ответных систем?
Что взять как baseline?","Всем привет! 

Посоветуйте, пожалуйста, хорошие небольшие датасеты для обучения моделей Voice Activity Detection. 
Задача - в учебных целях написать свою модель для VAD. Соответственно, датасеты нужны не слишком большие (вычислительные ресурсы для обучения ограниченные), но желательно и с речью, и с прочим шумом."
"зачем тренить сетку на таску которая решается и без неё
regex на вопросительный знак
пофильтровать вопросительными словами 100%ые кейсы

ну и как будто достаточно вопросительным знаком фильтровать (и чтобы восклицательным знаки не были рядом)","Добрый день.
Подскажите пожалуйста, какие сейчас наиболее актуальные решения в построении вопросно-ответных систем?
Что взять как baseline?","Всем привет! 

Посоветуйте, пожалуйста, хорошие небольшие датасеты для обучения моделей Voice Activity Detection. 
Задача - в учебных целях написать свою модель для VAD. Соответственно, датасеты нужны не слишком большие (вычислительные ресурсы для обучения ограниченные), но желательно и с речью, и с прочим шумом.","Его можно и самому собрать, взять любой датасет речи, пройтись vad от silero и добавить шумы. Для учебных целей вполне будет достаточно. Заодно и самому поиграться с добавлением шумов"
,,,Ребят подскажите какая сейчас sota по распознаванию русской речи которая работает быстро и  в колабе?
,,Ребят подскажите какая сейчас sota по распознаванию русской речи которая работает быстро и  в колабе?,"https://alphacephei.com/nsh/2023/01/22/russian-models.html - здесь список русскоязычных моделей с их качеством распознавания и скоростью
Ещё можешь посмотреть это: https://github.com/guillaumekln/faster-whisper"
,,,А можно промпт?
,,А можно промпт?,"Как-то так. Вроде, если сразу матом крыть, то будет кусаться"
,,,Огонь спасибо
,,,"Всем привет. Я правильно понимаю что в yolov8 confidence это softmax по классам, а в yolov5 отдельный канал в выходе?.. Поправьте пожалуйста, если неправ"
,,"Всем привет. Я правильно понимаю что в yolov8 confidence это softmax по классам, а в yolov5 отдельный канал в выходе?.. Поправьте пожалуйста, если неправ","Отвечу сам. И там и там отдельный confidence.

Ну не суть. Вообще походу v8 прям вообще нормально лучше v5 (даже на домене +/- чуть в сторону). Только раздражает манера ultralytics обещать paper, и не писать"
,,,Всем привет! Кто-то знает хорошие статьи и датасеты по hate speech recognition?
,,,а где работаешь если не секрет?
,,а где работаешь если не секрет?,Норси транс
,,,Пхукет отзовись
,,,"В Хуа Хине было 27к год, и иммиграха не так лютует как Пхукетская. Но ХХ для пенсов"
,,"В Хуа Хине было 27к год, и иммиграха не так лютует как Пхукетская. Но ХХ для пенсов","Про лютование хз хз. У меня уже 3 месяца занятий нет. В каких то школах даже приезжать не надо. По времени 2 раза по 2 часа в неделю было, без домашки само собой."
,,,Красивое
,,,"Приве, посоветуйте хостинг или сервис где можно сервер с gpu подешевле взять для экспериментов с DL. Colabe не подходит)"
,,"Приве, посоветуйте хостинг или сервис где можно сервер с gpu подешевле взять для экспериментов с DL. Colabe не подходит)",vast.ai
,,,Занятно
,,,Top 10 anime comebacks
,,Top 10 anime comebacks,Похоже на то учитывая малую разницу вариативности
,,,"Всем привет, а кто-нибудь может подсказать проекты, где учат LLM на midi?"
,,"Всем привет, а кто-нибудь может подсказать проекты, где учат LLM на midi?","Сбер учил, ещё кто то"
,,,"Там же крайне натуральным образом должны ложиться все языковые трюки, только контекст нужен длинный"
,,"Там же крайне натуральным образом должны ложиться все языковые трюки, только контекст нужен длинный",Да оно неплохо в целом учится
,"Там же крайне натуральным образом должны ложиться все языковые трюки, только контекст нужен длинный",Да оно неплохо в целом учится,"А opensource есть какие-то известные проекты? Была идея взять 1 группу и попытаться выучить ""стиль"" например. Насколько модель сможет воспроизводить гармоническую структуру"
"Там же крайне натуральным образом должны ложиться все языковые трюки, только контекст нужен длинный",Да оно неплохо в целом учится,"А opensource есть какие-то известные проекты? Была идея взять 1 группу и попытаться выучить ""стиль"" например. Насколько модель сможет воспроизводить гармоническую структуру","Всем привет! Есть моделька на торче, в которой используется апсемплинг (в feature pyramid network). Она конвертится в onnx, но вот инференс onnx'a на openCV падает, ругаясь на ноду resize (скорее всего именно на нее, судя по тому, что я гуглил + до этого без со старым бэкбоном все работает ок), которая как раз отвечает за апсемплинг (на скрине). Может кто-то сталкивался с подобным и как решали?"
,,,с каким опсетом конвертили?
,,с каким опсетом конвертили?,11
,,,На более поздних версиях такое же поведение?
,,На более поздних версиях такое же поведение?,Пробовал на 14-ом опсете. То же самое
,,,"Всем привет, кто нибудь сталкивался с задачей определения границ значений признаков для получения максимально возможного количества определенного класса в датасете.

Т.е. есть условно 10 признаков и 2 класса. Вопрос. По каким признакам и каким значениям я должен отфильтровать данные, чтобы получить максимальное количество объектов класса 1.

Реализовал дерево решений и сделал его интерпретацию. Может кто знает, как ещё можно решить эту задачу, хотел бы улучшить результаты"
,,"Всем привет, кто нибудь сталкивался с задачей определения границ значений признаков для получения максимально возможного количества определенного класса в датасете.

Т.е. есть условно 10 признаков и 2 класса. Вопрос. По каким признакам и каким значениям я должен отфильтровать данные, чтобы получить максимальное количество объектов класса 1.

Реализовал дерево решений и сделал его интерпретацию. Может кто знает, как ещё можно решить эту задачу, хотел бы улучшить результаты",По идее ничего лучше дерева тут не придумаешь. Можешь попробовать поменять критерий и потюнить гиперпараметры типа глубины и минимального количества элементов в листе
,"Всем привет, кто нибудь сталкивался с задачей определения границ значений признаков для получения максимально возможного количества определенного класса в датасете.

Т.е. есть условно 10 признаков и 2 класса. Вопрос. По каким признакам и каким значениям я должен отфильтровать данные, чтобы получить максимальное количество объектов класса 1.

Реализовал дерево решений и сделал его интерпретацию. Может кто знает, как ещё можно решить эту задачу, хотел бы улучшить результаты",По идее ничего лучше дерева тут не придумаешь. Можешь попробовать поменять критерий и потюнить гиперпараметры типа глубины и минимального количества элементов в листе,"Да, спасибо, я так и сделал"
,,,"Выглядит, имхо, как какая-то бага в опенсиви. Использовали несколько раз FPN через onnx с помощью onnxruntime и никогда с таким не сталкивались."
,,"Выглядит, имхо, как какая-то бага в опенсиви. Использовали несколько раз FPN через onnx с помощью onnxruntime и никогда с таким не сталкивались.","Окей, спасибо. Попробую на новой версии opencv. Сейчас использовал 4.6.0"
,"Выглядит, имхо, как какая-то бага в опенсиви. Использовали несколько раз FPN через onnx с помощью onnxruntime и никогда с таким не сталкивались.","Окей, спасибо. Попробую на новой версии opencv. Сейчас использовал 4.6.0","Была подобная проблема, решилось переходом на 4.7.0"
"Выглядит, имхо, как какая-то бага в опенсиви. Использовали несколько раз FPN через onnx с помощью onnxruntime и никогда с таким не сталкивались.","Окей, спасибо. Попробую на новой версии opencv. Сейчас использовал 4.6.0","Была подобная проблема, решилось переходом на 4.7.0","Спасибо! На 4.7.0 все работает. Кстати, дней 5 назад вышла 4.8.0. На ней тоже все ок)"
"Окей, спасибо. Попробую на новой версии opencv. Сейчас использовал 4.6.0","Была подобная проблема, решилось переходом на 4.7.0","Спасибо! На 4.7.0 все работает. Кстати, дней 5 назад вышла 4.8.0. На ней тоже все ок)","О, нужно попробовать собрать, на 7 версии как раз докучает баг с бэкендом."
,,,Какую тему сегодня обсуждаете?
,,Какую тему сегодня обсуждаете?,"завтра ( во вторник 4 июля ) планировали продолжить обзор торговых платформ, посмотреть на примеры использования. Текущее предложение по поводу кода - backtrader, zipline и PyFolio. Подключайтесь 😉."
,Какую тему сегодня обсуждаете?,"завтра ( во вторник 4 июля ) планировали продолжить обзор торговых платформ, посмотреть на примеры использования. Текущее предложение по поводу кода - backtrader, zipline и PyFolio. Подключайтесь 😉.",мы начали https://discord.gg/sZkePhaWSZ
,,,"Multitrack сразу... интересно
Было бы интересно как rlhf бы прошел на base model. Тут же можно было очень круто натюнить, потому что human feedback сдесь был бы более детерминированный и обоснованный"
,,,Вот насчёт human feedback здесь я бы не был так уверен. Музыка - сложная штука и к чистому миди не сводится. Да и миди в токены все по-своему кодируют
,,Вот насчёт human feedback здесь я бы не был так уверен. Музыка - сложная штука и к чистому миди не сводится. Да и миди в токены все по-своему кодируют,Так задача же отсеять всякую глупость с точки зрения стиля. Как раз это по идее разметить можно было бы
,,,выглядит как оч медленная хрень
,,выглядит как оч медленная хрень,"Хм, странная архитектура. Pitch, duration и instrument должно быть достаточно."
,,,"Возможно, в университетских статьях часто эффективностью не заморачиваются"
,,,"Ну и с другой стороны обогатить произведения функциональной теорией, когда не просто рандомно последовательность заучивать, а всякие блокт типа ii - v - i, тритоновые замены и прочее"
,,"Ну и с другой стороны обогатить произведения функциональной теорией, когда не просто рандомно последовательность заучивать, а всякие блокт типа ii - v - i, тритоновые замены и прочее","Видел работы, где в модель суют вместе с нотами название текущего аккорда. Именно в виде римских цифр или функций - вроде не видел. Возможно, если самостоятельно сесть и разметить, то что-то даст."
,"Ну и с другой стороны обогатить произведения функциональной теорией, когда не просто рандомно последовательность заучивать, а всякие блокт типа ii - v - i, тритоновые замены и прочее","Видел работы, где в модель суют вместе с нотами название текущего аккорда. Именно в виде римских цифр или функций - вроде не видел. Возможно, если самостоятельно сесть и разметить, то что-то даст.","Functional harmony - это как матан, тут надо образование получать. И это не просто ""сел и разметил все произведения"":)"
,,,"Думаю, что там предсказать следующий токен было бы проще, чем стихотворение"
,,"Думаю, что там предсказать следующий токен было бы проще, чем стихотворение","Но всегда можно найти техно, в котором 7 минут подряд играет ровно один аккорд)"
,"Думаю, что там предсказать следующий токен было бы проще, чем стихотворение","Но всегда можно найти техно, в котором 7 минут подряд играет ровно один аккорд)","Не, на техно и так выучит. Я про более академически сложную музыку"
"Думаю, что там предсказать следующий токен было бы проще, чем стихотворение","Но всегда можно найти техно, в котором 7 минут подряд играет ровно один аккорд)","Не, на техно и так выучит. Я про более академически сложную музыку","Всем ку! Это совсем чуть чуть полезной рекламы для вас. Короче если вы сейчас поступаете в магу, то у вас есть шансик залететь на нее бесплатно в итмо.

У них проходит контест где по пет проектам, по дипломной работе, по пейперам можно выиграть бви.

Я вот победил со своим пет проектом и вкр и рассказал про это в статье на хабре! (несмотря на то, что мой проект далек от идеала и пишу посты я тоже так сяк) то если у вас есть что то рабочее, вы скорее всего 100% пройдёте."
"Но всегда можно найти техно, в котором 7 минут подряд играет ровно один аккорд)","Не, на техно и так выучит. Я про более академически сложную музыку","Всем ку! Это совсем чуть чуть полезной рекламы для вас. Короче если вы сейчас поступаете в магу, то у вас есть шансик залететь на нее бесплатно в итмо.

У них проходит контест где по пет проектам, по дипломной работе, по пейперам можно выиграть бви.

Я вот победил со своим пет проектом и вкр и рассказал про это в статье на хабре! (несмотря на то, что мой проект далек от идеала и пишу посты я тоже так сяк) то если у вас есть что то рабочее, вы скорее всего 100% пройдёте.","Но на этом уровне теории музыка становится очень логически объяснимой, а значит можно было бы и модельку обучить
Просто на pitch/duration это брутфорс с большим количеством ошибок"
,,,"А вот на условное техно, интересно как скоро кто-то зарешает и войдет в топ spotify с генератором музыки"
,,"А вот на условное техно, интересно как скоро кто-то зарешает и войдет в топ spotify с генератором музыки",А яндексовская нейромузыка не катит?
,"А вот на условное техно, интересно как скоро кто-то зарешает и войдет в топ spotify с генератором музыки",А яндексовская нейромузыка не катит?,"Не катит, ответственно заявляю как имеющий отношение к ней)"
"А вот на условное техно, интересно как скоро кто-то зарешает и войдет в топ spotify с генератором музыки",А яндексовская нейромузыка не катит?,"Не катит, ответственно заявляю как имеющий отношение к ней)","Эка ты сам себя..:)
Раз уж я влез в беседу.. спрошу.
В разделе DL в звуках часто нужен слух и/или музыкальное образование? Просто интересно, я пока только в NLP какой-то опыт имею."
А яндексовская нейромузыка не катит?,"Не катит, ответственно заявляю как имеющий отношение к ней)","Эка ты сам себя..:)
Раз уж я влез в беседу.. спрошу.
В разделе DL в звуках часто нужен слух и/или музыкальное образование? Просто интересно, я пока только в NLP какой-то опыт имею.",Не катит на топ спотйфай в разделе техно. Она для другого
,,,"Да, я тоже из тех, кто матан учил, а функциональную гармонию - нет 🙂 Но было бы интересно разобраться лучше, конечно"
,,,"В техно очень важно звучание и грув в целом. Я пока не понимаю, как это понятно в сетку засунуть"
,,"В техно очень важно звучание и грув в целом. Я пока не понимаю, как это понятно в сетку засунуть","Каноны как ни странно, те же что и в классике, +/- вариации.

Например взять Tobias Thomas или Boris Breija - для сведения холодные старт и конец, внутри тема развивается провал, основа...

Квадратный драм, плоский бас, подложка атмосферы, развивающаяся напряжением в разрешение основная тема.

В общих чертах. (А теперь богателлу к Элизе сравните - один хрен)"
,"В техно очень важно звучание и грув в целом. Я пока не понимаю, как это понятно в сетку засунуть","Каноны как ни странно, те же что и в классике, +/- вариации.

Например взять Tobias Thomas или Boris Breija - для сведения холодные старт и конец, внутри тема развивается провал, основа...

Квадратный драм, плоский бас, подложка атмосферы, развивающаяся напряжением в разрешение основная тема.

В общих чертах. (А теперь богателлу к Элизе сравните - один хрен)","Опа, Бетховена и ""квадратный драм, плоский бас"" сравнили:)))"
"В техно очень важно звучание и грув в целом. Я пока не понимаю, как это понятно в сетку засунуть","Каноны как ни странно, те же что и в классике, +/- вариации.

Например взять Tobias Thomas или Boris Breija - для сведения холодные старт и конец, внутри тема развивается провал, основа...

Квадратный драм, плоский бас, подложка атмосферы, развивающаяся напряжением в разрешение основная тема.

В общих чертах. (А теперь богателлу к Элизе сравните - один хрен)","Опа, Бетховена и ""квадратный драм, плоский бас"" сравнили:)))","Yes, как ни странно. Левая рука это как раз оно"
,,,"Зилкова глядел немного, да. Спасибо!"
,,"Зилкова глядел немного, да. Спасибо!","Там как раз будут примеры почему музыка такая как она есть сейчас, почему одни группы аккордов более вероятны, чем другие и т.д."
,,,Space gremlin в голове играет)
,,Space gremlin в голове играет),"Т.е. невероятное многообразие гармонии, контрапункт и прочее уже зарешали?:)"
,,,"Как человек с музыкальным образованием, широким кругозором, и долгим опытом игры в группе...

Нейросетями не проблема вообще генерить музыку годную. Меня сильно впечатлила 10ая симфония.

Разные аудитории ""кушают"" разное, но теория классики это все покрывает - и эстраду, и рэп, и рэйв, и метал, и джаз.

В моем миропредставлении, тяготение к определенному жанру - это что-то про темперамент + социальную ментальность. 

Поэтому если есть вектор user mood - вытащить из него музыкальный паттерн и классифицировать аранжировку. И дело в шляпе (как в анекдоте про Бондарчука сейчас легкий сарказм :))"
,,"Как человек с музыкальным образованием, широким кругозором, и долгим опытом игры в группе...

Нейросетями не проблема вообще генерить музыку годную. Меня сильно впечатлила 10ая симфония.

Разные аудитории ""кушают"" разное, но теория классики это все покрывает - и эстраду, и рэп, и рэйв, и метал, и джаз.

В моем миропредставлении, тяготение к определенному жанру - это что-то про темперамент + социальную ментальность. 

Поэтому если есть вектор user mood - вытащить из него музыкальный паттерн и классифицировать аранжировку. И дело в шляпе (как в анекдоте про Бондарчука сейчас легкий сарказм :))",Western music theory
,,,"Всем привет! Есть ли среди вас те, кто решал какую-то задачу с помощью методов объяснения ИИ или просто с помощью интерпретируемых алгоритмов и кто готов поделиться опытом в опросе? 

Примеры (просто для сути):

- для объяснения заказчику применял/а тепловые карты
- для повышения доверия в задаче классификации использовал/а лес 

🙏🏻— да, это я
🤝— да, есть такой знакомый/знакомая/знакомые
💔— нет

И спасибо за то, что тыкнете!)"
,,"Всем привет! Есть ли среди вас те, кто решал какую-то задачу с помощью методов объяснения ИИ или просто с помощью интерпретируемых алгоритмов и кто готов поделиться опытом в опросе? 

Примеры (просто для сути):

- для объяснения заказчику применял/а тепловые карты
- для повышения доверия в задаче классификации использовал/а лес 

🙏🏻— да, это я
🤝— да, есть такой знакомый/знакомая/знакомые
💔— нет

И спасибо за то, что тыкнете!)","Лес глобально объяснимая история, но лучше... линрег/логрег. Для тепловых карт.

Для (гео) объекта значение признака ""потенциал"", коэффициент - ""интенсивность"". Если интенсивность заогранчить неотрицательностью - можно хорошо запредиктить суммой таргет."
,,,Миль пардон где нескромность :(
,,,Индийскую музыку это не покроет
,,Индийскую музыку это не покроет,Битлы покрыли же)
,,,"Вот есть ли статьи с reproducible code которые бы это покрывали? А не просто ""жахнем трансформером по миди собранию Баха и забрутфорсим все"""
,,"Вот есть ли статьи с reproducible code которые бы это покрывали? А не просто ""жахнем трансформером по миди собранию Баха и забрутфорсим все""","Так все дело в таргете. Надо брать другую разметку, в этом мысль, и не seq2seq решать.

8 нот - это практически до 8 аккордов или более, уже немалое пространство для аранжировки.

Вспомнить например Panjabi MC, или на что только what is love не перекладывали (trance hardcore моя любимая версия).

Вобщем мысль что Паттерн + Аранжировка + ??? = профит.

Как Бородина на рэп положили - даже я послушал."
,"Вот есть ли статьи с reproducible code которые бы это покрывали? А не просто ""жахнем трансформером по миди собранию Баха и забрутфорсим все""","Так все дело в таргете. Надо брать другую разметку, в этом мысль, и не seq2seq решать.

8 нот - это практически до 8 аккордов или более, уже немалое пространство для аранжировки.

Вспомнить например Panjabi MC, или на что только what is love не перекладывали (trance hardcore моя любимая версия).

Вобщем мысль что Паттерн + Аранжировка + ??? = профит.

Как Бородина на рэп положили - даже я послушал.",А можно ссылку где Бородина на рэп положили? ;)
"Вот есть ли статьи с reproducible code которые бы это покрывали? А не просто ""жахнем трансформером по миди собранию Баха и забрутфорсим все""","Так все дело в таргете. Надо брать другую разметку, в этом мысль, и не seq2seq решать.

8 нот - это практически до 8 аккордов или более, уже немалое пространство для аранжировки.

Вспомнить например Panjabi MC, или на что только what is love не перекладывали (trance hardcore моя любимая версия).

Вобщем мысль что Паттерн + Аранжировка + ??? = профит.

Как Бородина на рэп положили - даже я послушал.",А можно ссылку где Бородина на рэп положили? ;),https://dzen.ru/a/YAPgggz0oXC5El-L
,,,"Просто как для шахмат народ уже использует программы, чтобы находить новые нестандартные ходы и линии, про музыку я такого пока не слышал
Для начала бы human level performance получить
Единственное, что я слышал, это как copyright lawyers забрутфорсили мелодии до N (8 по-моему) нот и выложили под GPL, чтобы нельзя было (как это модно сейчас в Штатах) подавать на плагиат от малоизвестных групп 30 летней давности"
,,,никто не мешает жахнуть трансформером по индийским рагам)
,,никто не мешает жахнуть трансформером по индийским рагам),"в 4.8.0 авто дополнение  завезли от opencv .
однозначно нужно обновиться"
,,,"Продуманный таргет потянет за собой всю структуру рисерча. Мне вот интересно, хорошей разметкой кто-нибудь в опенсорс поделится?"
,,"Продуманный таргет потянет за собой всю структуру рисерча. Мне вот интересно, хорошей разметкой кто-нибудь в опенсорс поделится?",У Яндекса теоретически все есть... Но в опен сорс они редко
,,,"Ну и отдельно вопрос, кто на такое гранты выделит, потому что если зарешать такую задачку, то можно нексило так задисраптить индустрию музыки, отожрав хулиарды у лейблов... и как итог получить кучу исков в штатах
Потому что если один раз в топ spotify войти, и разтрезвонить об этом, то это будет конец музыкальной индустрии в таком виде, какая она сейчас"
,,,"Интересно, а как сейчас с транскрипцией сырого аудио в midi? Были ли какие-то недавние продвижения в этой области?"
,,"Интересно, а как сейчас с транскрипцией сырого аудио в midi? Были ли какие-то недавние продвижения в этой области?","https://arxiv.org/abs/2111.03017 - MT3 от Google
https://arxiv.org/pdf/2210.05148.pdf - DiffRoll от Sony с прикольной идеей
https://arxiv.org/pdf/2206.10805.pdf - и от Bytedance вот, но они обычно код не выкладывают"
,,,Wav to midi вроде же уже лет 10-20 были?
,,Wav to midi вроде же уже лет 10-20 были?,"Ну вот я и спрашиваю, было ли что-то новое в последние пару лет)"
,,,Было бы прикольно решить такую задачку как в VAE: делаем миди и сравниваем насколько близко получилось с оригиналом
,,Было бы прикольно решить такую задачку как в VAE: делаем миди и сравниваем насколько близко получилось с оригиналом,"И еще, раз я сюда затащил FastSam и MobileSam - последний сильно лучше. 

FastSam на базе yolov8-seg, а mobile - на базе легкого ViT. Как небо и земля. 

Но инференс полностью в браузер хз, хз..."
,,,"Из твоего описания не совскем понятно делала ли ты так, но неплохая идея следующая - пишешь основной алгоритм на чём угодно, а затем отдельно на предиктах обучаешь лес. В итоге любая модель интерпретируется второй моделью."
,,"Из твоего описания не совскем понятно делала ли ты так, но неплохая идея следующая - пишешь основной алгоритм на чём угодно, а затем отдельно на предиктах обучаешь лес. В итоге любая модель интерпретируется второй моделью.","Классный подход, спасибо! А есть еще подобные трюки для других категорий задач, которые повышают наглядность взаимосвязи вход-выход ?"
,"Из твоего описания не совскем понятно делала ли ты так, но неплохая идея следующая - пишешь основной алгоритм на чём угодно, а затем отдельно на предиктах обучаешь лес. В итоге любая модель интерпретируется второй моделью.","Классный подход, спасибо! А есть еще подобные трюки для других категорий задач, которые повышают наглядность взаимосвязи вход-выход ?","У меня есть список библиотек, которые дают возможность интерпретировать всяко-разное. 
https://github.com/SadSabrina/XAI"
"Из твоего описания не совскем понятно делала ли ты так, но неплохая идея следующая - пишешь основной алгоритм на чём угодно, а затем отдельно на предиктах обучаешь лес. В итоге любая модель интерпретируется второй моделью.","Классный подход, спасибо! А есть еще подобные трюки для других категорий задач, которые повышают наглядность взаимосвязи вход-выход ?","У меня есть список библиотек, которые дают возможность интерпретировать всяко-разное. 
https://github.com/SadSabrina/XAI",Спасибо большое!
,,,"Я видел лекцию, где в DS в Сбере так построил скоринг для малого бизнеса. И чтобы не был совсем блек бокс, он давал андеррайтерам объяснения из дерева, обученного поверх первой модели."
,,"Я видел лекцию, где в DS в Сбере так построил скоринг для малого бизнеса. И чтобы не был совсем блек бокс, он давал андеррайтерам объяснения из дерева, обученного поверх первой модели.",а в проде использовал первую модель? очень странно)
,,,А аутпуты первой модели как интерпретируются?
,,,"Мне кажется, что можно по SHAP VALUES отобрать признаки. В целом звучит, как задача feature selection. Если признаков всего 10 - то можно генетический алгоритм с отбором фич затащить."
,,"Мне кажется, что можно по SHAP VALUES отобрать признаки. В целом звучит, как задача feature selection. Если признаков всего 10 - то можно генетический алгоритм с отбором фич затащить.","Признаков много от 50 до 100 в зависимости от датасета. Нужно наверное решать задачу, как задачу оптимизации"
,,,Во торой модели таргеты - это аутпуты первой модели
,,,"первая модель:
- 10 фич - предсказывает 1 или 0, аутпут вероятности - [0.7, 0.2, 0.5, ...]
вторая модель:
- 10 фич - предсказывает  [0.7, 0.2, 0.5, ...]"
,,"первая модель:
- 10 фич - предсказывает 1 или 0, аутпут вероятности - [0.7, 0.2, 0.5, ...]
вторая модель:
- 10 фич - предсказывает  [0.7, 0.2, 0.5, ...]","чет это как то странно, одна модель предсказывает таргет, а вторая предсказывает предсказания первой…а в чем профит? вторая модель на деревьях будет такая же как если бы сразу обучать дерево… и зачем тогда нужна первая модель?"
,"первая модель:
- 10 фич - предсказывает 1 или 0, аутпут вероятности - [0.7, 0.2, 0.5, ...]
вторая модель:
- 10 фич - предсказывает  [0.7, 0.2, 0.5, ...]","чет это как то странно, одна модель предсказывает таргет, а вторая предсказывает предсказания первой…а в чем профит? вторая модель на деревьях будет такая же как если бы сразу обучать дерево… и зачем тогда нужна первая модель?","Дерево интерпретируемо, но само по себе является слабым алгоритмом. А вот первая модель может быть, допустим, бустингом над деревьями, который интерпретировать уже сложнее, но при этом можно добиться большего качества. На похожей идее (обучение суррогатной модели поверх черного ящика) основан LIME 2016 года, к примеру"
"первая модель:
- 10 фич - предсказывает 1 или 0, аутпут вероятности - [0.7, 0.2, 0.5, ...]
вторая модель:
- 10 фич - предсказывает  [0.7, 0.2, 0.5, ...]","чет это как то странно, одна модель предсказывает таргет, а вторая предсказывает предсказания первой…а в чем профит? вторая модель на деревьях будет такая же как если бы сразу обучать дерево… и зачем тогда нужна первая модель?","Дерево интерпретируемо, но само по себе является слабым алгоритмом. А вот первая модель может быть, допустим, бустингом над деревьями, который интерпретировать уже сложнее, но при этом можно добиться большего качества. На похожей идее (обучение суррогатной модели поверх черного ящика) основан LIME 2016 года, к примеру",ну lime далеко не просто строит дерево над выходом из первой модели…
,,,"И, я так понимаю, что вторую модель можно обучать без теста до 99% accuracy на трейне"
,,,"А есть у кого-нибудь под рукой статья, где рассказывают, как происходит трейн (претрейн) таких моделей, как LLama, alpaca, falcone. А именно, какие датасеты и на какие таски тюнятся? Я помню, что сначала берётся весь интернет и вроде бы учится задача по угадыванию mask word. При этом тренится одна эпоха. А что там дальше никак не могу найти..."
,,"А есть у кого-нибудь под рукой статья, где рассказывают, как происходит трейн (претрейн) таких моделей, как LLama, alpaca, falcone. А именно, какие датасеты и на какие таски тюнятся? Я помню, что сначала берётся весь интернет и вроде бы учится задача по угадыванию mask word. При этом тренится одна эпоха. А что там дальше никак не могу найти...","так в статье всё есть, ты её открывал?"
,"А есть у кого-нибудь под рукой статья, где рассказывают, как происходит трейн (претрейн) таких моделей, как LLama, alpaca, falcone. А именно, какие датасеты и на какие таски тюнятся? Я помню, что сначала берётся весь интернет и вроде бы учится задача по угадыванию mask word. При этом тренится одна эпоха. А что там дальше никак не могу найти...","так в статье всё есть, ты её открывал?","Распределение по датасетам мне известно. Мне интересно, как
реализован masking. И меняются ли цели в процессе. Типа в bert: 80 процентов маскируется случайный токен, 10 процентов времени токены меняются на случайные, и тп. Потом в берт была тема с предсказанием следующего предложения. И тп."
"А есть у кого-нибудь под рукой статья, где рассказывают, как происходит трейн (претрейн) таких моделей, как LLama, alpaca, falcone. А именно, какие датасеты и на какие таски тюнятся? Я помню, что сначала берётся весь интернет и вроде бы учится задача по угадыванию mask word. При этом тренится одна эпоха. А что там дальше никак не могу найти...","так в статье всё есть, ты её открывал?","Распределение по датасетам мне известно. Мне интересно, как
реализован masking. И меняются ли цели в процессе. Типа в bert: 80 процентов маскируется случайный токен, 10 процентов времени токены меняются на случайные, и тп. Потом в берт была тема с предсказанием следующего предложения. И тп.","BERT тренируется на задаче masked language modelling. 
А современные генеративные нейросети (GPT и всё похожее на него, типа ламы) тренируется на задаче обычного (авторегрессионного) language modelling, то есть просто предсказание следующего токена. То есть для их обучения маскировать или заменять ничего не надо, а надо просто по каждым n токенам в документе предсказывать n+1-й токен."
,,,"А зачем тебе это? Какая конечная цель? 
Есть требования к интерпретируемости построенной модели?"
,,"А зачем тебе это? Какая конечная цель? 
Есть требования к интерпретируемости построенной модели?",задачка с контеста в яндекс
,"А зачем тебе это? Какая конечная цель? 
Есть требования к интерпретируемости построенной модели?",задачка с контеста в яндекс,"Понял, абстрактная задача, значит.

А есть примеры функций, которые хотим приблизить?"
,,,"А почему с xgboost решили начать?
Как разбивали на трейн и тест?
Пробовали тут же на графике f1 выводить, чтобы видеть изменение в динамике?"
,,"А почему с xgboost решили начать?
Как разбивали на трейн и тест?
Пробовали тут же на графике f1 выводить, чтобы видеть изменение в динамике?",не могу найти
,,,задача E
,,задача E,Это решается через PolynomialFeatures+LinearRegression
,,,похожая
,,похожая,они семплируют кучу датасетов из изначальных данных и строят статистику зависимости выхода первой модели от каждой фичи.
,,,"Всем привет! У кого то может быть есть датасет с парами вроде

Хэллоу ворлд - Hello world
Найтвиш форева - Nightwish forever

Или какая то библиотека которая позволит качественно его сгенерировать (просто транслитерация не пойдет)"
,,"Всем привет! У кого то может быть есть датасет с парами вроде

Хэллоу ворлд - Hello world
Найтвиш форева - Nightwish forever

Или какая то библиотека которая позволит качественно его сгенерировать (просто транслитерация не пойдет)",soundex?)
,"Всем привет! У кого то может быть есть датасет с парами вроде

Хэллоу ворлд - Hello world
Найтвиш форева - Nightwish forever

Или какая то библиотека которая позволит качественно его сгенерировать (просто транслитерация не пойдет)",soundex?),То есть сравнивать транслитерацию на русском типа скутер -> skuter с аналогичными английскими словами вроде scooter?
,,,"Может просто сгенерировать TTS аудио на русском, а потом распознать с помощью STT на английском?)"
,,,"Добрый день всем, дайте совет пожалуйста.
Вот есть сеть, обученная на чат, мне по сути это и нужно. Но мне нужно как-то зафайнтьюнить её на информацию одной книги условно. Книга понятное дело не в форме чата. В инструкции сети там сказали собирать json в виде чата тоже. Как можно зафайнтьюнить так, чтоб она по сути свои чат способности сохранила, но умело инфу из книги и стиль автора переняла?
Или это надо вручную составлять датасет, в нужном виде?"
,,"Добрый день всем, дайте совет пожалуйста.
Вот есть сеть, обученная на чат, мне по сути это и нужно. Но мне нужно как-то зафайнтьюнить её на информацию одной книги условно. Книга понятное дело не в форме чата. В инструкции сети там сказали собирать json в виде чата тоже. Как можно зафайнтьюнить так, чтоб она по сути свои чат способности сохранила, но умело инфу из книги и стиль автора переняла?
Или это надо вручную составлять датасет, в нужном виде?","Через аугментацию диалогов невидимо для пользователя данными, полученными через retrieval."
,"Добрый день всем, дайте совет пожалуйста.
Вот есть сеть, обученная на чат, мне по сути это и нужно. Но мне нужно как-то зафайнтьюнить её на информацию одной книги условно. Книга понятное дело не в форме чата. В инструкции сети там сказали собирать json в виде чата тоже. Как можно зафайнтьюнить так, чтоб она по сути свои чат способности сохранила, но умело инфу из книги и стиль автора переняла?
Или это надо вручную составлять датасет, в нужном виде?","Через аугментацию диалогов невидимо для пользователя данными, полученными через retrieval.",+ тренировать отдельную сеть на стилистику по книге и через нее прогонять ответ обычной чат сети.
"Добрый день всем, дайте совет пожалуйста.
Вот есть сеть, обученная на чат, мне по сути это и нужно. Но мне нужно как-то зафайнтьюнить её на информацию одной книги условно. Книга понятное дело не в форме чата. В инструкции сети там сказали собирать json в виде чата тоже. Как можно зафайнтьюнить так, чтоб она по сути свои чат способности сохранила, но умело инфу из книги и стиль автора переняла?
Или это надо вручную составлять датасет, в нужном виде?","Через аугментацию диалогов невидимо для пользователя данными, полученными через retrieval.",+ тренировать отдельную сеть на стилистику по книге и через нее прогонять ответ обычной чат сети.,"Либо пропустить датасет реплик через сеть стилизации, а потом снова файнтюн и при обращении к боту делать retrieval с книжки для контекста."
,,,"1. Это очень сложная задача 
2. В книгах нет стиля автора в диалогах, у каждого персонажа свой стиль и характер
3. Вряд ли получится это сделать"
,,"1. Это очень сложная задача 
2. В книгах нет стиля автора в диалогах, у каждого персонажа свой стиль и характер
3. Вряд ли получится это сделать",Ну с НейроЖириновским неплохо же вышло)
,"1. Это очень сложная задача 
2. В книгах нет стиля автора в диалогах, у каждого персонажа свой стиль и характер
3. Вряд ли получится это сделать",Ну с НейроЖириновским неплохо же вышло),"а у нейрожириновского разве можно открыто поболтать? Мне казалось, они там че-то на презентации только сделали, весь потенциал сети не показали как будто"
"1. Это очень сложная задача 
2. В книгах нет стиля автора в диалогах, у каждого персонажа свой стиль и характер
3. Вряд ли получится это сделать",Ну с НейроЖириновским неплохо же вышло),"а у нейрожириновского разве можно открыто поболтать? Мне казалось, они там че-то на презентации только сделали, весь потенциал сети не показали как будто","У сбера свой старенький был где то, еще на ruGPT3"
,,,"1. Это не книга про жириновского
2. Скорее всего, там учили на стенограммах диалогов или монологов. Других персонажей там не было."
,,"1. Это не книга про жириновского
2. Скорее всего, там учили на стенограммах диалогов или монологов. Других персонажей там не было.","Так op и не говорил, что книга бедна на диалоги вроде?) плюс, если параметров достаточно, сеть может предположить манеру общения по описанию."
,"1. Это не книга про жириновского
2. Скорее всего, там учили на стенограммах диалогов или монологов. Других персонажей там не было.","Так op и не говорил, что книга бедна на диалоги вроде?) плюс, если параметров достаточно, сеть может предположить манеру общения по описанию.",А кого конкретно из персонажей книги?
"1. Это не книга про жириновского
2. Скорее всего, там учили на стенограммах диалогов или монологов. Других персонажей там не было.","Так op и не говорил, что книга бедна на диалоги вроде?) плюс, если параметров достаточно, сеть может предположить манеру общения по описанию.",А кого конкретно из персонажей книги?,Я не знаю :)
"Так op и не говорил, что книга бедна на диалоги вроде?) плюс, если параметров достаточно, сеть может предположить манеру общения по описанию.",А кого конкретно из персонажей книги?,Я не знаю :),"Это не будет работать, если в ручную диалоги по персонажам не разметить. И у нас задача стиль автора передать, а не персонажей"
А кого конкретно из персонажей книги?,Я не знаю :),"Это не будет работать, если в ручную диалоги по персонажам не разметить. И у нас задача стиль автора передать, а не персонажей","В таком случае это еще проще. Как я выше и писал, сеть стилизации + обычный чат бот."
Я не знаю :),"Это не будет работать, если в ручную диалоги по персонажам не разметить. И у нас задача стиль автора передать, а не персонажей","В таком случае это еще проще. Как я выше и писал, сеть стилизации + обычный чат бот.","Пример в студию, если это так просто"
"Это не будет работать, если в ручную диалоги по персонажам не разметить. И у нас задача стиль автора передать, а не персонажей","В таком случае это еще проще. Как я выше и писал, сеть стилизации + обычный чат бот.","Пример в студию, если это так просто",https://replicate.com/replicate/mpt-7b-storywriter/examples
"В таком случае это еще проще. Как я выше и писал, сеть стилизации + обычный чат бот.","Пример в студию, если это так просто",https://replicate.com/replicate/mpt-7b-storywriter/examples,"а, сорри, я забыл упомянуть, что книга на русском, значит что чат-сеть, которую надо файнтьюнить, надо искать предобученную на русском? Ну и сеть стилизации видимо тоже"
"Пример в студию, если это так просто",https://replicate.com/replicate/mpt-7b-storywriter/examples,"а, сорри, я забыл упомянуть, что книга на русском, значит что чат-сеть, которую надо файнтьюнить, надо искать предобученную на русском? Ну и сеть стилизации видимо тоже","Думаю да, так качество будет выше."
,,,"просто как будто столько влили в Жириновского, а на деле может и не так, как его презентовали. На презентации могли подкрутить что угодно"
,,"просто как будто столько влили в Жириновского, а на деле может и не так, как его презентовали. На презентации могли подкрутить что угодно","Но условно storywriter65k  прекрасно дописывает диалоги
Я ж выше написал mpt-7b-storywriter-65k"
,"просто как будто столько влили в Жириновского, а на деле может и не так, как его презентовали. На презентации могли подкрутить что угодно","Но условно storywriter65k  прекрасно дописывает диалоги
Я ж выше написал mpt-7b-storywriter-65k","чет смотрю, все мультиязычные сети, там 70% на англ обучались и мб 10% на русском. Как будто куча параметров не задействуется в таком случае"
"просто как будто столько влили в Жириновского, а на деле может и не так, как его презентовали. На презентации могли подкрутить что угодно","Но условно storywriter65k  прекрасно дописывает диалоги
Я ж выше написал mpt-7b-storywriter-65k","чет смотрю, все мультиязычные сети, там 70% на англ обучались и мб 10% на русском. Как будто куча параметров не задействуется в таком случае","Суть подхода, однако, не  меняется. Но затрат на достижение цели, теоретически, больше, да."
,,,"еще уточнить: сеть стилизации по типу text2text generation? Она примет аутпут обычной чат сети и изменит его?
Там еще такое может быть. Условно, цитату конфуция в тему вставить она примерно такое осилит?"
,,"еще уточнить: сеть стилизации по типу text2text generation? Она примет аутпут обычной чат сети и изменит его?
Там еще такое может быть. Условно, цитату конфуция в тему вставить она примерно такое осилит?","Поэтому если нужен Конфуций, то добавить retrieval из цитат Конфуция с какой то вероятностью в промпт."
,"еще уточнить: сеть стилизации по типу text2text generation? Она примет аутпут обычной чат сети и изменит его?
Там еще такое может быть. Условно, цитату конфуция в тему вставить она примерно такое осилит?","Поэтому если нужен Конфуций, то добавить retrieval из цитат Конфуция с какой то вероятностью в промпт.","понял, спасибо за оперативные и подробные ответы"
,,,"Вот тут скорее всего придется либо prompt engineer’ить либо instruct модель использовать.
По ссылке выше пример промпта для английской модели, которая ни разу не instruct до fine tune была, но обучена на длинном контекстном окне в 65к токенов.
Но по сути да, затравка + ( примеры, если не тюнить на авторе)+ контекст из книги через retrieval + контекст диалога из чат бота."
,,"Вот тут скорее всего придется либо prompt engineer’ить либо instruct модель использовать.
По ссылке выше пример промпта для английской модели, которая ни разу не instruct до fine tune была, но обучена на длинном контекстном окне в 65к токенов.
Но по сути да, затравка + ( примеры, если не тюнить на авторе)+ контекст из книги через retrieval + контекст диалога из чат бота.","А может просто есть какие то нормальные билингвальные модели кроме whisper? Стоит задача в риалтайме распознавать названия песен во фразах типа ""Включи песню скутер ноу фэйт""
Гугл как-то это делает и яндекс тоже
Или что вы имеете ввиду"
,"Вот тут скорее всего придется либо prompt engineer’ить либо instruct модель использовать.
По ссылке выше пример промпта для английской модели, которая ни разу не instruct до fine tune была, но обучена на длинном контекстном окне в 65к токенов.
Но по сути да, затравка + ( примеры, если не тюнить на авторе)+ контекст из книги через retrieval + контекст диалога из чат бота.","А может просто есть какие то нормальные билингвальные модели кроме whisper? Стоит задача в риалтайме распознавать названия песен во фразах типа ""Включи песню скутер ноу фэйт""
Гугл как-то это делает и яндекс тоже
Или что вы имеете ввиду","Да, но иметь ее заранее"
"Вот тут скорее всего придется либо prompt engineer’ить либо instruct модель использовать.
По ссылке выше пример промпта для английской модели, которая ни разу не instruct до fine tune была, но обучена на длинном контекстном окне в 65к токенов.
Но по сути да, затравка + ( примеры, если не тюнить на авторе)+ контекст из книги через retrieval + контекст диалога из чат бота.","А может просто есть какие то нормальные билингвальные модели кроме whisper? Стоит задача в риалтайме распознавать названия песен во фразах типа ""Включи песню скутер ноу фэйт""
Гугл как-то это делает и яндекс тоже
Или что вы имеете ввиду","Да, но иметь ее заранее",Так на входе облака точек? Тогда можно начат с Вики:
,,,"Всем привет.
Хочу попробовать генерировать изображения, но в преобразованном с помощью БПФ виде, типо такого.
Насколько такая фотография будет шумной? Устойчива ли такая генерация к выбросам или на выходе может получиться совсем не то что я хочу?"
,,"Всем привет.
Хочу попробовать генерировать изображения, но в преобразованном с помощью БПФ виде, типо такого.
Насколько такая фотография будет шумной? Устойчива ли такая генерация к выбросам или на выходе может получиться совсем не то что я хочу?","А как насчёт VAE ? 
В самом БПФ не должно быть прям супер много информации, судя по скрину
Сильно напоминает линейный смаз"
,,,"Cгенерировать не сложно, будет проблема с тем что оно может не иметь смысла"
,,,"в каком смысле? то есть если я ее натренирую на фурье изображениях белок, она может сгенерировать просто шумную картинку?"
,,"в каком смысле? то есть если я ее натренирую на фурье изображениях белок, она может сгенерировать просто шумную картинку?",Да
,,,"понял, спасибо большое"
,,"понял, спасибо большое","Тебе возможно это стоит рассмотреть не как преобразование фото а как генерация подобного тензора с клипом по значениям пикселя, возможно через нормализационные потоки"
,,,"не очень понял что вы имеете в виду, можно пожалуйста попроще немного?😅
на самом деле мне как раз нужно как можно более информативное изображение, при этом, чтобы генерация занимала немного времени"
,,,я ищу способ как генерировать какое то несложное распределение которое будет давать хороший результат
,,я ищу способ как генерировать какое то несложное распределение которое будет давать хороший результат,https://github.com/hse-ds/iad-applied-ds/blob/master/2023/lectures/lecture02-nf.pdf
,,,"Всем привет, могли бы вы скинуть работы или материалы, где в рекомендательной системе видео используется тегирование в качестве метаинформации. Например, определяются действия людей их количество, распознаются персоны в кадре и тд. Это скорее к контентным рекомендациям, но я пока не понимаю как такую метаинфу использовать. Буду благодарен за ответы."
,,"Всем привет, могли бы вы скинуть работы или материалы, где в рекомендательной системе видео используется тегирование в качестве метаинформации. Например, определяются действия людей их количество, распознаются персоны в кадре и тд. Это скорее к контентным рекомендациям, но я пока не понимаю как такую метаинфу использовать. Буду благодарен за ответы.","https://ieeexplore.ieee.org/abstract/document/8297150
https://link.springer.com/article/10.1007/s13740-016-0060-9

вроде вот что-то похожее, но ИМХО это вообще нестандартный подход к рекомендациям видосов, это типа чтобы обойти колд старт может делают разве что. Про ""не понимаю как такую метаинфу использовать"" - ну наверное как атрибуты айтемов, а дальше стандарные content-based подходы, разве нет?"
,,,"Привет всем. Покритикуйте размышления. 

Может появиться задача обнаружения изменений на парных снимках - какие то объекты могли добавиться или исчезнуть за время, прошедшее между снимками.  

Как я понимаю - решать ее можно как задачу Object Detection, потом совмещать букеты векторов и определять изменения. В этом случае правильнее наверное использовать YOLO и обучить ее объектам моего класса.  Основное преимущество, наверное, скорость YOLO и простота подготовки датасета с нужным классом. 

Другой подход - Image (Semantic) Segmentation, потом совмещать маски (как тут рекомендовали - задача Point Set Registration) и определять изменение.  Встреченные описания решений вращаются вокруг воспроизводства хорошо зарекомендовавшей себя U-net.  В чем тут преимущества и недостатки, почему делают такие решения сегодня - не понятно. 

Два альтернативных пути движения смущают. Что лучше в 2023 году? Куда двигаться?"
,,"Привет всем. Покритикуйте размышления. 

Может появиться задача обнаружения изменений на парных снимках - какие то объекты могли добавиться или исчезнуть за время, прошедшее между снимками.  

Как я понимаю - решать ее можно как задачу Object Detection, потом совмещать букеты векторов и определять изменения. В этом случае правильнее наверное использовать YOLO и обучить ее объектам моего класса.  Основное преимущество, наверное, скорость YOLO и простота подготовки датасета с нужным классом. 

Другой подход - Image (Semantic) Segmentation, потом совмещать маски (как тут рекомендовали - задача Point Set Registration) и определять изменение.  Встреченные описания решений вращаются вокруг воспроизводства хорошо зарекомендовавшей себя U-net.  В чем тут преимущества и недостатки, почему делают такие решения сегодня - не понятно. 

Два альтернативных пути движения смущают. Что лучше в 2023 году? Куда двигаться?","Ну... А если разницу кадров посмотреть? absdiff, как деды завещали"
,"Привет всем. Покритикуйте размышления. 

Может появиться задача обнаружения изменений на парных снимках - какие то объекты могли добавиться или исчезнуть за время, прошедшее между снимками.  

Как я понимаю - решать ее можно как задачу Object Detection, потом совмещать букеты векторов и определять изменения. В этом случае правильнее наверное использовать YOLO и обучить ее объектам моего класса.  Основное преимущество, наверное, скорость YOLO и простота подготовки датасета с нужным классом. 

Другой подход - Image (Semantic) Segmentation, потом совмещать маски (как тут рекомендовали - задача Point Set Registration) и определять изменение.  Встреченные описания решений вращаются вокруг воспроизводства хорошо зарекомендовавшей себя U-net.  В чем тут преимущества и недостатки, почему делают такие решения сегодня - не понятно. 

Два альтернативных пути движения смущают. Что лучше в 2023 году? Куда двигаться?","Ну... А если разницу кадров посмотреть? absdiff, как деды завещали",Фон тоже может меняться. Но за напоминание спасибо
"Привет всем. Покритикуйте размышления. 

Может появиться задача обнаружения изменений на парных снимках - какие то объекты могли добавиться или исчезнуть за время, прошедшее между снимками.  

Как я понимаю - решать ее можно как задачу Object Detection, потом совмещать букеты векторов и определять изменения. В этом случае правильнее наверное использовать YOLO и обучить ее объектам моего класса.  Основное преимущество, наверное, скорость YOLO и простота подготовки датасета с нужным классом. 

Другой подход - Image (Semantic) Segmentation, потом совмещать маски (как тут рекомендовали - задача Point Set Registration) и определять изменение.  Встреченные описания решений вращаются вокруг воспроизводства хорошо зарекомендовавшей себя U-net.  В чем тут преимущества и недостатки, почему делают такие решения сегодня - не понятно. 

Два альтернативных пути движения смущают. Что лучше в 2023 году? Куда двигаться?","Ну... А если разницу кадров посмотреть? absdiff, как деды завещали",Фон тоже может меняться. Но за напоминание спасибо,"Да, ок, время суток то же. Может попробовать MobileSAM?"
,,,"Всем привет, какие сейчас есть хорошие подходы в реиндентификации людей в униформе?"
,,"Всем привет, какие сейчас есть хорошие подходы в реиндентификации людей в униформе?","Сохранил, мне не хватало такой боевой картинки"
,,,"Господа кэгловцы, верно ли то, что: чтобы загрузить любой файл при работе с ноутбуком нужно создавать датасет. Или как в колабе все же можно прост файл закинуть который жить будет в течении сессии?"
,,"Господа кэгловцы, верно ли то, что: чтобы загрузить любой файл при работе с ноутбуком нужно создавать датасет. Или как в колабе все же можно прост файл закинуть который жить будет в течении сессии?",Ещё можно скачать ОДИН раз через !wget и переключиться в режим file persistence
,,,"Только через датасет
Либо скачивать каждый раз !wget"
,,"Только через датасет
Либо скачивать каждый раз !wget",еще как-то через гугл диск кажется можно было. Но вроде это тоже как кастомный датасет считается)
,,,"Чат, подскажите как строить рексис для дейтинга? Что взять как бейзлайн"
,,"Чат, подскажите как строить рексис для дейтинга? Что взять как бейзлайн","Полагаю, нужны фичи типо знака зодиака, главенствующих планет, косинусное расстояние по гороскопам и эмбеддинги от карт желаний"
,"Чат, подскажите как строить рексис для дейтинга? Что взять как бейзлайн","Полагаю, нужны фичи типо знака зодиака, главенствующих планет, косинусное расстояние по гороскопам и эмбеддинги от карт желаний",База
"Чат, подскажите как строить рексис для дейтинга? Что взять как бейзлайн","Полагаю, нужны фичи типо знака зодиака, главенствующих планет, косинусное расстояние по гороскопам и эмбеддинги от карт желаний",База,"А это будет считаться reciprocal recs? Я как-то думал, что дейтинг предполагает какой-то учёт вероятности взаимного лайка, и полагаться на схожесть интересов - это типа гипотеза, что они ищут такого же человека, как и они, но это ж вообще не факт, особенно в дейтинге, это ж не фильмы похожие подбирать)) Так что тут может имплисит фидбек нужен все-таки, чтобы что-то нормальное получить? Или как?"
,,,Если gdrive использовать то он прост в /kaggle/working скачивает
,,Если gdrive использовать то он прост в /kaggle/working скачивает,есть кто то из Гронингена?
,Если gdrive использовать то он прост в /kaggle/working скачивает,есть кто то из Гронингена?,о было недавно
Если gdrive использовать то он прост в /kaggle/working скачивает,есть кто то из Гронингена?,о было недавно,"Как раз убил пару недель на то, чтобы подружить с кудой вместе все модели, версии фреймворков без конфликтов и докер😅"
есть кто то из Гронингена?,о было недавно,"Как раз убил пару недель на то, чтобы подружить с кудой вместе все модели, версии фреймворков без конфликтов и докер😅","ребят, че думаете про бакс?)"
о было недавно,"Как раз убил пару недель на то, чтобы подружить с кудой вместе все модели, версии фреймворков без конфликтов и докер😅","ребят, че думаете про бакс?)",То же что про покойника
"Как раз убил пару недель на то, чтобы подружить с кудой вместе все модели, версии фреймворков без конфликтов и докер😅","ребят, че думаете про бакс?)",То же что про покойника,а еще)
"ребят, че думаете про бакс?)",То же что про покойника,а еще),ну вроде леджит выглядят с дивана следующие тэйки
,,,"Всем привет, реализую систему распознавания лиц, думаю использовать в качестве детектора RetinaFace, но есть ли лучше? Может быть есть у кого-нибудь пример современной системы распознавания лиц?"
,,"Всем привет, реализую систему распознавания лиц, думаю использовать в качестве детектора RetinaFace, но есть ли лучше? Может быть есть у кого-нибудь пример современной системы распознавания лиц?","Если совсем только вливаешься, то поюзай insightface. По детекторам довольно много более свежих, чем у них. Например, yolo5-face (и последущие)."
,,,норм можешь еще глянуть insightface
,,норм можешь еще глянуть insightface,через deepface думал все собирать вместе
,,,Кстати нужно ли отдельно еще применять алгоритмы по выравниванию лица делать или RetinaFace все сама делает?
,,Кстати нужно ли отдельно еще применять алгоритмы по выравниванию лица делать или RetinaFace все сама делает?,"ну ретина вроде только боксы и точки возвращает
кроп сделать и довернуть самому надо"
,Кстати нужно ли отдельно еще применять алгоритмы по выравниванию лица делать или RetinaFace все сама делает?,"ну ретина вроде только боксы и точки возвращает
кроп сделать и довернуть самому надо","Хорошо, спасибо"
Кстати нужно ли отдельно еще применять алгоритмы по выравниванию лица делать или RetinaFace все сама делает?,"ну ретина вроде только боксы и точки возвращает
кроп сделать и довернуть самому надо","Хорошо, спасибо","Детекторы обычно заменить легко, потому что они обучаются на почти идентичных данных."
"ну ретина вроде только боксы и точки возвращает
кроп сделать и довернуть самому надо","Хорошо, спасибо","Детекторы обычно заменить легко, потому что они обучаются на почти идентичных данных.","Понял, спасибо"
"Хорошо, спасибо","Детекторы обычно заменить легко, потому что они обучаются на почти идентичных данных.","Понял, спасибо","Вот это конечно бот намиксовал наш 😅
Прикольно 👌
Это очень круто, с лицами сложно работать весьма
Ахах 🤣"
,,,что выбрали бы: бали vs тай vs вьетнам vs малайзия для легкого дауншифтинга поделать свои штучки на несколько месяцев?
,,что выбрали бы: бали vs тай vs вьетнам vs малайзия для легкого дауншифтинга поделать свои штучки на несколько месяцев?,"мне пока больше всего кл нравится (4 месяца бордер ранами), все говорят на англе (вообще не кейс во вьете/тае), довольно рич страна сама по себе (ну и культурно она более понятна, думаю тк английская колония), там дёшево в плане ренты если лонг терм, еда тоже примерно на уровне Вьетнама по ценам, электроника стоит ничего (вроде самая дешёвая в регионе), есть варик digital nomad виз, но там надо показывать налоги за последние 2 года + вроде что салари от 2к$"
,что выбрали бы: бали vs тай vs вьетнам vs малайзия для легкого дауншифтинга поделать свои штучки на несколько месяцев?,"мне пока больше всего кл нравится (4 месяца бордер ранами), все говорят на англе (вообще не кейс во вьете/тае), довольно рич страна сама по себе (ну и культурно она более понятна, думаю тк английская колония), там дёшево в плане ренты если лонг терм, еда тоже примерно на уровне Вьетнама по ценам, электроника стоит ничего (вроде самая дешёвая в регионе), есть варик digital nomad виз, но там надо показывать налоги за последние 2 года + вроде что салари от 2к$",кл?
,,,"мне кажется стоит заранее найти коммьюнити в которых будешь вариться в кокнретном месте 
чтобы не было такого что приехал - а там полтора русскоговорящих на квадратный километр а с иностранцами общаться в напряг"
,,,"всем привет!
нужно по данному фото чтобы ИИ дорисовывал в хорошем качестве отдельные элементы
подскажите, как можно решить такую задачу?"
,,"всем привет!
нужно по данному фото чтобы ИИ дорисовывал в хорошем качестве отдельные элементы
подскажите, как можно решить такую задачу?",inpainting ?
,"всем привет!
нужно по данному фото чтобы ИИ дорисовывал в хорошем качестве отдельные элементы
подскажите, как можно решить такую задачу?",inpainting ?,"да, inpainting в первую очередь, внутри картинки"
,,,"""Дорисовывал""  - расширял изображение или внутри картинки по маске?"
,,,ну што sdxl  утек
,,ну што sdxl  утек,Ага
,,,Проще найти норм файнтюн из тех что наварили шизоалхимики на 1.5
,,Проще найти норм файнтюн из тех что наварили шизоалхимики на 1.5,"А мб подскажешь где можно поискать эти файнтюны и мб какие-то пайпы посмотреть?
Позапускал несколько вариантов с HF, но результаты прям не оч"
,Проще найти норм файнтюн из тех что наварили шизоалхимики на 1.5,"А мб подскажешь где можно поискать эти файнтюны и мб какие-то пайпы посмотреть?
Позапускал несколько вариантов с HF, но результаты прям не оч","В основном таким занимаются фотографы, поэтому подходы могут показаться странными
Но почему-то у них получается."
,,,What a time to be alive!
,,,"посоветуйте хорошие переводчики на python
пока что лучше всех переводит chatgpt, но это платная тема
также есть библиотека translatepy, которая использует различные апи для перевода - но тут тоже зависимости от других сервисов, да и переводит она хуже, чем chatgpt

В общем есть ли моделька какая-нибудь, которая хорошо переводит текста с любых языков?"
,,"посоветуйте хорошие переводчики на python
пока что лучше всех переводит chatgpt, но это платная тема
также есть библиотека translatepy, которая использует различные апи для перевода - но тут тоже зависимости от других сервисов, да и переводит она хуже, чем chatgpt

В общем есть ли моделька какая-нибудь, которая хорошо переводит текста с любых языков?",Yandex Free Translate
,,,"deepl api, или обязательно пыхтеть с моделькой ?"
,,"deepl api, или обязательно пыхтеть с моделькой ?","сразу не сказал, нужно что-то бесплатное
лучше модель, чтобы не зависеть ни от какого апи"
,,,"ну NLLB в целом неплох, если хотите локально"
,,"ну NLLB в целом неплох, если хотите локально",Да только без аккаунта 🤗 есть ограничения
,,,"Если готов терять веру в человечество, то civitai 
Это главная помойка по вопросу"
,,"Если готов терять веру в человечество, то civitai 
Это главная помойка по вопросу","Позапускал модельки, качество и фотореалистичность получаются клевые, но вот человека изменяет до неузнаваемости, а я бы хотел чтобы лицо допустим меняло стиль, но сохраняло характерные черты/узнваемость
Пробовал играться с параметрами, но желаемого эффекта не получил
Мб подскажешь куда копать?"
,"Если готов терять веру в человечество, то civitai 
Это главная помойка по вопросу","Позапускал модельки, качество и фотореалистичность получаются клевые, но вот человека изменяет до неузнаваемости, а я бы хотел чтобы лицо допустим меняло стиль, но сохраняло характерные черты/узнваемость
Пробовал играться с параметрами, но желаемого эффекта не получил
Мб подскажешь куда копать?","Чтобы приколачивать детали есть контролнет 
Но это все область алхимии, нормальных решений скорее нет (чел который собрался и подготовил трансфер лиц с референса пока на этапе «купил ферму, обмыл ее и сказал что будет держать в курсе дальнейших экспериментов»). Люди от безысходности даже файнтюнят на лица."
"Если готов терять веру в человечество, то civitai 
Это главная помойка по вопросу","Позапускал модельки, качество и фотореалистичность получаются клевые, но вот человека изменяет до неузнаваемости, а я бы хотел чтобы лицо допустим меняло стиль, но сохраняло характерные черты/узнваемость
Пробовал играться с параметрами, но желаемого эффекта не получил
Мб подскажешь куда копать?","Чтобы приколачивать детали есть контролнет 
Но это все область алхимии, нормальных решений скорее нет (чел который собрался и подготовил трансфер лиц с референса пока на этапе «купил ферму, обмыл ее и сказал что будет держать в курсе дальнейших экспериментов»). Люди от безысходности даже файнтюнят на лица.",Ну т.е если я хочу чтобы модель генерила всяких разных персонажей с конкретным фэйсом нужно ее файнтюнить все-таки?)
"Позапускал модельки, качество и фотореалистичность получаются клевые, но вот человека изменяет до неузнаваемости, а я бы хотел чтобы лицо допустим меняло стиль, но сохраняло характерные черты/узнваемость
Пробовал играться с параметрами, но желаемого эффекта не получил
Мб подскажешь куда копать?","Чтобы приколачивать детали есть контролнет 
Но это все область алхимии, нормальных решений скорее нет (чел который собрался и подготовил трансфер лиц с референса пока на этапе «купил ферму, обмыл ее и сказал что будет держать в курсе дальнейших экспериментов»). Люди от безысходности даже файнтюнят на лица.",Ну т.е если я хочу чтобы модель генерила всяких разных персонажей с конкретным фэйсом нужно ее файнтюнить все-таки?),"Да нет, просто освоиться с и2и и вкурить контролнет. Если не лень коллажировать то вообще изи. 
Но с обучением попроще с нуля генерить"
,,,"Хуже всего то, что правильные ответы на фотореал лежат за пределами safe"
,,"Хуже всего то, что правильные ответы на фотореал лежат за пределами safe","О, не думал что кого-то с родного физфака встречу."
,,,"Кому интересно попробовать свои модели с RL? Наконец-то получилось сделать работающего RL агента под трейдинг 🚀. Сейчас задача дать агенту как можно больше предиктов/фитчей от других моделей, имеющих хоть какую-то предсказательную способность. Например такие вот результаты с текущим набором моделей:"
,,"Кому интересно попробовать свои модели с RL? Наконец-то получилось сделать работающего RL агента под трейдинг 🚀. Сейчас задача дать агенту как можно больше предиктов/фитчей от других моделей, имеющих хоть какую-то предсказательную способность. Например такие вот результаты с текущим набором моделей:","Подскажи, пжл, может пропустил, это все ещё выгрузки или пейпертрейдинг?"
,"Кому интересно попробовать свои модели с RL? Наконец-то получилось сделать работающего RL агента под трейдинг 🚀. Сейчас задача дать агенту как можно больше предиктов/фитчей от других моделей, имеющих хоть какую-то предсказательную способность. Например такие вот результаты с текущим набором моделей:","Подскажи, пжл, может пропустил, это все ещё выгрузки или пейпертрейдинг?","это бэктест, валидация."
"Кому интересно попробовать свои модели с RL? Наконец-то получилось сделать работающего RL агента под трейдинг 🚀. Сейчас задача дать агенту как можно больше предиктов/фитчей от других моделей, имеющих хоть какую-то предсказательную способность. Например такие вот результаты с текущим набором моделей:","Подскажи, пжл, может пропустил, это все ещё выгрузки или пейпертрейдинг?","это бэктест, валидация.",Спасибо
,,,Что значит Perp? Perpetual protocol?
,,Что значит Perp? Perpetual protocol?,Это фьючи на бинансе (BTC-USDT-Perpetual)
,Что значит Perp? Perpetual protocol?,Это фьючи на бинансе (BTC-USDT-Perpetual),Спасибо
,,,"Можем попробовать добавить ваши модели и посмотреть даст ли это буст RL агенту. Сама модель не нужна, достаточно OOF предиктов от модели."
,,"Можем попробовать добавить ваши модели и посмотреть даст ли это буст RL агенту. Сама модель не нужна, достаточно OOF предиктов от модели.",Это у тебя пейпертрейдинг уже или пока на выгрузках?
,,,"А можно подробней... 
Что где как?
Как и что давать и пробовать?"
,,"А можно подробней... 
Что где как?
Как и что давать и пробовать?","Достаточно OOF (Out-of-Fold) предикты (это прогнозы модели машинного обучения, которые были получены путем валидации модели на обучающем наборе данных с использованием подхода кросс-валидации.) Могу скинуть в личке код примера генерации oof предиктов"
,"А можно подробней... 
Что где как?
Как и что давать и пробовать?","Достаточно OOF (Out-of-Fold) предикты (это прогнозы модели машинного обучения, которые были получены путем валидации модели на обучающем наборе данных с использованием подхода кросс-валидации.) Могу скинуть в личке код примера генерации oof предиктов","Для RL_модели есть разница - получить предикты другой модели или получить признаки, на которых эта другая модель обучалась?"
"А можно подробней... 
Что где как?
Как и что давать и пробовать?","Достаточно OOF (Out-of-Fold) предикты (это прогнозы модели машинного обучения, которые были получены путем валидации модели на обучающем наборе данных с использованием подхода кросс-валидации.) Могу скинуть в личке код примера генерации oof предиктов","Для RL_модели есть разница - получить предикты другой модели или получить признаки, на которых эта другая модель обучалась?","Есть, лучше предикты, в самой RL сетка небольшая, посути это только решающий слой"
,,,"Ну и было бы интересно, как ты все это реализовывал. Потому что я только пытаюсь подойти к RL"
,,,"Прикольно!
Если не секрет, какой action space у агента?
Только вход-выход или увеличение-сокращение позиций тоже?"
,,"Прикольно!
Если не секрет, какой action space у агента?
Только вход-выход или увеличение-сокращение позиций тоже?","Портфельная. При этом может брать как buy так и sell позицую по каждому из активов. Портфель тоже распределяет (пример: [-0.2817048 ,  0.01549482,  0.17566522,  0.30094784, -0.17590041,
         0.05044534])"
,"Прикольно!
Если не секрет, какой action space у агента?
Только вход-выход или увеличение-сокращение позиций тоже?","Портфельная. При этом может брать как buy так и sell позицую по каждому из активов. Портфель тоже распределяет (пример: [-0.2817048 ,  0.01549482,  0.17566522,  0.30094784, -0.17590041,
         0.05044534])","Ага, понял. 
Интересно будет такого агента затестить на большом количестве активов
А какой-нибудь фильтр на размер позиции использовал?
А то агент может научиться усредняться до бесконечности)"
"Прикольно!
Если не секрет, какой action space у агента?
Только вход-выход или увеличение-сокращение позиций тоже?","Портфельная. При этом может брать как buy так и sell позицую по каждому из активов. Портфель тоже распределяет (пример: [-0.2817048 ,  0.01549482,  0.17566522,  0.30094784, -0.17590041,
         0.05044534])","Ага, понял. 
Интересно будет такого агента затестить на большом количестве активов
А какой-нибудь фильтр на размер позиции использовал?
А то агент может научиться усредняться до бесконечности)","так он не трейдит, в классическом понимании, а держит портфель активов, и меняет размер актива в портфеле (и направление) в зависимости от предиктов моеделей"
"Портфельная. При этом может брать как buy так и sell позицую по каждому из активов. Портфель тоже распределяет (пример: [-0.2817048 ,  0.01549482,  0.17566522,  0.30094784, -0.17590041,
         0.05044534])","Ага, понял. 
Интересно будет такого агента затестить на большом количестве активов
А какой-нибудь фильтр на размер позиции использовал?
А то агент может научиться усредняться до бесконечности)","так он не трейдит, в классическом понимании, а держит портфель активов, и меняет размер актива в портфеле (и направление) в зависимости от предиктов моеделей",Ну размер портфеля же не бесконечный?
"Ага, понял. 
Интересно будет такого агента затестить на большом количестве активов
А какой-нибудь фильтр на размер позиции использовал?
А то агент может научиться усредняться до бесконечности)","так он не трейдит, в классическом понимании, а держит портфель активов, и меняет размер актива в портфеле (и направление) в зависимости от предиктов моеделей",Ну размер портфеля же не бесконечный?,"100%. Он конечно может уходить в кеш давая предикты по 0. Но чаще в непонятной ситуации он занимает рыночно нейтральную позицию (например купит btc и продаст eth, а это уже парный трейдинг кстати))"
"так он не трейдит, в классическом понимании, а держит портфель активов, и меняет размер актива в портфеле (и направление) в зависимости от предиктов моеделей",Ну размер портфеля же не бесконечный?,"100%. Он конечно может уходить в кеш давая предикты по 0. Но чаще в непонятной ситуации он занимает рыночно нейтральную позицию (например купит btc и продаст eth, а это уже парный трейдинг кстати))","Я просто к тому, что агент может научиться усредняться и пересиживать просадку
Если нет штрафа за размер позиции/размер просадки)"
Ну размер портфеля же не бесконечный?,"100%. Он конечно может уходить в кеш давая предикты по 0. Но чаще в непонятной ситуации он занимает рыночно нейтральную позицию (например купит btc и продаст eth, а это уже парный трейдинг кстати))","Я просто к тому, что агент может научиться усредняться и пересиживать просадку
Если нет штрафа за размер позиции/размер просадки)","Это если он торгует по сделкам (купил продал). А тут другая задача, по сути это портфельная оптимизация."
"100%. Он конечно может уходить в кеш давая предикты по 0. Но чаще в непонятной ситуации он занимает рыночно нейтральную позицию (например купит btc и продаст eth, а это уже парный трейдинг кстати))","Я просто к тому, что агент может научиться усредняться и пересиживать просадку
Если нет штрафа за размер позиции/размер просадки)","Это если он торгует по сделкам (купил продал). А тут другая задача, по сути это портфельная оптимизация.","Я правильно понял, что он сделал 19,3% денег?
Это с учетом комиссии Binanc  к примеру?
 А сколько сделок было"
"Я просто к тому, что агент может научиться усредняться и пересиживать просадку
Если нет штрафа за размер позиции/размер просадки)","Это если он торгует по сделкам (купил продал). А тут другая задача, по сути это портфельная оптимизация.","Я правильно понял, что он сделал 19,3% денег?
Это с учетом комиссии Binanc  к примеру?
 А сколько сделок было","С учётом комиссии. Там нет сделок, только верное распределение портфеля. Или считай сделки на каждом степе, так как веса в портфеле меняются постоянно. Что-то убавляет, что-то увеличивает из активов в портфеле."
,,,"RL знаю только теорию базовую. Сейчас читаю и не пойму, типа в данном случае RL используется для файнтюна, например, условного классификатора бустинга?"
,,"RL знаю только теорию базовую. Сейчас читаю и не пойму, типа в данном случае RL используется для файнтюна, например, условного классификатора бустинга?","Тут RL работает как мета модель, может объеденять множество стратегий (предикты от них) и распределять между ними портфель."
,"RL знаю только теорию базовую. Сейчас читаю и не пойму, типа в данном случае RL используется для файнтюна, например, условного классификатора бустинга?","Тут RL работает как мета модель, может объеденять множество стратегий (предикты от них) и распределять между ними портфель.","Поняла, здорово!"
,,,там предыдущие сообщения не видны (
,,там предыдущие сообщения не видны (,как воцап чтоле
,,,и много таких чатов? накидайте что есть
,,и много таких чатов? накидайте что есть,я думаю всем может быть интересно) Можешь кинуть прям здесь или уже в чате про RL
,и много таких чатов? накидайте что есть,я думаю всем может быть интересно) Можешь кинуть прям здесь или уже в чате про RL,"Мне интересно. Вот пример диалога на эту тему -
Дребезг моделей на переходных участках очень плохо влияет на конечный результат (подлые красные сделки на краях)
Ответ -"
,,,Это какой инструмент так пилит?
,,Это какой инструмент так пилит?,NQ
,,,"Да крайние сделки неочень. Что если создать вторую модель, которая по истории этих сделок обучиться подтверждать вход? Это уже будет не lstm а flat модель. Ей не нужно тайм серию. Достаточно давать на вход срез скажем 10 значений ohlcv, направление сделки и обучение - это результат сделки. Тогда можно сделать композицию сетей.
Первая ваша, вторая эта - подтверждающая. Из плюсов - эта сеть может быть рекурентной - самообучаемой в процессе работы.
Так что да - было бы интересно обсудить"
,,"Да крайние сделки неочень. Что если создать вторую модель, которая по истории этих сделок обучиться подтверждать вход? Это уже будет не lstm а flat модель. Ей не нужно тайм серию. Достаточно давать на вход срез скажем 10 значений ohlcv, направление сделки и обучение - это результат сделки. Тогда можно сделать композицию сетей.
Первая ваша, вторая эта - подтверждающая. Из плюсов - эта сеть может быть рекурентной - самообучаемой в процессе работы.
Так что да - было бы интересно обсудить","решаю задача ранкинга 5 позиций (всегда одни и те же), использую lightgbm ranker. Хочется, чтобы модель возвращала в одном предсказании рейтинги сразу для 5 позиций. Насколько разумного попробовать multi-class модель с кастомной функцией ndcg? По сути, немного подпилить напильником стандартный мультикласс"
,"Да крайние сделки неочень. Что если создать вторую модель, которая по истории этих сделок обучиться подтверждать вход? Это уже будет не lstm а flat модель. Ей не нужно тайм серию. Достаточно давать на вход срез скажем 10 значений ohlcv, направление сделки и обучение - это результат сделки. Тогда можно сделать композицию сетей.
Первая ваша, вторая эта - подтверждающая. Из плюсов - эта сеть может быть рекурентной - самообучаемой в процессе работы.
Так что да - было бы интересно обсудить","решаю задача ранкинга 5 позиций (всегда одни и те же), использую lightgbm ranker. Хочется, чтобы модель возвращала в одном предсказании рейтинги сразу для 5 позиций. Насколько разумного попробовать multi-class модель с кастомной функцией ndcg? По сути, немного подпилить напильником стандартный мультикласс","И тут не Профит важен, смотри Sharp и просадку. Модель афигенно сглаживает все рывки актива, По сути можно брать с х2 плечами и при этом это все равно будет лучше битка)"
,,,"А насколько максимально может шуметь само предсказание, чтобы управление портфелем работало в плюс?"
,,"А насколько максимально может шуметь само предсказание, чтобы управление портфелем работало в плюс?","нужно пробовать, если давать фитчи с рандом шумом то агент не обучиться и будет вот такая картинка:"
,"А насколько максимально может шуметь само предсказание, чтобы управление портфелем работало в плюс?","нужно пробовать, если давать фитчи с рандом шумом то агент не обучиться и будет вот такая картинка:","Хм, вот этот странный график получился. Ведь если алгоритм случайно шарит потрфель между ETH и  BTC, то итог должен быть примерно средним между их графиками. А тут - как-будто он вообще в позицию не входил."
"А насколько максимально может шуметь само предсказание, чтобы управление портфелем работало в плюс?","нужно пробовать, если давать фитчи с рандом шумом то агент не обучиться и будет вот такая картинка:","Хм, вот этот странный график получился. Ведь если алгоритм случайно шарит потрфель между ETH и  BTC, то итог должен быть примерно средним между их графиками. А тут - как-будто он вообще в позицию не входил.","Так это фьючи, он шорт тоже может брать. Вот и получается что-то около 0 минус комиссия."
"нужно пробовать, если давать фитчи с рандом шумом то агент не обучиться и будет вот такая картинка:","Хм, вот этот странный график получился. Ведь если алгоритм случайно шарит потрфель между ETH и  BTC, то итог должен быть примерно средним между их графиками. А тут - как-будто он вообще в позицию не входил.","Так это фьючи, он шорт тоже может брать. Вот и получается что-то около 0 минус комиссия.","Да, про шорты видно по небольшой ступеньке вниз.
Кстати, интересно было бы посмотреть на падающем рынке - не окажется ли эта рандомная модель лучше обученной :)
EDIT: впрочем, даже если так и будет, это мало о чём скажет. Вероятно, полезнее сравнить Sharpe Ratio с какой-то тривиальной моделью - той же парной (если в процентном отношении ETH ниже BTC, то ETH long, BTC short и наоборот)."
,,,"Насколько точна для этого агента сама модель предсказаний, другими словами?"
,,"Насколько точна для этого агента сама модель предсказаний, другими словами?","Чат, если вы готовы провести лекцию по алго трейдингу(лучше с кодом), то better data community идет к вам! 
Оплаты нет, но будет мерч!"
,,,если бы так просто было
,,если бы так просто было,А что там происходит?)
,,,"не знаю, как я понял, какое-то сообщество, похожее на ods в слаке"
,,"не знаю, как я понял, какое-то сообщество, похожее на ods в слаке","Как там в эмбеддингах...

ODS - toxic = BDS + content

😀"
,,,"Привет. Какие бд лучше использовать для сохранения market data ? MySQL vs какая-то time-series DB

Данных пока не очень много, но дальше будет много, хочу сразу спроектировать нормальный прод."
,,"Привет. Какие бд лучше использовать для сохранения market data ? MySQL vs какая-то time-series DB

Данных пока не очень много, но дальше будет много, хочу сразу спроектировать нормальный прод.","я через ClickHouse сделал, там фишка - он сам схлопывает дубликаты, а значит можно с разных потоков собирать и не париться про дубли. Плюс он заточен под timeseries, работает намного быстрее того-же MySQL)   https://github.com/Alex-Lekov/trade-data-collection-service"
,"Привет. Какие бд лучше использовать для сохранения market data ? MySQL vs какая-то time-series DB

Данных пока не очень много, но дальше будет много, хочу сразу спроектировать нормальный прод.","я через ClickHouse сделал, там фишка - он сам схлопывает дубликаты, а значит можно с разных потоков собирать и не париться про дубли. Плюс он заточен под timeseries, работает намного быстрее того-же MySQL)   https://github.com/Alex-Lekov/trade-data-collection-service","он не совсем заточен под временные ряды, но может конкурировать со специализированными TimeSeries базами данных. Clickhouse -  is  ageneric data storage solution for OLAP workloads и имеет в себе кодеки для компактного хранения временных рядов
https://clickhouse.com/docs/en/faq/use-cases/time-series"
,,,"в зависимости от того, как потом использовать 

ивенты/стаканы лучше в паркетах/.csv.gz 

если хранить сделки для постаналитики, если частотность не очень высокая и хочется хранить долго их, можно в обычной sql, для всяких графан проще в прометеус писать / если высокая частота и надо хранить всё, то я бы лучше в .csv.gz

но сота, наверное, .csv.gz (в паркетах с типами данных может быть запара, особенно если на наносекуном уровне таймстемпы) и прописать интерфейсы взаимодействия с ними"
,,,"Привет, не хочешь это в рамках BDC сделать? С нас закрепы везде, платный зум, с вас - оформить доклад в шаблонную презу"
,,"Привет, не хочешь это в рамках BDC сделать? С нас закрепы везде, платный зум, с вас - оформить доклад в шаблонную презу","Привет, у нас бесплатный Discord, закрепы имеются тоже, пока это проходит как еженедельный митап, к докладу нужно готовиться."
,,,"Кто-то пробовал получить API Kandinsky 2.1, SD или Midjourney для своего сервиса (tg bot)? Это возможно сейчас?"
,,"Кто-то пробовал получить API Kandinsky 2.1, SD или Midjourney для своего сервиса (tg bot)? Это возможно сейчас?",на репликейте есть кастомные апи SD
,,,"У MJ, K2.1 нет апи"
,,"У MJ, K2.1 нет апи",К2.1 же можно у себя развернуть из репо
,,,Sd надо поискать
,,,"Привет всем!
Хочу заменить голос на песне, но не знаю как(
Можете рассказать как это можно сделать?😊
Может есть какие-то jupyter-блокноты, automl-сервисы для этой цели..."
,,"Привет всем!
Хочу заменить голос на песне, но не знаю как(
Можете рассказать как это можно сделать?😊
Может есть какие-то jupyter-блокноты, automl-сервисы для этой цели...","Если нужно заменить именно сам голос на чей-то, без изменения смыслового содержимого вокала, то вот этим щас пользуются, в тиктоке хайпит https://github.com/justinjohn0306/so-vits-svc-4.0-v2"
,"Привет всем!
Хочу заменить голос на песне, но не знаю как(
Можете рассказать как это можно сделать?😊
Может есть какие-то jupyter-блокноты, automl-сервисы для этой цели...","Если нужно заменить именно сам голос на чей-то, без изменения смыслового содержимого вокала, то вот этим щас пользуются, в тиктоке хайпит https://github.com/justinjohn0306/so-vits-svc-4.0-v2","Нашел еще вот такой блокнот
https://colab.research.google.com/drive/1z31ZfcisCXCSGA5jeid0UNjiHb9oupuV?usp=sharing"
"Привет всем!
Хочу заменить голос на песне, но не знаю как(
Можете рассказать как это можно сделать?😊
Может есть какие-то jupyter-блокноты, automl-сервисы для этой цели...","Если нужно заменить именно сам голос на чей-то, без изменения смыслового содержимого вокала, то вот этим щас пользуются, в тиктоке хайпит https://github.com/justinjohn0306/so-vits-svc-4.0-v2","Нашел еще вот такой блокнот
https://colab.research.google.com/drive/1z31ZfcisCXCSGA5jeid0UNjiHb9oupuV?usp=sharing",А как можно новый голос для него обучить? И сколько примерно аудиоматериала нужно?
,,,"Можно через spleeter/demucs разделить песню на голос и всё остальное, а потом спеть новый голос поверх всего остального"
,,"Можно через spleeter/demucs разделить песню на голос и всё остальное, а потом спеть новый голос поверх всего остального","Спасибо, попробую"
,,,А вы сами учили модель?
,,А вы сами учили модель?,"Я недавно заджойнила тим, поэтому точно не знаю, и эта другая тима. Вроде как да, наши мл инженеры запилили."
,,,"Спасибо, я попробую)"
,,,"Какую модель можно взять для унарной классификации небольших изображений (до 100*100 пикселей)? На входе изображение на выходе 0 если нет объекта, 1 если есть.  И очень нужно чтобы можно было конвертировать в onnx после обучения."
,,"Какую модель можно взять для унарной классификации небольших изображений (до 100*100 пикселей)? На входе изображение на выходе 0 если нет объекта, 1 если есть.  И очень нужно чтобы можно было конвертировать в onnx после обучения.","я бы посмотрел на зоопарк из torchvision с изменением последнего линейного слоя. там есть информация по метрикам и сложности, соотвественно идти от самой простой модели к более сложным и выбирать трейд-оф между сложностью и точностью.
Я не знаю домен, но две-три девятки по аккураси должно получиться даже очень простыми самописными моделями при достаточном размере датасета. или там какая-то засада ? :)"
,"Какую модель можно взять для унарной классификации небольших изображений (до 100*100 пикселей)? На входе изображение на выходе 0 если нет объекта, 1 если есть.  И очень нужно чтобы можно было конвертировать в onnx после обучения.","я бы посмотрел на зоопарк из torchvision с изменением последнего линейного слоя. там есть информация по метрикам и сложности, соотвественно идти от самой простой модели к более сложным и выбирать трейд-оф между сложностью и точностью.
Я не знаю домен, но две-три девятки по аккураси должно получиться даже очень простыми самописными моделями при достаточном размере датасета. или там какая-то засада ? :)",Засада только в том что я не DS) и не очень умею в это. Поэтому и консультируюсь
"Какую модель можно взять для унарной классификации небольших изображений (до 100*100 пикселей)? На входе изображение на выходе 0 если нет объекта, 1 если есть.  И очень нужно чтобы можно было конвертировать в onnx после обучения.","я бы посмотрел на зоопарк из torchvision с изменением последнего линейного слоя. там есть информация по метрикам и сложности, соотвественно идти от самой простой модели к более сложным и выбирать трейд-оф между сложностью и точностью.
Я не знаю домен, но две-три девятки по аккураси должно получиться даже очень простыми самописными моделями при достаточном размере датасета. или там какая-то засада ? :)",Засада только в том что я не DS) и не очень умею в это. Поэтому и консультируюсь,"ну заодно и разберешься тогда :)
(свертка + батчнорм + активация + макспулл) * 3 + флаттен + дропаут + линеар + активация + линеар -> профит
и я бы делал все-таки бинарную классификацию с лейбл-смуффингом"
,,,"Всем привет! 
Предположим, мы имеем название, описание и STT по видеоконтенту. Каким образом можно делать на основе этих данных контентные рекомендации? Видео может быть длинным, поэтому STT может не влезать в max_len трансформера для векторизации
Понимаю, что нужно обучать энкодеры текста в постановке metric learning, но не очень понятно, где взять положительные и отрицательные примеры и объединять ли все эмбеды в один для поиска фаиссом или заводить три векторных пространства для увеличения реколла?"
,,,"Это бинарная классификация. В зависимости от домена - начиная от логрега и заканчивая всем на что травили на mnist/fashion mnist.

Любой модель (практически 99%) конвертируется в onnx"
,,"Это бинарная классификация. В зависимости от домена - начиная от логрега и заканчивая всем на что травили на mnist/fashion mnist.

Любой модель (практически 99%) конвертируется в onnx",Интересует sota какая сейчас в этом
,"Это бинарная классификация. В зависимости от домена - начиная от логрега и заканчивая всем на что травили на mnist/fashion mnist.

Любой модель (практически 99%) конвертируется в onnx",Интересует sota какая сейчас в этом,https://paperswithcode.com/sota/image-classification-on-cifar-10
,,,*модуль pytorch
,,*модуль pytorch,"Мб можно суммаризовать stt, чтобы влезло? 
Ролики от не-академий часто имеют океан воды"
,,,Ладно
,,,ну можно покопировать чего левелс делае
,,ну можно покопировать чего левелс делае,это который запускает стартапы levelsio?)
,,,"у него в твитторе есть история
да"
,,"у него в твитторе есть история
да","а он разве постил промпты или название моделей?
Я видел только, что он показывал резы img2img с его сервиса фотоэйай
или мб я не понял что предлагается покопировать)"
,"у него в твитторе есть история
да","а он разве постил промпты или название моделей?
Я видел только, что он показывал резы img2img с его сервиса фотоэйай
или мб я не понял что предлагается покопировать)","контролнет лайнарта вообще закрывает большую часть банальных задач, но если нужно больше то нормали хорошо хватают лицо."
,,,"Привет! Кто-нибудь использовал (или слышал о таких кейсах) AutoML решения вот прямо на практике (включая соревнования), и чтобы «все заработало и помогло решить задачу »? Речь и библиотеках типа auto sklearn, autogluon и так далее"
,,"Привет! Кто-нибудь использовал (или слышал о таких кейсах) AutoML решения вот прямо на практике (включая соревнования), и чтобы «все заработало и помогло решить задачу »? Речь и библиотеках типа auto sklearn, autogluon и так далее","читал пост победителей одного соревнования от вк, там сберовская лама помогла победить)"
,"Привет! Кто-нибудь использовал (или слышал о таких кейсах) AutoML решения вот прямо на практике (включая соревнования), и чтобы «все заработало и помогло решить задачу »? Речь и библиотеках типа auto sklearn, autogluon и так далее","читал пост победителей одного соревнования от вк, там сберовская лама помогла победить)","Там соревнование было на предсказание то ли возраста, то ли дружбы между пользователями 
Там особенность была, что нужно было быстро обработать большой массив тестовых данных"
,,,"Всем ку
У вас тут проходят мероприятия какие-либо?"
,,"Всем ку
У вас тут проходят мероприятия какие-либо?",Как из РБ купить подписку в MJ?
,"Всем ку
У вас тут проходят мероприятия какие-либо?",Как из РБ купить подписку в MJ?,Кто нибудь тренил Video Swin Transformer на Something Something v2?
"Всем ку
У вас тут проходят мероприятия какие-либо?",Как из РБ купить подписку в MJ?,Кто нибудь тренил Video Swin Transformer на Something Something v2?,картинки еще перед подачей в сетку полезно нормализовывать бывает :)
,,,"Всем привет!
Кто-нибудь решал задачу определения оффенсив картинок (начиная с nude фотографий или рисунков, заканчивая свастиками)? Куда смотреть в первую очередь?"
,,"Всем привет!
Кто-нибудь решал задачу определения оффенсив картинок (начиная с nude фотографий или рисунков, заканчивая свастиками)? Куда смотреть в первую очередь?","Такую систему не строил, но кажется, что вам сюда:

https://habr.com/ru/articles/550604/"
,,,"Всём привет, какие можно применить методы по детекции объекта на видео, без нейросетей(так как данных мало и обучаться по сути не на чем), вроде как можно сделать это методами opencv, но может что-то есть получше?"
,,"Всём привет, какие можно применить методы по детекции объекта на видео, без нейросетей(так как данных мало и обучаться по сути не на чем), вроде как можно сделать это методами opencv, но может что-то есть получше?","Если есть хотя бы 5-10 примеров, то для начала можно обучить YOLOv5, даже так она может хорошо обучиться. Вопрос в том, на чем вы будете тестировать качество, если у вас мало данных?"
,,,Сфера специфичная - детекция бактерий определённых
,,Сфера специфичная - детекция бактерий определённых,"Segment Anything. С нейросетью, но обучать не надо. Дальше уже можно для ""определеных"" - эвристиками"
,,,"Спасибо, посмотрю"
,,,"если бактерии занимают всего несколько пикселей, то можно погуглить по термину low-level vision. Тут нужен неглубокий детектор объектов (чтобы было мало слоев)"
,,"если бактерии занимают всего несколько пикселей, то можно погуглить по термину low-level vision. Тут нужен неглубокий детектор объектов (чтобы было мало слоев)","Да, пикселей мало и ещё проблема в том, что все бактерии очень похожи, и нужно детектить ту, которая двигается определённым образом"
,,,спасибо)
,,спасибо),То есть для детекции нужно несколько кадров?
,,,"Всем привет!
Понадобилось оптимизировать yolov4-tiny-3l. 
Кто-то делал такой финт ушами: Darknet —> ONNX —-> OpenCV DNN Inference?"
,,"Всем привет!
Понадобилось оптимизировать yolov4-tiny-3l. 
Кто-то делал такой финт ушами: Darknet —> ONNX —-> OpenCV DNN Inference?",Зачем тут onnx? OpenCV же умеет darknet
,"Всем привет!
Понадобилось оптимизировать yolov4-tiny-3l. 
Кто-то делал такой финт ушами: Darknet —> ONNX —-> OpenCV DNN Inference?",Зачем тут onnx? OpenCV же умеет darknet,"Да
На тот момент думал что при конвертации в onnx граф оптимизируется, заблуждаются"
"Всем привет!
Понадобилось оптимизировать yolov4-tiny-3l. 
Кто-то делал такой финт ушами: Darknet —> ONNX —-> OpenCV DNN Inference?",Зачем тут onnx? OpenCV же умеет darknet,"Да
На тот момент думал что при конвертации в onnx граф оптимизируется, заблуждаются","Там же есть onnx-simplifier. он оптимизирует, насколько мне известно
Правда до конца непонятно, какого рода оптимизация вам нужна (для какого типа устройств)"
Зачем тут onnx? OpenCV же умеет darknet,"Да
На тот момент думал что при конвертации в onnx граф оптимизируется, заблуждаются","Там же есть onnx-simplifier. он оптимизирует, насколько мне известно
Правда до конца непонятно, какого рода оптимизация вам нужна (для какого типа устройств)",Должно работать только на opencv
,,,Можно попробовать взять предобученную модель для трекинга и классифицировать бактерии по траектории
,,Можно попробовать взять предобученную модель для трекинга и классифицировать бактерии по траектории,"Чуваки, соблюдайте правила сообщества"
,,,"Всем привет, сейчас начал решать задачу ocr. Хочется распознавать английский и русский текст плюс цифры . 

Вопрос, что обычно предсказывают.
Буквы или некоторые токены? Как предсказывают на несколько языков сразу?

Хотел начать с синтетики. Но вот если генерировать английскую A , она будет такой же как и русская. То есть визуально одинаково выглядит.😅

Скорее всего это очень просто решается, буду рад совету"
,,"Всем привет, сейчас начал решать задачу ocr. Хочется распознавать английский и русский текст плюс цифры . 

Вопрос, что обычно предсказывают.
Буквы или некоторые токены? Как предсказывают на несколько языков сразу?

Хотел начать с синтетики. Но вот если генерировать английскую A , она будет такой же как и русская. То есть визуально одинаково выглядит.😅

Скорее всего это очень просто решается, буду рад совету","привет :)
обозначь цели, а то так не очень понятно. Выше правильно написали, если английская A выглядит как русская А, то с точки зрения распознавания какая разница ?"
,"Всем привет, сейчас начал решать задачу ocr. Хочется распознавать английский и русский текст плюс цифры . 

Вопрос, что обычно предсказывают.
Буквы или некоторые токены? Как предсказывают на несколько языков сразу?

Хотел начать с синтетики. Но вот если генерировать английскую A , она будет такой же как и русская. То есть визуально одинаково выглядит.😅

Скорее всего это очень просто решается, буду рад совету","привет :)
обозначь цели, а то так не очень понятно. Выше правильно написали, если английская A выглядит как русская А, то с точки зрения распознавания какая разница ?","Да, по сути разницы нет 

Просто меня смущает, что одному входу может соответствовать два класса))"
"Всем привет, сейчас начал решать задачу ocr. Хочется распознавать английский и русский текст плюс цифры . 

Вопрос, что обычно предсказывают.
Буквы или некоторые токены? Как предсказывают на несколько языков сразу?

Хотел начать с синтетики. Но вот если генерировать английскую A , она будет такой же как и русская. То есть визуально одинаково выглядит.😅

Скорее всего это очень просто решается, буду рад совету","привет :)
обозначь цели, а то так не очень понятно. Выше правильно написали, если английская A выглядит как русская А, то с точки зрения распознавания какая разница ?","Да, по сути разницы нет 

Просто меня смущает, что одному входу может соответствовать два класса))","Хорошо обученная crnn будет различать одинаковые по написанию буквы в зависимости от контекста 

https://arxiv.org/abs/1805.09441

Если смысл символов неважен - можно и на уникальных учить"
"привет :)
обозначь цели, а то так не очень понятно. Выше правильно написали, если английская A выглядит как русская А, то с точки зрения распознавания какая разница ?","Да, по сути разницы нет 

Просто меня смущает, что одному входу может соответствовать два класса))","Хорошо обученная crnn будет различать одинаковые по написанию буквы в зависимости от контекста 

https://arxiv.org/abs/1805.09441

Если смысл символов неважен - можно и на уникальных учить","Просто интересно как с этим работают, так сам в первый раз)

Для распознавания текста после детекции. (Картинка - таргет)
Вот думаю взять dinov2 для извлечения признаков, а затем с помощью decoder как в DETR предсказывать буквы. Просто cross entropy.

Заведется?)"
"Да, по сути разницы нет 

Просто меня смущает, что одному входу может соответствовать два класса))","Хорошо обученная crnn будет различать одинаковые по написанию буквы в зависимости от контекста 

https://arxiv.org/abs/1805.09441

Если смысл символов неважен - можно и на уникальных учить","Просто интересно как с этим работают, так сам в первый раз)

Для распознавания текста после детекции. (Картинка - таргет)
Вот думаю взять dinov2 для извлечения признаков, а затем с помощью decoder как в DETR предсказывать буквы. Просто cross entropy.

Заведется?)","Я бы порекомендовал рассмотреть стэк из детекции и crnn модели для начала, однако, надо учесть плотность текста, количество сущностей и т.п.

https://habr.com/ru/amp/publications/720614/

Для генерации можешь попробовать https://github.com/Belval/TextRecognitionDataGenerator

https://github.com/clovaai/synthtiger

Из личного опыта отмечу, что модели распознавания быстро переобучаются без хорошей аугментации, поэтому советую использовать сложные генераторы (две ссылки выше)"
,,,"В принципе есть отдельная задача в NLP, language detection, решения от простых до сложных, но и простые работают

Так что я бы в сторону токенов смотрел бы. Человек когда читает, ему неважно из какой раскладки А"
,,,"Всем привет. Недавно заинтересовал trading, можете подсказать куда развиваться в этой области от классического ML и DL?"
,,"Всем привет. Недавно заинтересовал trading, можете подсказать куда развиваться в этой области от классического ML и DL?",В личку напишите - обсудим
,"Всем привет. Недавно заинтересовал trading, можете подсказать куда развиваться в этой области от классического ML и DL?",В личку напишите - обсудим,"потенциально опасный ответ, у меня примерно тот же вопрос - тоже можно в личку написать?"
"Всем привет. Недавно заинтересовал trading, можете подсказать куда развиваться в этой области от классического ML и DL?",В личку напишите - обсудим,"потенциально опасный ответ, у меня примерно тот же вопрос - тоже можно в личку написать?",you welcome
,,,"Я все больше слышу в последнее время что люди рисерчат применение NLP в трейдинге. И вот думаю, какой потенциал этого в контексте high frequency..

Кто что читал/слышал про применение NLP в hft на практике? И круто если есть пример конкретный где и как"
,,"Я все больше слышу в последнее время что люди рисерчат применение NLP в трейдинге. И вот думаю, какой потенциал этого в контексте high frequency..

Кто что читал/слышал про применение NLP в hft на практике? И круто если есть пример конкретный где и как","https://arxiv.org/pdf/2212.01807.pdf

Мнения?)"
,,,"Либо вообще в трейдинге, не обязательно hft 😁 любой материал интересен!"
,,"Либо вообще в трейдинге, не обязательно hft 😁 любой материал интересен!","""Вообще в трейдинге"" как раз много материалов, bloombergGPT тот же) Даже тут в чате обсуждали было дело"
,"Либо вообще в трейдинге, не обязательно hft 😁 любой материал интересен!","""Вообще в трейдинге"" как раз много материалов, bloombergGPT тот же) Даже тут в чате обсуждали было дело","Ну прям классический нлп, типа новоости, жпт и все такое я знаю) подумала,  что вы именно о подходах нлп конкретно к данным в трейдинге)"
"Либо вообще в трейдинге, не обязательно hft 😁 любой материал интересен!","""Вообще в трейдинге"" как раз много материалов, bloombergGPT тот же) Даже тут в чате обсуждали было дело","Ну прям классический нлп, типа новоости, жпт и все такое я знаю) подумала,  что вы именно о подходах нлп конкретно к данным в трейдинге)",Откровенно говоря мне тоже больше интересно применение поверх трейдинговых данных
"""Вообще в трейдинге"" как раз много материалов, bloombergGPT тот же) Даже тут в чате обсуждали было дело","Ну прям классический нлп, типа новоости, жпт и все такое я знаю) подумала,  что вы именно о подходах нлп конкретно к данным в трейдинге)",Откровенно говоря мне тоже больше интересно применение поверх трейдинговых данных,"ну я применяю какой-то 5y-ago (всякие атеншены и проч) на ивент уровне данных, работает неплохо в моей парадигме, особенно для развивающихся рынков"
,,,подходы из NLP или буквально NLP?
,,подходы из NLP или буквально NLP?,Подходы тоже интересно
,,,"кажется что именно в hft у nlp не может быть никакого применения, просто из за скорости"
,,"кажется что именно в hft у nlp не может быть никакого применения, просто из за скорости","+ может конечно как категориальный признак режима, но не думаю, что это может быть сильно важным чем-то"
,"кажется что именно в hft у nlp не может быть никакого применения, просто из за скорости","+ может конечно как категориальный признак режима, но не думаю, что это может быть сильно важным чем-то","подразумеваю, что оно не меняется в течение дня/часа/минуты (время реализации выше времени подсчета)"
"кажется что именно в hft у nlp не может быть никакого применения, просто из за скорости","+ может конечно как категориальный признак режима, но не думаю, что это может быть сильно важным чем-то","подразумеваю, что оно не меняется в течение дня/часа/минуты (время реализации выше времени подсчета)","аа, вот теперь понял, интересная мысль"
,,,а у кого то из чата получилось посмотреть?
,,а у кого то из чата получилось посмотреть?,"тыкал его, выглядит как просто прикольный плагин  для чатгпт"
,а у кого то из чата получилось посмотреть?,"тыкал его, выглядит как просто прикольный плагин  для чатгпт",плагин который транслирует в блумбовый язык запросов и имеет знание как там все называется
,,,"глобально подходы работают, какие именно и с какими танцами — не скажу)"
,,"глобально подходы работают, какие именно и с какими танцами — не скажу)",Только хотел попросить рассказать поподробнее)
,,,"Слушай, ""какие именно и с какими танцами"" и не думал просить"
,,,"Но вот интересно, какие методы именно nlp-специфичные могут быть полезными"
,,"Но вот интересно, какие методы именно nlp-специфичные могут быть полезными","Хз, классик нор к сигнал процесс Синг - ну хз"
,,,"так а что такое NLP-специфичные, представь каждый бакет (трейд, филл, минута) как токен, и подходы ставим, вопрос в том что тут signal 2 noice ration"
,,"так а что такое NLP-специфичные, представь каждый бакет (трейд, филл, минута) как токен, и подходы ставим, вопрос в том что тут signal 2 noice ration",Звучит как анекдот)
,,,"необычный, скажем так"
,,"необычный, скажем так","Есть методы всякие в ml, которые в nlp применяют, но также применяют и в других местах

Например взять какой-нибудь subsampling или наоборот augmentation, когда датасет собирают для оценки тональности текста
Эти механики общие, и в трейдинге применяются
Но с другой стороны, я лично никогда глубоко nlp не изучал, и интересно что более часто именно в этой сфере применяется, но могло бы работать и в трейдинге"
,,,Раз уж про nlp - кто-то пробовал скармливать рыночные данные в трансформер?
,,Раз уж про nlp - кто-то пробовал скармливать рыночные данные в трансформер?,"Сделать можно, смысле мало"
,,,у нас более значимая проблема
,,у нас более значимая проблема,equilibrium propagation
,,,идеи начали кончаться
,,идеи начали кончаться,Тогда самое время херакнуть llm на hft данных:))) только пожирнее модель конечно:)))
,,,В целом language modeling и nlp не сильно пересекается с signal processing
,,В целом language modeling и nlp не сильно пересекается с signal processing,"Signal processing тоже не сильно пересекается с маркет дата (вернее исторически так сложилось, что подошли с этой стороны, но дорожки уже давно разошлись)"
,В целом language modeling и nlp не сильно пересекается с signal processing,"Signal processing тоже не сильно пересекается с маркет дата (вернее исторически так сложилось, что подошли с этой стороны, но дорожки уже давно разошлись)",да ладно. Все MA - это фнч фильтры. Качество этих фильтров - ну это уже второй вопрос
В целом language modeling и nlp не сильно пересекается с signal processing,"Signal processing тоже не сильно пересекается с маркет дата (вернее исторически так сложилось, что подошли с этой стороны, но дорожки уже давно разошлись)",да ладно. Все MA - это фнч фильтры. Качество этих фильтров - ну это уже второй вопрос,Фнч?
,,,"Нашли админа ебаных идей для ресерча, слава богу"
,,"Нашли админа ебаных идей для ресерча, слава богу","правда много пишет,выдохнется скоро"
,,,(соре я tupoy ds ваще не шарю за квантовые движения)
,,(соре я tupoy ds ваще не шарю за квантовые движения),Ты сейчас про разметку или про что ?
,,,"Сетка не отличит А английскую от А русской, если не будет каких-то различий в том, как они выглядят"
,,"Сетка не отличит А английскую от А русской, если не будет каких-то различий в том, как они выглядят","кхм... ну я бы поспорил. например если есть контекст, в рамках которого идет распознавание. в таком случае в слове ZAZ может распознаться латинская, а в слове ГАГ - русская :)"
,,,а как сейчас?
,,а как сейчас?,"Чисто методами обработки сигнала сыт не будешь, да и специфика применения очевидно сильно отличается от электроники."
,,,новая мемофабрика
,,новая мемофабрика,скретч язык 💀💀💀
,новая мемофабрика,скретч язык 💀💀💀,😀
,,,ну а какие?
,,ну а какие?,А можно расшифровку?
,,,фильтры нижних частот
,,фильтры нижних частот,"А есть фильтры, которые без лага низкие частоты фильтруют?"
,фильтры нижних частот,"А есть фильтры, которые без лага низкие частоты фильтруют?",они фильтруют высокие. Низкие-то зачем? Там вся информация
,,,лаг нельзя обойти т.к. природу нельзя обмануть - часть информации из сигнала удаляется. Но вокруг этого все танцы с бубнами и происходят
,,,"Всем привет, тут резюмешка, пытаюсь пробиться на intern/junior CV/ML engineer, буду рад фидбеку)"
,,"Всем привет, тут резюмешка, пытаюсь пробиться на intern/junior CV/ML engineer, буду рад фидбеку)","Лучше описать не просто задачу и что делала команда, а какая была роль именно у вас
Исходя из резюме непонятно, они делали, а вы рядом стояли, или вы делали, а они рядом стояли"
,"Всем привет, тут резюмешка, пытаюсь пробиться на intern/junior CV/ML engineer, буду рад фидбеку)","Лучше описать не просто задачу и что делала команда, а какая была роль именно у вас
Исходя из резюме непонятно, они делали, а вы рядом стояли, или вы делали, а они рядом стояли","Понял, спасибо"
,,,Стоит уложить все резюме в одну страничку
,,Стоит уложить все резюме в одну страничку,Ну это бывает очень тяжело...
,Стоит уложить все резюме в одну страничку,Ну это бывает очень тяжело...,Можно же шрифт уменьшить...
,,,"зависит от требований и ожиданий, личного минимума, бюджета и т.п. Мы на Бали, но планируем скоро уехать, минусы плавно перевешивают плюсы, о многих минусах не говорят (но это по всей ЮВ Азии, если блоги и чаты почитать, особенно комменты). Планируем посмотреть тай и вьетнам, но во вьетнаме новая визовая политика начнет действовать с 15 августа только. На Бали одним из плюсов была возможность заранее онлайн оформить 211 визу на 60 дней и потом продлевать ее еще 2 раза по 60 дней"
,,"зависит от требований и ожиданий, личного минимума, бюджета и т.п. Мы на Бали, но планируем скоро уехать, минусы плавно перевешивают плюсы, о многих минусах не говорят (но это по всей ЮВ Азии, если блоги и чаты почитать, особенно комменты). Планируем посмотреть тай и вьетнам, но во вьетнаме новая визовая политика начнет действовать с 15 августа только. На Бали одним из плюсов была возможность заранее онлайн оформить 211 визу на 60 дней и потом продлевать ее еще 2 раза по 60 дней","> На Бали одним из плюсов была возможность заранее онлайн оформить 211 визу на 60 дней и потом продлевать ее еще 2 раза по 60 дней

Сейчас такой возможности нет? Я думал, отменили только возможность оншор-продления спустя полгода"
,"зависит от требований и ожиданий, личного минимума, бюджета и т.п. Мы на Бали, но планируем скоро уехать, минусы плавно перевешивают плюсы, о многих минусах не говорят (но это по всей ЮВ Азии, если блоги и чаты почитать, особенно комменты). Планируем посмотреть тай и вьетнам, но во вьетнаме новая визовая политика начнет действовать с 15 августа только. На Бали одним из плюсов была возможность заранее онлайн оформить 211 визу на 60 дней и потом продлевать ее еще 2 раза по 60 дней","> На Бали одним из плюсов была возможность заранее онлайн оформить 211 визу на 60 дней и потом продлевать ее еще 2 раза по 60 дней

Сейчас такой возможности нет? Я думал, отменили только возможность оншор-продления спустя полгода","такая есть, неправильно написал. Имел в виду, что такая возможность была на момент принятия решения о поездке. Сейчас офшор 211 все так же оформляют, а вот оншор 211 можно только продлевать ранее выданные, новые больше не оформить, только визаран"
,,,"сеньоры, утра доброго (у кого утро). 
Хотел бы посоветоваться про mlops архитектуру на новом месте работы - насколько нужна, в контексте стоящих задач. Но лучше в личку.
И если кто-то может посоветовать менторские программы какие-то, было бы круто."
,,,"Хай.
Хочу посоветоваться. Задача: распознавание дефектов на продукции. 
Снимки по 20 Мегапискелей, зело тяжелые. И их много. 
Вопрос: как быть с разметкой(много размечать,  есть пара идей, но может что-то автоматическое уже придумалось в мире).
и как вообще работать с такими тяжелыми данными. Типа датасет на сотню гигабайт это норма. Ходить за таким на сервер безумие. Наверняка есть решения. Кроме как в папке проекта все держать."
,,"Хай.
Хочу посоветоваться. Задача: распознавание дефектов на продукции. 
Снимки по 20 Мегапискелей, зело тяжелые. И их много. 
Вопрос: как быть с разметкой(много размечать,  есть пара идей, но может что-то автоматическое уже придумалось в мире).
и как вообще работать с такими тяжелыми данными. Типа датасет на сотню гигабайт это норма. Ходить за таким на сервер безумие. Наверняка есть решения. Кроме как в папке проекта все держать.",Звучит так как буд-то это должно помочь. https://github.com/amazon-science/patchcore-inspection Там просто нужно по папкам распихать снимки с разными дефектами и отдельно без дефектов. Модель сама научиться сегментировать дефекты
,"Хай.
Хочу посоветоваться. Задача: распознавание дефектов на продукции. 
Снимки по 20 Мегапискелей, зело тяжелые. И их много. 
Вопрос: как быть с разметкой(много размечать,  есть пара идей, но может что-то автоматическое уже придумалось в мире).
и как вообще работать с такими тяжелыми данными. Типа датасет на сотню гигабайт это норма. Ходить за таким на сервер безумие. Наверняка есть решения. Кроме как в папке проекта все держать.",Звучит так как буд-то это должно помочь. https://github.com/amazon-science/patchcore-inspection Там просто нужно по папкам распихать снимки с разными дефектами и отдельно без дефектов. Модель сама научиться сегментировать дефекты,"А вот не уверен. 
Специфика и всё такое
Но попробую."
,,,"Идеи semi-supervised подход, и попробовать SAM заюзать, посмотреть что вернет"
,,,"Sam точно стоит попробовать, а пересохранить со сжатием не вариант?"
,,"Sam точно стоит попробовать, а пересохранить со сжатием не вариант?",не все дефекты видно
,,,"Ребят, может кто-то проходил курсы по CV от DeepSchool, посоветуйте, стоит ли оно своих денег для джуна?"
,,"Ребят, может кто-то проходил курсы по CV от DeepSchool, посоветуйте, стоит ли оно своих денег для джуна?","У них вроде не для джунов курс (хотя джун джуну рознь). Но, честно говоря, рекомендовал бы скорее посты в их тг канале изучать - там гораздо больше полезной информации."
,,,"но вообще да, сжимать то я буду. 
Но все равно там много будет"
,,"но вообще да, сжимать то я буду. 
Но все равно там много будет","Всем привет! Подскажите, пожалуйста, есть ли кому известные датасеты для LLM, иллюстрирующие spatial comprehension & reasoning? Чтобы научить LLM расставлять объекты семантически логично (чашка на столе) и корректно по координатам, форме и размеру объектов, без пересечений между твердыми телами (чашка не застряла в столе).
Или может есть prompt-fu на эту тему какой."
,,,"Всем привет!

Подскажите, пожалуйста, где взять ""самые качественные"" эмбеддинги для слов?

Желательно, чтобы модель в Colab / Kaggle помещалась"
,,"Всем привет!

Подскажите, пожалуйста, где взять ""самые качественные"" эмбеддинги для слов?

Желательно, чтобы модель в Colab / Kaggle помещалась","+

где вообще можно взять готовые эмбеддинги на русском языке?"
,"Всем привет!

Подскажите, пожалуйста, где взять ""самые качественные"" эмбеддинги для слов?

Желательно, чтобы модель в Colab / Kaggle помещалась","+

где вообще можно взять готовые эмбеддинги на русском языке?",navec например
,,,"Дефекты должны иметь характерные признаки - текстура, форма, аспекты... MobileSAM => контуры => эвристики => кандидаты (база для разметки)"
,,"Дефекты должны иметь характерные признаки - текстура, форма, аспекты... MobileSAM => контуры => эвристики => кандидаты (база для разметки)","эвристики?
и про ансамбль не очень понятно тоже - что зачем должно идти. Или yolo умеет классифицировать уже сегментированные куски?
Я просто с sam пока не работал.
По здравому смыслу он вернет огромный массив классов, из которых мне надо будет част выкинуть, часть разметить как верные."
,"Дефекты должны иметь характерные признаки - текстура, форма, аспекты... MobileSAM => контуры => эвристики => кандидаты (база для разметки)","эвристики?
и про ансамбль не очень понятно тоже - что зачем должно идти. Или yolo умеет классифицировать уже сегментированные куски?
Я просто с sam пока не работал.
По здравому смыслу он вернет огромный массив классов, из которых мне надо будет част выкинуть, часть разметить как верные.","MobileSAM даст (быстрее остального нынче) более-менее вменяемые контуры. Из них можно или базу составить, прогнав через эвристики, или кластеризовать например эмбеддингами реснета того же.

Там уже глазами отсматривать характерных представителей и/или аномалии.

Даже MobileSAM может на таких фотках работать долго, я бы патчил"
,,,именно для слов?а в контексте какого использования?
,,именно для слов?а в контексте какого использования?,"Да, для слов
Искать близость, проецировать на плоскость для визуализации"
,,,"Всем привет, ищу кто меня мог бы рефнуть в МТС на одну DL вакансию.🙃"
,,"Всем привет, ищу кто меня мог бы рефнуть в МТС на одну DL вакансию.🙃","Куала-Лумпур, наверное"
,"Всем привет, ищу кто меня мог бы рефнуть в МТС на одну DL вакансию.🙃","Куала-Лумпур, наверное","Ещё оншор потом можно было новую делать, а теперь отменили и обязательно вылетать раз в пол года"
,,,"Хм, кто-то видел пост этот?"
,,,"Всем привет!
Подскажите, пожалуйста, что почитать\посмотреть про ценообразование в сфере ритейла"
,,"Всем привет!
Подскажите, пожалуйста, что почитать\посмотреть про ценообразование в сфере ритейла",Ценообразование чего?
,"Всем привет!
Подскажите, пожалуйста, что почитать\посмотреть про ценообразование в сфере ритейла",Ценообразование чего?,"Желательно в продуктовой части, но можно и в других (хочу понять, что к чему)"
"Всем привет!
Подскажите, пожалуйста, что почитать\посмотреть про ценообразование в сфере ритейла",Ценообразование чего?,"Желательно в продуктовой части, но можно и в других (хочу понять, что к чему)",А как это относится к classic ml?
Ценообразование чего?,"Желательно в продуктовой части, но можно и в других (хочу понять, что к чему)",А как это относится к classic ml?,Оно не относится?
"Желательно в продуктовой части, но можно и в других (хочу понять, что к чему)",А как это относится к classic ml?,Оно не относится?,Лично я не понял реквест )
,,,"Ну я думал оно относится к классик мл, но если не так, подправьте :)"
,,"Ну я думал оно относится к классик мл, но если не так, подправьте :)","Субъективно: ценообразования история в основном про выстраивание правильного накопления данных, проведения корректных экспериментов и уже на основе всего этого - построение модели. А чем будет строится модель - классическим мл, нейронкой или экспертом - вопрос десятый."
,"Ну я думал оно относится к классик мл, но если не так, подправьте :)","Субъективно: ценообразования история в основном про выстраивание правильного накопления данных, проведения корректных экспериментов и уже на основе всего этого - построение модели. А чем будет строится модель - классическим мл, нейронкой или экспертом - вопрос десятый.","Понял, спасибо, но получается и тут можно спросить об этом :)"
"Ну я думал оно относится к классик мл, но если не так, подправьте :)","Субъективно: ценообразования история в основном про выстраивание правильного накопления данных, проведения корректных экспериментов и уже на основе всего этого - построение модели. А чем будет строится модель - классическим мл, нейронкой или экспертом - вопрос десятый.","Понял, спасибо, но получается и тут можно спросить об этом :)","А на счет почитать - погуглите, возможно от х5 какие-то дельные материалы где-нибудь публиковались. Опять же, субъективно: чужой опыт в лучшем случае даст общее направление. Большинство шишек все равно придется набивать самостоятельно."
"Субъективно: ценообразования история в основном про выстраивание правильного накопления данных, проведения корректных экспериментов и уже на основе всего этого - построение модели. А чем будет строится модель - классическим мл, нейронкой или экспертом - вопрос десятый.","Понял, спасибо, но получается и тут можно спросить об этом :)","А на счет почитать - погуглите, возможно от х5 какие-то дельные материалы где-нибудь публиковались. Опять же, субъективно: чужой опыт в лучшем случае даст общее направление. Большинство шишек все равно придется набивать самостоятельно.","Да понимаю, мне бы первоначальный вектор развития задать, спасибо!"
"Понял, спасибо, но получается и тут можно спросить об этом :)","А на счет почитать - погуглите, возможно от х5 какие-то дельные материалы где-нибудь публиковались. Опять же, субъективно: чужой опыт в лучшем случае даст общее направление. Большинство шишек все равно придется набивать самостоятельно.","Да понимаю, мне бы первоначальный вектор развития задать, спасибо!","Первоначальный вектор лежит в микроэкономике. Цена = деньги / количество, эластичность и тп"
"А на счет почитать - погуглите, возможно от х5 какие-то дельные материалы где-нибудь публиковались. Опять же, субъективно: чужой опыт в лучшем случае даст общее направление. Большинство шишек все равно придется набивать самостоятельно.","Да понимаю, мне бы первоначальный вектор развития задать, спасибо!","Первоначальный вектор лежит в микроэкономике. Цена = деньги / количество, эластичность и тп",Благодарю
,,,"Всем привет, оцените пожалуйста резюме. Пытаюсь в junior/middle data scientist (ml engineer) или data analyst (с упором на classic ml)"
,,"Всем привет, оцените пожалуйста резюме. Пытаюсь в junior/middle data scientist (ml engineer) или data analyst (с упором на classic ml)",fasttext мб?
,"Всем привет, оцените пожалуйста резюме. Пытаюсь в junior/middle data scientist (ml engineer) или data analyst (с упором на classic ml)",fasttext мб?,"Хотелось бы для русского и английского языков (отдельно, не в одном пространстве)

Думал просто из Берта взять, у кого качество получше"
"Всем привет, оцените пожалуйста резюме. Пытаюсь в junior/middle data scientist (ml engineer) или data analyst (с упором на classic ml)",fasttext мб?,"Хотелось бы для русского и английского языков (отдельно, не в одном пространстве)

Думал просто из Берта взять, у кого качество получше","ну тут есть дискуссия шо у берта не самые лучшие представления именно слов
хотя если брать не выход а чисто слой эмбединга - може быть
тема вроде старая и холиварная"
fasttext мб?,"Хотелось бы для русского и английского языков (отдельно, не в одном пространстве)

Думал просто из Берта взять, у кого качество получше","ну тут есть дискуссия шо у берта не самые лучшие представления именно слов
хотя если брать не выход а чисто слой эмбединга - може быть
тема вроде старая и холиварная","А, вот что за серия постов и за что удалили"
"Хотелось бы для русского и английского языков (отдельно, не в одном пространстве)

Думал просто из Берта взять, у кого качество получше","ну тут есть дискуссия шо у берта не самые лучшие представления именно слов
хотя если брать не выход а чисто слой эмбединга - може быть
тема вроде старая и холиварная","А, вот что за серия постов и за что удалили","Хотя...
Может быть это третий кусочек решения. Спасибо!"
,,,Разорились - это сколько за месяц вышло ? За сколько жилье снимали ?
,,Разорились - это сколько за месяц вышло ? За сколько жилье снимали ?,90 000₽ выходило за двушку с кухней далеко от моря по старому курсу у ребят
,Разорились - это сколько за месяц вышло ? За сколько жилье снимали ?,90 000₽ выходило за двушку с кухней далеко от моря по старому курсу у ребят,"Жёстко , на airbnb вроде подешевле аналогичные варианты есть 
Может в самый сезон в ноябре с китайцами приехали ? Но да, Пхукет точно не из дешёвых )"
Разорились - это сколько за месяц вышло ? За сколько жилье снимали ?,90 000₽ выходило за двушку с кухней далеко от моря по старому курсу у ребят,"Жёстко , на airbnb вроде подешевле аналогичные варианты есть 
Может в самый сезон в ноябре с китайцами приехали ? Но да, Пхукет точно не из дешёвых )",Январь февраль были
,,,"Мы жили в Хуа Хине, однушку снимали за 14к бат, потом зимой в сезон находили такую же минимум за 20к. Отец снимает двушку за 25к бат, тоже ещё в несезон взял. В Бангкоке тоже находили по таким же ценам.

Если нет прав или страшно ездить, острова лучше вообще не выбирать. Если нет прав, лучше Чианг Май, Бангкок, Хуа Хин, Паттайя.

Хуа Хин дешевле всего, думаю, потому что меньше всего. Учебную делали за 21-27к бат за год, на Пхукете и в Чианг Мае минимум был под 40, если правильно помню, а в Паттайе иммиграшка злая.

В Хуа Хине ещё один плюс — по сравнению с остальными местами в городе достаточно сухо (вещи все же сушатся и стены от влажности не гниют), а в сезон дождей город почти не затапливает.

Минус, пожалуй, в том, что коворкингов нет — их постоянно разгоняют. Зато классный спот для кайт-серфинга. Но сам город вообще не клубный, например.

Чианг Май хорош, если хочется прохладнее и горы, но нет моря и осенью смог из-за того, что жгут траву. На Лой-Кратонг в ноябре там очень красиво :)
Ещё одна неочевидная проблема Тая: после учебной визы тяжело визаранить. Допустим, вы хотите побыть там не 12 и не 24 месяца, а 14 или типа того. Не оформляйте тур визы в Малайзии… это нигде не написано, но турвизы должны выдавать только если за последний год вы в Тае провели меньше, чем 6 месяцев. Мы за последний год в Тае провели 12 месяцев (🤡), и поэтому возврат в страну нам стоил 2-х часов угроз депортацией, 10к бат с человека и ещё какой-то унизительной бумагой в духе «мы больше никогда не будем визаранить» за нашей подписью
Либо стоит пользоваться специальными компаниями с услугами визарана, потому что офицеры могут очень обижаться, если им не отстегнули грошей за этих фарангов…
Вообще, если есть вопросы по Таю — пишите. На какие-то специфические, наверное, не отвечу, но на общие смогу"
,,,Ваш хуахин в не сезон просто адское пекло
,,Ваш хуахин в не сезон просто адское пекло,"Да как и везде примерно. Что в Бкк +36 было, в Паттайе ещё жарче."
,,,"У всех этих сеток жестокое обломинго с виндсерфингом, только 😀"
,,,Тим лид на 2 курсе кнч мощно
,,Тим лид на 2 курсе кнч мощно,"Я был на первом🚬🚬🚬
Правда у меня в подчинении было только 3 стажёра"
,Тим лид на 2 курсе кнч мощно,"Я был на первом🚬🚬🚬
Правда у меня в подчинении было только 3 стажёра",Стажеры лягушки?
Тим лид на 2 курсе кнч мощно,"Я был на первом🚬🚬🚬
Правда у меня в подчинении было только 3 стажёра",Стажеры лягушки?,"Нет((
Они все были старше меня"
"Я был на первом🚬🚬🚬
Правда у меня в подчинении было только 3 стажёра",Стажеры лягушки?,"Нет((
Они все были старше меня",Старшие лягушки...
,,,"Это было в рамках команды проекта, а сами проекты в основном личные, не от компании где работаю) а так конечно понимаю что до реального тим лида еще очень далеко))"
,,,Да все равно круто
,,Да все равно круто,Но круто да согласен
,,,"Ребят, а кто не может делать модели делать внутри приложения и нужно отсылать на серв, есть какие-то приёмы для уменьшения трафика?"
,,"Ребят, а кто не может делать модели делать внутри приложения и нужно отсылать на серв, есть какие-то приёмы для уменьшения трафика?","уменьшить фпс?
ну т.е. посылать каждый н-ный кадр а не все"
,,,"Просто задумался, что в целом много трафика генерится и в целом это долго быть дорого"
,,"Просто задумался, что в целом много трафика генерится и в целом это долго быть дорого","Как вариант, если разговор про картинки, то ты их скорее всего сжимаешь перед подачей в сеть, можно сделать этот препроцессинг на устройстве и кол-во данных, передаваемых по сети, снизится"
,"Просто задумался, что в целом много трафика генерится и в целом это долго быть дорого","Как вариант, если разговор про картинки, то ты их скорее всего сжимаешь перед подачей в сеть, можно сделать этот препроцессинг на устройстве и кол-во данных, передаваемых по сети, снизится","максимально перенести предобработку на сторону клиента, ну и сжимать данные, да"
,,,"Всем привет, появился вопрос: есть две строчки текста с одинаковым содержимым
можем прогнать через crnn и получить две ctc матрицы
есть ли какой-то способ объединить предсказания, чем усреднять?"
,,"Всем привет, появился вопрос: есть две строчки текста с одинаковым содержимым
можем прогнать через crnn и получить две ctc матрицы
есть ли какой-то способ объединить предсказания, чем усреднять?","Ничо непонятно, но очень интересно.

Конкатенировать есть способ"
,"Всем привет, появился вопрос: есть две строчки текста с одинаковым содержимым
можем прогнать через crnn и получить две ctc матрицы
есть ли какой-то способ объединить предсказания, чем усреднять?","Ничо непонятно, но очень интересно.

Конкатенировать есть способ","Сам виноват, плохо сформулировал)
Цель: распознавать текст без ошибок
Исходные: есть две строчки с одинаковым содержимом но разным написанием/световыми условиями/чем угодно. Мы можем получить предсказания модели (crnn) на каждой картинке. Как мы можем декодировать два предсказания, чтобы минимизировать ошибки?"
"Всем привет, появился вопрос: есть две строчки текста с одинаковым содержимым
можем прогнать через crnn и получить две ctc матрицы
есть ли какой-то способ объединить предсказания, чем усреднять?","Ничо непонятно, но очень интересно.

Конкатенировать есть способ","Сам виноват, плохо сформулировал)
Цель: распознавать текст без ошибок
Исходные: есть две строчки с одинаковым содержимом но разным написанием/световыми условиями/чем угодно. Мы можем получить предсказания модели (crnn) на каждой картинке. Как мы можем декодировать два предсказания, чтобы минимизировать ошибки?",это tta для задачи ocr?
,,,"Подать в обучающий набор лучше всего
Если нет такой возможности, взвесить по confidence"
,,,традиционное в автоматике когда ?
,,традиционное в автоматике когда ?,"в целом естьЁ
https://github.com/seruva19/kubin"
,,,аспект ратио и 1024 радуют конечно
,,аспект ратио и 1024 радуют конечно,"правда вот в боте кривая цензура, и не пропускает безобидный промпт
придется локально запускать"
,,,а ну и вот это да цензура - ненужная
,,а ну и вот это да цензура - ненужная,"к сожалению, это хотелки Сбера, а на них оказывают давление всякие политики, которые недовольны генерациями на политические темы)
к счастью, всё можно запустить локально без цензуры)"
,,,какая то она молодая
,,какая то она молодая,еще один уи тащить лень
,какая то она молодая,еще один уи тащить лень,kek
,,,"родинка воспринята как ""малая Родина"", очевидно)"
,,"родинка воспринята как ""малая Родина"", очевидно)","Я бы родинку не развидел, а так красивоэ"
,,,"Выглядит так, как наконец что-то начало получаться)
Короче недурно"
,,"Выглядит так, как наконец что-то начало получаться)
Короче недурно","я верю что тут будут всякие sdxl и прочее обсуждать
обязательно.."
,,,Флаг это ползашквара - отражение космос конечно
,,Флаг это ползашквара - отражение космос конечно,судя по звездочкам там около сотни штатов)
,,,"эх, теперь смешных котеек не погенерить?(("
,,"эх, теперь смешных котеек не погенерить?((",а почему в 2.2 не погенерить их?)
,,,"веса кандинского 2.1 никуда не делись, можно на колабе накатить
прожженка в боте конечно зверская"
,,"веса кандинского 2.1 никуда не делись, можно на колабе накатить
прожженка в боте конечно зверская",кислотно чот всё
,"веса кандинского 2.1 никуда не делись, можно на колабе накатить
прожженка в боте конечно зверская",кислотно чот всё,если брать макс рахзрешение то становится ок
"веса кандинского 2.1 никуда не делись, можно на колабе накатить
прожженка в боте конечно зверская",кислотно чот всё,если брать макс рахзрешение то становится ок,Верхом на Котаносе
кислотно чот всё,если брать макс рахзрешение то становится ок,Верхом на Котаносе,"так что похоже на артефакты от неудобного разрешения
в боте сжимается картинка вниз если взять другое соотношение
для нарядности надо делать ровно наоборот
моделька обучена на 1024х1024
@ 
сделать в боте и на сайте новую фичу которая кастрирует до 1024х576"
,,,если в сд генерить 384х512 то любая моделька чувствует себя неуверенно
,,если в сд генерить 384х512 то любая моделька чувствует себя неуверенно,Я не очень вот это понял
,,,И потом inpaint?
,,И потом inpaint?,?
,,,В чем прикол 384*512 инферить
,,В чем прикол 384*512 инферить,"не, там у них размеровка минимально 1024х576 если 16:9
но рабочее разрешение же заявлено как 1024 по идее"
,В чем прикол 384*512 инферить,"не, там у них размеровка минимально 1024х576 если 16:9
но рабочее разрешение же заявлено как 1024 по идее",Ну fusionbrain кривой
В чем прикол 384*512 инферить,"не, там у них размеровка минимально 1024х576 если 16:9
но рабочее разрешение же заявлено как 1024 по идее",Ну fusionbrain кривой,в боте то же
"не, там у них размеровка минимально 1024х576 если 16:9
но рабочее разрешение же заявлено как 1024 по идее",Ну fusionbrain кривой,в боте то же,Апи одно и тоже
,,,"в статье пишут так
в общем я бурчу чисто на решения
на 1024х1024 все намного адекватнее выглядит в выдаче"
,,"в статье пишут так
в общем я бурчу чисто на решения
на 1024х1024 все намного адекватнее выглядит в выдаче","Вообще его лучше локально поднимать
Но он обжиристый"
,"в статье пишут так
в общем я бурчу чисто на решения
на 1024х1024 все намного адекватнее выглядит в выдаче","Вообще его лучше локально поднимать
Но он обжиристый","колаб лень поднимать
так-то потанцевал хороший
смешение картинок хорошо постарались"
"в статье пишут так
в общем я бурчу чисто на решения
на 1024х1024 все намного адекватнее выглядит в выдаче","Вообще его лучше локально поднимать
Но он обжиристый","колаб лень поднимать
так-то потанцевал хороший
смешение картинок хорошо постарались",Будет тред кандивский 2.2?
"Вообще его лучше локально поднимать
Но он обжиристый","колаб лень поднимать
так-то потанцевал хороший
смешение картинок хорошо постарались",Будет тред кандивский 2.2?,"Гигантское червеподобное существо, мимикрирующее под репу. Длина тела - около 15-ти метров. Выцвевшая фотография из секретных архивов спецслужб ссср. Реализм, настоящее фото

⛔ Запрос не соответствует правилам работы с ботом! ⛔

Ух нагнули ребят за некоторые генерации, чую"
,,,"гайз. кто с yolo от ultralytics работал.
Там есть способ подрубить обычный dataloader?
У меня пока мало снимков, хочу их поаугментировать, но не хочу все это заливать в отдельную папку. Идеально если батчами получится скармливать"
,,"гайз. кто с yolo от ultralytics работал.
Там есть способ подрубить обычный dataloader?
У меня пока мало снимков, хочу их поаугментировать, но не хочу все это заливать в отдельную папку. Идеально если батчами получится скармливать",Можешь модель юзать как обычный торч модуль и вокруг него любой рантайм строить
,,,У йоло есть неплохие встроенные аугментации
,,У йоло есть неплохие встроенные аугментации,"Йее кайф новый кандинский гораздо лучше не только в графике, но и в понимании что на белом фоне чет надо, я еще не тестил но кажется лучше вообще всех прочих моделек"
,У йоло есть неплохие встроенные аугментации,"Йее кайф новый кандинский гораздо лучше не только в графике, но и в понимании что на белом фоне чет надо, я еще не тестил но кажется лучше вообще всех прочих моделек",0_0
,,,"типа только веса брать, я правильно понял?"
,,"типа только веса брать, я правильно понял?",Torch nn module
,,,"ладно, разберусь.
спасибо)
да, я понял.
жизнь заиграла новыми красками"
,,"ладно, разберусь.
спасибо)
да, я понял.
жизнь заиграла новыми красками","Не, пережиг никуда не делся, а вот качество объектов намного лучше"
,"ладно, разберусь.
спасибо)
да, я понял.
жизнь заиграла новыми красками","Не, пережиг никуда не делся, а вот качество объектов намного лучше",извините
,,,"ага кринж отборный, вообщем он на простых каких-то запросах совершенно дичь выдает часто, видимо только обвешивать промптами"
,,"ага кринж отборный, вообщем он на простых каких-то запросах совершенно дичь выдает часто, видимо только обвешивать промптами",я напишу в канал про то почему sdxl sd2.1 обсосные и свяжу это с vicuna-wizard
,"ага кринж отборный, вообщем он на простых каких-то запросах совершенно дичь выдает часто, видимо только обвешивать промптами",я напишу в канал про то почему sdxl sd2.1 обсосные и свяжу это с vicuna-wizard,почему? датасет?
"ага кринж отборный, вообщем он на простых каких-то запросах совершенно дичь выдает часто, видимо только обвешивать промптами",я напишу в канал про то почему sdxl sd2.1 обсосные и свяжу это с vicuna-wizard,почему? датасет?,"Сложнее, но верно да"
я напишу в канал про то почему sdxl sd2.1 обсосные и свяжу это с vicuna-wizard,почему? датасет?,"Сложнее, но верно да",Ну по той же причине
,,,ток мне бы блять время найти
,,,они кстати обсосные по одним и тем же причинам
,,они кстати обсосные по одним и тем же причинам,Архитектура?
,они кстати обсосные по одним и тем же причинам,Архитектура?,Архитектура у всего +- одно и тоже
,,,что иронично
,,что иронично,Зато они умудрились сделать сдхл цензурной
,что иронично,Зато они умудрились сделать сдхл цензурной,Вообще хз зачем
что иронично,Зато они умудрились сделать сдхл цензурной,Вообще хз зачем,"ну вот в sdxl пишешь кот и есть два стула, либо выпадет арт/фото нормальное +/- 
либо какой-то кринж, среднего пока не видел"
,,,С ладно но они рил не понимают зачем юзажт sd
,,С ладно но они рил не понимают зачем юзажт sd,в котором из смыслов ? не понимают запрос пользователей ?
,С ладно но они рил не понимают зачем юзажт sd,в котором из смыслов ? не понимают запрос пользователей ?,потребности пользователей
С ладно но они рил не понимают зачем юзажт sd,в котором из смыслов ? не понимают запрос пользователей ?,потребности пользователей,нуу эээ да сложно делать бизнес в порно ))
в котором из смыслов ? не понимают запрос пользователей ?,потребности пользователей,нуу эээ да сложно делать бизнес в порно )),это довольно узкая прослойка пользователей как ни крути
,,,А кто кроме коадущих либертарианский болт анонов художникодихайнеров понимает?
,,А кто кроме коадущих либертарианский болт анонов художникодихайнеров понимает?,Не понял
,А кто кроме коадущих либертарианский болт анонов художникодихайнеров понимает?,Не понял,"Как инструмент за который не спросят это все классно
А как это внедрять не во фриланс?"
,,,Я так понял стабилити проделали большую работу по тому чтобы с них и их базы взятки были гладки
,,,Оч сложно доебаться до стабилити
,,Оч сложно доебаться до стабилити,Как только используешь их апи в бизнесе сразу начинается
,Оч сложно доебаться до стабилити,Как только используешь их апи в бизнесе сразу начинается,Ну никто не юзает их апи
Оч сложно доебаться до стабилити,Как только используешь их апи в бизнесе сразу начинается,Ну никто не юзает их апи,"В случае сдхл оно оди из самых адекватнх вариантов на рынке 
Поднимать локально непойми что п робами и ошибками это очевидно авантюра"
Как только используешь их апи в бизнесе сразу начинается,Ну никто не юзает их апи,"В случае сдхл оно оди из самых адекватнх вариантов на рынке 
Поднимать локально непойми что п робами и ошибками это очевидно авантюра","проблема, безусловно, в том что на рынке шаром покати и все рубят быстрое бабло на тех кто зависим от черных паттернов поиска сидов промптами"
,,,"Ну примерно как до фотошопа
За то что в Фотошопе лицо знаменитости к шлюхи приделали"
,,"Ну примерно как до фотошопа
За то что в Фотошопе лицо знаменитости к шлюхи приделали","С юр статусом генеративной копии тяжба еще не решилась
У фотошопов галочка в соглашении есть
Копирайт в этой сфзере не просто умер - не родился"
,"Ну примерно как до фотошопа
За то что в Фотошопе лицо знаменитости к шлюхи приделали","С юр статусом генеративной копии тяжба еще не решилась
У фотошопов галочка в соглашении есть
Копирайт в этой сфзере не просто умер - не родился",Ну типа вообще картиночных моделей
,,,Ну а зачем? Он не специализированный
,,Ну а зачем? Он не специализированный,"Для специализированного есть нормальный софт к которому опять же проще через плагин по апи с контролнетом приткнуть чем поднимать самим 
А неспециализированное для широкого спектра «чтоб было»"
,,,эээ
,,,ну типа просто сет
,,ну типа просто сет,"да но что он делает ...

селфи Илона Кандинским, дипфейки уже скоро реально будет не отличить,"
,ну типа просто сет,"да но что он делает ...

селфи Илона Кандинским, дипфейки уже скоро реально будет не отличить,",Это даже не дипфейк строго говоря
ну типа просто сет,"да но что он делает ...

селфи Илона Кандинским, дипфейки уже скоро реально будет не отличить,",Это даже не дипфейк строго говоря,поясни?
"да но что он делает ...

селфи Илона Кандинским, дипфейки уже скоро реально будет не отличить,",Это даже не дипфейк строго говоря,поясни?,Ну обычно вроде имеют ввиду именно фейс свап
,,,"Привет, может кто-нибудь вкратце рассказать как распознать норм ли рекрутер пишет или что-то нечисто?)"
,,"Привет, может кто-нибудь вкратце рассказать как распознать норм ли рекрутер пишет или что-то нечисто?)",На сайт компании зайдите
,,,О_о
,,,как понять норм ?
,,как понять норм ?,Он может быть только красивым отвечает)
,,,ну это просто нарицательное уже для всех нейронных фейков же
,,ну это просто нарицательное уже для всех нейронных фейков же,Соре что доебался
,,,Чо Канди не деплоете
,,Чо Канди не деплоете,"сделаем да, чуть позже, хочу еще гифки потрейнить лорой хз что выйдет"
,,,Он пизже
,,Он пизже,мы видимо разную литературу читаем я основном просто твитере и всякие линкединовские новости там все дипфейки
,,,Ну лучше temporal attention после декодера
,,Ну лучше temporal attention после декодера,ок спасибо гляну
,,,И на 8 кадров
,,,"Что по тюнам кстати? 
Я краем уха что-то слышал по «сделаю анимешный тюн на кандинского» но не помню где"
,,"Что по тюнам кстати? 
Я краем уха что-то слышал по «сделаю анимешный тюн на кандинского» но не помню где",Уже есть
,"Что по тюнам кстати? 
Я краем уха что-то слышал по «сделаю анимешный тюн на кандинского» но не помню где",Уже есть,"Я про резултаты

Я такто и на лору колаб видел"
"Что по тюнам кстати? 
Я краем уха что-то слышал по «сделаю анимешный тюн на кандинского» но не помню где",Уже есть,"Я про резултаты

Я такто и на лору колаб видел",Я ещё не тюнил
,,,"Код
Для полного тюна
Мб выложу dreamboth"
,,"Код
Для полного тюна
Мб выложу dreamboth",Впрочем не искал
,"Код
Для полного тюна
Мб выложу dreamboth",Впрочем не искал,Но прошлый Канди пиздато тюнился
"Код
Для полного тюна
Мб выложу dreamboth",Впрочем не искал,Но прошлый Канди пиздато тюнился,Покеж
,,,Выше по каналу трейн найдешь
,,,Лучше чем было на 2.1 😅
,,,"Результат генерации по запросу ""Айтишник в возрасте, в лодке, на фоне заката, думает о своей жизни, эстетика СССР"""
,,"Результат генерации по запросу ""Айтишник в возрасте, в лодке, на фоне заката, думает о своей жизни, эстетика СССР""",Ну я
,,,"То есть оно не дробя запомнило картинку целиком выходит?
Очень интересный результат, наводит на мысли."
,,"То есть оно не дробя запомнило картинку целиком выходит?
Очень интересный результат, наводит на мысли.","Ну это же очевидный фейк))
Просто кропнуто из видео
Перешли из бота такой же результат)"
,,,"Лайк, мне нравится"
,,,Кто-нибудь использовал MMM(media mix modelling) модели в работе и может поделиться опытом?
,,Кто-нибудь использовал MMM(media mix modelling) модели в работе и может поделиться опытом?,Я раньше делал. Но уже довольно давно.
,,,Yet another ml for beginners course.
,,Yet another ml for beginners course.,Ic
,Yet another ml for beginners course.,Ic,"Коллеги привет. Подскажите пожалуста, какие сейчас решения есть для speech-2-text с поддержкой деаризации? Как работает whisper с русским языком и несколькими спикерами?
Владислав спасибо, пошёл тестить)"
,,,"Ладонь повернута? Все по тз, хозяин 😀"
,,"Ладонь повернута? Все по тз, хозяин 😀","Ребзя, не получается сгенерить ""золотые руки которые растут из задницы"" . Почему так?
Такое ощущение что это невозможная задача, как с кентавром"
,"Ладонь повернута? Все по тз, хозяин 😀","Ребзя, не получается сгенерить ""золотые руки которые растут из задницы"" . Почему так?
Такое ощущение что это невозможная задача, как с кентавром",может селфи сделать?
,,,"Всем привет! Вопрос возможно немного не по теме, но мб кто-нибудь учится / учился в онлайн магистратуре ИТМО ""Искусственный интеллект"" или в целом в магистратуре ИТМО. Хотел бы узнать про обучение более подробно, Заранее спасибо)"
,,"Всем привет! Вопрос возможно немного не по теме, но мб кто-нибудь учится / учился в онлайн магистратуре ИТМО ""Искусственный интеллект"" или в целом в магистратуре ИТМО. Хотел бы узнать про обучение более подробно, Заранее спасибо)","Учусь, можешь в лс написать ;)"
,,,"Заранее извините за глупый вопрос, я просто первый раз в жизни решил попробовать сгенерировать что-нибудь, но я правильно понимаю, что она не умеет писать текст на картинке? Я пишу запрос типа ""такой-то такой-то логотип с надписью ""ШАХМАТНЫЙ КРУЖОК"""", и получаю иероглифы вместо текста."
,,"Заранее извините за глупый вопрос, я просто первый раз в жизни решил попробовать сгенерировать что-нибудь, но я правильно понимаю, что она не умеет писать текст на картинке? Я пишу запрос типа ""такой-то такой-то логотип с надписью ""ШАХМАТНЫЙ КРУЖОК"""", и получаю иероглифы вместо текста.","у нас есть контролнет или image2image, выбери в меню одно из двух
и потом загрузи текст прикольным шрифтом написанный и попробуй написать примерно такой же текст, но так твой текст который ты загрузил превратится в логотип (возможно придется подбирать промпт)"
,,,"Да, Кандинский пока не умеет писать текст"
,,"Да, Кандинский пока не умеет писать текст","Ок, спасибо!"
,"Да, Кандинский пока не умеет писать текст","Ок, спасибо!",канди
"Да, Кандинский пока не умеет писать текст","Ок, спасибо!",канди,"Не одна модель не умеет, но начни с 

A logo of chess club, svg stylr
Ладно есть if но нахуй не упал никому"
,,,Ну дальше prompt engineering и полетели
,,Ну дальше prompt engineering и полетели,"напиши если будут проблемы, я бы использовал еще поменьше букв для логотопа это же слишком много кмк"
,Ну дальше prompt engineering и полетели,"напиши если будут проблемы, я бы использовал еще поменьше букв для логотопа это же слишком много кмк",а я то что
Ну дальше prompt engineering и полетели,"напиши если будут проблемы, я бы использовал еще поменьше букв для логотопа это же слишком много кмк",а я то что,
,,,Картинка у меня не загружена
,,,"Он нормальные лого в целом сгенерил, я уже штук 5 сохранил годных, просто с текстом интересовал вопрос)"
,,"Он нормальные лого в целом сгенерил, я уже штук 5 сохранил годных, просто с текстом интересовал вопрос)",Ну ручками в фш
,,,"Понятно, но лень) Не критично. А в чём проблема текста, раз уж заговорили?"
,,"Понятно, но лень) Не критично. А в чём проблема текста, раз уж заговорили?","Требует совсем уж тяжелой архитектурной эквилибристики 
Можно разместить текст через контролнет впрочем 
Попробуй кинуь надпись в стилизацию"
,,,Ммммм заглушка цензуры
,,Ммммм заглушка цензуры,Ну ты тоже пиши если проблемы
,Ммммм заглушка цензуры,Ну ты тоже пиши если проблемы,"Привет! Собираю бенчмарк для задачи детекции объектов. Изображения планирую брать из какого-то большого датасета, вроде LAION-5B. Но там фото доступны по URL.

- Если я буду распространять сами фотографии - это будет нарушением копирайта
- Если буду распространять их по URL - то есть шанс, что они будут удалены с сайтов, что сломает бенчмарк

Есть из этой ситуации выход? Если кто-то знает, посоветуйте пожалуйста юриста в сфере ML-датасетов, хочется проконсультироваться, не за бесплатно"
Ммммм заглушка цензуры,Ну ты тоже пиши если проблемы,"Привет! Собираю бенчмарк для задачи детекции объектов. Изображения планирую брать из какого-то большого датасета, вроде LAION-5B. Но там фото доступны по URL.

- Если я буду распространять сами фотографии - это будет нарушением копирайта
- Если буду распространять их по URL - то есть шанс, что они будут удалены с сайтов, что сломает бенчмарк

Есть из этой ситуации выход? Если кто-то знает, посоветуйте пожалуйста юриста в сфере ML-датасетов, хочется проконсультироваться, не за бесплатно",Да когда уже будет чятик по timeseries....
,,,"С месяц назад как у того ежика из сигнала против шума стрельнула очередная идея Грааля/демона Лапласа/универсального способа/etc))

Все базируется на идее, что для любых хотя бы минимально взаимно связанных серий, существует паттерн (heartbeat), продолжение которого по t как полинома от одного только t эту интерполяцию переводит в экстраполяцию в пространстве изначальных серий.

Есть кое-какие мат. намеки на существование, и недоделанный эксперимент на простых сетках, которые говорят скорее ""да, есть"", чем ""нет, такого нет""

Знаю некоторые серии в которых это теоретически могло бы быть полезно, но вдруг существуют железные доводы против, а я не в курсе 🙈"
,,"С месяц назад как у того ежика из сигнала против шума стрельнула очередная идея Грааля/демона Лапласа/универсального способа/etc))

Все базируется на идее, что для любых хотя бы минимально взаимно связанных серий, существует паттерн (heartbeat), продолжение которого по t как полинома от одного только t эту интерполяцию переводит в экстраполяцию в пространстве изначальных серий.

Есть кое-какие мат. намеки на существование, и недоделанный эксперимент на простых сетках, которые говорят скорее ""да, есть"", чем ""нет, такого нет""

Знаю некоторые серии в которых это теоретически могло бы быть полезно, но вдруг существуют железные доводы против, а я не в курсе 🙈","Могу быть суперпримитивен, но это не автокорреляция называется?"
,"С месяц назад как у того ежика из сигнала против шума стрельнула очередная идея Грааля/демона Лапласа/универсального способа/etc))

Все базируется на идее, что для любых хотя бы минимально взаимно связанных серий, существует паттерн (heartbeat), продолжение которого по t как полинома от одного только t эту интерполяцию переводит в экстраполяцию в пространстве изначальных серий.

Есть кое-какие мат. намеки на существование, и недоделанный эксперимент на простых сетках, которые говорят скорее ""да, есть"", чем ""нет, такого нет""

Знаю некоторые серии в которых это теоретически могло бы быть полезно, но вдруг существуют железные доводы против, а я не в курсе 🙈","Могу быть суперпримитивен, но это не автокорреляция называется?",Автокорреляция - это то что хотелось бы найти для произвольной системы
,,,"Может я что-то не так понял, но вот берём кусок натурального ряда от 1 до n, и функцию (-1)^t на нем, разве ж можно придумать хоть сколько адекватную экстраполяцию такого ряда полиномом?

В общем, я думаю, что-то подобное должно работать, только если один ряд представляет собой аналитическую или очень гладкую (имею в виду много раз непрерывно дифференцируемую функцию во всех точках) функцию от другого. Если это подразумевалось, то звучит прикольно

Upd, думаю, пример функции, который я привел, не очень хороший по некоторым причинам. Пусть лучше так, f(t) = 1, если t натуральное число, f(t) = 0, если нет."
,,"Может я что-то не так понял, но вот берём кусок натурального ряда от 1 до n, и функцию (-1)^t на нем, разве ж можно придумать хоть сколько адекватную экстраполяцию такого ряда полиномом?

В общем, я думаю, что-то подобное должно работать, только если один ряд представляет собой аналитическую или очень гладкую (имею в виду много раз непрерывно дифференцируемую функцию во всех точках) функцию от другого. Если это подразумевалось, то звучит прикольно

Upd, думаю, пример функции, который я привел, не очень хороший по некоторым причинам. Пусть лучше так, f(t) = 1, если t натуральное число, f(t) = 0, если нет.","Ну конечно речь про какие-то ""гладкие"" (в бытовом смысле, не в смысле бесконечно дифференцируемые) связанные другим другом (запутанные) функции.

В смысле даже речь про какие-то системы ОДУ"
,,,"За рулём.... Через час смогу ответить, не раньше :(
Идея в следующем. x = g(H(f(x)), H - полином от t, x - вектор от t

И H, такая что, двигаясь по t в ней, ее ""разворачивание"" экстраполирует
То есть эмебддинг многомерного timeseries в полином от t"
,,"За рулём.... Через час смогу ответить, не раньше :(
Идея в следующем. x = g(H(f(x)), H - полином от t, x - вектор от t

И H, такая что, двигаясь по t в ней, ее ""разворачивание"" экстраполирует
То есть эмебддинг многомерного timeseries в полином от t","Прикольно, что после Илона идет Игорь Бабушкин)))"
,"За рулём.... Через час смогу ответить, не раньше :(
Идея в следующем. x = g(H(f(x)), H - полином от t, x - вектор от t

И H, такая что, двигаясь по t в ней, ее ""разворачивание"" экстраполирует
То есть эмебддинг многомерного timeseries в полином от t","Прикольно, что после Илона идет Игорь Бабушкин)))","Я посмотрел как работает токенизация в роберте, выглядит очень плохо, как думаете, зайдет обучение какого-нибудь self-supervised подхода типо MLM на корпусе моего домена с обучением под это дело токенизатора? У меня мало опыта и пока не понятно, зайдет ли MLM учитывая, что у меня пары ключ : значение
Ну и вообще для кросс энкодера
Как я понимаю, там смысл в том, чтоб он атеншн кидал с одного предложения в другое, а если я буду склеивать рандомное предложение из датасета с атрибутами _one и одно из _two ему эта логика не нужна будет"
"За рулём.... Через час смогу ответить, не раньше :(
Идея в следующем. x = g(H(f(x)), H - полином от t, x - вектор от t

И H, такая что, двигаясь по t в ней, ее ""разворачивание"" экстраполирует
То есть эмебддинг многомерного timeseries в полином от t","Прикольно, что после Илона идет Игорь Бабушкин)))","Я посмотрел как работает токенизация в роберте, выглядит очень плохо, как думаете, зайдет обучение какого-нибудь self-supervised подхода типо MLM на корпусе моего домена с обучением под это дело токенизатора? У меня мало опыта и пока не понятно, зайдет ли MLM учитывая, что у меня пары ключ : значение
Ну и вообще для кросс энкодера
Как я понимаю, там смысл в том, чтоб он атеншн кидал с одного предложения в другое, а если я буду склеивать рандомное предложение из датасета с атрибутами _one и одно из _two ему эта логика не нужна будет","Нет, не ARIMA
То есть точнее, ts с рабочей по максимуму аримой, но завернутой в енкодер/декодер
Нутром чую, существуют достаточно приемлемые критерии для практики, когда эта штука существует"
,,,"Всем привет, ищу работу аналитиком/аналитиком-разработчиком, уровня 15 грейда яндекса. Буду рад советам по резюме"
,,"Всем привет, ищу работу аналитиком/аналитиком-разработчиком, уровня 15 грейда яндекса. Буду рад советам по резюме",А есть англ версия?
,"Всем привет, ищу работу аналитиком/аналитиком-разработчиком, уровня 15 грейда яндекса. Буду рад советам по резюме",А есть англ версия?,"Пока нет, но ее тоже сделаю, а для чего тебе английская версия?)"
"Всем привет, ищу работу аналитиком/аналитиком-разработчиком, уровня 15 грейда яндекса. Буду рад советам по резюме",А есть англ версия?,"Пока нет, но ее тоже сделаю, а для чего тебе английская версия?)",Тебе чтобы не ограничиваться Русс рынком
,,,Какой нужен уровень знания английского чтобы не ограничиваться рос рынком?
,,Какой нужен уровень знания английского чтобы не ограничиваться рос рынком?,"В CV пиши профешнл и иди на собесы. Если не хватит, тебе прямым текстом скажут.
Собственно уровень нужен такой чтобы собесы проходить"
,,,"Приветствую!
Существует ли что-то типа фреймворка для обучения нейронок для идентификации людей? 
Хотелось бы иметь готовый каркас для:
- загрузки, препроцессинга датасетов (детекции точек, выравнивания, аугментаций)
- описания моделек (но тут вроде ничего сложного от фреймворка не требуется, можно пофантазировать на счёт конфигов с описанием слоев, но как по мне - лучше красиво написанный код на PyTorch, чем дописывать парсер конфига, когда захочется добавить какой-нибудь мой-супер-пупер-крутой-слой)
- обучения (удобное конфигурирование параметров обучения, функций потерь, стратегий обучения, логирование в какой-нибудь ClearML...)
- тестирования (в соответствии с протоколом популярного бенчмарка, или с кучей всяких интересных метрик)
Нашел пока только FaceX-Zoo, но проект похоже мертв... Остальное, что попадалось: ""вот наша супер библиотека, берите пользуйтесь, точность - умопомрачительные 99% на LFW!"".
А если я хочу идентифицировать хомячков? Или создать свою супер-пупер нейронку?
Велосипеды уже написаны, захотелось пересесть на автобус)"
,,"Приветствую!
Существует ли что-то типа фреймворка для обучения нейронок для идентификации людей? 
Хотелось бы иметь готовый каркас для:
- загрузки, препроцессинга датасетов (детекции точек, выравнивания, аугментаций)
- описания моделек (но тут вроде ничего сложного от фреймворка не требуется, можно пофантазировать на счёт конфигов с описанием слоев, но как по мне - лучше красиво написанный код на PyTorch, чем дописывать парсер конфига, когда захочется добавить какой-нибудь мой-супер-пупер-крутой-слой)
- обучения (удобное конфигурирование параметров обучения, функций потерь, стратегий обучения, логирование в какой-нибудь ClearML...)
- тестирования (в соответствии с протоколом популярного бенчмарка, или с кучей всяких интересных метрик)
Нашел пока только FaceX-Zoo, но проект похоже мертв... Остальное, что попадалось: ""вот наша супер библиотека, берите пользуйтесь, точность - умопомрачительные 99% на LFW!"".
А если я хочу идентифицировать хомячков? Или создать свою супер-пупер нейронку?
Велосипеды уже написаны, захотелось пересесть на автобус)","Если захотите идентифицировать хомячков, то вам придётся писать всё с нуля :)
Одно из самых популярных решений по распознаванию лиц - https://github.com/deepinsight/insightface
Насколько я помню, там используются готовые модели детекции, определения антропометрических точек
То есть не факт, что то работает для людей, будет работать и для остальных существ
Например, выравнивание на основе лицевых ориентиров, очевидно, может повести себя иначе"
,"Приветствую!
Существует ли что-то типа фреймворка для обучения нейронок для идентификации людей? 
Хотелось бы иметь готовый каркас для:
- загрузки, препроцессинга датасетов (детекции точек, выравнивания, аугментаций)
- описания моделек (но тут вроде ничего сложного от фреймворка не требуется, можно пофантазировать на счёт конфигов с описанием слоев, но как по мне - лучше красиво написанный код на PyTorch, чем дописывать парсер конфига, когда захочется добавить какой-нибудь мой-супер-пупер-крутой-слой)
- обучения (удобное конфигурирование параметров обучения, функций потерь, стратегий обучения, логирование в какой-нибудь ClearML...)
- тестирования (в соответствии с протоколом популярного бенчмарка, или с кучей всяких интересных метрик)
Нашел пока только FaceX-Zoo, но проект похоже мертв... Остальное, что попадалось: ""вот наша супер библиотека, берите пользуйтесь, точность - умопомрачительные 99% на LFW!"".
А если я хочу идентифицировать хомячков? Или создать свою супер-пупер нейронку?
Велосипеды уже написаны, захотелось пересесть на автобус)","Если захотите идентифицировать хомячков, то вам придётся писать всё с нуля :)
Одно из самых популярных решений по распознаванию лиц - https://github.com/deepinsight/insightface
Насколько я помню, там используются готовые модели детекции, определения антропометрических точек
То есть не факт, что то работает для людей, будет работать и для остальных существ
Например, выравнивание на основе лицевых ориентиров, очевидно, может повести себя иначе","Не могу на 100% согласиться. В том же FaceX-Zoo под хомячков переписать придется только код, отвечающий за загрузку фоток моих хомячков, детекцию точек и выравнивание по этим точкам мордочек. Бэкбоны, трейнинглуп, лоссы можно взять готовые. И поскольку мы не знаем наверняка, какой бэкбон лучше всех справляется с хомячками (или может быть какого нам достаточно, чтобы не ""стрелять из трансформера по хомячкам""), удобно было бы, если их (и прочее из тех компонентов, которые не нуждаются в переписывании) можно было бы просто перебирать конфигом, а не прикручивать к собственному велосипеду одно за другим.

Insightface популярен, да. Но позволяет ли он двинуться дальше, чем готовой нейронкой пораспознавать людей? Каких-либо скриптов для обучения я у них не нашел. Может плохо искал. Но в том же FaceX-Zoo всё на поверхности, сразу понятно: вот готовые, вот если пообучать, вот ещё всякая ерунда по фану. Но когда автор где-то в скриптах прописывает пути до своей домашней директории и прям так льет в гитхаб, это настораживает. А когда заходишь в мёртвый ишью и пустынную историю коммитов - настораживаешься ещё больше."
"Приветствую!
Существует ли что-то типа фреймворка для обучения нейронок для идентификации людей? 
Хотелось бы иметь готовый каркас для:
- загрузки, препроцессинга датасетов (детекции точек, выравнивания, аугментаций)
- описания моделек (но тут вроде ничего сложного от фреймворка не требуется, можно пофантазировать на счёт конфигов с описанием слоев, но как по мне - лучше красиво написанный код на PyTorch, чем дописывать парсер конфига, когда захочется добавить какой-нибудь мой-супер-пупер-крутой-слой)
- обучения (удобное конфигурирование параметров обучения, функций потерь, стратегий обучения, логирование в какой-нибудь ClearML...)
- тестирования (в соответствии с протоколом популярного бенчмарка, или с кучей всяких интересных метрик)
Нашел пока только FaceX-Zoo, но проект похоже мертв... Остальное, что попадалось: ""вот наша супер библиотека, берите пользуйтесь, точность - умопомрачительные 99% на LFW!"".
А если я хочу идентифицировать хомячков? Или создать свою супер-пупер нейронку?
Велосипеды уже написаны, захотелось пересесть на автобус)","Если захотите идентифицировать хомячков, то вам придётся писать всё с нуля :)
Одно из самых популярных решений по распознаванию лиц - https://github.com/deepinsight/insightface
Насколько я помню, там используются готовые модели детекции, определения антропометрических точек
То есть не факт, что то работает для людей, будет работать и для остальных существ
Например, выравнивание на основе лицевых ориентиров, очевидно, может повести себя иначе","Не могу на 100% согласиться. В том же FaceX-Zoo под хомячков переписать придется только код, отвечающий за загрузку фоток моих хомячков, детекцию точек и выравнивание по этим точкам мордочек. Бэкбоны, трейнинглуп, лоссы можно взять готовые. И поскольку мы не знаем наверняка, какой бэкбон лучше всех справляется с хомячками (или может быть какого нам достаточно, чтобы не ""стрелять из трансформера по хомячкам""), удобно было бы, если их (и прочее из тех компонентов, которые не нуждаются в переписывании) можно было бы просто перебирать конфигом, а не прикручивать к собственному велосипеду одно за другим.

Insightface популярен, да. Но позволяет ли он двинуться дальше, чем готовой нейронкой пораспознавать людей? Каких-либо скриптов для обучения я у них не нашел. Может плохо искал. Но в том же FaceX-Zoo всё на поверхности, сразу понятно: вот готовые, вот если пообучать, вот ещё всякая ерунда по фану. Но когда автор где-то в скриптах прописывает пути до своей домашней директории и прям так льет в гитхаб, это настораживает. А когда заходишь в мёртвый ишью и пустынную историю коммитов - настораживаешься ещё больше.",Есть скрипты
,,,Будет нужно делать свой автобус под собственные задачи.
,,,"Добрый день! Если не жалко, поделитесь, пожалуйста, курсами с основами всяких квантовских дисциплин. (Возможно, вас прям какой-то курс зацепил/вы с него удачно стартанули) Конечно, все не изучить, но, может, есть база, которую стоит начать изучать уже на 1-2 курсе?) Буду очень благодарна за ваши советы🙏"
,,"Добрый день! Если не жалко, поделитесь, пожалуйста, курсами с основами всяких квантовских дисциплин. (Возможно, вас прям какой-то курс зацепил/вы с него удачно стартанули) Конечно, все не изучить, но, может, есть база, которую стоит начать изучать уже на 1-2 курсе?) Буду очень благодарна за ваши советы🙏","выше кидал ссылку на цмф, там сейчас идет отбор"
,"Добрый день! Если не жалко, поделитесь, пожалуйста, курсами с основами всяких квантовских дисциплин. (Возможно, вас прям какой-то курс зацепил/вы с него удачно стартанули) Конечно, все не изучить, но, может, есть база, которую стоит начать изучать уже на 1-2 курсе?) Буду очень благодарна за ваши советы🙏","выше кидал ссылку на цмф, там сейчас идет отбор","а кто-то учился на данном курсе? какое расписание примерное, с работой реально совмещать?"
"Добрый день! Если не жалко, поделитесь, пожалуйста, курсами с основами всяких квантовских дисциплин. (Возможно, вас прям какой-то курс зацепил/вы с него удачно стартанули) Конечно, все не изучить, но, может, есть база, которую стоит начать изучать уже на 1-2 курсе?) Буду очень благодарна за ваши советы🙏","выше кидал ссылку на цмф, там сейчас идет отбор","а кто-то учился на данном курсе? какое расписание примерное, с работой реально совмещать?","лекции смотришь в любое время, занятия по проектам по разному, но либо вечером, либо в выходные

потому что работают как ученики так и преподы"
,,,"Привет, подскажите пожалуста, что можно почитать/использовать готовое в беспилотных машинках (я имею в виду именно мини-машинки, для соревнования нужно), в машинке есть оперативка, видеокарта и всё такое, но всё равно, нужна какая-то не слишком большая сетка. И вообще, если кто такую задачу решал и готов поделиться опытом, напишите мне в лс, пожалуйста)"
,,"Привет, подскажите пожалуста, что можно почитать/использовать готовое в беспилотных машинках (я имею в виду именно мини-машинки, для соревнования нужно), в машинке есть оперативка, видеокарта и всё такое, но всё равно, нужна какая-то не слишком большая сетка. И вообще, если кто такую задачу решал и готов поделиться опытом, напишите мне в лс, пожалуйста)",Напоминаю про ссылку на соревнование)
,"Привет, подскажите пожалуста, что можно почитать/использовать готовое в беспилотных машинках (я имею в виду именно мини-машинки, для соревнования нужно), в машинке есть оперативка, видеокарта и всё такое, но всё равно, нужна какая-то не слишком большая сетка. И вообще, если кто такую задачу решал и готов поделиться опытом, напишите мне в лс, пожалуйста)",Напоминаю про ссылку на соревнование),Да я найти не могу
,,,"Всем привет
Ищу проекты под мой прфиль.
Могу и в бэкенд, и в задачи оптимизации.
Моё cv.
Пишите в лс, кому интересно поговорить."
,,,"а можно ссылку на соревнование, а то уж очень интересно стало"
,,"а можно ссылку на соревнование, а то уж очень интересно стало","Да, сейчас найду"
,,,А можно мне такую машинку тоже?
,,А можно мне такую машинку тоже?,^
,А можно мне такую машинку тоже?,^,"Благодарю, добрые люди"
А можно мне такую машинку тоже?,^,"Благодарю, добрые люди","Приветик школиё. Ну я директор департамента ml в одном стартапике в Барселоне. Всякое трасформерное CV, ну ещё в 3d, потому что медицина, а там CBCT. 15 человек в департаменте. Чё как?"
,,,а что сейчас есть интересного типа dtw для 1d pattern matching?
,,а что сейчас есть интересного типа dtw для 1d pattern matching?,Transformer
,,,"Добрый день, есть задача детекции клеток крови на видео. С классификацией разобрался, но чтобы их ""ловить"" нужна детекция. Пробовал YOLO v8n, слишком низкая производительность на CPU, один кадр несколько секунд, очень долго учиться, почитал про SSD, fastCNN, примерно тоже будет. Можно ли собрать что-нибудь ""на коленке"" в keras на полносвязной сети например? Для упрощения можно перейти в чёрно-белое изображение 640*480 (можно меньше), классов будет 2-10 (пока не определился). Может YOLO передискретизировать? Не знаю куда копать, короче надо чтобы на CPU было 10-20 к/с где-то. Спасибо, товарищи, заранее 👍"
,,"Добрый день, есть задача детекции клеток крови на видео. С классификацией разобрался, но чтобы их ""ловить"" нужна детекция. Пробовал YOLO v8n, слишком низкая производительность на CPU, один кадр несколько секунд, очень долго учиться, почитал про SSD, fastCNN, примерно тоже будет. Можно ли собрать что-нибудь ""на коленке"" в keras на полносвязной сети например? Для упрощения можно перейти в чёрно-белое изображение 640*480 (можно меньше), классов будет 2-10 (пока не определился). Может YOLO передискретизировать? Не знаю куда копать, короче надо чтобы на CPU было 10-20 к/с где-то. Спасибо, товарищи, заранее 👍","https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB
Вот эта штука довольно шустрая на cpu. По сути, это дефолтный SSD, но с легким бэкбоном и всякими оптимизациями. Думаю, на твоем проце даст тебе нужные фпсы, если использовать tiny версию бэкбона."
,"Добрый день, есть задача детекции клеток крови на видео. С классификацией разобрался, но чтобы их ""ловить"" нужна детекция. Пробовал YOLO v8n, слишком низкая производительность на CPU, один кадр несколько секунд, очень долго учиться, почитал про SSD, fastCNN, примерно тоже будет. Можно ли собрать что-нибудь ""на коленке"" в keras на полносвязной сети например? Для упрощения можно перейти в чёрно-белое изображение 640*480 (можно меньше), классов будет 2-10 (пока не определился). Может YOLO передискретизировать? Не знаю куда копать, короче надо чтобы на CPU было 10-20 к/с где-то. Спасибо, товарищи, заранее 👍","https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB
Вот эта штука довольно шустрая на cpu. По сути, это дефолтный SSD, но с легким бэкбоном и всякими оптимизациями. Думаю, на твоем проце даст тебе нужные фпсы, если использовать tiny версию бэкбона.",А с mAP у него как?
"Добрый день, есть задача детекции клеток крови на видео. С классификацией разобрался, но чтобы их ""ловить"" нужна детекция. Пробовал YOLO v8n, слишком низкая производительность на CPU, один кадр несколько секунд, очень долго учиться, почитал про SSD, fastCNN, примерно тоже будет. Можно ли собрать что-нибудь ""на коленке"" в keras на полносвязной сети например? Для упрощения можно перейти в чёрно-белое изображение 640*480 (можно меньше), классов будет 2-10 (пока не определился). Может YOLO передискретизировать? Не знаю куда копать, короче надо чтобы на CPU было 10-20 к/с где-то. Спасибо, товарищи, заранее 👍","https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB
Вот эта штука довольно шустрая на cpu. По сути, это дефолтный SSD, но с легким бэкбоном и всякими оптимизациями. Думаю, на твоем проце даст тебе нужные фпсы, если использовать tiny версию бэкбона.",А с mAP у него как?,"В репозитории не написано, моделька у них в целом заточена конкретно на детекцию лиц, то есть единственный класс. В этом случае вроде можно просто считать precision или accuracy. Для своих задач я тоже детектил с этой сеткой только один класс, по метрикам сейчас не скажу, сколько было. Но работала она прямо хорошо по точности. Я еще добавил мозаичную аугментацию при обучении, неплохо бустануло метрики."
"https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB
Вот эта штука довольно шустрая на cpu. По сути, это дефолтный SSD, но с легким бэкбоном и всякими оптимизациями. Думаю, на твоем проце даст тебе нужные фпсы, если использовать tiny версию бэкбона.",А с mAP у него как?,"В репозитории не написано, моделька у них в целом заточена конкретно на детекцию лиц, то есть единственный класс. В этом случае вроде можно просто считать precision или accuracy. Для своих задач я тоже детектил с этой сеткой только один класс, по метрикам сейчас не скажу, сколько было. Но работала она прямо хорошо по точности. Я еще добавил мозаичную аугментацию при обучении, неплохо бустануло метрики.",Мозаичная аугментация — это как?
А с mAP у него как?,"В репозитории не написано, моделька у них в целом заточена конкретно на детекцию лиц, то есть единственный класс. В этом случае вроде можно просто считать precision или accuracy. Для своих задач я тоже детектил с этой сеткой только один класс, по метрикам сейчас не скажу, сколько было. Но работала она прямо хорошо по точности. Я еще добавил мозаичную аугментацию при обучении, неплохо бустануло метрики.",Мозаичная аугментация — это как?,Тут в целом понятно написано: https://hasty.ai/docs/mp-wiki/augmentations/mosaic
,,,"Плохая идея без ускорителя идти в детекцию.
Лучше сразу решить вопрос с железом а потом убивать ресурсы....

Наелся по уши работой с плохим железом..."
,,"Плохая идея без ускорителя идти в детекцию.
Лучше сразу решить вопрос с железом а потом убивать ресурсы....

Наелся по уши работой с плохим железом...","Согласен, тут пет-проект, если не найду решение на сетях - соберу на openCV"
,,,А че за Цпу такой? Можно ещё картинку подрезать по разрешению
,,А че за Цпу такой? Можно ещё картинку подрезать по разрешению,"Amd a6-3420M с 4 ГБ оперативы. Это ноут я в нём пишу и проверяю, обучаю на стационарном компе китайская материнка , проц 12 ядер, 16 ГБ оперативы, видео без тензорных ядер. Недавно собрал YOLO v1 в Keras запустил учиться, за 12 часов 2.5 эпохи, мы так далеко не уедем."
,,,ну старый процессор просто не производительный
,,ну старый процессор просто не производительный,"А я так посмотрел, почитал, на не старых тоже быстро не будет
Просто может кто кинет ссылку какую-нибудь типа сети с пяток сверхточных слоёв, потом немного полносвязных, какая-нибудь своя функция потерь..."
,ну старый процессор просто не производительный,"А я так посмотрел, почитал, на не старых тоже быстро не будет
Просто может кто кинет ссылку какую-нибудь типа сети с пяток сверхточных слоёв, потом немного полносвязных, какая-нибудь своя функция потерь...",Ну вроде я 5ю нормально заводил на мобильном проце
ну старый процессор просто не производительный,"А я так посмотрел, почитал, на не старых тоже быстро не будет
Просто может кто кинет ссылку какую-нибудь типа сети с пяток сверхточных слоёв, потом немного полносвязных, какая-нибудь своя функция потерь...",Ну вроде я 5ю нормально заводил на мобильном проце,"Возможно, просто прога планирует крутится на этом ноуте, может какой и по бодрее попадётся"
"А я так посмотрел, почитал, на не старых тоже быстро не будет
Просто может кто кинет ссылку какую-нибудь типа сети с пяток сверхточных слоёв, потом немного полносвязных, какая-нибудь своя функция потерь...",Ну вроде я 5ю нормально заводил на мобильном проце,"Возможно, просто прога планирует крутится на этом ноуте, может какой и по бодрее попадётся",Да уж обучение на CPU и если yolo столько на нем выдаёт - это боль. Может лучше тогда запихнуть на какой-нибудь сервер в интернете?
,,,А обучать в колабе
,,А обучать в колабе,"Да можно, но обученный YOLO всё равно должен работать на ноуте"
,А обучать в колабе,"Да можно, но обученный YOLO всё равно должен работать на ноуте",А зачем ему на ноуте работать ?
А обучать в колабе,"Да можно, но обученный YOLO всё равно должен работать на ноуте",А зачем ему на ноуте работать ?,"Чтобы я мог его куда-нибудь притащить и показать, как все работает"
"Да можно, но обученный YOLO всё равно должен работать на ноуте",А зачем ему на ноуте работать ?,"Чтобы я мог его куда-нибудь притащить и показать, как все работает",Ну есть huggingface space
А зачем ему на ноуте работать ?,"Чтобы я мог его куда-нибудь притащить и показать, как все работает",Ну есть huggingface space,"ага,но он сказал что ему ещё надо платы по ком порту конектить"
,,,Так показывайте в колабе/интернете/в стримлите 😁
,,Так показывайте в колабе/интернете/в стримлите 😁,"К программулине ещё, кроме камеры, будет плата по COM порту подключаться"
,Так показывайте в колабе/интернете/в стримлите 😁,"К программулине ещё, кроме камеры, будет плата по COM порту подключаться",на ноуте очень больно такое запускать
,,,"Привет всем, я тут лишний."
,,"Привет всем, я тут лишний.",даже в инференс
,"Привет всем, я тут лишний.",даже в инференс,"- автоматизировать first line of support (обычный чат помощник, как на больших крутых сайтах)
- уметь находить инфу в документах по запросу в чате (покрывает ли моя страховка если у меня украли машину)

Чуваки, посоветуйте как такие кейсы при помощи НЛП решать?
Грубо говоря, готовлюсь к кейс интервью, про простые подходы типа регулярок, конечных автоматов и классического поиска по ключевым словам уже подумал, а что можно более продвинутого прикрутить, и как? Вплоть до файнтюнинга чатгпшек?)
Заранее спасибо"
"Привет всем, я тут лишний.",даже в инференс,"- автоматизировать first line of support (обычный чат помощник, как на больших крутых сайтах)
- уметь находить инфу в документах по запросу в чате (покрывает ли моя страховка если у меня украли машину)

Чуваки, посоветуйте как такие кейсы при помощи НЛП решать?
Грубо говоря, готовлюсь к кейс интервью, про простые подходы типа регулярок, конечных автоматов и классического поиска по ключевым словам уже подумал, а что можно более продвинутого прикрутить, и как? Вплоть до файнтюнинга чатгпшек?)
Заранее спасибо",Обучай модель в колабе. Конвертируй в onnx и юзай для инференса если надо где-то показывать. Плюс Колаб же вообще можно откуда угодно показыыать
,,,"Для выделения клеток на микроснимках в своё время придумали U-net.  В размере 128^2 она без GPU учится довольно шустро, но не думаю что там инференс будет за 50мСек.    Хотя можете попробовать и измерить. 

Тут ещё зависит от размера клетки на изображении.  Сколько у вас минимальный размер клетки в % от короткой стороны кадра?   Другими словами — вам выделять крупные изображения на картинке или мелкие?"
,,"Для выделения клеток на микроснимках в своё время придумали U-net.  В размере 128^2 она без GPU учится довольно шустро, но не думаю что там инференс будет за 50мСек.    Хотя можете попробовать и измерить. 

Тут ещё зависит от размера клетки на изображении.  Сколько у вас минимальный размер клетки в % от короткой стороны кадра?   Другими словами — вам выделять крупные изображения на картинке или мелкие?","Думал об этом тоже, пройтись unet ом, потом openCV поискать нужные контуры в выходной маске и обрамлять из в прямоугольники. Хорошая идея."
,"Для выделения клеток на микроснимках в своё время придумали U-net.  В размере 128^2 она без GPU учится довольно шустро, но не думаю что там инференс будет за 50мСек.    Хотя можете попробовать и измерить. 

Тут ещё зависит от размера клетки на изображении.  Сколько у вас минимальный размер клетки в % от короткой стороны кадра?   Другими словами — вам выделять крупные изображения на картинке или мелкие?","Думал об этом тоже, пройтись unet ом, потом openCV поискать нужные контуры в выходной маске и обрамлять из в прямоугольники. Хорошая идея.","В пакете scipy есть небольшой набор процедур для работы с масками — группировка, центры масс,…"
,,,"Вообще посмотри, тут много таких вопросов было (про поиск доков конкретно)."
,,,"Сайга 13B работает неплохо, но у неё очень плохой парсер и часто не хватает длинных ввода (2048 токенов) на весь док"
,,"Сайга 13B работает неплохо, но у неё очень плохой парсер и часто не хватает длинных ввода (2048 токенов) на весь док",Это больше требует ресурсов чем 760m фред
,,,Всем привет 👋 Оцените пожалуйста CV на позицию стажера или джуна ML. Буду благодарен за любую критику
,,Всем привет 👋 Оцените пожалуйста CV на позицию стажера или джуна ML. Буду благодарен за любую критику,"если ты прикладываешь ссылку на гит, то лучше оформить ридми.
как у профиля, так и у проектов"
,,,"Кстати, а какие неплохие и легкие русскоязычные модели можете посоветовать? Я пробовал fred от Ильи Гусева, вроде норм, но мб еще что интересное есть)"
,,"Кстати, а какие неплохие и легкие русскоязычные модели можете посоветовать? Я пробовал fred от Ильи Гусева, вроде норм, но мб еще что интересное есть)","SiberianFred разносит гусевского Фреда. Потому, что учили правильно🙂😏"
,,,В пайплайне LLM + векторизованная БД (ретривер) + langchain
,,,"Чаттеры, подскажите пожалуйста, где можно находить обзоры (или хотя бы ссылки) на свежие статьи, но не про какие-нибудь очередные хайповые файнтьюны LLM или диффузии (или статьи вида ""вот тут поменяли энкодер, качество выросло на 0.1%, это новая СОТА""), а что-нибудь более интересное, научное и фундаментальное (типа: исследование рельефа функции потерь, гипотезы почему работает условный batchnorm, связь трансформеров и градиентного спуска и тд)?"
,,"Чаттеры, подскажите пожалуйста, где можно находить обзоры (или хотя бы ссылки) на свежие статьи, но не про какие-нибудь очередные хайповые файнтьюны LLM или диффузии (или статьи вида ""вот тут поменяли энкодер, качество выросло на 0.1%, это новая СОТА""), а что-нибудь более интересное, научное и фундаментальное (типа: исследование рельефа функции потерь, гипотезы почему работает условный batchnorm, связь трансформеров и градиентного спуска и тд)?","https://arxiv.org/list/cs.AI/recent
http://www.jmlr.org/
https://www.nature.com/natmachintell/
https://www.deepmind.com/blog
https://jack-clark.net/
https://nips.cc/
https://www.ijcai.org/"
,,,Подписываюсь
,,,ну вы сильно больше с ним возились
,,ну вы сильно больше с ним возились,Первая версия которая обогнала Фреда Гусева была обучена на той же ру турбо альпаке.
,ну вы сильно больше с ним возились,Первая версия которая обогнала Фреда Гусева была обучена на той же ру турбо альпаке.,"Саша про то, что я вообще 2 запуска обучения делал, один неправильный, и один почти правильный"
,,,потратив примерно 15 минут своего времени на всё
,,потратив примерно 15 минут своего времени на всё,А модель есть?
,потратив примерно 15 минут своего времени на всё,А модель есть?,"так в смысле, офк есть, раз её тут обсуждают 😄"
потратив примерно 15 минут своего времени на всё,А модель есть?,"так в смысле, офк есть, раз её тут обсуждают 😄",Это старая же
А модель есть?,"так в смысле, офк есть, раз её тут обсуждают 😄",Это старая же,"ну да, это неправильная"
,,,"почти правильная не была сильно лучше, я не стал заливать"
,,,разница в LR/scheduler и префиксных токенах была
,,разница в LR/scheduler и префиксных токенах была,А ты это закинул в rulm? Я тогда гляну
,разница в LR/scheduler и префиксных токенах была,А ты это закинул в rulm? Я тогда гляну,"неа, конфиг тоже только старый лежит"
,,,"короче я на 100% уверен, что мой фред хуже, но есть какие-то цифры, это подтверждающие?"
,,"короче я на 100% уверен, что мой фред хуже, но есть какие-то цифры, это подтверждающие?",Мы же SBS делали
,"короче я на 100% уверен, что мой фред хуже, но есть какие-то цифры, это подтверждающие?",Мы же SBS делали,твоего фреда с моим? не было такого
"короче я на 100% уверен, что мой фред хуже, но есть какие-то цифры, это подтверждающие?",Мы же SBS делали,твоего фреда с моим? не было такого,"saiga7b_v2 vs den4ik_fred: 124-5-47
saiga7b_v4 vs saiga7b_v2: 80-8-88"
,,,а хотя был мой фред vs сайга и твой фред vs сайга
,,а хотя был мой фред vs сайга и твой фред vs сайга,И там у твоего Фреда были какие-то оч смешные цифры. Вроде 7
,а хотя был мой фред vs сайга и твой фред vs сайга,И там у твоего Фреда были какие-то оч смешные цифры. Вроде 7,"turbo vs fred: 77-13-6
6, но то против ChatGPT"
,,,"да, я свой фред только с chatgpt сравнивал"
,,"да, я свой фред только с chatgpt сравнивал","Вот что-то нашёл, посмотрим на быстродействие"
,"да, я свой фред только с chatgpt сравнивал","Вот что-то нашёл, посмотрим на быстродействие",генерация лиц 👏
,,,можно посмотреть?
,,можно посмотреть?,Это домашка по ганам в deep learning school
,можно посмотреть?,Это домашка по ганам в deep learning school,ничесе домашка
,,,дай сслыку на проект в гитхабе
,,,С IP РФ плохо открывается
,,С IP РФ плохо открывается,"прошу прощения за оффтоп, но ава - топчик."
,,,пойду ка я бенчмаркать все эти ваши fredы
,,пойду ка я бенчмаркать все эти ваши fredы,Нашёл)
,пойду ка я бенчмаркать все эти ваши fredы,Нашёл),+
пойду ка я бенчмаркать все эти ваши fredы,Нашёл),+,Дед просит?
Нашёл),+,Дед просит?,Смешная реклама (другая)
+,Дед просит?,Смешная реклама (другая),Специалисты нужны везде
,,,"Кто-нибудь знает, какие задачи может решать ML в контексте телефонных компаний по типу мегафона? Как пример — оценка риска того, что клиент может скоро уйти к другому оператору, и чтобы в таком случае мы могли подобрать новый тариф, чтобы удержать клиента."
,,"Кто-нибудь знает, какие задачи может решать ML в контексте телефонных компаний по типу мегафона? Как пример — оценка риска того, что клиент может скоро уйти к другому оператору, и чтобы в таком случае мы могли подобрать новый тариф, чтобы удержать клиента.","Там много всякого. 

Fraud detection 
RecSys 
Customer segmentation
Чат боты
…"
,,,speech enhancement
,,,"Всем привет!
Сейчас разбираюсь в теме и пробую найти решение следующей задачи:

На вход даются два текста

Задача - предсказать, могут ли они быть друг с другом связаны/идти в одном из двух вариантов порядка в одном большом тексте и предсказать нужную связку (опционально). То есть нужно оценить, насколько первому тексту подходит второй.

То есть это не базовая задача similarity - similarity просто покажет, насколько утверждения в двух текстах похожи: ""Шарик - хороший мальчик"" и ""Шарик - очень хороший мальчик"". 

Подход ломается, когда мы сравниваем ""I am a businessman"" и ""I am not a businessman"".

Приведу пример своего контекста.

Скажем, дано нам утверждение:
""Рекомендательная система - это программа, которая пытается предсказать, какие объекты будут интересны пользователю, используя контекст - определенную информацию о нем.""
И дано:
""Рекомендательные системы могут применяться в приложениях стриминга, в каталогах книг и для персонализации новостной ленты""

Они далеко не похожи, но относятся друг к другу как понятие и контекст использования.

Можно ли такое осуществить, и если да, то посоветуйте, пожалуйста, что изучить, какие подходы. Готов утонуть в любых сложных papers и куче информации, все это поизучать

И есть ли возможность обойти необходимость разметки своего датасета с labels связей между двумя текстами? Может, где-то они уже есть, или и вовсе есть подход, который позволяет решить задачу.

Понимаю, что это стык nlp и recsys, и здесь могут пригодиться Relation и Entity Extraction. Ну и эмбеддинги конечно 

Возможно, я усложняю)

Заранее спасибо!"
,,"Всем привет!
Сейчас разбираюсь в теме и пробую найти решение следующей задачи:

На вход даются два текста

Задача - предсказать, могут ли они быть друг с другом связаны/идти в одном из двух вариантов порядка в одном большом тексте и предсказать нужную связку (опционально). То есть нужно оценить, насколько первому тексту подходит второй.

То есть это не базовая задача similarity - similarity просто покажет, насколько утверждения в двух текстах похожи: ""Шарик - хороший мальчик"" и ""Шарик - очень хороший мальчик"". 

Подход ломается, когда мы сравниваем ""I am a businessman"" и ""I am not a businessman"".

Приведу пример своего контекста.

Скажем, дано нам утверждение:
""Рекомендательная система - это программа, которая пытается предсказать, какие объекты будут интересны пользователю, используя контекст - определенную информацию о нем.""
И дано:
""Рекомендательные системы могут применяться в приложениях стриминга, в каталогах книг и для персонализации новостной ленты""

Они далеко не похожи, но относятся друг к другу как понятие и контекст использования.

Можно ли такое осуществить, и если да, то посоветуйте, пожалуйста, что изучить, какие подходы. Готов утонуть в любых сложных papers и куче информации, все это поизучать

И есть ли возможность обойти необходимость разметки своего датасета с labels связей между двумя текстами? Может, где-то они уже есть, или и вовсе есть подход, который позволяет решить задачу.

Понимаю, что это стык nlp и recsys, и здесь могут пригодиться Relation и Entity Extraction. Ну и эмбеддинги конечно 

Возможно, я усложняю)

Заранее спасибо!","В простейшем случае можно RNN попробовать или cross-encoder
Можно разбивать тексты на несколько частей и предсказывать вероятность, что один кусок текста идет где-то после другого

Соответственно, 2 куска текста реально находятся в одном тексте - метка 1. Для отрицательных примеров можно брать случайные куски из других текстов. Бинарная классификация.
Собрать выборку и закодить такое должно быть довольно легко"
,"Всем привет!
Сейчас разбираюсь в теме и пробую найти решение следующей задачи:

На вход даются два текста

Задача - предсказать, могут ли они быть друг с другом связаны/идти в одном из двух вариантов порядка в одном большом тексте и предсказать нужную связку (опционально). То есть нужно оценить, насколько первому тексту подходит второй.

То есть это не базовая задача similarity - similarity просто покажет, насколько утверждения в двух текстах похожи: ""Шарик - хороший мальчик"" и ""Шарик - очень хороший мальчик"". 

Подход ломается, когда мы сравниваем ""I am a businessman"" и ""I am not a businessman"".

Приведу пример своего контекста.

Скажем, дано нам утверждение:
""Рекомендательная система - это программа, которая пытается предсказать, какие объекты будут интересны пользователю, используя контекст - определенную информацию о нем.""
И дано:
""Рекомендательные системы могут применяться в приложениях стриминга, в каталогах книг и для персонализации новостной ленты""

Они далеко не похожи, но относятся друг к другу как понятие и контекст использования.

Можно ли такое осуществить, и если да, то посоветуйте, пожалуйста, что изучить, какие подходы. Готов утонуть в любых сложных papers и куче информации, все это поизучать

И есть ли возможность обойти необходимость разметки своего датасета с labels связей между двумя текстами? Может, где-то они уже есть, или и вовсе есть подход, который позволяет решить задачу.

Понимаю, что это стык nlp и recsys, и здесь могут пригодиться Relation и Entity Extraction. Ну и эмбеддинги конечно 

Возможно, я усложняю)

Заранее спасибо!","В простейшем случае можно RNN попробовать или cross-encoder
Можно разбивать тексты на несколько частей и предсказывать вероятность, что один кусок текста идет где-то после другого

Соответственно, 2 куска текста реально находятся в одном тексте - метка 1. Для отрицательных примеров можно брать случайные куски из других текстов. Бинарная классификация.
Собрать выборку и закодить такое должно быть довольно легко",Благодарю за ответ!
,,,Это не nli случайно?
,,Это не nli случайно?,"Кстати может подойти, сейчас посмотрел, но я так понимаю, что там определяется именно логическое следование одной мысли из другой"
,,,"Можешь сделать бинарную классификацию, на вход подавать sentence1 [SEP] sentence2"
,,"Можешь сделать бинарную классификацию, на вход подавать sentence1 [SEP] sentence2",А что имеете в виду под разделителем?
,,,"В берте есть спец токен [SEP], можно любой другой

Про nli: есть и постановка в логическом следовании, но по сути это частность, а nli это все задачи на ""понимание"" текста"
,,"В берте есть спец токен [SEP], можно любой другой

Про nli: есть и постановка в логическом следовании, но по сути это частность, а nli это все задачи на ""понимание"" текста","Уловил, спасибо
Значит, буду копать в сторону nli"
,,,дорисовка кадра из мульта))
,,дорисовка кадра из мульта)),👍👍👍 затестим
,,,"Прикольно, но в движении не генерит картинки."
,,,"Попробовал whisperX. Работает, но в части распознавания русских слов есть определенные сложности… Во-первых не всегда точно распознаются слова, порой сложно понять что за слово было, нужно переслушивать запись чтобы понять. Во-вторых (что вобщем то логично) — английские слова транскрибирются их русским звучанием (например NDA -- эндиа или индиа). Для работы с русским языком и диаризацией использовал параметры и модели по умолчанию. Возможно есть лучшие модели, которые нужно указать ручками (буду признателен за рекомендации и комментарии). Как мне кажется, после получения финального результата (итоговый текст из аудиозаписи) нужно прогнать его через языковую модельку, чтобы внести правки и исправить ошибки в словах и фразах. Возможно есть уже готовые решения (пайплайны) под эту задачу? Можете что-то посоветовать в качестве дополнительного изучения вопроса?"
,,,"Где-то натыкался на стартап (к сожалению сейчас найти его не могу), который из видеоконференций выдергивает текст, выполняет диаризацию по спикерам, делает суммаризацию совещания и формирует конкретные задания для участников (по сути — follow up message). Может кто-то знает подобные решения?"
,,"Где-то натыкался на стартап (к сожалению сейчас найти его не могу), который из видеоконференций выдергивает текст, выполняет диаризацию по спикерам, делает суммаризацию совещания и формирует конкретные задания для участников (по сути — follow up message). Может кто-то знает подобные решения?",recall.ai делают что-то такое
,"Где-то натыкался на стартап (к сожалению сейчас найти его не могу), который из видеоконференций выдергивает текст, выполняет диаризацию по спикерам, делает суммаризацию совещания и формирует конкретные задания для участников (по сути — follow up message). Может кто-то знает подобные решения?",recall.ai делают что-то такое,Мария спасибо!
,,,не умеют виндсерфинг они (
,,,"Привет, подскажите по формированию набора изображений для задачи сегментации.  После нарезки изображений получается примерно половина изображений пустых (маска не попала) и содержательных (кусок маски попал). Есть ли смысл оставлять в наборе такое количество пустых изображений в датасете? Может сократить их до какого количества?"
,,"Привет, подскажите по формированию набора изображений для задачи сегментации.  После нарезки изображений получается примерно половина изображений пустых (маска не попала) и содержательных (кусок маски попал). Есть ли смысл оставлять в наборе такое количество пустых изображений в датасете? Может сократить их до какого количества?",Количество пустых желательно соотносить с их частотой в дикой природе
,,,Лучше с пустыми. Потому что иначе сетка будет думать что контур всегда должен быть и находить его в шумах
,,Лучше с пустыми. Потому что иначе сетка будет думать что контур всегда должен быть и находить его в шумах,"Это не всегда так, зависит от домена, лосса... Но в целом так"
,,,"Вобщем пустые - это такая же регуляризация, сродни аугментации"
,,"Вобщем пустые - это такая же регуляризация, сродни аугментации","Всем здарова. Занимался ли кто-нибудь детектированием объектов на видео? Но не тупо покадрово + трекинг, а что-то подобное centertrack? Если да, то куда смотреть? Кроме тупых MLP на выходе детекторов ничего не нашел. Есть велосипеды с запоминанием объектов типо XMEM. Но на мобилках оно не влезет."
,"Вобщем пустые - это такая же регуляризация, сродни аугментации","Всем здарова. Занимался ли кто-нибудь детектированием объектов на видео? Но не тупо покадрово + трекинг, а что-то подобное centertrack? Если да, то куда смотреть? Кроме тупых MLP на выходе детекторов ничего не нашел. Есть велосипеды с запоминанием объектов типо XMEM. Но на мобилках оно не влезет.","Когда ты лиспер, у тебя не возникает вопросов о таком в коде"
"Вобщем пустые - это такая же регуляризация, сродни аугментации","Всем здарова. Занимался ли кто-нибудь детектированием объектов на видео? Но не тупо покадрово + трекинг, а что-то подобное centertrack? Если да, то куда смотреть? Кроме тупых MLP на выходе детекторов ничего не нашел. Есть велосипеды с запоминанием объектов типо XMEM. Но на мобилках оно не влезет.","Когда ты лиспер, у тебя не возникает вопросов о таком в коде","Добрый день! Я новичок в trading, причем спот на mexc. Может кто знает, там действительно комиссии taker/maker на споте по 0% ?
Но почему тогда при продаже у меня получается меньше чем было, хотя цена актива выросла?"
"Всем здарова. Занимался ли кто-нибудь детектированием объектов на видео? Но не тупо покадрово + трекинг, а что-то подобное centertrack? Если да, то куда смотреть? Кроме тупых MLP на выходе детекторов ничего не нашел. Есть велосипеды с запоминанием объектов типо XMEM. Но на мобилках оно не влезет.","Когда ты лиспер, у тебя не возникает вопросов о таком в коде","Добрый день! Я новичок в trading, причем спот на mexc. Может кто знает, там действительно комиссии taker/maker на споте по 0% ?
Но почему тогда при продаже у меня получается меньше чем было, хотя цена актива выросла?",Украдено из чата статистики. Никогда не занимайтесь регрессией)))
,,,"Ребят, а куда сейчас открыты наборы на позицию продуктового аналитика?"
,,"Ребят, а куда сейчас открыты наборы на позицию продуктового аналитика?","и тут, соответственно, https://t.me/betterdatacommunity/9"
,,,Отпишу тебе в лс)
,,Отпишу тебе в лс),"А посоветуйте, где можно по-быстрому сгенерировать ракету из говна и палок, не пробиваясь через цензуру
(stable diffusion на таком промпте не тестировал)"
,Отпишу тебе в лс),"А посоветуйте, где можно по-быстрому сгенерировать ракету из говна и палок, не пробиваясь через цензуру
(stable diffusion на таком промпте не тестировал)",такой вариант?
Отпишу тебе в лс),"А посоветуйте, где можно по-быстрому сгенерировать ракету из говна и палок, не пробиваясь через цензуру
(stable diffusion на таком промпте не тестировал)",такой вариант?,"Что? Кто? Почему? 
А у нас конкурс на 5000 подписчиков!

У нас есть топик - papers please, участники сообщества могут выкладывать туда обзоры статей - гайды -  блогпосты на платформах: habr, medium, dtf, picabu,(обязательно укажите внизу что на конкурс в Better data community) тот который за неделю наберет больше всех реакций в чате(обратите внимание, только положительных) будет иметь шанс получить

БОНУС трек: статья про то файнтюнить Kandinskiy2.2 на одной из платформ, первый написавший получит подпись в сообщество на свой выбор.

- УНИКАЛЬНЫЙ мерч Better Data Community(тестовый, от этого более уникальный)
- 100$ на vast/amazon или 5000 рублей на карту
- 3 месяца на яндекс+"
"А посоветуйте, где можно по-быстрому сгенерировать ракету из говна и палок, не пробиваясь через цензуру
(stable diffusion на таком промпте не тестировал)",такой вариант?,"Что? Кто? Почему? 
А у нас конкурс на 5000 подписчиков!

У нас есть топик - papers please, участники сообщества могут выкладывать туда обзоры статей - гайды -  блогпосты на платформах: habr, medium, dtf, picabu,(обязательно укажите внизу что на конкурс в Better data community) тот который за неделю наберет больше всех реакций в чате(обратите внимание, только положительных) будет иметь шанс получить

БОНУС трек: статья про то файнтюнить Kandinskiy2.2 на одной из платформ, первый написавший получит подпись в сообщество на свой выбор.

- УНИКАЛЬНЫЙ мерч Better Data Community(тестовый, от этого более уникальный)
- 100$ на vast/amazon или 5000 рублей на карту
- 3 месяца на яндекс+",":D ура конкурс на 5к. Жаль, что метрика положительных реактов, я хотел посты Алерона кинуть... Отмена"
,,,"в парном трейдинге полезно понимать ответ на как минимум два важных вопроса: 1) как оно перформит на реальном рынке, а не бэктестах, какие там пролазят объемы 2) как понять, что лошадь сдохла и пора с нее слезть, прежде чем на счету кончились деньги"
,,"в парном трейдинге полезно понимать ответ на как минимум два важных вопроса: 1) как оно перформит на реальном рынке, а не бэктестах, какие там пролазят объемы 2) как понять, что лошадь сдохла и пора с нее слезть, прежде чем на счету кончились деньги","Артур, спасибо, что откликнулся. Честно он дал 13 листов pdf особо ничего не понятно: типа такой единственный инсайт
Поиск торговых пар осуществляется с помощью разработанного программного
обеспечения, которое анализирует показатель SPREAD между двумя инструментами"
,"в парном трейдинге полезно понимать ответ на как минимум два важных вопроса: 1) как оно перформит на реальном рынке, а не бэктестах, какие там пролазят объемы 2) как понять, что лошадь сдохла и пора с нее слезть, прежде чем на счету кончились деньги","Артур, спасибо, что откликнулся. Честно он дал 13 листов pdf особо ничего не понятно: типа такой единственный инсайт
Поиск торговых пар осуществляется с помощью разработанного программного
обеспечения, которое анализирует показатель SPREAD между двумя инструментами",а сколько нужно инвестировать минимальнро?
"в парном трейдинге полезно понимать ответ на как минимум два важных вопроса: 1) как оно перформит на реальном рынке, а не бэктестах, какие там пролазят объемы 2) как понять, что лошадь сдохла и пора с нее слезть, прежде чем на счету кончились деньги","Артур, спасибо, что откликнулся. Честно он дал 13 листов pdf особо ничего не понятно: типа такой единственный инсайт
Поиск торговых пар осуществляется с помощью разработанного программного
обеспечения, которое анализирует показатель SPREAD между двумя инструментами",а сколько нужно инвестировать минимальнро?,Ничего не сказали по поводу этого.
"Артур, спасибо, что откликнулся. Честно он дал 13 листов pdf особо ничего не понятно: типа такой единственный инсайт
Поиск торговых пар осуществляется с помощью разработанного программного
обеспечения, которое анализирует показатель SPREAD между двумя инструментами",а сколько нужно инвестировать минимальнро?,Ничего не сказали по поводу этого.,предлагаю построить свою платформу и по принципу SPREAD торговать)
а сколько нужно инвестировать минимальнро?,Ничего не сказали по поводу этого.,предлагаю построить свою платформу и по принципу SPREAD торговать),Надо бы посмотреть тогда)
,,,"впрочем, это для всякого трейдинга актуально, чего это я"
,,,пока что звучит так себе
,,пока что звучит так себе,"вот еще оказывается есть это, но опять так себе это ничего не дает
Механизм стратегии
следующий: одновременно открываются длинные позиции (long) и короткие позиции
(short) по бумагам на одинаковые объемы
Торгуемые инструменты: BINANCE USDⓈ-Margined Futures c торговым оборотом за
прошедшие 24ч от 15 млн USD
Капитал распределяется между разными инвестиционными инструментами (от 5 пар)"
,пока что звучит так себе,"вот еще оказывается есть это, но опять так себе это ничего не дает
Механизм стратегии
следующий: одновременно открываются длинные позиции (long) и короткие позиции
(short) по бумагам на одинаковые объемы
Торгуемые инструменты: BINANCE USDⓈ-Margined Futures c торговым оборотом за
прошедшие 24ч от 15 млн USD
Капитал распределяется между разными инвестиционными инструментами (от 5 пар)","Суть торговли не раскрыть, наверное так приятно, общие вещи говорить"
,,,"это все основы, достаточно общие слова"
,,"это все основы, достаточно общие слова",
,"это все основы, достаточно общие слова",,это не парный трейдинг
"это все основы, достаточно общие слова",,это не парный трейдинг,А что это?
,это не парный трейдинг,А что это?,"Херня какая-то, разводка для лохов, которые на умные слова клюнут. Накинули график спреда, и торгуем спред по графику, то есть алхимией занимаемся. Как говорил один умный человек - если ты что-то купил, а что-то продал, это еще не значит, что ты market-neutral."
,,,"пусть покажет, как его стратегия перформит на реале"
,,,"пока то, что он описывает, делает каждый первокурсник. в чем именно его преимущество перед ними"
,,"пока то, что он описывает, делает каждый первокурсник. в чем именно его преимущество перед ними","он ему продает то, что у него уже есть платформа"
,,,Ничего если поделюсь тут файлом? Там общая презентация)
,,Ничего если поделюсь тут файлом? Там общая презентация),"ну пусть знакомый посмотрит трекрекорд лайва, желательно чтобы там хотя бы полгода было, тогда есть о чем говорить, а так все что написали — супер общие слова и размахивания руками :)"
,Ничего если поделюсь тут файлом? Там общая презентация),"ну пусть знакомый посмотрит трекрекорд лайва, желательно чтобы там хотя бы полгода было, тогда есть о чем говорить, а так все что написали — супер общие слова и размахивания руками :)",сколько у вас есть на руках денег которых не жалко?
,,,"Дайте мне, если не жалко. У меня 2% за прошлую неделю))"
,,"Дайте мне, если не жалко. У меня 2% за прошлую неделю))","Да вот есть люди оказываются, если годная стратегия. Мне скинули такую сырую презентацию, сказали дать фидбек))."
,,,"тут уже без иронии: потратьте деньги на себя, попробуйте обучиться, вдруг это ваше"
,,,"Есть промпт и 4 сгенерированные по нему картинки. Надо их ранжировать, т.е расставить в убывающем порядке по ""качеству"". С ранжированием раньше не работал, скиньте, пожалуйста, пару ссылок, которые помогут вкатиться в эту область и реализовать поставленную задачу."
,,"Есть промпт и 4 сгенерированные по нему картинки. Надо их ранжировать, т.е расставить в убывающем порядке по ""качеству"". С ранжированием раньше не работал, скиньте, пожалуйста, пару ссылок, которые помогут вкатиться в эту область и реализовать поставленную задачу.",Бери human preference clip
,,,"Смотрите CLIP, нейросеть"
,,"Смотрите CLIP, нейросеть","Речь идет не про наибольшее соответствие картинки пропмту. Допустим, если задача - генерация стикеров, то надо отобрать картинку, которая превосходит остальных по следующим свойствам: ""красивость""(как бы ужасно это не звучало); отсутствие артефактов; должна выглядеть как стикер, а не просто как обычная картинка... Поэтому у меня будет датасет для обучения модели ранжирования, где X_train - картинки в рандомном порядке + промпт, y_train - картинки в отсортированном порядке."
,"Смотрите CLIP, нейросеть","Речь идет не про наибольшее соответствие картинки пропмту. Допустим, если задача - генерация стикеров, то надо отобрать картинку, которая превосходит остальных по следующим свойствам: ""красивость""(как бы ужасно это не звучало); отсутствие артефактов; должна выглядеть как стикер, а не просто как обычная картинка... Поэтому у меня будет датасет для обучения модели ранжирования, где X_train - картинки в рандомном порядке + промпт, y_train - картинки в отсортированном порядке.","Ранжируй их как раз по близости к CLIP-вектору ""КРАСИВОСТИ"" и далекости от ""НЕКРАСИВОСТИ"".
CLIP-подобный сетки позволяют из простеньких текстовых описаний собирать самые разные классификаторы.

Имхо это очень удобное (ктож тебя знает что для тебя оптимально) решение для прототипов и грубого отбора данных для обучения.
Как соберешь датасетик, можешь MLP поверх этих же векторов проучить, чтобы ранжировал _лучше_ (какое-то количество откровенных стьюпидов в clip-based классификаторах/ранкерах будет, их можно обучением головы победить).

Незачем для такой задачи учить что-то с нуля."
"Смотрите CLIP, нейросеть","Речь идет не про наибольшее соответствие картинки пропмту. Допустим, если задача - генерация стикеров, то надо отобрать картинку, которая превосходит остальных по следующим свойствам: ""красивость""(как бы ужасно это не звучало); отсутствие артефактов; должна выглядеть как стикер, а не просто как обычная картинка... Поэтому у меня будет датасет для обучения модели ранжирования, где X_train - картинки в рандомном порядке + промпт, y_train - картинки в отсортированном порядке.","Ранжируй их как раз по близости к CLIP-вектору ""КРАСИВОСТИ"" и далекости от ""НЕКРАСИВОСТИ"".
CLIP-подобный сетки позволяют из простеньких текстовых описаний собирать самые разные классификаторы.

Имхо это очень удобное (ктож тебя знает что для тебя оптимально) решение для прототипов и грубого отбора данных для обучения.
Как соберешь датасетик, можешь MLP поверх этих же векторов проучить, чтобы ранжировал _лучше_ (какое-то количество откровенных стьюпидов в clip-based классификаторах/ранкерах будет, их можно обучением головы победить).

Незачем для такой задачи учить что-то с нуля.","Интересный подход, для RLHF учат с нуля, вот и я думал сделать тоже самое
https://docs.argilla.io/en/latest/guides/llms/examples/train-reward-model-rlhf.html"
,,,"Какую-нибудь архитектуру, решающую эту задачу, придумать несложно, но я хочу сразу понять, как это решать оптимально"
,,"Какую-нибудь архитектуру, решающую эту задачу, придумать несложно, но я хочу сразу понять, как это решать оптимально","Был на kaggle такой конкурс - pawpularity, где надо было предсказать популярность питомца по фотке, можно туда копнуть."
,,,"Я не делал этого с LLM и RLHF (мне кажется это сложно), с CLIP-like моделями делал часто (это ОЧЕНЬ просто)"
,,"Я не делал этого с LLM и RLHF (мне кажется это сложно), с CLIP-like моделями делал часто (это ОЧЕНЬ просто)","Так и с ретривал моделями на текстах, тк клип тот же ретривал по сути"
,,,"Эм.. что клип -- ретривал я понимаю) мне RLHF не кажется простой штукой.

Учить MLP на фичах по разметке - опциональный шаг, и без него можно жить."
,,,Яндекс видео переводчик или что?
,,Яндекс видео переводчик или что?,Почти. Только мы не яндекс)
,Яндекс видео переводчик или что?,Почти. Только мы не яндекс),Пет проект (1 мин).
,,,Ну тут найдешь все что ищешь
,,Ну тут найдешь все что ищешь,"ни говна, ни палок
о, первый вариант ничего так
спасибо, буду теперь знать, что кандинский норм"
,Ну тут найдешь все что ищешь,"ни говна, ни палок
о, первый вариант ничего так
спасибо, буду теперь знать, что кандинский норм",Кек)))
Ну тут найдешь все что ищешь,"ни говна, ни палок
о, первый вариант ничего так
спасибо, буду теперь знать, что кандинский норм",Кек))),Ну оно на говно тригерит
,,,Кто-то имел успех в применение llm в классификации? Я потестил неплохой ренж моделей и успехи какие-то скромные
,,Кто-то имел успех в применение llm в классификации? Я потестил неплохой ренж моделей и успехи какие-то скромные,Учите Bert/robert/what else
,,,С лорой?
,,С лорой?,ну которые с инстракт лорой перформят лучше в zero shot и начиная с 13б начинается неплохой результат после промт магии
,С лорой?,ну которые с инстракт лорой перформят лучше в zero shot и начиная с 13б начинается неплохой результат после промт магии,"Я не про инстракт, а про голову с линейным слоем"
С лорой?,ну которые с инстракт лорой перформят лучше в zero shot и начиная с 13б начинается неплохой результат после промт магии,"Я не про инстракт, а про голову с линейным слоем",которая будет кушать атеншн скор или что?
ну которые с инстракт лорой перформят лучше в zero shot и начиная с 13б начинается неплохой результат после промт магии,"Я не про инстракт, а про голову с линейным слоем",которая будет кушать атеншн скор или что?,"Нет, выкидываешь lm слой и обучаешь обычный классификатор"
,,,а что вы использовали?
,,а что вы использовали?,Лол кек кринж
,,,"Так вы гвозди забиваете смартфоном, для этого миллиарды энкодеров есть."
,,"Так вы гвозди забиваете смартфоном, для этого миллиарды энкодеров есть.",есть енкодеры которые кушают 8-100к токенов? (вопрос без подвоха)
,"Так вы гвозди забиваете смартфоном, для этого миллиарды энкодеров есть.",есть енкодеры которые кушают 8-100к токенов? (вопрос без подвоха),Можно под себя расширить как лламы расширяют
"Так вы гвозди забиваете смартфоном, для этого миллиарды энкодеров есть.",есть енкодеры которые кушают 8-100к токенов? (вопрос без подвоха),Можно под себя расширить как лламы расширяют,"А есть гайд под рукой, как это делают?"
есть енкодеры которые кушают 8-100к токенов? (вопрос без подвоха),Можно под себя расширить как лламы расширяют,"А есть гайд под рукой, как это делают?",https://kaiokendev.github.io/context
,,,"Всем привет. Можно парой слов, что такое top_k для contrastive search? С альфа понятно"
,,"Всем привет. Можно парой слов, что такое top_k для contrastive search? С альфа понятно","top_k выбирает указанное количество самых вероятных следующих токенов, и отсекает остальные варианты, перераспределяя вероятности между выбранными токенами"
,,,"проще говоря - если top_k = 10, то берем топ 10 токенов по вероятности, остальные игнорим"
,,,"Спасибо. По идее можно и без него, просто подольше?"
,,"Спасибо. По идее можно и без него, просто подольше?","мы после отсечения маловероятных токенов, выбираем следующий токен случайным образом из оставшихся
а если бы мы не отсекали эти токены, то, например, топ 5 токенов по сумме вероятностей у нас дает процентов 80
а остальные, маловероятные токены, дают в сумме 20%
т.е. у нас шанс 20% того, что нам попадется какой-то токен, плохо подходящий под наш промпт, и вся генерация пойдет не туда, куда надо)"
,"Спасибо. По идее можно и без него, просто подольше?","мы после отсечения маловероятных токенов, выбираем следующий токен случайным образом из оставшихся
а если бы мы не отсекали эти токены, то, например, топ 5 токенов по сумме вероятностей у нас дает процентов 80
а остальные, маловероятные токены, дают в сумме 20%
т.е. у нас шанс 20% того, что нам попадется какой-то токен, плохо подходящий под наш промпт, и вся генерация пойдет не туда, куда надо)","Понял, спасибо!"
,,,Так что?
,,,Размечайте контуры (края) дороги и считайте оптимальную траекторию))
,,Размечайте контуры (края) дороги и считайте оптимальную траекторию)),То есть по сути предсказывать по маске дороги траекторию машинки?
,Размечайте контуры (края) дороги и считайте оптимальную траекторию)),То есть по сути предсказывать по маске дороги траекторию машинки?,Находить оптимальную (максимум скорости при ограничениях)
,,,Какие есть хорошие публикации по разметке краев дороги?  Как эта задача называется на английском? Road Edge Detection?
,,Какие есть хорошие публикации по разметке краев дороги?  Как эта задача называется на английском? Road Edge Detection?,"Наверняка есть готовые сегментаторы. Road segmentation, или road semantic segmentation"
,,,Скорее lane detection
,,Скорее lane detection,"гайх где-то видел красивую визуализацию text2image с CLIP, VQ-VAE, GLIDE и co
ни у кого не завалялась?"
,,,"Всем привет. Сейчас какие-нибудь API к LLM кроме OpenAI, кто нибудь еще задеплоил в открытый доступ?"
,,"Всем привет. Сейчас какие-нибудь API к LLM кроме OpenAI, кто нибудь еще задеплоил в открытый доступ?",Клод вроде сделал
,,,"не порекомендуете аналог roboflow? очень удобный функционал, но местами ограничен и + там макс 1000 картинок всего, есть ли аналоги, чем вы пользуетесь для хранения датасетов и валидации разметки?"
,,"не порекомендуете аналог roboflow? очень удобный функционал, но местами ограничен и + там макс 1000 картинок всего, есть ли аналоги, чем вы пользуетесь для хранения датасетов и валидации разметки?",CVAT неплох
,,,"Label Studio
Но ещё нет pose estimation."
,,"Label Studio
Но ещё нет pose estimation.","а туда можно уже готовую разметку загрузить и посмотреть как выглядит? поставил себе, но надо разбираться"
,"Label Studio
Но ещё нет pose estimation.","а туда можно уже готовую разметку загрузить и посмотреть как выглядит? поставил себе, но надо разбираться","Да, можно. https://labelstud.io/guide/predictions.html"
,,,"Добрый день!
Подскажите, а остался ли в свободном доступе kandinskiy2.1?
И как на него можно перейти?"
,,"Добрый день!
Подскажите, а остался ли в свободном доступе kandinskiy2.1?
И как на него можно перейти?",в боте https://t.me/kandinsky21_bot можно выбрать версию модели командой /model
,"Добрый день!
Подскажите, а остался ли в свободном доступе kandinskiy2.1?
И как на него можно перейти?",в боте https://t.me/kandinsky21_bot можно выбрать версию модели командой /model,"Спасибо большое, это отличная новость!👍"
,,,"веса есть на hugginface, возможно где-то осталось развёрнутые"
,,"веса есть на hugginface, возможно где-то осталось развёрнутые","А что можно посмотреть\почитать чтобы базово зашарить зоопарк LLM-ок за вечер? Хотя бы самые основные? 
Смотрел лекцию ШАД-а по ллмкам, но хочтеся что-то еще почитать или посмотреть, плюс как я понял она немного устарела"
,"веса есть на hugginface, возможно где-то осталось развёрнутые","А что можно посмотреть\почитать чтобы базово зашарить зоопарк LLM-ок за вечер? Хотя бы самые основные? 
Смотрел лекцию ШАД-а по ллмкам, но хочтеся что-то еще почитать или посмотреть, плюс как я понял она немного устарела","Не знаю насколько за вечер, но вот есть подборка"
"веса есть на hugginface, возможно где-то осталось развёрнутые","А что можно посмотреть\почитать чтобы базово зашарить зоопарк LLM-ок за вечер? Хотя бы самые основные? 
Смотрел лекцию ШАД-а по ллмкам, но хочтеся что-то еще почитать или посмотреть, плюс как я понял она немного устарела","Не знаю насколько за вечер, но вот есть подборка",Добавьте вилку или придется удалить
,,,"Вилка 2 раза дифф, полечите ее пожалуйста..."
,,"Вилка 2 раза дифф, полечите ее пожалуйста...","Она не больная, она просто не может быть более узкой. Такие специалисты большая редкость, и при уменьшении вилки резко снизятся шансы, что найдется хотя бы один подходящий кандидат."
,"Вилка 2 раза дифф, полечите ее пожалуйста...","Она не больная, она просто не может быть более узкой. Такие специалисты большая редкость, и при уменьшении вилки резко снизятся шансы, что найдется хотя бы один подходящий кандидат.",Уменьшать вилку можно в сторону поднятия нижней границы
,,,.
,,.,"Зарплатная, а не та что в глаз"
,.,"Зарплатная, а не та что в глаз",Vanishing point не надо считать? Разметку?
.,"Зарплатная, а не та что в глаз",Vanishing point не надо считать? Разметку?,а MPT из pypfopt не так уж плохи. Что думаете? MinVariance работает?)
"Зарплатная, а не та что в глаз",Vanishing point не надо считать? Разметку?,а MPT из pypfopt не так уж плохи. Что думаете? MinVariance работает?),Ну я про реализацию без reinforcement learning
Vanishing point не надо считать? Разметку?,а MPT из pypfopt не так уж плохи. Что думаете? MinVariance работает?),Ну я про реализацию без reinforcement learning,"Более конкретно: я бы очень хотел не упустить того, кому бы можно было бы платить 200к, но намного выше вероятность, что не найдется никого, кому можно было бы платить больше 80. В науке всё-таки денег на зарплаты весьма немного. 

Я понимаю, что тут есть несоответствие правилам, могу, конечно, удалить, тем более что DS вакансия касается довольно косвенно."
а MPT из pypfopt не так уж плохи. Что думаете? MinVariance работает?),Ну я про реализацию без reinforcement learning,"Более конкретно: я бы очень хотел не упустить того, кому бы можно было бы платить 200к, но намного выше вероятность, что не найдется никого, кому можно было бы платить больше 80. В науке всё-таки денег на зарплаты весьма немного. 

Я понимаю, что тут есть несоответствие правилам, могу, конечно, удалить, тем более что DS вакансия касается довольно косвенно.","А что у вас за организация, если не секрет?"
Ну я про реализацию без reinforcement learning,"Более конкретно: я бы очень хотел не упустить того, кому бы можно было бы платить 200к, но намного выше вероятность, что не найдется никого, кому можно было бы платить больше 80. В науке всё-таки денег на зарплаты весьма немного. 

Я понимаю, что тут есть несоответствие правилам, могу, конечно, удалить, тем более что DS вакансия касается довольно косвенно.","А что у вас за организация, если не секрет?",">У нас пока не было никого, кто заработал бы меньше 300к)
>200тыс+. за проведение одного курса
ладно"
"Более конкретно: я бы очень хотел не упустить того, кому бы можно было бы платить 200к, но намного выше вероятность, что не найдется никого, кому можно было бы платить больше 80. В науке всё-таки денег на зарплаты весьма немного. 

Я понимаю, что тут есть несоответствие правилам, могу, конечно, удалить, тем более что DS вакансия касается довольно косвенно.","А что у вас за организация, если не секрет?",">У нас пока не было никого, кто заработал бы меньше 300к)
>200тыс+. за проведение одного курса
ладно","Не знал что для поступления в вуз теперь нужно ml знать
Серьезные у вас абитуриенты"
"А что у вас за организация, если не секрет?",">У нас пока не было никого, кто заработал бы меньше 300к)
>200тыс+. за проведение одного курса
ладно","Не знал что для поступления в вуз теперь нужно ml знать
Серьезные у вас абитуриенты",Говорите как настоящий капиталист!
">У нас пока не было никого, кто заработал бы меньше 300к)
>200тыс+. за проведение одного курса
ладно","Не знал что для поступления в вуз теперь нужно ml знать
Серьезные у вас абитуриенты",Говорите как настоящий капиталист!,я думал уже классифицировать суммаризацию от ллм бертом но еще не тестил
"Не знал что для поступления в вуз теперь нужно ml знать
Серьезные у вас абитуриенты",Говорите как настоящий капиталист!,я думал уже классифицировать суммаризацию от ллм бертом но еще не тестил,Спасибо!
,,,"Ребята, посоветуйте модельку которую просто обучить/дообучить классификации по картинкам? 
Есть задача определять болезнь растения по фото листьев."
,,"Ребята, посоветуйте модельку которую просто обучить/дообучить классификации по картинкам? 
Есть задача определять болезнь растения по фото листьев.",yolovo там ее можно под классификацию обучить
,,,Ну если совсем не париться то в EffNet удобно встроено все для дообучения
,,Ну если совсем не париться то в EffNet удобно встроено все для дообучения,long former
,Ну если совсем не париться то в EffNet удобно встроено все для дообучения,long former,"Resnet, ConvNext"
Ну если совсем не париться то в EffNet удобно встроено все для дообучения,long former,"Resnet, ConvNext",Добрый день! кто-нибудь использовал вокодер на 44 кГц. онлайн пока нашёл только NSFHifigan но по лицензии его нельзя использовать в коммерческих целях
long former,"Resnet, ConvNext",Добрый день! кто-нибудь использовал вокодер на 44 кГц. онлайн пока нашёл только NSFHifigan но по лицензии его нельзя использовать в коммерческих целях,На случай важных переговоров: старый новый способ сказать «Ой все»
,,,Есть задача и решается и на датасете(флот значение и тексты) она решается плохо. Сделал авто фючр инжиниринг через featuretools и получил немного снижение МАЕ на катбусте. Есть какие-то другие бибилотеки или может кто посоветует чтиво?
,,Есть задача и решается и на датасете(флот значение и тексты) она решается плохо. Сделал авто фючр инжиниринг через featuretools и получил немного снижение МАЕ на катбусте. Есть какие-то другие бибилотеки или может кто посоветует чтиво?,"попробую ламу - у нее из коробки поддержка для текстовых фичей, причем для разного вида моделей"
,,,"тексты — это типа одна колонка и там какой-то текст который можно заэмбеддить любой современной nlp моделью?
можно так начать, приконкатить результат к остальным фичам и подать в бустинг"
,,"тексты — это типа одна колонка и там какой-то текст который можно заэмбеддить любой современной nlp моделью?
можно так начать, приконкатить результат к остальным фичам и подать в бустинг","Да, тот самый текст. Текст я засунул в кэтбуст и понаделся на разрабов кэтбуста из яндекса. Ничего зачительно не изменилось. Да и текст лишь малая часть всех признаков, поэтому кажется надо что-то большее"
,"тексты — это типа одна колонка и там какой-то текст который можно заэмбеддить любой современной nlp моделью?
можно так начать, приконкатить результат к остальным фичам и подать в бустинг","Да, тот самый текст. Текст я засунул в кэтбуст и понаделся на разрабов кэтбуста из яндекса. Ничего зачительно не изменилось. Да и текст лишь малая часть всех признаков, поэтому кажется надо что-то большее","Деревья и тексты плохо дружат.

Ищете [your_domain]BERT и делаете с него вектора, конкатенируете с вашим флоатом"
,,,но по сути ты выбираешь модель которая будет эмбедить тексты)
,,,"Это чо, прям генерация??... Если так то отвал башки"
,,"Это чо, прям генерация??... Если так то отвал башки",дорисовка кадра из деревни дураков)
,,,что-то напоминает)))
,,что-то напоминает))),Деревня дураков конечно
,,,Думаю аутпеинт в фотошопе
,,Думаю аутпеинт в фотошопе,Похоже на истину
,,,Сохранил
,,Сохранил,вызываю олдфагов рассудить
,Сохранил,вызываю олдфагов рассудить,outpaint
,,,"Ребята, кто имел дело с моделью Single Shot Detector, подскажите, пожалуйста, ссылки на хорошую и внятную, на ваш взгляд, ее реализацию на Tensorflow 2."
,,"Ребята, кто имел дело с моделью Single Shot Detector, подскажите, пожалуйста, ссылки на хорошую и внятную, на ваш взгляд, ее реализацию на Tensorflow 2.",Так она вроде есть в tensorflow object detection api
,"Ребята, кто имел дело с моделью Single Shot Detector, подскажите, пожалуйста, ссылки на хорошую и внятную, на ваш взгляд, ее реализацию на Tensorflow 2.",Так она вроде есть в tensorflow object detection api,"Смотрел там, не смог разобраться, в разделе моделей , что касается ssd, увидел там только файлы, типа ""ssd_feature_extractor""... Хочется даже не Api, а найти какой-то пример, желательно ноутбук с хорошей технической реализацией, чтобы сопоставить со статьей и понять лучше этот алгоритм."
,,,"Всем привет, такой вопрос. Есть не оцифрованный файл pdf, в котором есть скан таблицы, ну типа обычная excel таблица только в виде скана на бумаге. Можно ли как то экспортнуть ее в excel обычным OCR или нужно придумывать что то кастомное завязанное на сегментировании?"
,,"Всем привет, такой вопрос. Есть не оцифрованный файл pdf, в котором есть скан таблицы, ну типа обычная excel таблица только в виде скана на бумаге. Можно ли как то экспортнуть ее в excel обычным OCR или нужно придумывать что то кастомное завязанное на сегментировании?","Tabula посмотри
Ну я делал пайплайн из ocrmypdf и потом наверх tabula
Большинство таблиц находит и может экспортировать хоть как json хоть как csv"
,,,"Еще вопрос по тем же беспилотным машинкам: есть ли способ собирать данные кроме как самому ездить на машинке и фиксировать угол поворота руля и ее скорость? Да, можно симулировать среду в юнити и обучить RL алгоритм какой-нибудь, но у этого подхода есть проблема: очень сложно симулировать среду такую же, какая есть у конкретной машинки. Подскажите пожалуйста)"
,,"Еще вопрос по тем же беспилотным машинкам: есть ли способ собирать данные кроме как самому ездить на машинке и фиксировать угол поворота руля и ее скорость? Да, можно симулировать среду в юнити и обучить RL алгоритм какой-нибудь, но у этого подхода есть проблема: очень сложно симулировать среду такую же, какая есть у конкретной машинки. Подскажите пожалуйста)","Глава 16, 17 моделирование и создание беспилотных автомобилей. Рассмотрены симуляторы, как готовить данные, обучать и т.д."
,,,"Очень легко сделать симуляцию в GTA5, используя RAGE. Сам в нем набирал искусственный датасет."
,,"Очень легко сделать симуляцию в GTA5, используя RAGE. Сам в нем набирал искусственный датасет.","Есть какой-нибудь гайд как это сделать? Уже давно хочу автопилот сделать для ГТА именно, но не мог найти никакую адекватную информацию в интернете, кроме 6ти летней серии видео sentdex'a"
,"Очень легко сделать симуляцию в GTA5, используя RAGE. Сам в нем набирал искусственный датасет.","Есть какой-нибудь гайд как это сделать? Уже давно хочу автопилот сделать для ГТА именно, но не мог найти никакую адекватную информацию в интернете, кроме 6ти летней серии видео sentdex'a",https://rage-script.com/forums/tutorials/
"Очень легко сделать симуляцию в GTA5, используя RAGE. Сам в нем набирал искусственный датасет.","Есть какой-нибудь гайд как это сделать? Уже давно хочу автопилот сделать для ГТА именно, но не мог найти никакую адекватную информацию в интернете, кроме 6ти летней серии видео sentdex'a",https://rage-script.com/forums/tutorials/,Спасибо
,,,"Датасет то да, но вот у нас такая проблема, что обученная сетка на одной машине например, не работает на другой. Я думаю так же будет и с датасетом, собранным в симуляции"
,,"Датасет то да, но вот у нас такая проблема, что обученная сетка на одной машине например, не работает на другой. Я думаю так же будет и с датасетом, собранным в симуляции","Возможно, хотя именно про машины беспилотные раньше слышал что в GTA обучали"
,"Датасет то да, но вот у нас такая проблема, что обученная сетка на одной машине например, не работает на другой. Я думаю так же будет и с датасетом, собранным в симуляции","Возможно, хотя именно про машины беспилотные раньше слышал что в GTA обучали",Ну у меня машинки из jetracer jetson nano и там решает буквально точность сборки движков китайскими детьми)
,,,"Кто-нибудь развертывал superset в docker?
Superset по умолчанию доступен только для локального входа. Что сделать, чтобы можно было выполнить вход с удаленного пк?"
,,"Кто-нибудь развертывал superset в docker?
Superset по умолчанию доступен только для локального входа. Что сделать, чтобы можно было выполнить вход с удаленного пк?","при запуске суперсета добавляй ""-h 0.0.0.0"". Про докер не уверен, но вне него эт так работало. Возможно, в докере порты еще наружу нужно пробросить"
,"Кто-нибудь развертывал superset в docker?
Superset по умолчанию доступен только для локального входа. Что сделать, чтобы можно было выполнить вход с удаленного пк?","при запуске суперсета добавляй ""-h 0.0.0.0"". Про докер не уверен, но вне него эт так работало. Возможно, в докере порты еще наружу нужно пробросить",Попробую внутри докера перезапустить приложение. Только бы знать как его остановить)
,,,"по информации доступной пусть условно есть +- любая информация, пусть условно все fills"
,,,"видел, не мимо, хороший бейзлайн, но хочется чего-то свежее"
,,"видел, не мимо, хороший бейзлайн, но хочется чего-то свежее",Напишу авторам утром
,,,но надо понимать что времени придется тратить много
,,но надо понимать что времени придется тратить много,"проект можно свой предложить, или работаешь по тем проектам что уже представлены?"
,,,"Скорее всего эта задача не имеет однозначного красивого решения. Сходу видно только как вы будете с openCV детектить линии, потом по ним резать, и эти кусочки отправлять в какой-нибудь python модуль для распознавания, потом каждый кусочек в свою клеточку в Excel."
,,"Скорее всего эта задача не имеет однозначного красивого решения. Сходу видно только как вы будете с openCV детектить линии, потом по ним резать, и эти кусочки отправлять в какой-нибудь python модуль для распознавания, потом каждый кусочек в свою клеточку в Excel.","понял, спасибо большое"
,"Скорее всего эта задача не имеет однозначного красивого решения. Сходу видно только как вы будете с openCV детектить линии, потом по ним резать, и эти кусочки отправлять в какой-нибудь python модуль для распознавания, потом каждый кусочек в свою клеточку в Excel.","понял, спасибо большое",Может ещё что-то скажут комрады
,,,В докере bridge-сеть. С этим все норм.
,,В докере bridge-сеть. С этим все норм.,"Посмотрите deepdoctection, detectron2... но красивого да... Из коробки не оч вероятно что есть"
,В докере bridge-сеть. С этим все норм.,"Посмотрите deepdoctection, detectron2... но красивого да... Из коробки не оч вероятно что есть","Отвечаю как юзер, не как разработчик. Можно открыть в abby finereader и оттуда экспортнуть"
В докере bridge-сеть. С этим все норм.,"Посмотрите deepdoctection, detectron2... но красивого да... Из коробки не оч вероятно что есть","Отвечаю как юзер, не как разработчик. Можно открыть в abby finereader и оттуда экспортнуть","всем спасибо, обязательно попробую всё)"
,,,"Перепиши описание опыта работы и проектов в формате ""Сделал систему для распознавания персонажей симпоснов, точность распознавания по метрике ... составила ...""
В общем классическое достижения, а не обязанности"
,,"Перепиши описание опыта работы и проектов в формате ""Сделал систему для распознавания персонажей симпоснов, точность распознавания по метрике ... составила ...""
В общем классическое достижения, а не обязанности",По такой логике можно написать accuracy = 100.  Это никак не проверить
,"Перепиши описание опыта работы и проектов в формате ""Сделал систему для распознавания персонажей симпоснов, точность распознавания по метрике ... составила ...""
В общем классическое достижения, а не обязанности",По такой логике можно написать accuracy = 100.  Это никак не проверить,"Достоверность информации, указанной в резюме, остаётся на совести соискателя :)"
,,,"При стабильной доходности 23% в мес по-моему легко взять кредиты или по нетворкингу пробежаться, где тебя люди знают и меньше сил потратят на проверку стратегии. При этом у хозяина стратегии должно быть меньше 100к баксов, например, поэтому ему лень сложным процентом копить со своих активов. 

Так что я бы сомневался."
,,"При стабильной доходности 23% в мес по-моему легко взять кредиты или по нетворкингу пробежаться, где тебя люди знают и меньше сил потратят на проверку стратегии. При этом у хозяина стратегии должно быть меньше 100к баксов, например, поэтому ему лень сложным процентом копить со своих активов. 

Так что я бы сомневался.","И вообще я не про это писал. Он же посчитал какие-то метрики наверняка, когда тренил модельку? В самом процессе тренировки нет ничего интересного, важен конечный результат
Посмотри clrnet для детекции линий, но возможно не влезет в твою карточку, смотря какая у тебя ""средняя""
И ещё недавно вышла CLRERnet или что-то такое"
,,,"Интересно было бы сравнить все эти lane detectoin с тем, что есть у Теслы. Они, насколько я понимаю, на картинках вообще ничего не детектируют и не сегментируют, а работают в своём пространстве"
,,"Интересно было бы сравнить все эти lane detectoin с тем, что есть у Теслы. Они, насколько я понимаю, на картинках вообще ничего не детектируют и не сегментируют, а работают в своём пространстве",В каком? По радару?
,"Интересно было бы сравнить все эти lane detectoin с тем, что есть у Теслы. Они, насколько я понимаю, на картинках вообще ничего не детектируют и не сегментируют, а работают в своём пространстве",В каком? По радару?,"Было в Тесла AI Day 2021. Раньше они работали по каждой камере индивидуально, а потом объединяли результаты. Теперь по всем камерам они делают некое своё 3D пространство (похоже на Nerf), в котором уже делают детекцию. То есть не по картинкам, а по 3D выходу другой сети. И это им сильно повысило качество"
,,,"Мне говорили, что в серийных автопилотах вообще все на классике построено
Но у меня на машине настолько хорошо работает, что я слабо в это верю"
,,"Мне говорили, что в серийных автопилотах вообще все на классике построено
Но у меня на машине настолько хорошо работает, что я слабо в это верю",Скорее комбинация классика(одометрия) + нейронки(сегментация и детекции)
,,,"Всем привет!
Кто-то знает, какие используют LLMs для написания/анализа кода?
Python, Go, C++ - можно разные под разные языки, искал инфу и такого чё-то не нашёл"
,,"Всем привет!
Кто-то знает, какие используют LLMs для написания/анализа кода?
Python, Go, C++ - можно разные под разные языки, искал инфу и такого чё-то не нашёл",Для написания есть starcoder
,,,You need to be an admin to do this.
,,You need to be an admin to do this.,"Всем привет. 
Я тут за свежими идеями, так как испытываю проблемы на новом месте. 
Контора маленькая, развернуть инфру не очень получается пока что. 

У меня данные -снимки под детекцию. Много разных типов, плюс их будут ""Как-то"" Кропать, что отдельный датасет. 
И хотя у меня они пока что собраны вручную, папка data в проекте раздулась неприлично и там бардак. 

Как по хорошему версировать данные? 
Допустим, их у меня три типа по папкам, один из этих типов кропается не так, как другие, и нужна собрать из этого один сет с выделением тестовой выборки. 

 Пока что я собираюсь делать это отчасти вручную, отчасти автоматизирует в коде. 
Но если есть понятный алгоритм с dvc либо какой нибудь репозиторий с примерами, было бы круто. 

Dvc пользоваться умею, но пока не очень ясно, как его применить.
Точнее мне нужен настраиваемый пайплайн обработки и подготовки обучающих выборок. 

Или придётся самому писать?)
Очень вкусно. Спасибо"
,,,"Всем привет. Вопрос по freqtrade / freqai. 
В документации часто повторяется фраза For each pair in the whitelist, …

Таким образом, я понимаю как работать с каждой парой независимо.
Есть ли встроенные возможности обрабатывать сразу несколько пар одновременно?

То есть хотелось бы перед началом цикла получить очередной батч данных сразу по всем парам из whitelist, провести анализ, сохранить его результаты в память тем или иным образом;
Уже после этого в цикле проходить по парам и писать кастомные populate_entry_trend, populate_exit_trend (с доступом к данным из предыдущего шага)"
,,"Всем привет. Вопрос по freqtrade / freqai. 
В документации часто повторяется фраза For each pair in the whitelist, …

Таким образом, я понимаю как работать с каждой парой независимо.
Есть ли встроенные возможности обрабатывать сразу несколько пар одновременно?

То есть хотелось бы перед началом цикла получить очередной батч данных сразу по всем парам из whitelist, провести анализ, сохранить его результаты в память тем или иным образом;
Уже после этого в цикле проходить по парам и писать кастомные populate_entry_trend, populate_exit_trend (с доступом к данным из предыдущего шага)","Вроде как можно подгрузить кастомные пары в начале. Но в этом проблема freqtrade, изначальная логика бота была проста, а дальше разработчики пытались расширить функционал дополнительными костылями."
,"Всем привет. Вопрос по freqtrade / freqai. 
В документации часто повторяется фраза For each pair in the whitelist, …

Таким образом, я понимаю как работать с каждой парой независимо.
Есть ли встроенные возможности обрабатывать сразу несколько пар одновременно?

То есть хотелось бы перед началом цикла получить очередной батч данных сразу по всем парам из whitelist, провести анализ, сохранить его результаты в память тем или иным образом;
Уже после этого в цикле проходить по парам и писать кастомные populate_entry_trend, populate_exit_trend (с доступом к данным из предыдущего шага)","Вроде как можно подгрузить кастомные пары в начале. Но в этом проблема freqtrade, изначальная логика бота была проста, а дальше разработчики пытались расширить функционал дополнительными костылями.",Спасибо
,,,"Кстати, так как бот популярный и довольно старый, chatgpt по нему не плохо ориентируется и хорошо отвечает по вопросам связанным с ним.
Недавно нужно было протестировать гипотезу, достаточно быстро с помощью chatgpt во freqtrade её имплементировал."
,,,"Ищу специалиста для консультации в детекции и классификации (train в pytorch + экспорт в onnx), готов оплатить консультацию. По итогу мне нужно понимание какую архитектуру взять и какой код для нее использовать чтобы это работало. Сейчас из рабочего что нашел только darknet и ultralitycs из коробки работают по документации, всё остальное нужно костылить. Хочется найти что то качественное и открытое для использования."
,,"Ищу специалиста для консультации в детекции и классификации (train в pytorch + экспорт в onnx), готов оплатить консультацию. По итогу мне нужно понимание какую архитектуру взять и какой код для нее использовать чтобы это работало. Сейчас из рабочего что нашел только darknet и ultralitycs из коробки работают по документации, всё остальное нужно костылить. Хочется найти что то качественное и открытое для использования.","Пиши в личку, бесплатно подскажу если соображу)"
,,,"Или сюда, если нечувствительно"
,,"Или сюда, если нечувствительно","Привет всем
Torchtext пытаюсь установить на локалке в ноуте, но не получается
Может ли быть такое что это из-за не совместимости с чипом M1 ?"
,,,"Привет! Хочу потестить map_rerank подход, задача заставить модель возвращать вместе с ответом на вопрос оценку ответа от 0 до 100. ChatGPT это делает без проблем, но вот для рксских LLM никак не подберу нужный промпт :( 

Может есть у кого опыт? Интересуют русские модели, сейчас конкретно Siberian Fred-T5-large"
,,"Привет! Хочу потестить map_rerank подход, задача заставить модель возвращать вместе с ответом на вопрос оценку ответа от 0 до 100. ChatGPT это делает без проблем, но вот для рксских LLM никак не подберу нужный промпт :( 

Может есть у кого опыт? Интересуют русские модели, сейчас конкретно Siberian Fred-T5-large",вот так?
,,,"Возможно saiga 7б умеет, но вообще все текущие модели сильно маловаиы"
,,"Возможно saiga 7б умеет, но вообще все текущие модели сильно маловаиы","Не, она слишком тупая."
,"Возможно saiga 7б умеет, но вообще все текущие модели сильно маловаиы","Не, она слишком тупая.",Не факт
,,,Попробуйте llama2 chat
,,Попробуйте llama2 chat,Ну 70б ллама точно потянет
,Попробуйте llama2 chat,Ну 70б ллама точно потянет,"Понял, спасибо) Ну мне еще что-то полегче хотелось, так что видимо буду альтернативы искать"
Попробуйте llama2 chat,Ну 70б ллама точно потянет,"Понял, спасибо) Ну мне еще что-то полегче хотелось, так что видимо буду альтернативы искать",Их довольно много и у опен АИ есть апи
,,,"О, над будет глянуть, а есть какие-нибудь без регистрации и кода? А то нужно ньюслеттеры еженедельные делать о том как АИ делает мир  аишней, а текст2покемон имадж2мем уже заканчиваются а недели нет :("
,,"О, над будет глянуть, а есть какие-нибудь без регистрации и кода? А то нужно ньюслеттеры еженедельные делать о том как АИ делает мир  аишней, а текст2покемон имадж2мем уже заканчиваются а недели нет :(","Как насчет просто пересказывать этого чела 

https://youtu.be/j-HCBPhmMc4"
,,,"вот кстати мемоген нашёл
он прям добротный на blip+gpt..."
,,"вот кстати мемоген нашёл
он прям добротный на blip+gpt...","Ты за людей не решай, а пости нормальное с пояснениями насколько это круто. То, что очередная приложенька построенная вокруг промпта к чатгпт апи это фуфел, люди и так просигнализируют отписками. 

Всякий тиктоктвиттер bycloud  тоже покрывает хотя его чаще уносит на пересказ пейперов конечно"
,"вот кстати мемоген нашёл
он прям добротный на blip+gpt...","Ты за людей не решай, а пости нормальное с пояснениями насколько это круто. То, что очередная приложенька построенная вокруг промпта к чатгпт апи это фуфел, люди и так просигнализируют отписками. 

Всякий тиктоктвиттер bycloud  тоже покрывает хотя его чаще уносит на пересказ пейперов конечно","Можно ocr движок другой использовать, там в базе tesseract"
,,,"Подскажите плиз, что-либо сравнимое с colab, только с возможностью оплаты из РФ. Yandex'овский сервис смотрел, запутано и дорого. Jetbrains смотрел, вроде тоже не совсем то. Надо чтобы бахнул N и неделю учи модельку"
,,"Подскажите плиз, что-либо сравнимое с colab, только с возможностью оплаты из РФ. Yandex'овский сервис смотрел, запутано и дорого. Jetbrains смотрел, вроде тоже не совсем то. Надо чтобы бахнул N и неделю учи модельку",Datasphere dedicated от Яндекса думаю единственное решение
,"Подскажите плиз, что-либо сравнимое с colab, только с возможностью оплаты из РФ. Yandex'овский сервис смотрел, запутано и дорого. Jetbrains смотрел, вроде тоже не совсем то. Надо чтобы бахнул N и неделю учи модельку",Datasphere dedicated от Яндекса думаю единственное решение,Далековато от колаба по функционалу и по тарификация
"Подскажите плиз, что-либо сравнимое с colab, только с возможностью оплаты из РФ. Yandex'овский сервис смотрел, запутано и дорого. Jetbrains смотрел, вроде тоже не совсем то. Надо чтобы бахнул N и неделю учи модельку",Datasphere dedicated от Яндекса думаю единственное решение,Далековато от колаба по функционалу и по тарификация,Я рекомендую наконец сделать иностранную карту и не мучиться
Datasphere dedicated от Яндекса думаю единственное решение,Далековато от колаба по функционалу и по тарификация,Я рекомендую наконец сделать иностранную карту и не мучиться,"Идея хорошая, но тут как у кота Матроскина дилемма. Что написать ""большую красную кнопку сто миллионов мне в оффшор"", нужен оффшор. Ладно, шучу.

Тут законы у нас не самые простые, но впрочем похоже на единственный выход, да"
,,,vast ai вроде обычно советуют
,,vast ai вроде обычно советуют,vast без оплаты из рф
,,,"Но я хз, как там сейчас с оплатой ру картами
Ищи мб где киви можно оплатить"
,,"Но я хз, как там сейчас с оплатой ру картами
Ищи мб где киви можно оплатить","Ох, а я только было дело обрадовался"
,,,"Коллеги, а если я учу кросс энкодер (text1, text2, label) и у меня дефолтный токенайзер модели не отдает token_type_ids, критично ли это или просто модели после Берта научились и без них справляться?"
,,"Коллеги, а если я учу кросс энкодер (text1, text2, label) и у меня дефолтный токенайзер модели не отдает token_type_ids, критично ли это или просто модели после Берта научились и без них справляться?",У меня RoBERTA вполне выучивалась чисто по [sep]-токену два текста различать.
,,,В тиньке можно вроде оформить карту казахского банка удаленно за 5к
,,В тиньке можно вроде оформить карту казахского банка удаленно за 5к,"Спасибо, вариант"
,,,"> Cтартап использует девайс в форме шара для сканирования глаз людей в обмен на криптовалюту

Даже тут круглые тензоры..."
,,"> Cтартап использует девайс в форме шара для сканирования глаз людей в обмен на криптовалюту

Даже тут круглые тензоры...","Если очень долго замешивать, то можно говорить «вы не поверите, но это кандинский»"
,"> Cтартап использует девайс в форме шара для сканирования глаз людей в обмен на криптовалюту

Даже тут круглые тензоры...","Если очень долго замешивать, то можно говорить «вы не поверите, но это кандинский»",верю
"> Cтартап использует девайс в форме шара для сканирования глаз людей в обмен на криптовалюту

Даже тут круглые тензоры...","Если очень долго замешивать, то можно говорить «вы не поверите, но это кандинский»",верю,"точно, надо поразвлекаться с тем, какие надписи они на японском генерируют. (про китайский не смогу ничего сказать 😞
предсказуемо. бредятина"
,,,lucid dream texts )
,,lucid dream texts ),"плитка не собянинская, не верю!"
,lucid dream texts ),"плитка не собянинская, не верю!","Всем привет! Подскажите пожалуйста, какие примерно (по очень грубой оценке) вычислительные ресурсы могут потребоваться, чтобы зафайнтьюнить llama 2 (7В или 13В) под свою небольшую задачу"
lucid dream texts ),"плитка не собянинская, не верю!","Всем привет! Подскажите пожалуйста, какие примерно (по очень грубой оценке) вычислительные ресурсы могут потребоваться, чтобы зафайнтьюнить llama 2 (7В или 13В) под свою небольшую задачу",с LoRА хватит одной T4
,,,"Здравствуйте господа NLPисты.
Подскажите пожалуйста, были ли какие-то попытки натаскать языковую модель на поиск по гитхабу, чтобы получить что-то вроде chat-gpt заточенного конкретно под репозитории?
Чтобы можно было спросить: ""дорогой гит-чат, скажи мне пожалуйста какие есть решения для анимации рыжих котиков в дополненной реальности на вреймвёке radcat на языке Moo"""
,,"Здравствуйте господа NLPисты.
Подскажите пожалуйста, были ли какие-то попытки натаскать языковую модель на поиск по гитхабу, чтобы получить что-то вроде chat-gpt заточенного конкретно под репозитории?
Чтобы можно было спросить: ""дорогой гит-чат, скажи мне пожалуйста какие есть решения для анимации рыжих котиков в дополненной реальности на вреймвёке radcat на языке Moo""","Полагаю, если решать эту задачу чисто генеративно, модель будет регулярно выдумывать несуществующие репозитории. Ну и при добавлении или существенном обновлении репозиториев модель будет устаревать и требовать дообучения.

Поэтому лично я бы для этой задачи использовал бы retrieval решение. А если очень хочется использовать трансформеры, можно их использовать как энкодеры для запросов и для документов, то есть текстов репо (для простоты можно только readme индексировать для начала).

Обучающую выборку для энкодера можно набрать например со stackoverflow (запрос - заголовок и теги вопроса, таргет - упоминающийся в ответе url с гитхаба), а потом обученным таким образом энкодером заиндексирвоать все репо в гитхабе и регулярно этот индекс обновлять (энкодер при этом дообучать не обязательно).

Ну а в качестве бейзлайна можно вообще ничего не обучать, а просто elastic поднять над собранными readme репозиториев)"
,"Здравствуйте господа NLPисты.
Подскажите пожалуйста, были ли какие-то попытки натаскать языковую модель на поиск по гитхабу, чтобы получить что-то вроде chat-gpt заточенного конкретно под репозитории?
Чтобы можно было спросить: ""дорогой гит-чат, скажи мне пожалуйста какие есть решения для анимации рыжих котиков в дополненной реальности на вреймвёке radcat на языке Moo""","Полагаю, если решать эту задачу чисто генеративно, модель будет регулярно выдумывать несуществующие репозитории. Ну и при добавлении или существенном обновлении репозиториев модель будет устаревать и требовать дообучения.

Поэтому лично я бы для этой задачи использовал бы retrieval решение. А если очень хочется использовать трансформеры, можно их использовать как энкодеры для запросов и для документов, то есть текстов репо (для простоты можно только readme индексировать для начала).

Обучающую выборку для энкодера можно набрать например со stackoverflow (запрос - заголовок и теги вопроса, таргет - упоминающийся в ответе url с гитхаба), а потом обученным таким образом энкодером заиндексирвоать все репо в гитхабе и регулярно этот индекс обновлять (энкодер при этом дообучать не обязательно).

Ну а в качестве бейзлайна можно вообще ничего не обучать, а просто elastic поднять над собранными readme репозиториев)","Надо сказать сам я тоже это видел каким-то похожим образом. Чувствую мой экскурс в работу с языком обещает быть интересным. 

Но все же не могу поверить, что никто до сих пор не пытался."
"Здравствуйте господа NLPисты.
Подскажите пожалуйста, были ли какие-то попытки натаскать языковую модель на поиск по гитхабу, чтобы получить что-то вроде chat-gpt заточенного конкретно под репозитории?
Чтобы можно было спросить: ""дорогой гит-чат, скажи мне пожалуйста какие есть решения для анимации рыжих котиков в дополненной реальности на вреймвёке radcat на языке Moo""","Полагаю, если решать эту задачу чисто генеративно, модель будет регулярно выдумывать несуществующие репозитории. Ну и при добавлении или существенном обновлении репозиториев модель будет устаревать и требовать дообучения.

Поэтому лично я бы для этой задачи использовал бы retrieval решение. А если очень хочется использовать трансформеры, можно их использовать как энкодеры для запросов и для документов, то есть текстов репо (для простоты можно только readme индексировать для начала).

Обучающую выборку для энкодера можно набрать например со stackoverflow (запрос - заголовок и теги вопроса, таргет - упоминающийся в ответе url с гитхаба), а потом обученным таким образом энкодером заиндексирвоать все репо в гитхабе и регулярно этот индекс обновлять (энкодер при этом дообучать не обязательно).

Ну а в качестве бейзлайна можно вообще ничего не обучать, а просто elastic поднять над собранными readme репозиториев)","Надо сказать сам я тоже это видел каким-то похожим образом. Чувствую мой экскурс в работу с языком обещает быть интересным. 

Но все же не могу поверить, что никто до сих пор не пытался.","Пытались, конечно. Были даже соревнования по задаче Code Search / Code Retrieval.

По этой, как и по любой другой задаче NLP, можно начинать искать примеры решений тут: https://paperswithcode.com/task/code-search"
,,,"Мне кажется смешно
Без обработки
Идеологически верней для нас не давать людям токены за то, что они на нас смотрят (а ведь по сути это и происходит), а обращать на них внимание если у них есть немного сатоши в их бикоин-кошельке, которым (его тайным ключом) они подписывают свой контент.  Но эксплуататоры так не думают :-$"
,,,"Всем привет. 
Стоит задача получения сущностей из файла, полученного OCR.

Насколько понимаю, мои средства - это какая-то BERT-то подобная модель, желательно, с русским языком (только ли?). Важно, что метки данных нужны кастомные (персона, организация и т.п. из дефолтной не подойдут).

Правильно ли полагаю, что следует выбрать Берт, возможно rubert (или что-то иное из зоопарка DeepPavlov), причем без файнтюна, чтобы самому сделать его на размеченных моими метками данных? 

Доп. вопросы: 
1) что именно из этих бертов та самая ""базовая модель"", которую следует брать для файнтюна?
2) Можно ли для этой цели использовать генеративный подход, в частности, например, новую ллм от сбера?
Заранее спасибо."
,,"Всем привет. 
Стоит задача получения сущностей из файла, полученного OCR.

Насколько понимаю, мои средства - это какая-то BERT-то подобная модель, желательно, с русским языком (только ли?). Важно, что метки данных нужны кастомные (персона, организация и т.п. из дефолтной не подойдут).

Правильно ли полагаю, что следует выбрать Берт, возможно rubert (или что-то иное из зоопарка DeepPavlov), причем без файнтюна, чтобы самому сделать его на размеченных моими метками данных? 

Доп. вопросы: 
1) что именно из этих бертов та самая ""базовая модель"", которую следует брать для файнтюна?
2) Можно ли для этой цели использовать генеративный подход, в частности, например, новую ллм от сбера?
Заранее спасибо.","1) Если хочется что-то дообучить, то можно действительно посмотреть в сторону моделей, которые знают русский. Помимо rubert могу еще предложить xlmroberta. В скрипты из hf можно при желании добавить лосс на crf.
2) Можно генеративно, и в последнее время кстати уже множество задач решается именно так. Если есть доступ к какой-то ллм, типа chatgpt, можно базовые промты попробовать. А можно даже верификацию добавить сверху, как в https://github.com/ShuheWang1998/GPT-NER/tree/main
В теории можно и свою модель на каком-нибудь mbart или rugpt+ зафайнтюнить, но я бы посоветовал лучше начинать со стандартной нер постановки задачи"
,,,"Привет! Не знаю, сюда ли с этим вопросом, но вдруг подскажете: знаете годные курсы по MLOps, не растянутые на полгода, куда можно просто взять и отправить сотрудников?"
,,"Привет! Не знаю, сюда ли с этим вопросом, но вдруг подскажете: знаете годные курсы по MLOps, не растянутые на полгода, куда можно просто взять и отправить сотрудников?","Вот ссылка
https://ods.ai/tracks/ml-in-production-spring-23"
,"Привет! Не знаю, сюда ли с этим вопросом, но вдруг подскажете: знаете годные курсы по MLOps, не растянутые на полгода, куда можно просто взять и отправить сотрудников?","Вот ссылка
https://ods.ai/tracks/ml-in-production-spring-23",спасибо!
,,,"Только что закончились
Ну и если копаться дальше, то там всякие материалы вылезут по пути."
,,,"А кто-то баловался компьютерным зрением не через камеры, а через лидары?"
,,"А кто-то баловался компьютерным зрением не через камеры, а через лидары?","Знакомые делают проект, где через лидары контроль периметра осуществляется 
А в чём вопрос ?"
,"А кто-то баловался компьютерным зрением не через камеры, а через лидары?","Знакомые делают проект, где через лидары контроль периметра осуществляется 
А в чём вопрос ?",Слэм? Не очень понятен вектор движения с чудесным облаком точек. Почитать толком нечего
"А кто-то баловался компьютерным зрением не через камеры, а через лидары?","Знакомые делают проект, где через лидары контроль периметра осуществляется 
А в чём вопрос ?",Слэм? Не очень понятен вектор движения с чудесным облаком точек. Почитать толком нечего,"в Open3d есть маленькие туториалы, но в общем и целом концепция облака точек не сложная, поэтом я бы про конкретную задачу читал копал спрашивал"
"Знакомые делают проект, где через лидары контроль периметра осуществляется 
А в чём вопрос ?",Слэм? Не очень понятен вектор движения с чудесным облаком точек. Почитать толком нечего,"в Open3d есть маленькие туториалы, но в общем и целом концепция облака точек не сложная, поэтом я бы про конкретную задачу читал копал спрашивал","А к росу он прикручивается?

Конкретно хочу понять, как для роса пишут на питоне, делают пакеты и заставляют все крутиться."
Слэм? Не очень понятен вектор движения с чудесным облаком точек. Почитать толком нечего,"в Open3d есть маленькие туториалы, но в общем и целом концепция облака точек не сложная, поэтом я бы про конкретную задачу читал копал спрашивал","А к росу он прикручивается?

Конкретно хочу понять, как для роса пишут на питоне, делают пакеты и заставляют все крутиться.","Прикрутить можно все, что угодно, через dds"
,,,"Ну смотря насколько все сложно находить эти сущности
Если нужен чуть более продвинутый аналог регулярок, то можно и spacy использовать, и BERT будет оверклеймом наверное"
,,,"Всем привет, а какие сейчас SOTA по разделению уже готовых треков на дорожки? Например, разделить трек на барабаны, бас, вокал/волальные партии, гитары, клавиши и т.д.? Вроде уже видел где-то демки год назад наверное, но не могу даже вспомнить названия"
,,"Всем привет, а какие сейчас SOTA по разделению уже готовых треков на дорожки? Например, разделить трек на барабаны, бас, вокал/волальные партии, гитары, клавиши и т.д.? Вроде уже видел где-то демки год назад наверное, но не могу даже вспомнить названия","Морда называется ultimate voice remover, она умеет несколько моделей качать разных (три типа, я забыл все названия, одна тож меты, и две других) и запускать. А так же есть audio-webui - тоже модели разделения  и в прошлый раз я смотрел, были два генератора, audiocraft и ещё какой то + tts (зачем я и ставил) с обучением голосу."
,,,"Всем привет)
Можете подсказать годные курсы по ДС(окончила яп, но не уверена в полученных знаниях и хочу дальше изучать эту сферу)"
,,"Всем привет)
Можете подсказать годные курсы по ДС(окончила яп, но не уверена в полученных знаниях и хочу дальше изучать эту сферу)","Англоязычный ютуб, вэлком. Документация + кагл + хаки + ВШЭ"
,"Всем привет)
Можете подсказать годные курсы по ДС(окончила яп, но не уверена в полученных знаниях и хочу дальше изучать эту сферу)","Англоязычный ютуб, вэлком. Документация + кагл + хаки + ВШЭ",Спасибо
,,,"Гляну. Спасибо!
Кстати. Знаю, в колаб прикручивают гпт для объяснения кода. Так что мысль с трансформерами может быть интересной на поздних этапах"
,,,"Привет, коллеги! Не могу найти, но помню, что точно был какой-то датасет с языками России (например, бурятский, мордовский и т. д.). У кого-нибудь есть ссылка на него?"
,,"Привет, коллеги! Не могу найти, но помню, что точно был какой-то датасет с языками России (например, бурятский, мордовский и т. д.). У кого-нибудь есть ссылка на него?","https://github.com/kod-odin/lang-tasks/wiki/3.-%D0%9A%D0%BE%D1%80%D0%BF%D1%83%D1%81-%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D1%85-%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2#%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BD%D1%8B%D0%B5-%D0%BA%D0%BE%D1%80%D0%BF%D1%83%D1%81%D0%B0-%D0%BD%D0%B0-hugging-face
если про параллельные корпуса речь, то тут башкирский, марийский и чувашский.
так же можно пингануть @averkij по поводу бурятского"
,,,Спасибо!
,,Спасибо!,"Всем привет! Делаю мультилейбл-мультиголовую модель action recognition, сделал отдельно голову для каждого лейбла и bce лосс. Есть ли какие-то подходы хорошие в этой задаче? Например объединить выходы голов и добавить еще один общий лосс и т.д?"
,,,Рос это?
,,Рос это?,Это ось для роботов.)
,,,"Всем привет! Работаю над одной задачей: по фотографиям пользователя понять, что он за человек такой (какие у него хобби, есть ли друзья или домашние питомцы и прочую информацию, которую только можно получить из фото). Я так понимаю, что лучше использовать модели, которые генерируют текстовое описание фотографии. Подскажите, пожалуйста, что можно почитать по этой теме, какие модели посмотреть? 

пс. С видео предстоит подобная задача, если сможете и в этом направлении подсказать, буду благодарна x2 ахаха"
,,"Всем привет! Работаю над одной задачей: по фотографиям пользователя понять, что он за человек такой (какие у него хобби, есть ли друзья или домашние питомцы и прочую информацию, которую только можно получить из фото). Я так понимаю, что лучше использовать модели, которые генерируют текстовое описание фотографии. Подскажите, пожалуйста, что можно почитать по этой теме, какие модели посмотреть? 

пс. С видео предстоит подобная задача, если сможете и в этом направлении подсказать, буду благодарна x2 ахаха","Это похоже на приложение, которое определяло твой этническую принадлежность по фото, но сложнее
По-хорошему, извлекайте эмбеддинги из ваших фото какой-нибудь хорошей моделькой, а затем делать мультиклассовую классификацию на этих эмбеддингах
Правда всё равно звучит очень прохладно"
,,,или мб кто посоветует норм инструмент для генерации синтетических изображений на своем датасете который можно в коллабе дообучить и запускать
,,или мб кто посоветует норм инструмент для генерации синтетических изображений на своем датасете который можно в коллабе дообучить и запускать,"Либо что-нибудь на бустингах, но используя чек-лист в качестве фичей 
Наличие очков, цвет глаз, волос, одежда, поза и т.д"
,,,То есть любой скрипт на питоне можно забилдить как библиотеку?
,,То есть любой скрипт на питоне можно забилдить как библиотеку?,"практически, много чего можно оборачивать и запускать"
,То есть любой скрипт на питоне можно забилдить как библиотеку?,"практически, много чего можно оборачивать и запускать","Ок, спасибо"
,,,"Привет! А подскажите, пожалуйста, есть ли какой-нибудь актуальный список вопросов по ML/DL для собесов? Например, по C++ есть 400 вопросов для джунов/миддлов/сеньоров и хотелось бы что-то такое же, но по ML. Беглый поиск чего-то интересного не дал("
,,"Привет! А подскажите, пожалуйста, есть ли какой-нибудь актуальный список вопросов по ML/DL для собесов? Например, по C++ есть 400 вопросов для джунов/миддлов/сеньоров и хотелось бы что-то такое же, но по ML. Беглый поиск чего-то интересного не дал(","Привет! Я думаю, что все зависит от позиции. Есть же по сути базовые вопросы, касаемые общего понимания ML и углубленные по направлениям (ранжирование, рекомендательные системы, NLP и др.)"
,,,"Пни чатгпт, он тебе хоть 400, хоть 4000 вопросов выдаст"
,,"Пни чатгпт, он тебе хоть 400, хоть 4000 вопросов выдаст",Там устаревшие немного варианты будут
,,,"были какие-то книжки типа deep learning interviews
хз насколько они валидны"
,,,Гугли ros subscriber publisher
,,Гугли ros subscriber publisher,"В принципе, понятно. Лишь бы название файла билось с именем пакета. 

Ток непонятна зависимость исправной работы воркспейса от окружения питона. 

Рос же любит плюсы и свои пакеты, а для чистого кода под питон нужно будет костыль делать. 

Посмотрю примеры, мб понятнее станет"
,Гугли ros subscriber publisher,"В принципе, понятно. Лишь бы название файла билось с именем пакета. 

Ток непонятна зависимость исправной работы воркспейса от окружения питона. 

Рос же любит плюсы и свои пакеты, а для чистого кода под питон нужно будет костыль делать. 

Посмотрю примеры, мб понятнее станет","Возможно я неправильно понял тебя, питон пакет делаешь как обычно. Рос ставишь отдельным пакетом
Можно сделать запускатор, где сорсишься на рос и потом вызываешь свой сабскрайбер"
Гугли ros subscriber publisher,"В принципе, понятно. Лишь бы название файла билось с именем пакета. 

Ток непонятна зависимость исправной работы воркспейса от окружения питона. 

Рос же любит плюсы и свои пакеты, а для чистого кода под питон нужно будет костыль делать. 

Посмотрю примеры, мб понятнее станет","Возможно я неправильно понял тебя, питон пакет делаешь как обычно. Рос ставишь отдельным пакетом
Можно сделать запускатор, где сорсишься на рос и потом вызываешь свой сабскрайбер","Спасибо. 

Скорее всего, я ещё не так хорошо разобрался в росе, чтоб это понять"
,,,"Постпроцессишь выход сетки и готово, можно пересылать"
,,"Постпроцессишь выход сетки и готово, можно пересылать","Всем привет, кто то работал с библиотекой для инференса моделей на unity - barracuda? Сам инференс быстрый вроде, а вот когда данные с тензора берешь, то  это занимает много времени, критично для мобилки"
,"Постпроцессишь выход сетки и готово, можно пересылать","Всем привет, кто то работал с библиотекой для инференса моделей на unity - barracuda? Сам инференс быстрый вроде, а вот когда данные с тензора берешь, то  это занимает много времени, критично для мобилки","с библиотекой не работал, но по общему описанию есть подозрение, что тензор перекладывается с cpu на gpu (на мобилках это очень ощутимо)"
,,,"Да, проблема в этом, если смотреть через профайлер, только там с gpu на cpu"
,,"Да, проблема в этом, если смотреть через профайлер, только там с gpu на cpu","ну тут тогда остается разве что учиться не перекладывать без крайней необходимости. По описанию либы, она инференс умеет делать и на том и на том"
,,,"Очень интересно, но может есть результат не в твиттере? Я даже не знаю как им пользоваться"
,,"Очень интересно, но может есть результат не в твиттере? Я даже не знаю как им пользоваться",Вот
,"Очень интересно, но может есть результат не в твиттере? Я даже не знаю как им пользоваться",Вот,А какой тип данных и какая задача?
"Очень интересно, но может есть результат не в твиттере? Я даже не знаю как им пользоваться",Вот,А какой тип данных и какая задача?,там разные табличные датасеты из статьи: https://arxiv.org/abs/2207.08815 (Why do tree-based models still outperform deep learning on tabular data?)
Вот,А какой тип данных и какая задача?,там разные табличные датасеты из статьи: https://arxiv.org/abs/2207.08815 (Why do tree-based models still outperform deep learning on tabular data?),They still outperform cause too few people still use NNs for tabular data
,,,"А, надо было залогиниться"
,,"А, надо было залогиниться","Не могу просто продвинуться уже 3 дня, не могу просто засунуть матрицу афинных в торч, все уже перерыл, не пашет
Но задача подобная точно решалась, мб паршиво ищу"
,"А, надо было залогиниться","Не могу просто продвинуться уже 3 дня, не могу просто засунуть матрицу афинных в торч, все уже перерыл, не пашет
Но задача подобная точно решалась, мб паршиво ищу",Просто дальше постпроцессинг надо делать с данных с тензора
,,,Ты именно обучаешь с 0 на 3к семплах или тюнишь?
,,Ты именно обучаешь с 0 на 3к семплах или тюнишь?,"С нуля, там есть только обученная на imagenetе большого размера модель, которая не влезает в память гпу на колабе при дообучении"
,,,"Привет! Буду благодарен, если кто-то сможет подсказать как лучше подойти к этой задаче.

Задача следующая:
Есть тексты на английском языке. Нужно в них расставить пунктуацию примерно по правилам русского языка - то есть между всеми простыми предложениями в составе сложного, обрамить причастные / деепричастные обороты (вернее participle constructions) запятыми. Ну или сделать хотя бы одно действие из этих двух

Например (не из датасета, для иллюстрации)
One boy goes to London, and one girl goes to New York
One boy goes to London, being very sad, because his cat is not with him"
,,"Привет! Буду благодарен, если кто-то сможет подсказать как лучше подойти к этой задаче.

Задача следующая:
Есть тексты на английском языке. Нужно в них расставить пунктуацию примерно по правилам русского языка - то есть между всеми простыми предложениями в составе сложного, обрамить причастные / деепричастные обороты (вернее participle constructions) запятыми. Ну или сделать хотя бы одно действие из этих двух

Например (не из датасета, для иллюстрации)
One boy goes to London, and one girl goes to New York
One boy goes to London, being very sad, because his cat is not with him","Первое, что приходит в голову: 1) если есть данные, дообучить seq2seq; 2) если без данных, то попробовать формализовать правила над дискурсивными rst (или синтаксическими) деревьями"
,"Привет! Буду благодарен, если кто-то сможет подсказать как лучше подойти к этой задаче.

Задача следующая:
Есть тексты на английском языке. Нужно в них расставить пунктуацию примерно по правилам русского языка - то есть между всеми простыми предложениями в составе сложного, обрамить причастные / деепричастные обороты (вернее participle constructions) запятыми. Ну или сделать хотя бы одно действие из этих двух

Например (не из датасета, для иллюстрации)
One boy goes to London, and one girl goes to New York
One boy goes to London, being very sad, because his cat is not with him","Первое, что приходит в голову: 1) если есть данные, дообучить seq2seq; 2) если без данных, то попробовать формализовать правила над дискурсивными rst (или синтаксическими) деревьями","Голосую за 2) или за (3) какой-нибудь sequence tagger, предсказывающий для каждого токена, должна ли после него быть запятая.

Seq2seq и работать будет не супер быстро, и будет порой вносить в текст непрошенные правки, помимо запятых."
"Привет! Буду благодарен, если кто-то сможет подсказать как лучше подойти к этой задаче.

Задача следующая:
Есть тексты на английском языке. Нужно в них расставить пунктуацию примерно по правилам русского языка - то есть между всеми простыми предложениями в составе сложного, обрамить причастные / деепричастные обороты (вернее participle constructions) запятыми. Ну или сделать хотя бы одно действие из этих двух

Например (не из датасета, для иллюстрации)
One boy goes to London, and one girl goes to New York
One boy goes to London, being very sad, because his cat is not with him","Первое, что приходит в голову: 1) если есть данные, дообучить seq2seq; 2) если без данных, то попробовать формализовать правила над дискурсивными rst (или синтаксическими) деревьями","Голосую за 2) или за (3) какой-нибудь sequence tagger, предсказывающий для каждого токена, должна ли после него быть запятая.

Seq2seq и работать будет не супер быстро, и будет порой вносить в текст непрошенные правки, помимо запятых.","Да, согласен, тагер получше будет. Но от размера датасета тоже сильно зависит. Если данных много и выкрутить параметры инфера, то базовый seq2seq по идее не будет особо глючить, и учить его просто"
,,,Ничего не выйдет
,,Ничего не выйдет,недостаточно данных для подобного масштаба модели с нуля?
,,,Да
,,Да,"Всем привет! 
Пробовал тут кто-то дообучать llm? Знаете успешные примеры?"
,Да,"Всем привет! 
Пробовал тут кто-то дообучать llm? Знаете успешные примеры?","Спасибо ребят, посмотрю!"
Да,"Всем привет! 
Пробовал тут кто-то дообучать llm? Знаете успешные примеры?","Спасибо ребят, посмотрю!","В 3Д для преобразований лучше уходить в сторону кватернионов. Если брать углы Эйлера, то там возникают неоднозначности в интерпретации позиций.
Есть PyTorch3D для более удобной работы с 3D данными в торче"
,,,FC - full connected?
,,FC - full connected?,furry collected
,,,"Всем привет, sbert рекомендует делать пулинг поверх всех токенов, кто-то пробовал брать [CLS] токен вместо пулинга? Он хуже работает? Или какие подводные камни?"
,,"Всем привет, sbert рекомендует делать пулинг поверх всех токенов, кто-то пробовал брать [CLS] токен вместо пулинга? Он хуже работает? Или какие подводные камни?",Ответ на самом деле на этот вопрос лежит в статье SBERT
,,,"Пробовал, у меня минпулинг лучше работал на руберттини2, но я чиста разок попробовал, поэтому не отвечаю"
,,"Пробовал, у меня минпулинг лучше работал на руберттини2, но я чиста разок попробовал, поэтому не отвечаю",Спасибо!
,,,Вот интересный момент из комментов относительно пулингов
,,Вот интересный момент из комментов относительно пулингов,А вы смотрели более свежий коммент?
,,,"Хуже
Ссылаетесь на устаревшую инфу
Пуллинг был там сломан"
,,,Вот мы с Давидом уже обсудили почему пуллинг был не тот.
,,Вот мы с Давидом уже обсудили почему пуллинг был не тот.,"Интересно
Поделитесь почему?)"
,Вот мы с Давидом уже обсудили почему пуллинг был не тот.,"Интересно
Поделитесь почему?)",Код был не тот расчёта
,,,"Поэтому нужно пересчёт сделать и заново делать выводы, что где лучше
В том месте где и как обучали.
Напомню
А значит там более эффективным является представление pooling, тк именно его тюнили"
,,,"Я просто беру «xlm-roberta-base» из HF, там пулинга нету, как я понимаю
И интересно то, стоит для всех трансформеров пулинг юзать, или  [CLS] в каких-то случаях лучше"
,,"Я просто беру «xlm-roberta-base» из HF, там пулинга нету, как я понимаю
И интересно то, стоит для всех трансформеров пулинг юзать, или  [CLS] в каких-то случаях лучше",нет NSP таски в RoBERTa
,"Я просто беру «xlm-roberta-base» из HF, там пулинга нету, как я понимаю
И интересно то, стоит для всех трансформеров пулинг юзать, или  [CLS] в каких-то случаях лучше",нет NSP таски в RoBERTa,"Можете еще подсказать 🙂
У меня задача обучить кросс энкодер на бинарную классификацию одинаковый это товар или нет 
Я беру «xlm-roberta-base» и она заводится неплохо, но там ужасный токенизатор
Я обучил свой токенизатор на корпусе слов и пытаюсь завести кросс энкодер с 0, но он довольно плохо заводится
Я думаю, нужно обучить unsupervised learning, но пока не могу понять будет ли от этого смысл на моих данных и как это правильно задизайнить, раз я хочу потом кросс энкодер обучать
Данные выглядят как-то так"
"Я просто беру «xlm-roberta-base» из HF, там пулинга нету, как я понимаю
И интересно то, стоит для всех трансформеров пулинг юзать, или  [CLS] в каких-то случаях лучше",нет NSP таски в RoBERTa,"Можете еще подсказать 🙂
У меня задача обучить кросс энкодер на бинарную классификацию одинаковый это товар или нет 
Я беру «xlm-roberta-base» и она заводится неплохо, но там ужасный токенизатор
Я обучил свой токенизатор на корпусе слов и пытаюсь завести кросс энкодер с 0, но он довольно плохо заводится
Я думаю, нужно обучить unsupervised learning, но пока не могу понять будет ли от этого смысл на моих данных и как это правильно задизайнить, раз я хочу потом кросс энкодер обучать
Данные выглядят как-то так",Ты не можешь свой обучить токенизатор для этой модели
,,,"Но вопрос-то задавался про сберт
Значит там cls может быть не таким сильным для представления предложения, а может и быть. Пуллинг можно кодом выше получить в любом случае
У нас пуллинг на Роберте сильнее"
,,"Но вопрос-то задавался про сберт
Значит там cls может быть не таким сильным для представления предложения, а может и быть. Пуллинг можно кодом выше получить в любом случае
У нас пуллинг на Роберте сильнее",Спасибо!
,,,"Друзья, а вопрос может не совсем касательно НЛП, а скорее DL в целом, но вот когда учу кросс-энкодер получаю такую картину,  то есть в какой-то момент метрики начинают резко ""скакать"", казалось бы оверфит, но все равно могут обновлять топы, если спрашивать прямо в лоб, то ""почему так и легально ли это""? На графике метрики по валидационному фолду"
,,"Друзья, а вопрос может не совсем касательно НЛП, а скорее DL в целом, но вот когда учу кросс-энкодер получаю такую картину,  то есть в какой-то момент метрики начинают резко ""скакать"", казалось бы оверфит, но все равно могут обновлять топы, если спрашивать прямо в лоб, то ""почему так и легально ли это""? На графике метрики по валидационному фолду",Почитай про гроккинг
,"Друзья, а вопрос может не совсем касательно НЛП, а скорее DL в целом, но вот когда учу кросс-энкодер получаю такую картину,  то есть в какой-то момент метрики начинают резко ""скакать"", казалось бы оверфит, но все равно могут обновлять топы, если спрашивать прямо в лоб, то ""почему так и легально ли это""? На графике метрики по валидационному фолду",Почитай про гроккинг,"Круто, спасибо!"
"Друзья, а вопрос может не совсем касательно НЛП, а скорее DL в целом, но вот когда учу кросс-энкодер получаю такую картину,  то есть в какой-то момент метрики начинают резко ""скакать"", казалось бы оверфит, но все равно могут обновлять топы, если спрашивать прямо в лоб, то ""почему так и легально ли это""? На графике метрики по валидационному фолду",Почитай про гроккинг,"Круто, спасибо!",https://github.com/Sea-Snell/grokking
Почитай про гроккинг,"Круто, спасибо!",https://github.com/Sea-Snell/grokking,эффект плохой инициализации
,,,"Всем привет, подскажите, есть ли какие-нибудь качественные анти спуфинг системы в распознавании лиц не требующие дополнительного оборудования (то есть определяющие просто по изображению с камеры) и не требующие дообучения?"
,,"Всем привет, подскажите, есть ли какие-нибудь качественные анти спуфинг системы в распознавании лиц не требующие дополнительного оборудования (то есть определяющие просто по изображению с камеры) и не требующие дообучения?",https://github.com/minivision-ai/Silent-Face-Anti-Spoofing/tree/master/src
,"Всем привет, подскажите, есть ли какие-нибудь качественные анти спуфинг системы в распознавании лиц не требующие дополнительного оборудования (то есть определяющие просто по изображению с камеры) и не требующие дообучения?",https://github.com/minivision-ai/Silent-Face-Anti-Spoofing/tree/master/src,Спасибо! А если для прода?
"Всем привет, подскажите, есть ли какие-нибудь качественные анти спуфинг системы в распознавании лиц не требующие дополнительного оборудования (то есть определяющие просто по изображению с камеры) и не требующие дообучения?",https://github.com/minivision-ai/Silent-Face-Anti-Spoofing/tree/master/src,Спасибо! А если для прода?,Для прода много ресурсов людских и много данных
,,,"Кросс энкодер учить надо с sep token
Для Роберты он </s></s> такой кажется
Погугли
ФразаА sep token ФразаБ"
,,"Кросс энкодер учить надо с sep token
Для Роберты он </s></s> такой кажется
Погугли
ФразаА sep token ФразаБ","Да, это я делаю, но все равно без претрена, но на своем токенизаторе оч плохо получается"
,,,Только если с 0 претрейн свой делать
,,Только если с 0 претрейн свой делать,"Все так, это я и собираюсь делать
Потому что домен очень специфичный"
,,,"Ну сделай сначала претрейн
Потом тюнь на кросс таске"
,,,У тебя есть на чем с 0 учить Роберту?
,,У тебя есть на чем с 0 учить Роберту?,"Планировал берт учить, 350М строк есть"
,,,Прям на к десятков или сотен гигов текстов и тп)
,,,"Претрейн лучше делать как-то так
(ФразаА sep token ФразаБ)(поверх этого МЛМ)
Или 
(ФразаА/ФразаБ)(поверх этого МЛМ)"
,,"Претрейн лучше делать как-то так
(ФразаА sep token ФразаБ)(поверх этого МЛМ)
Или 
(ФразаА/ФразаБ)(поверх этого МЛМ)",Нет
,,,"Делать с кодом Роберты на данных твоих и твоём токенизаторе
Или берта
В нём обе таски уже встроены
Он без тебя всё сделает
Тут как на обычной карте соло обучить свой bert"
,,"Делать с кодом Роберты на данных твоих и твоём токенизаторе
Или берта
В нём обе таски уже встроены
Он без тебя всё сделает
Тут как на обычной карте соло обучить свой bert","Я к тому, что если последующая задача - кросс энкодер
Стоит ли мне конкатить свои строки через [SEP] и подавать это в MLM
Или просто по одной строчке засовывать без конкатинации
Смотри, у меня кросс энкодер будет обучаться так
(Предложение 1 + sep + Предложение 1)
Я думаю взять рандомную строку из корпуса с Предложениями 1
Поставить sep токен
И потом взять еще одну рандомную строку из корпуса с Предложениями 2 
На таком претрениться
Или я могу претрениться на рандомной строке из {корпуса с Предложениями 1, корпус с Предложениями 2}"
,"Делать с кодом Роберты на данных твоих и твоём токенизаторе
Или берта
В нём обе таски уже встроены
Он без тебя всё сделает
Тут как на обычной карте соло обучить свой bert","Я к тому, что если последующая задача - кросс энкодер
Стоит ли мне конкатить свои строки через [SEP] и подавать это в MLM
Или просто по одной строчке засовывать без конкатинации
Смотри, у меня кросс энкодер будет обучаться так
(Предложение 1 + sep + Предложение 1)
Я думаю взять рандомную строку из корпуса с Предложениями 1
Поставить sep токен
И потом взять еще одну рандомную строку из корпуса с Предложениями 2 
На таком претрениться
Или я могу претрениться на рандомной строке из {корпуса с Предложениями 1, корпус с Предложениями 2}","Ещё раз у тебя автоматом в BERT есть и млм и nsp таска
Понимаешь?
Что такое NSP?"
,,,Почитай теорию по BERT
,,Почитай теорию по BERT,"Я понял, спасибо за ответ
Я просто планировал обучаться на BertForMaskedLM
Но, видимо, правильнее будет на transformers.BertForPreTraining"
,,,Есть но стоят дорого)
,,Есть но стоят дорого),с чего бы?
,,,Для начала сойдёт.
,,,"Тут недавно тюнил gpt2 на собственном языке, domain specific. Perplexity < 1.6, но часто не с того символа начинает. И это все ломает. И структуру портит.

Научу свой ванильный трансформер. С покером и экскортницами"
,,"Тут недавно тюнил gpt2 на собственном языке, domain specific. Perplexity < 1.6, но часто не с того символа начинает. И это все ломает. И структуру портит.

Научу свой ванильный трансформер. С покером и экскортницами",Исходный код декодера есть в тф2 😜
,"Тут недавно тюнил gpt2 на собственном языке, domain specific. Perplexity < 1.6, но часто не с того символа начинает. И это все ломает. И структуру портит.

Научу свой ванильный трансформер. С покером и экскортницами",Исходный код декодера есть в тф2 😜,Ахах
,,,Да я взял сразу [my domain] gpt2 с huggingface
,,Да я взял сразу [my domain] gpt2 с huggingface,Ну если хочется в потрохах копаться HF такое себе. Оч инкапсулированно
,,,Лучше уж тогда пойти туда где чистый торч
,,Лучше уж тогда пойти туда где чистый торч,"это был план б, и теперь он единственный..."
,,,"Я не знаю лучше из свободного доступа.
Да и все более менее нормальные закрыты как только для исследований.
Если коммерческие, то на рынке в целом много. Я работаю на одного из таких вендоров."
,,"Я не знаю лучше из свободного доступа.
Да и все более менее нормальные закрыты как только для исследований.
Если коммерческие, то на рынке в целом много. Я работаю на одного из таких вендоров.","Понял, спасибо!"
,"Я не знаю лучше из свободного доступа.
Да и все более менее нормальные закрыты как только для исследований.
Если коммерческие, то на рынке в целом много. Я работаю на одного из таких вендоров.","Понял, спасибо!",Александр
,,,Ну уже не тот год на дворе
,,Ну уже не тот год на дворе,Погоди ща кекас будет обёрткой над...
,,,Убийца jax???
,,Убийца jax???,"jax кстати не оч плохая штука, потому что его тензоры можно заколупать в алгоритмы scipy.

Выручило с одним подсказчиком технологических процессов"
,Убийца jax???,"jax кстати не оч плохая штука, потому что его тензоры можно заколупать в алгоритмы scipy.

Выручило с одним подсказчиком технологических процессов",Угу
,,,Антиспуфинг на минималках: yolo detections (tablet/monitor/etc...) bbox
,,Антиспуфинг на минималках: yolo detections (tablet/monitor/etc...) bbox,"Я так делал: детектил телефоны и фотки, в целом  работает неплохо, но когда слишком близко подносят фотку или телефон перестаёт работать"
,,,"Ну и свои находки сливать чот не хочется)
У меня в планах год выжать на индексах.. Про эту штуку типа hardest читал"
,,,А в чем смысл мероприятия?
,,А в чем смысл мероприятия?,"ну там есть варианты для участников зарабатывать тоже, так как в финале все предикшены составляются в факторную метамодель, которая реально торгует, но там весь механизм с получением своей доли с работы модели через крипту, так что кажется даже топперформеры все сейчас в долларовом эквиваленте в минусе :)"
,А в чем смысл мероприятия?,"ну там есть варианты для участников зарабатывать тоже, так как в финале все предикшены составляются в факторную метамодель, которая реально торгует, но там весь механизм с получением своей доли с работы модели через крипту, так что кажется даже топперформеры все сейчас в долларовом эквиваленте в минусе :)",Удивительный график.
А в чем смысл мероприятия?,"ну там есть варианты для участников зарабатывать тоже, так как в финале все предикшены составляются в факторную метамодель, которая реально торгует, но там весь механизм с получением своей доли с работы модели через крипту, так что кажется даже топперформеры все сейчас в долларовом эквиваленте в минусе :)",Удивительный график.,"но опять же, делайте поправку на turnover, учитывая, что у них только факторная модель с горизонтом на месяц плюс, если это не зафиксированные убытки, то выглядит ок"
,,,"Понятно - движение - всё, результат -ничто"
,,"Понятно - движение - всё, результат -ничто","примерно, но идея правда неплохая"
,,,"Всем привет 
Кто-нибудь проходил ассессмент в компанию axenix? Или что-нибудь знает про нее?"
,,"Всем привет 
Кто-нибудь проходил ассессмент в компанию axenix? Или что-нибудь знает про нее?","Был бы рад, если бы статьи были на русском языке"
,"Всем привет 
Кто-нибудь проходил ассессмент в компанию axenix? Или что-нибудь знает про нее?","Был бы рад, если бы статьи были на русском языке","Всем привет, шкила на связи"
,,,ну они открыли для себя минревёржен
,,ну они открыли для себя минревёржен,Минревержен профита🤣🤣🤣
,,,"я насколько помню, там на прибыль твою как участника на 80% влияет курс их крипты"
,,"я насколько помню, там на прибыль твою как участника на 80% влияет курс их крипты",там весы Sdxl1.0 выложили
,,,"никто не парсил случаем степик? на кегле лежит база данных с курсами от курсеры, мб кто-то что-то подобное делал"
,,"никто не парсил случаем степик? на кегле лежит база данных с курсами от курсеры, мб кто-то что-то подобное делал",Неа
,,,вот вае сюрприз
,,вот вае сюрприз,"вот это веселей, Do Not Under Any Circumstances Load The SDXL 0.9 VAE Weights Into SDXL 1.0! That Definitely Won't Remove The Weird Lines That Are Absolutely Not Stupid Watermark Bullshit"
,,,эт фигня
,,,"Приходи к нам на собес, если пройдешь, покажем как работает лайвнес"
,,"Приходи к нам на собес, если пройдешь, покажем как работает лайвнес",Интересно
,,,room-temperature? 😄
,,room-temperature? 😄,"Доброго вечора, ми за України 🇺🇦! Є хтось з Дніпра?"
,,,"Всем привет!
Подскажите, пожалуйста, хорошие датасеты для ocr на русском языке, чтобы в них также были формулы (соответственно и всякие математические символы в разметке тоже были)"
,,"Всем привет!
Подскажите, пожалуйста, хорошие датасеты для ocr на русском языке, чтобы в них также были формулы (соответственно и всякие математические символы в разметке тоже были)",Нагенерить?
,,,"Привет всем! Хочу стать проджект менеджером, делал cv впервые, подскажите где-что исправить

Если у кого есть - накидайте пожалуйста ссылки на гайды для пм"
,,,А где пельмени...
,,А где пельмени...,"Пельмени пока ещё ходят, но на кадре присутствуют. 😅"
,,,Пельменная без инопланетян была очень криптовая
,,Пельменная без инопланетян была очень криптовая,Всем привет! Есть кто живет в Испании?
,,,"Из браузера пельмени получались, но из зебр 😀"
,,"Из браузера пельмени получались, но из зебр 😀",see no difference
,"Из браузера пельмени получались, но из зебр 😀",see no difference,Зебры как будто уже заправились пельмешками
"Из браузера пельмени получались, но из зебр 😀",see no difference,Зебры как будто уже заправились пельмешками,Круто! Стоит погрузиться
see no difference,Зебры как будто уже заправились пельмешками,Круто! Стоит погрузиться,"Всем привет! Подскажите пожалуйста, как получить эмбединги с RuGPT-2 для задачи кластеризации? Верно понимаю, в таком случае паддинги не нужны? И ещё вопрос - как обычно делите данные на батчи? С помощью DataCollator или просто Dataloader из Pytotch?"
Зебры как будто уже заправились пельмешками,Круто! Стоит погрузиться,"Всем привет! Подскажите пожалуйста, как получить эмбединги с RuGPT-2 для задачи кластеризации? Верно понимаю, в таком случае паддинги не нужны? И ещё вопрос - как обычно делите данные на батчи? С помощью DataCollator или просто Dataloader из Pytotch?",А почему ГПТ выбран?
,,,"Потому что эта версия обучалась на части банковских документов, легковесная, и нужна именно русскоязычныая для отработки далее большого количества документов. Возможно есть варианты получше? Если да, то подскажите пожалуйста)"
,,"Потому что эта версия обучалась на части банковских документов, легковесная, и нужна именно русскоязычныая для отработки далее большого количества документов. Возможно есть варианты получше? Если да, то подскажите пожалуйста)",Бери
,,,"Обычно, если нужно сделать кластеризацию текстов, берут какие нить сентценц берты"
,,,Ну можно дообучить энкодер какой-нибудь
,,Ну можно дообучить энкодер какой-нибудь,Вроде Universal Sentence Encoder?
,Ну можно дообучить энкодер какой-нибудь,Вроде Universal Sentence Encoder?,Да
,,,"Всем привет. Может не в эту категорию, но всё же. Кто-то подскажет сайты для хоста небольших файлов(csv для ML и т.д.) и скачивания через !wget в jupyter/colab?"
,,"Всем привет. Может не в эту категорию, но всё же. Кто-то подскажет сайты для хоста небольших файлов(csv для ML и т.д.) и скачивания через !wget в jupyter/colab?","github, качать по прямой ссылке на raw"
,"Всем привет. Может не в эту категорию, но всё же. Кто-то подскажет сайты для хоста небольших файлов(csv для ML и т.д.) и скачивания через !wget в jupyter/colab?","github, качать по прямой ссылке на raw","хорошая идея, спасибо"
,,,А SBERT?)
,,,"Всем привет! Кто какие может посоветовать легковесные модельки с норм качеством по object detection, у которых скорость инференса хорошая, в том числе и на CPU? (за исключением yolo)?"
,,"Всем привет! Кто какие может посоветовать легковесные модельки с норм качеством по object detection, у которых скорость инференса хорошая, в том числе и на CPU? (за исключением yolo)?",https://github.com/RangiLyu/nanodet
,"Всем привет! Кто какие может посоветовать легковесные модельки с норм качеством по object detection, у которых скорость инференса хорошая, в том числе и на CPU? (за исключением yolo)?",https://github.com/RangiLyu/nanodet,Спасибо!
,,,"А что такое искусственный интеллект, и причем тут мозг человека?

То что архитектура сетки влияет на ее перфоманс ... Вот блин открытие"
,,"А что такое искусственный интеллект, и причем тут мозг человека?

То что архитектура сетки влияет на ее перфоманс ... Вот блин открытие","Тут про то, что изначально делали нейронки по подобию мозга человека, но эта модель не объясняет почему произошло именно это с твоим мозгом, а не то. Тут же хотят изменить модель, то есть использовать другую математику(другие уравнения). Если цель создать AGI, то мб и ИИ сфера свернёт чуток"
,"А что такое искусственный интеллект, и причем тут мозг человека?

То что архитектура сетки влияет на ее перфоманс ... Вот блин открытие","Тут про то, что изначально делали нейронки по подобию мозга человека, но эта модель не объясняет почему произошло именно это с твоим мозгом, а не то. Тут же хотят изменить модель, то есть использовать другую математику(другие уравнения). Если цель создать AGI, то мб и ИИ сфера свернёт чуток","1. AGI пока что философия
2. Сетки уже лет 50 как известно что не аналог мозга, а универсальный интерполятор,
3. Другую математику... Ждем. Нейросети Шредингера - как квантовые компьютеры, только нейросети,
4. Авторы переборщили с самооценкой своей работы,
5. ИИ сфера свернёт чуток, если ИИ будет определённым понятием. Пока что это все data science"
,,,"Такой вопрос, пробовал кто брать декодер архитектуры, и дообучить на классическую задачу энкодер архитектур, но  поменять маску атеншена с casual, на biderectional?"
,,"Такой вопрос, пробовал кто брать декодер архитектуры, и дообучить на классическую задачу энкодер архитектур, но  поменять маску атеншена с casual, на biderectional?",Знаю что брали pool и в reward
,,,А зачем. Похоже на identity transformation.
,,,Ну вот как девушка выше хотела gpt2 использовать для кластеризации
,,Ну вот как девушка выше хотела gpt2 использовать для кластеризации,"На мой взгляд это не совсем корректно. Decoder-only архитектура избавилась от енкодера как раз вследствие causal, то что атншн не берет весь контекст, а достраивает.

Если весь контекст есть, то с ним должно работать лучше. Несмотря на боттлнек"
,,,"Хотя на самом деле с точки зрения естественных наук результат безусловно интересный.

Если будет иметь какую-то объясняющую силу далее аналогических интерпретаций. Это инсайт из данных.

Модели мозга для биологов должны пересмотреться, да.
Могут появиться новые лекарства например.
Жена биолог говорит со времён открытия ЭЭГ известно было что ""волны по мозгу бегают"""
,,"Хотя на самом деле с точки зрения естественных наук результат безусловно интересный.

Если будет иметь какую-то объясняющую силу далее аналогических интерпретаций. Это инсайт из данных.

Модели мозга для биологов должны пересмотреться, да.
Могут появиться новые лекарства например.
Жена биолог говорит со времён открытия ЭЭГ известно было что ""волны по мозгу бегают""",Не более
,"Хотя на самом деле с точки зрения естественных наук результат безусловно интересный.

Если будет иметь какую-то объясняющую силу далее аналогических интерпретаций. Это инсайт из данных.

Модели мозга для биологов должны пересмотреться, да.
Могут появиться новые лекарства например.
Жена биолог говорит со времён открытия ЭЭГ известно было что ""волны по мозгу бегают""",Не более,"Можно ли заставить модуль MultiheadAttention pytorch работать на встроенном в pytorch бекенде flash attention если просто переставить флаги командами:
torch.backends.cuda.enable_flash_sdp(True)
torch.backends.cuda.enable_mem_efficient_sdp(False)
torch.backends.cuda.enable_math_sdp(False)

Судя по официальному туториалу флаги влияют на бекенд функции F.scaled_dot_product_attention, она же используется в коде F.multi_head_attention_forward, эта, в свою очередь, вызывается в форвардпасе модуля MultiheadAttention. Выглядит все стройно, но официальный туториал в качестве примера пишет свой модуль attention чисто на F.scaled_dot_product_attention. 

При попытке запустить доселе рабочую модель на бекенде flash attention, посредством установки соответствующего флага, форвардпас первого же модуля MultiheadAttention в модели падает с ошибкой:
UserWarning: Expected query, key and value to all be of dtype: {Half}. Got Query dtype: float, Key dtype: float, and Value dtype: float instead. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/transformers/cuda/sdp_utils.h:92.)

Если же принудительно привести входной тензор к torch.float16, то на форвардпасе первой свертки вылетает уже следующая ошибка:
RuntimeError: Input type (float) and bias type (c10::Half) should be the same"
,,,"Всем привет)
Можете кто нибудь подсказать LLM для генерации табличных данных. Может кто-то пробовал, буду благодарен советам. Спасибо"
,,"Всем привет)
Можете кто нибудь подсказать LLM для генерации табличных данных. Может кто-то пробовал, буду благодарен советам. Спасибо","Если табличные данные закодировать в виде sequence, то что угодно начиная с distilgpt2 с huggingface"
,,,"Всем привет, может кто-то посоветовать хорошие статейки\ресурсы по использованию нейросеток в науке? Например недавно узнал про PINN и загорелся этим, может есть развитие идеи PINN?"
,,"Всем привет, может кто-то посоветовать хорошие статейки\ресурсы по использованию нейросеток в науке? Например недавно узнал про PINN и загорелся этим, может есть развитие идеи PINN?","В разных науках довольно по-разному используются. Если интересна не только физика, то, к примеру, в нейронауках очень популярная тема. И в моделировании работы мозга, и просто для классификации сигналов и изображений, ""декодирования"", вплоть до ""чтения мыслей""))"
,"Всем привет, может кто-то посоветовать хорошие статейки\ресурсы по использованию нейросеток в науке? Например недавно узнал про PINN и загорелся этим, может есть развитие идеи PINN?","В разных науках довольно по-разному используются. Если интересна не только физика, то, к примеру, в нейронауках очень популярная тема. И в моделировании работы мозга, и просто для классификации сигналов и изображений, ""декодирования"", вплоть до ""чтения мыслей""))","Я бы ещё поизучал использование в химии, хемоинформатике"
"Всем привет, может кто-то посоветовать хорошие статейки\ресурсы по использованию нейросеток в науке? Например недавно узнал про PINN и загорелся этим, может есть развитие идеи PINN?","В разных науках довольно по-разному используются. Если интересна не только физика, то, к примеру, в нейронауках очень популярная тема. И в моделировании работы мозга, и просто для классификации сигналов и изображений, ""декодирования"", вплоть до ""чтения мыслей""))","Я бы ещё поизучал использование в химии, хемоинформатике","10.1039/C6SC05720A
Можешь вот это глянуть
С точки зрения нейронок новизны не много, но там кодирование системы интересное. 
Одна из классических статей по дл в химии"
"В разных науках довольно по-разному используются. Если интересна не только физика, то, к примеру, в нейронауках очень популярная тема. И в моделировании работы мозга, и просто для классификации сигналов и изображений, ""декодирования"", вплоть до ""чтения мыслей""))","Я бы ещё поизучал использование в химии, хемоинформатике","10.1039/C6SC05720A
Можешь вот это глянуть
С точки зрения нейронок новизны не много, но там кодирование системы интересное. 
Одна из классических статей по дл в химии",Спасибо
,,,Ммммм
,,,"Всем привет, не подскажете, какой тренировочный цикл будет быстрее: через fabric у pytorch lightning или через accelerator у hugging face?"
,,"Всем привет, не подскажете, какой тренировочный цикл будет быстрее: через fabric у pytorch lightning или через accelerator у hugging face?",Через Details 💅
,,,А можете пж привести пример или в каком источнике смотреть (разные опредления и тд) нескалярной функции
,,А можете пж привести пример или в каком источнике смотреть (разные опредления и тд) нескалярной функции,"нескалярная функция — любая функция, образ которой состоит не из скаляров (например функция R^n -> R^n)"
,,,"товарищи, а реально ли распозновать лица ? грубо говоря у меня есть Х человек в офисе, и я хочу по камерам в офисе их находить и записывать в лог, где они были"
,,"товарищи, а реально ли распозновать лица ? грубо говоря у меня есть Х человек в офисе, и я хочу по камерам в офисе их находить и записывать в лог, где они были",Так может проще трекер нацепить?
,"товарищи, а реально ли распозновать лица ? грубо говоря у меня есть Х человек в офисе, и я хочу по камерам в офисе их находить и записывать в лог, где они были",Так может проще трекер нацепить?,чипируем🥴
,,,Более чем
,,Более чем,не подскажете в какую сторону смотреть?
,Более чем,не подскажете в какую сторону смотреть?,За меня в принципе уже ответили :)
,,,"nice :)
спасибо, погляжу"
,,"nice :)
спасибо, погляжу","я думаю, что, если X << 10000, то можно попробовать взять легкую модельку"
,"nice :)
спасибо, погляжу","я думаю, что, если X << 10000, то можно попробовать взять легкую модельку","Можно, но нужно сделать банк с фотками лиц"
"nice :)
спасибо, погляжу","я думаю, что, если X << 10000, то можно попробовать взять легкую модельку","Можно, но нужно сделать банк с фотками лиц","Q all, есть у кого-то контакты админов ?"
"я думаю, что, если X << 10000, то можно попробовать взять легкую модельку","Можно, но нужно сделать банк с фотками лиц","Q all, есть у кого-то контакты админов ?",Эта штука даже перформит
"Можно, но нужно сделать банк с фотками лиц","Q all, есть у кого-то контакты админов ?",Эта штука даже перформит,"ага
но млп рано выкидывать"
"Q all, есть у кого-то контакты админов ?",Эта штука даже перформит,"ага
но млп рано выкидывать","Спасибо большое, да последнее видел, там отправил запрос на тестовый. В моем случае для sme кредита есть поля и какие значения может принять, я хочу из комбинации сгенерить."
,,,"Всем привет, пытаюсь сгенерировать табличные данные для симуляции нагрузки дата кластеров (сэмпл на фото)
задачи нет, вопрос такой: какие корреляционные тесты подойдут для сравнения фейк и реальных данных?"
,,"Всем привет, пытаюсь сгенерировать табличные данные для симуляции нагрузки дата кластеров (сэмпл на фото)
задачи нет, вопрос такой: какие корреляционные тесты подойдут для сравнения фейк и реальных данных?",а раскрой про околоценовое?
,"Всем привет, пытаюсь сгенерировать табличные данные для симуляции нагрузки дата кластеров (сэмпл на фото)
задачи нет, вопрос такой: какие корреляционные тесты подойдут для сравнения фейк и реальных данных?",а раскрой про околоценовое?,"Цены и выручка логнормально распределены, это правда"
,,,"использовал CTABGAN-Plus для генерации,  compute_associations от dython показывает слабую корреляцию между данными
думаю это из-за огромных выбросов, которые могут отличаться порядками"
,,"использовал CTABGAN-Plus для генерации,  compute_associations от dython показывает слабую корреляцию между данными
думаю это из-за огромных выбросов, которые могут отличаться порядками","Бэйзлайн заряжали, логрег какой?..."
,"использовал CTABGAN-Plus для генерации,  compute_associations от dython показывает слабую корреляцию между данными
думаю это из-за огромных выбросов, которые могут отличаться порядками","Бэйзлайн заряжали, логрег какой?...","генерировал без задачи, задачи как таковой нет"
"использовал CTABGAN-Plus для генерации,  compute_associations от dython показывает слабую корреляцию между данными
думаю это из-за огромных выбросов, которые могут отличаться порядками","Бэйзлайн заряжали, логрег какой?...","генерировал без задачи, задачи как таковой нет",Так генерировали поди с реальных данных...
"Бэйзлайн заряжали, логрег какой?...","генерировал без задачи, задачи как таковой нет",Так генерировали поди с реальных данных...,"да, там данные гугла с кластеров, они изначально без задачи, но думаю попробовать переделать в задачу классификации"
,,,"Либо обычную корреляцию смотреть (что, скорее всего, мало что даст), либо распределения сравнивать: KL-divergence (или симметричная версия JS-divergence), тест Колмогорова-Смирнова"
,,"Либо обычную корреляцию смотреть (что, скорее всего, мало что даст), либо распределения сравнивать: KL-divergence (или симметричная версия JS-divergence), тест Колмогорова-Смирнова","KS-test сильно к выбросам чувствителен, особенно на малых выборках
0.0001 p-value покажет — будет невесело"
,,,?
,,?,"pearsonr ничего не дал, попробую kl-divergence и колмогорова 👍"
,,,"KL грамотная мысль, но если GAN отучился годно, то не поможет"
,,"KL грамотная мысль, но если GAN отучился годно, то не поможет","можно ли сказать что если статистические атрибуты (mean,median,std,variance) коррелируют в 1, но сами данные не коррелируют, то наш GAN хорошо научился генерировать фейк данные?"
,"KL грамотная мысль, но если GAN отучился годно, то не поможет","можно ли сказать что если статистические атрибуты (mean,median,std,variance) коррелируют в 1, но сами данные не коррелируют, то наш GAN хорошо научился генерировать фейк данные?","GAN хорошо научился, когда дискриминатор сэмплы не различает...

В частности и первые-вторые моменты будут у сэмплов сильно рядом"
,,,"дело в том что у меня первые моменты сильно рядом, а вторые вообще не там, вот и в ступор бросает..
покопаюсь что внутри происходит"
,,"дело в том что у меня первые моменты сильно рядом, а вторые вообще не там, вот и в ступор бросает..
покопаюсь что внутри происходит","Если у гана можно сменить лосс, на тот же l1 , может посодействовать. Идея что ган учит шум (переобучается под выборку), раз второй момент отличен"
,"дело в том что у меня первые моменты сильно рядом, а вторые вообще не там, вот и в ступор бросает..
покопаюсь что внутри происходит","Если у гана можно сменить лосс, на тот же l1 , может посодействовать. Идея что ган учит шум (переобучается под выборку), раз второй момент отличен",Спасибо большое! попробую все эти моменты
,,,"Мысль вобщем в том, что синтетика - это тоже в некотором ""модель"", результат inductive bias. GAN, VAE, Diffusion - тут не столь важно.

Вот как раз KL поможет, если второй момент отличен"
,,"Мысль вобщем в том, что синтетика - это тоже в некотором ""модель"", результат inductive bias. GAN, VAE, Diffusion - тут не столь важно.

Вот как раз KL поможет, если второй момент отличен","Вообще говоря, есть распределения с бесконечной дисперсией и тогда корреляции не существует,  а KL что-то там все равно оптимизирует... 
На конечных выборках дисперсия будет всегда конечной и сильно неустойчивой"
,,,"Доброго времени суток. 
Есть ли сейчас какие-то решения по трекингу мяча/шайбы на спортивных трансляциях матчей? 
Поиграть с якорями для YOLO прошу не предлагать."
,,"Доброго времени суток. 
Есть ли сейчас какие-то решения по трекингу мяча/шайбы на спортивных трансляциях матчей? 
Поиграть с якорями для YOLO прошу не предлагать.","Если задуматься, то в кадре не может быть > 1 шайбы/мяча, так что тут всё упирается в качество детекции"
,"Доброго времени суток. 
Есть ли сейчас какие-то решения по трекингу мяча/шайбы на спортивных трансляциях матчей? 
Поиграть с якорями для YOLO прошу не предлагать.","Если задуматься, то в кадре не может быть > 1 шайбы/мяча, так что тут всё упирается в качество детекции","В футболе может например при смене мяча, но в целом да"
,,,"Всем привет. 
Есть вопрос по yolo8 от ultralytics. 
Обучаю в пайчарме на ГПУ, оперативки 16 гигов
Отследил странное поведение: на этапе подготовки к обучению пайчарм/yolo создаёт множество процессов Python (причём основного, не из venv) , каждый из которых отбирает порядка 300 мб. 
Попытавшись дропнуть один из них выяснил, что там даталоадер (обучение упало). 

Это нормальное поведение? 
Просто конкретно сейчас обучается на маленьких снимках и едва может переварить, хотя утром без вылетов обучалась на больших и тяжёлых. 
Вообще, от чего это может зависить и какими параметрами на эти процессы влиять (видимо, размер батча, может быть количество эпох, ещё что-то)"
,,"Всем привет. 
Есть вопрос по yolo8 от ultralytics. 
Обучаю в пайчарме на ГПУ, оперативки 16 гигов
Отследил странное поведение: на этапе подготовки к обучению пайчарм/yolo создаёт множество процессов Python (причём основного, не из venv) , каждый из которых отбирает порядка 300 мб. 
Попытавшись дропнуть один из них выяснил, что там даталоадер (обучение упало). 

Это нормальное поведение? 
Просто конкретно сейчас обучается на маленьких снимках и едва может переварить, хотя утром без вылетов обучалась на больших и тяжёлых. 
Вообще, от чего это может зависить и какими параметрами на эти процессы влиять (видимо, размер батча, может быть количество эпох, ещё что-то)","Возможно, стоит workers при обучении понизить.
Мне вроде помогало"
,,,"16 беда... Без шуток, я восьмую без проблем запинал под 32. 

Планки памяти копье стоят, на 16 не отучите. А на 32 я сходу отучил
Это ж жесть конечно какая частная история... С удовольствием почитаю если кто вам что-то подскажет. 

Особенно с шайбой
Ну и еще. Учите через cli, пучарм мало ли что чудит"
,,,Трекинг или детекция? YOLO - это детектор
,,Трекинг или детекция? YOLO - это детектор,YOLO применяют для трекинга
,Трекинг или детекция? YOLO - это детектор,YOLO применяют для трекинга,"в 8 версии встроен трекер, но yolo - это детектор"
Трекинг или детекция? YOLO - это детектор,YOLO применяют для трекинга,"в 8 версии встроен трекер, но yolo - это детектор","В оригинальной YOLOv4 тоже есть трекер, только его никто особо не использует.
А под ""встроен"" подразумевается JDE? Или там просто в коде есть пример с трекингом?"
YOLO применяют для трекинга,"в 8 версии встроен трекер, но yolo - это детектор","В оригинальной YOLOv4 тоже есть трекер, только его никто особо не использует.
А под ""встроен"" подразумевается JDE? Или там просто в коде есть пример с трекингом?",https://docs.ultralytics.com/modes/track/#tracking
"в 8 версии встроен трекер, но yolo - это детектор","В оригинальной YOLOv4 тоже есть трекер, только его никто особо не использует.
А под ""встроен"" подразумевается JDE? Или там просто в коде есть пример с трекингом?",https://docs.ultralytics.com/modes/track/#tracking,"tracker_type: botsort  # tracker type, ['botsort', 'bytetrack']"
,,,"детекция. вроде про трекинг и не писал нигде.
Странно что раньше оно мне в глаза не бросалось. Все модельки обучались без особых трудностей, я последний месяц горе-эксперименты на этой машине с yolo гоняю."
,,"детекция. вроде про трекинг и не писал нигде.
Странно что раньше оно мне в глаза не бросалось. Все модельки обучались без особых трудностей, я последний месяц горе-эксперименты на этой машине с yolo гоняю.","сорри, не тебе хотел ответить. там был вопрос про трекинг мяча"
,,,"а тут начало чудить, на довольно легких данных.
Там сет ужатый весит 24 мб всего.
А раньше обучалось на материалах на порядок более тяжелых"
,,"а тут начало чудить, на довольно легких данных.
Там сет ужатый весит 24 мб всего.
А раньше обучалось на материалах на порядок более тяжелых","Ты да, я и отвечал не тебе"
,"а тут начало чудить, на довольно легких данных.
Там сет ужатый весит 24 мб всего.
А раньше обучалось на материалах на порядок более тяжелых","Ты да, я и отвечал не тебе","Я не так давно делал трекер нескольких частиц на видео с микроскопа, просто обучил yolov8 на детекцию этих частиц и если просто запустить покадровую детекцию с присвоением id, то они переприсваивались на каждом кадре по разному, поэтому я просто искал на каждом кадре ближайшую частицу по евклидовому расстоянию, может вам такой подход тоже пригодится, если не справятся трекеры по типу deepsort или встроенный в yolo метод track"
,,,А поиграть с якорями йоло пробовал?
,,,"v8 - это индийское чудо, там лик на лике"
,,"v8 - это индийское чудо, там лик на лике",Что вы подразумеваете под лик? Может имеются в виду баги?
,,,"Привет от нуба ✌️
Может, пожалуйста, кто-нибудь описать плюсы идти в ML? Зп как будто примерно на уровне мобайл и веб девелоперов, а порог вхождения очевидно на порядок выше, так что почему вы сюда пошли? 😄

Есть техническая вышка, ушёл в армейку и хочу заранее определиться, чему обучаться, когда вернусь. Мобилки и веб отталкивают отсутствием какого-то вызова, всё монотонно и трудозатратно, но не видел в процессе обучения какие-то интересные задачи, которые приходится решать. Не знаю, что делают мл-инженеры и тп, боюсь после изучения базы столкнуться с такими же монотонными скучными задачками)"
,,"Привет от нуба ✌️
Может, пожалуйста, кто-нибудь описать плюсы идти в ML? Зп как будто примерно на уровне мобайл и веб девелоперов, а порог вхождения очевидно на порядок выше, так что почему вы сюда пошли? 😄

Есть техническая вышка, ушёл в армейку и хочу заранее определиться, чему обучаться, когда вернусь. Мобилки и веб отталкивают отсутствием какого-то вызова, всё монотонно и трудозатратно, но не видел в процессе обучения какие-то интересные задачи, которые приходится решать. Не знаю, что делают мл-инженеры и тп, боюсь после изучения базы столкнуться с такими же монотонными скучными задачками)","Я лично умею и во фронт, и в мобайл, и в бэкэнд, и в десктоп, и в гис, и в СУБД, и свои языки писать.

Не очень понимаю почему за все это платят так же как за ML, - который я люблю как математик по первому образованию.

Но догадываюсь, что скорее всего если поделить число дата саентистов на число проектов для них, и поделить число фронтендеров на число проектов с фронтендом...

все окажется на своих местах"
,,,"низкое качество кода с утечками памяти видимо подразумевается, хотя конкретно в данном случае я думаю просто по умолчанию какой нибудь даталоадер запускается на кучу воркеров"
,,"низкое качество кода с утечками памяти видимо подразумевается, хотя конкретно в данном случае я думаю просто по умолчанию какой нибудь даталоадер запускается на кучу воркеров","Судя по всему да. 
Сокращение числа воркеров в два раза снизило кратно количество процессов. 
Правда получается что там по три питон процесса на воркер.)"
,,,Неплохой выбор
,,Неплохой выбор,"upd: найдено)
привет! нашел интересную вакансию в сбере, хочу податься через реферал. может кто-нибудь помочь?
или это не для этого чятика вопрос?"
,,,">> Мобилки и веб отталкивают отсутствием какого-то вызова, всё монотонно и трудозатратно, но не видел в процессе обучения какие-то интересные задачи, которые приходится решать. 

В МЛ я пошёл как раз потому что всё наоборот"
,,">> Мобилки и веб отталкивают отсутствием какого-то вызова, всё монотонно и трудозатратно, но не видел в процессе обучения какие-то интересные задачи, которые приходится решать. 

В МЛ я пошёл как раз потому что всё наоборот",Каждый день немонотонные интересные вызовы?)
,">> Мобилки и веб отталкивают отсутствием какого-то вызова, всё монотонно и трудозатратно, но не видел в процессе обучения какие-то интересные задачи, которые приходится решать. 

В МЛ я пошёл как раз потому что всё наоборот",Каждый день немонотонные интересные вызовы?),"Путаешься во временах. Я про прошедшее время, а ты про настоящее"
,,,"в абсолютно любой сфере можно попасть как и в место, где будет монотонно и без вызовов, так и наоборот. В мобильной и веб разработке тоже хватает челленджа, если знать где искать"
,,"в абсолютно любой сфере можно попасть как и в место, где будет монотонно и без вызовов, так и наоборот. В мобильной и веб разработке тоже хватает челленджа, если знать где искать","Если не знать где искать, можно столкнуться с интересными задачами на работе.
Беда технического образования в том, что DS/MLщики захватили его и теперь студенты думают что ТОЛЬКО это секси работа в айти.
В мобилках, фронте и беке дофига интересного и сложного."
,,,это правда
,,это правда,"хотя значительная часть мльщиков которых я знаю занимаются тем что дергают репы с детекторами, подливая в ямл конфиги свои датасеты, тоже не шибко увлекательная работа"
,это правда,"хотя значительная часть мльщиков которых я знаю занимаются тем что дергают репы с детекторами, подливая в ямл конфиги свои датасеты, тоже не шибко увлекательная работа","Ого, это стартаперы наверное?
Как же джейсоны поперекладывать"
,,,"но все почему-то думают, что это обязательно чето секси"
,,,"ямл конфиг чтобы понять, надо пэйпер прочитать как минимум"
,,"ямл конфиг чтобы понять, надо пэйпер прочитать как минимум",)
,,,ну вот короч я к тому что в мль есть точно такой же эквивалент перекладывания джейсонов
,,,"и чем дальше, тем больше его"
,,"и чем дальше, тем больше его",да если бы... у меня из пяти текущих в проектов в одном одна из трех моделей такое произошло
,,,что именно такое?
,,что именно такое?,ямл конфиг и готовый датасет
,,,В остальных что-то из разряда звезду с неба ухватить
,,,"ну как математик ты же понимаешь, что один человек из выборки не репрезентативен"
,,"ну как математик ты же понимаешь, что один человек из выборки не репрезентативен","Если этот человек - я, то вполне репрезентативно"
,,,"Для физически движущихся объектов (мысль) фильтр Калмана - который в ванильных сортерах - должен норм заходить.

Вот когда человеки кренделями ходят, вот тут он слабосилен)"
,,"Для физически движущихся объектов (мысль) фильтр Калмана - который в ванильных сортерах - должен норм заходить.

Вот когда человеки кренделями ходят, вот тут он слабосилен)",Кальман для спортивных событий плохо работает. Слишком нелинейные движения!
,"Для физически движущихся объектов (мысль) фильтр Калмана - который в ванильных сортерах - должен норм заходить.

Вот когда человеки кренделями ходят, вот тут он слабосилен)",Кальман для спортивных событий плохо работает. Слишком нелинейные движения!,"Ну ок, ок. Это была просто мысль)"
,,,"Есть сомнение, что линенйный Калман для шайб будет работать. Она же никогда по прямой не едет (ломаная - это не прямая)"
,,,У меня есть для вас кандидат
,,У меня есть для вас кандидат,На Се начинается?
,,,Привет! Есть у кого-нибудь опыт в предсказании локации пользователя/POI?
,,Привет! Есть у кого-нибудь опыт в предсказании локации пользователя/POI?,"Всем привет! Ищу товарища по вкатыванию в сложный мир ds. Считаю, что в дуэте намного эффективнее и интереснее этим делом заниматься. Цель у меня такая: пройти в топ-компанию на позицию стажёра/джуна. Если преследуешь ту же цель -- смело пиши мне в личку, буду очень рад знакомству 🤝"
,Привет! Есть у кого-нибудь опыт в предсказании локации пользователя/POI?,"Всем привет! Ищу товарища по вкатыванию в сложный мир ds. Считаю, что в дуэте намного эффективнее и интереснее этим делом заниматься. Цель у меня такая: пройти в топ-компанию на позицию стажёра/джуна. Если преследуешь ту же цель -- смело пиши мне в личку, буду очень рад знакомству 🤝","А ты прям с 0 или есть уже какие-то знания, опыт?"
,,,"Примерный план у меня как в закрепе: начну с тервера Райгородского, ml Соколова, потом к статистике перейду, потом может чуть плотнее ml, либо dls какой нибудь. Но это все так - ориентировочно, если найду с кем ботать, естественно будем подстраиваться и обсуждать (+ хочу sql и мб алгосы)"
,,"Примерный план у меня как в закрепе: начну с тервера Райгородского, ml Соколова, потом к статистике перейду, потом может чуть плотнее ml, либо dls какой нибудь. Но это все так - ориентировочно, если найду с кем ботать, естественно будем подстраиваться и обсуждать (+ хочу sql и мб алгосы)","Лучше начни по другому пути.
Если знаешь питон, то попробуй любой вводный курс по мл/каглить
Так ты сразу поймёшь, нравится и любопытно тебе это или нет
Ты выбрал длинный путь самурая с которого можешь сойти/либо потом осознать, что мл не твое:)
А если сначала и сразу понравится, то математика начнет потом сама наслаиваться
И вообще лучше не расплываться и растекаться, потому что вместо полугода у тебя это может занять 2годв:)"
,,,"Всем привет! Вдруг кто-то сможет подсказать: ищем аналоги gpt, пробовали лламу 2, falcon. gpt норм по потреблению ресурсов, но сильно дорого выходит. Со всем остальным не проходим по ресурсам:( Нужна поддержка русского языка. Если кто-то знает, что еще можно попробовать, напишите, пж🙏"
,,"Всем привет! Вдруг кто-то сможет подсказать: ищем аналоги gpt, пробовали лламу 2, falcon. gpt норм по потреблению ресурсов, но сильно дорого выходит. Со всем остальным не проходим по ресурсам:( Нужна поддержка русского языка. Если кто-то знает, что еще можно попробовать, напишите, пж🙏","Вы менеджер? В любом случае, советы выше актуальны, для пробы демонстрации того, на что вы максимум можете рассчитывать с вашими ресурсами, но эта задача (проект, продукт, нужное подчеркнуть) выглядит нежизнеспособной с самого начала. Правильнее эту работу таковой признать, скипнуть и двигаться дальше. Для ChatGPT-подобных систем нужно СИЛЬНО больше ресурсов и как бы вы не крутились результат будет сильно хуже ожиданий. 

Если прям надо запихнуть ChatGPT-подобное нечто в калькулятор, то самой правильной стратегией с точки зрения потраченных ресурсов и получения ожидаемого результата будет подождать несколько лет пока за вас это научатся делать OpenAI (Microsoft, FAIR, DeepMind, Google Research, нужное подчеркнуть), и тупо стянуть готовое)"
,"Всем привет! Вдруг кто-то сможет подсказать: ищем аналоги gpt, пробовали лламу 2, falcon. gpt норм по потреблению ресурсов, но сильно дорого выходит. Со всем остальным не проходим по ресурсам:( Нужна поддержка русского языка. Если кто-то знает, что еще можно попробовать, напишите, пж🙏","Вы менеджер? В любом случае, советы выше актуальны, для пробы демонстрации того, на что вы максимум можете рассчитывать с вашими ресурсами, но эта задача (проект, продукт, нужное подчеркнуть) выглядит нежизнеспособной с самого начала. Правильнее эту работу таковой признать, скипнуть и двигаться дальше. Для ChatGPT-подобных систем нужно СИЛЬНО больше ресурсов и как бы вы не крутились результат будет сильно хуже ожиданий. 

Если прям надо запихнуть ChatGPT-подобное нечто в калькулятор, то самой правильной стратегией с точки зрения потраченных ресурсов и получения ожидаемого результата будет подождать несколько лет пока за вас это научатся делать OpenAI (Microsoft, FAIR, DeepMind, Google Research, нужное подчеркнуть), и тупо стянуть готовое)","Либо не научится, и все купят 5/6G и построят больше датацентров"
,,,а ресурсы-то какие?
,,а ресурсы-то какие?,"Грустные)) 6 гигов оперативки, 4 процессора. Пока пришли к тому, что минималка для моделей 30 гигов оперативки, но мб есть что более легковесное"
,а ресурсы-то какие?,"Грустные)) 6 гигов оперативки, 4 процессора. Пока пришли к тому, что минималка для моделей 30 гигов оперативки, но мб есть что более легковесное",А задача у вас есть конкретная? Или просто ищите инструкт модель?
а ресурсы-то какие?,"Грустные)) 6 гигов оперативки, 4 процессора. Пока пришли к тому, что минималка для моделей 30 гигов оперативки, но мб есть что более легковесное",А задача у вас есть конкретная? Или просто ищите инструкт модель?,"Конечная цель, чтобы был ассистент как gpt) но пока хотим, чтобы хотя бы с простыми вопросами и задачами модель справлялась, более ранние версии смотрим, лишь бы русский был"
"Грустные)) 6 гигов оперативки, 4 процессора. Пока пришли к тому, что минималка для моделей 30 гигов оперативки, но мб есть что более легковесное",А задача у вас есть конкретная? Или просто ищите инструкт модель?,"Конечная цель, чтобы был ассистент как gpt) но пока хотим, чтобы хотя бы с простыми вопросами и задачами модель справлялась, более ранние версии смотрим, лишь бы русский был","4-битная 7-миллиардная Сайга влезает https://huggingface.co/IlyaGusev/saiga2_7b_ggml
но как gpt в 6 Гб RAM - это конечно сильно"
А задача у вас есть конкретная? Или просто ищите инструкт модель?,"Конечная цель, чтобы был ассистент как gpt) но пока хотим, чтобы хотя бы с простыми вопросами и задачами модель справлялась, более ранние версии смотрим, лишь бы русский был","4-битная 7-миллиардная Сайга влезает https://huggingface.co/IlyaGusev/saiga2_7b_ggml
но как gpt в 6 Гб RAM - это конечно сильно",Лора базовой модели аутперформит ванильный  chat вариант 2й ламы в бенчмарках? Просто интересно
"Конечная цель, чтобы был ассистент как gpt) но пока хотим, чтобы хотя бы с простыми вопросами и задачами модель справлялась, более ранние версии смотрим, лишь бы русский был","4-битная 7-миллиардная Сайга влезает https://huggingface.co/IlyaGusev/saiga2_7b_ggml
но как gpt в 6 Гб RAM - это конечно сильно",Лора базовой модели аутперформит ванильный  chat вариант 2й ламы в бенчмарках? Просто интересно,"так ванильный chat вариант на английском отвечает, а если сказать явно ""отвечай на русском"", то всё равно на английский срывается
то есть sbs и zero-shot на rsg заведомо проиграет"
"4-битная 7-миллиардная Сайга влезает https://huggingface.co/IlyaGusev/saiga2_7b_ggml
но как gpt в 6 Гб RAM - это конечно сильно",Лора базовой модели аутперформит ванильный  chat вариант 2й ламы в бенчмарках? Просто интересно,"так ванильный chat вариант на английском отвечает, а если сказать явно ""отвечай на русском"", то всё равно на английский срывается
то есть sbs и zero-shot на rsg заведомо проиграет","Кстати, а почему так? Llama2 русского текста мало при обучении видела? Есть ли способ решить проблему без файнтюна? Задача саммари диалога из подкаста."
Лора базовой модели аутперформит ванильный  chat вариант 2й ламы в бенчмарках? Просто интересно,"так ванильный chat вариант на английском отвечает, а если сказать явно ""отвечай на русском"", то всё равно на английский срывается
то есть sbs и zero-shot на rsg заведомо проиграет","Кстати, а почему так? Llama2 русского текста мало при обучении видела? Есть ли способ решить проблему без файнтюна? Задача саммари диалога из подкаста.","Для суммаризации лучше специализированные модели юзать. Типа барта, т5"
"так ванильный chat вариант на английском отвечает, а если сказать явно ""отвечай на русском"", то всё равно на английский срывается
то есть sbs и zero-shot на rsg заведомо проиграет","Кстати, а почему так? Llama2 русского текста мало при обучении видела? Есть ли способ решить проблему без файнтюна? Задача саммари диалога из подкаста.","Для суммаризации лучше специализированные модели юзать. Типа барта, т5","Да, спасибо! Но интересно и про Llama2 понять. Условно Chatgpt с простым промптом сделай саммари этого текста, даже в версии 3.5 перформит гораздо лучше в этой задаче чем Llama2 70b q4b."
"Кстати, а почему так? Llama2 русского текста мало при обучении видела? Есть ли способ решить проблему без файнтюна? Задача саммари диалога из подкаста.","Для суммаризации лучше специализированные модели юзать. Типа барта, т5","Да, спасибо! Но интересно и про Llama2 понять. Условно Chatgpt с простым промптом сделай саммари этого текста, даже в версии 3.5 перформит гораздо лучше в этой задаче чем Llama2 70b q4b.",Ну значит chatGPT обучали на эту задачу
"Для суммаризации лучше специализированные модели юзать. Типа барта, т5","Да, спасибо! Но интересно и про Llama2 понять. Условно Chatgpt с простым промптом сделай саммари этого текста, даже в версии 3.5 перформит гораздо лучше в этой задаче чем Llama2 70b q4b.",Ну значит chatGPT обучали на эту задачу,Вопрос скорее про склонность Llama2 поменять язык на английский в середине ответа. Это особенность квантизованных моделек или оригинал тем же страдает?
"Да, спасибо! Но интересно и про Llama2 понять. Условно Chatgpt с простым промптом сделай саммари этого текста, даже в версии 3.5 перформит гораздо лучше в этой задаче чем Llama2 70b q4b.",Ну значит chatGPT обучали на эту задачу,Вопрос скорее про склонность Llama2 поменять язык на английский в середине ответа. Это особенность квантизованных моделек или оригинал тем же страдает?,"Это особенность ламы. Т.к и на претрейне не особо много русского было, а потом ещё файнтюнинг на английских инструкциях скорее всего."
Ну значит chatGPT обучали на эту задачу,Вопрос скорее про склонность Llama2 поменять язык на английский в середине ответа. Это особенность квантизованных моделек или оригинал тем же страдает?,"Это особенность ламы. Т.к и на претрейне не особо много русского было, а потом ещё файнтюнинг на английских инструкциях скорее всего.",Спасибо)
,,,"Спасибо большое за ответ)🙏
Спасибо!)✨"
,,,"Есть какие нибудь бесплатные модельки для генерации картинок по текстовому описанию, чтобы можно было прям скачать к себе и пользоваться без ограничений?"
,,"Есть какие нибудь бесплатные модельки для генерации картинок по текстовому описанию, чтобы можно было прям скачать к себе и пользоваться без ограничений?","Я бы начал с этого, если с железом нет проблем. Если они все же есть, то же самое вполне работает в колабе. 

https://keras.io/guides/keras_cv/generate_images_with_stable_diffusion/"
,,,Stable diffusion
,,,Диффузий разных сортов и размеров полно. А мощность у тебя есть?
,,Диффузий разных сортов и размеров полно. А мощность у тебя есть?,"Что можно поставить кстати, какое железо? Или где это можно прошарить?"
,Диффузий разных сортов и размеров полно. А мощность у тебя есть?,"Что можно поставить кстати, какое железо? Или где это можно прошарить?","Я пытаюсь вспомнить пример из гитхаба, они использовали 8 А100"
,,,Там для комфортного инференса многих целый кластер нужен
,,Там для комфортного инференса многих целый кластер нужен,"Мощности не проблема, поставим что нибудь"
,Там для комфортного инференса многих целый кластер нужен,"Мощности не проблема, поставим что нибудь","это ж обучение, для генерации хватит попроще"
Там для комфортного инференса многих целый кластер нужен,"Мощности не проблема, поставим что нибудь","это ж обучение, для генерации хватит попроще",Наяр с Редмоном это просто мастхев
,,,"Всех приветствую!

Заранее благодарю за внимание, и прошу прощения, если мое сообщение покажется вам спамом)

Надеюсь сможете уделить время и ответить)

Я разработал идею проекта, на основе ИИ видео обработки. 
Мне очень нужно найти человека, кто мог бы в режиме консультации рассказать, что из моих задумок реально реализовать, а что еще невозможно.

Можете ли посоветовать такого специалиста?"
,,"Всех приветствую!

Заранее благодарю за внимание, и прошу прощения, если мое сообщение покажется вам спамом)

Надеюсь сможете уделить время и ответить)

Я разработал идею проекта, на основе ИИ видео обработки. 
Мне очень нужно найти человека, кто мог бы в режиме консультации рассказать, что из моих задумок реально реализовать, а что еще невозможно.

Можете ли посоветовать такого специалиста?","Так пишите здесь, поможем"
,,,"Я опишу в общих чертах моменты, по которым у меня сомнения. Буду рад любым подсказкам)

Задумка:
Школьники и любой активный пользователь соцсетей устанавливает приложение, загружает свое видео, выбирает шаблон, и получает сгенерированное видео, которое можно доредактировать
Люди которые умеют создавать и обучать ИИ модели для stable diffusion,  загружают свои шаблоны и зарабатывают на том, что их шаблон используют

Основные блоки, по которым вопросы:
- развертывание нашего stable diffusion для ИИ видеомейкеров, которые будут на нем создавать или импортировать свои шаблоны
- создание и размещение своих шаблонов (моделей) для стартового контента. Каждый из шаблонов обучен под определенный стиль (например кантри, персонажи истории игрушек, манга)
- генерирование пользователю видео по одному из шаблонов, на основе видео пользователя. Исходное видео загружается из памяти устройства пользователя. 
- Тестовый режим, с водяным знаком, с ограничением на количество сгенерированного видео. Желательно чтобы водяной знак было сложно удалить, например сделать его как печать или вышивку на элементах видео
- загрузка и обработка шаблонов (моделей) от пользователя, и публикация для всех (возможно только в веб интерфейсе)
- редактор сгенерированного видео. Какие параметры можем добавить, чтобы не раздувать затрачиваемые ресурсы. Например: сгенерировать заново, убрать/добавить/заменить предмет или область, сгенерировать другой бекграунд, обрезать видео по таймлайну или нарезать из частей, стабилизация дергавшейся картинки, Eye detection, Upscale, motion detection для качественного удаления бекграунда. Увеличить или уменьшить степень диффузии. Наложить звук из нашей библиотеки или загруженный с устройства. Редактирование в режиме диалога со встроенным чатИИ
- режим камеры. Обработка видео по выбранному пользователем шаблону в режиме реального времени (насколько это реально). Запись сразу обработанной по шаблону версии видео и последующее редактирование

Пока сформировались такие мысли:
0. Есть понимание, что для стабильного достижения достаточного уровня качества, видеоряд, который загружает пользователь должен соответствовать некоторым требованиям.
1. Брать с оригинала видео только человека его лицо в первую очередь и черты тела, запоминать движения, а остальное дорисовывать из заданного стиля.
2. На этапе анализа сразу указывать, что на видео не удалось распознать человека и его движения, а значит результат хороший получить не получится, и пользователю следует загрузить другое видео.
3. Так сказать делать аватара человека в разных стилях. Можно даже записывать общие характеристики аватара человека, чтобы при загрузке нового видео с ним же, ускорять обработку, используя уже имеющиеся параметры аватара. 
4. На этапе подготовки видео проводить предобработку. При этом упростить процесс вычислений, чтобы дать максимальную скорость. Так как цель, это чтобы аватар повторил движения, может быть сразу и делать только захват движений. Может быть даже с камеры будет проще его делать, чем с отснятого видео. Особенно если накладывать распознанные базовые линии уже на экране камеры, что будет наглядно показывать пользователю, где алгоритм теряется и не может распознать.

Вопрос основной: Что из описанного невозможно реализовать полностью или возможно лишь частично, в ближайшие несколько месяцев, в связи с еще не достаточным развитием видео генеративных ИИ платформ"
,,"Я опишу в общих чертах моменты, по которым у меня сомнения. Буду рад любым подсказкам)

Задумка:
Школьники и любой активный пользователь соцсетей устанавливает приложение, загружает свое видео, выбирает шаблон, и получает сгенерированное видео, которое можно доредактировать
Люди которые умеют создавать и обучать ИИ модели для stable diffusion,  загружают свои шаблоны и зарабатывают на том, что их шаблон используют

Основные блоки, по которым вопросы:
- развертывание нашего stable diffusion для ИИ видеомейкеров, которые будут на нем создавать или импортировать свои шаблоны
- создание и размещение своих шаблонов (моделей) для стартового контента. Каждый из шаблонов обучен под определенный стиль (например кантри, персонажи истории игрушек, манга)
- генерирование пользователю видео по одному из шаблонов, на основе видео пользователя. Исходное видео загружается из памяти устройства пользователя. 
- Тестовый режим, с водяным знаком, с ограничением на количество сгенерированного видео. Желательно чтобы водяной знак было сложно удалить, например сделать его как печать или вышивку на элементах видео
- загрузка и обработка шаблонов (моделей) от пользователя, и публикация для всех (возможно только в веб интерфейсе)
- редактор сгенерированного видео. Какие параметры можем добавить, чтобы не раздувать затрачиваемые ресурсы. Например: сгенерировать заново, убрать/добавить/заменить предмет или область, сгенерировать другой бекграунд, обрезать видео по таймлайну или нарезать из частей, стабилизация дергавшейся картинки, Eye detection, Upscale, motion detection для качественного удаления бекграунда. Увеличить или уменьшить степень диффузии. Наложить звук из нашей библиотеки или загруженный с устройства. Редактирование в режиме диалога со встроенным чатИИ
- режим камеры. Обработка видео по выбранному пользователем шаблону в режиме реального времени (насколько это реально). Запись сразу обработанной по шаблону версии видео и последующее редактирование

Пока сформировались такие мысли:
0. Есть понимание, что для стабильного достижения достаточного уровня качества, видеоряд, который загружает пользователь должен соответствовать некоторым требованиям.
1. Брать с оригинала видео только человека его лицо в первую очередь и черты тела, запоминать движения, а остальное дорисовывать из заданного стиля.
2. На этапе анализа сразу указывать, что на видео не удалось распознать человека и его движения, а значит результат хороший получить не получится, и пользователю следует загрузить другое видео.
3. Так сказать делать аватара человека в разных стилях. Можно даже записывать общие характеристики аватара человека, чтобы при загрузке нового видео с ним же, ускорять обработку, используя уже имеющиеся параметры аватара. 
4. На этапе подготовки видео проводить предобработку. При этом упростить процесс вычислений, чтобы дать максимальную скорость. Так как цель, это чтобы аватар повторил движения, может быть сразу и делать только захват движений. Может быть даже с камеры будет проще его делать, чем с отснятого видео. Особенно если накладывать распознанные базовые линии уже на экране камеры, что будет наглядно показывать пользователю, где алгоритм теряется и не может распознать.

Вопрос основной: Что из описанного невозможно реализовать полностью или возможно лишь частично, в ближайшие несколько месяцев, в связи с еще не достаточным развитием видео генеративных ИИ платформ","ТЗ слегка эклектика конечно... Возможно вот эта ссылка сориентирует немного

https://stability.ai/blog/stable-animation-sdk"
,"Я опишу в общих чертах моменты, по которым у меня сомнения. Буду рад любым подсказкам)

Задумка:
Школьники и любой активный пользователь соцсетей устанавливает приложение, загружает свое видео, выбирает шаблон, и получает сгенерированное видео, которое можно доредактировать
Люди которые умеют создавать и обучать ИИ модели для stable diffusion,  загружают свои шаблоны и зарабатывают на том, что их шаблон используют

Основные блоки, по которым вопросы:
- развертывание нашего stable diffusion для ИИ видеомейкеров, которые будут на нем создавать или импортировать свои шаблоны
- создание и размещение своих шаблонов (моделей) для стартового контента. Каждый из шаблонов обучен под определенный стиль (например кантри, персонажи истории игрушек, манга)
- генерирование пользователю видео по одному из шаблонов, на основе видео пользователя. Исходное видео загружается из памяти устройства пользователя. 
- Тестовый режим, с водяным знаком, с ограничением на количество сгенерированного видео. Желательно чтобы водяной знак было сложно удалить, например сделать его как печать или вышивку на элементах видео
- загрузка и обработка шаблонов (моделей) от пользователя, и публикация для всех (возможно только в веб интерфейсе)
- редактор сгенерированного видео. Какие параметры можем добавить, чтобы не раздувать затрачиваемые ресурсы. Например: сгенерировать заново, убрать/добавить/заменить предмет или область, сгенерировать другой бекграунд, обрезать видео по таймлайну или нарезать из частей, стабилизация дергавшейся картинки, Eye detection, Upscale, motion detection для качественного удаления бекграунда. Увеличить или уменьшить степень диффузии. Наложить звук из нашей библиотеки или загруженный с устройства. Редактирование в режиме диалога со встроенным чатИИ
- режим камеры. Обработка видео по выбранному пользователем шаблону в режиме реального времени (насколько это реально). Запись сразу обработанной по шаблону версии видео и последующее редактирование

Пока сформировались такие мысли:
0. Есть понимание, что для стабильного достижения достаточного уровня качества, видеоряд, который загружает пользователь должен соответствовать некоторым требованиям.
1. Брать с оригинала видео только человека его лицо в первую очередь и черты тела, запоминать движения, а остальное дорисовывать из заданного стиля.
2. На этапе анализа сразу указывать, что на видео не удалось распознать человека и его движения, а значит результат хороший получить не получится, и пользователю следует загрузить другое видео.
3. Так сказать делать аватара человека в разных стилях. Можно даже записывать общие характеристики аватара человека, чтобы при загрузке нового видео с ним же, ускорять обработку, используя уже имеющиеся параметры аватара. 
4. На этапе подготовки видео проводить предобработку. При этом упростить процесс вычислений, чтобы дать максимальную скорость. Так как цель, это чтобы аватар повторил движения, может быть сразу и делать только захват движений. Может быть даже с камеры будет проще его делать, чем с отснятого видео. Особенно если накладывать распознанные базовые линии уже на экране камеры, что будет наглядно показывать пользователю, где алгоритм теряется и не может распознать.

Вопрос основной: Что из описанного невозможно реализовать полностью или возможно лишь частично, в ближайшие несколько месяцев, в связи с еще не достаточным развитием видео генеративных ИИ платформ","ТЗ слегка эклектика конечно... Возможно вот эта ссылка сориентирует немного

https://stability.ai/blog/stable-animation-sdk","Благодарю за ответ
Встречался раньше со stability AI
Изучу подробнее)"
,,,А где 🍴и причем тут ops)
,,А где 🍴и причем тут ops),"полечите оформление пожалуйста, иначе удалим

не полечили, удалил"
,А где 🍴и причем тут ops),"полечите оформление пожалуйста, иначе удалим

не полечили, удалил","Всем привет, пытался загуглить инфу по chatgpt и yagpt относительно бюджета и команды, но смог найти только про 700к в день на поддержание работ чата, может кто встречал такую инфу?"
,,,Почему так?
,,,а кто-то файнтюнит sdxl?
,,а кто-то файнтюнит sdxl?,На сивитаи лежит некоторое количество лор
,а кто-то файнтюнит sdxl?,На сивитаи лежит некоторое количество лор,"это да, но вопрос про натив трейнинг, а то пообщался с haru из wd и они страдают подобрать гиперпараметры"
,,,"В тематических чатиках в тг этим занимаются в основном безумцы
Говорят, быстро схватывает
Конечно страдают, два клипа воткнуто хз зачем"
,,"В тематических чатиках в тг этим занимаются в основном безумцы
Говорят, быстро схватывает
Конечно страдают, два клипа воткнуто хз зачем",у них модель на трейне унета даж умирает при неподходящеи лр
,,,"Всем привет, не знаю отнести в эту категорию или нет, но всё же. Недавно начал анализировать log scale, появился вопрос: Какая польза будет/не будет оттого, что преобразованию подвергнется не только целевая переменная, но и остальные признаки? Помогите, пожалуйста"
,,"Всем привет, не знаю отнести в эту категорию или нет, но всё же. Недавно начал анализировать log scale, появился вопрос: Какая польза будет/не будет оттого, что преобразованию подвергнется не только целевая переменная, но и остальные признаки? Помогите, пожалуйста","Если у тебя бустинг, лучше фичи готовить через https://contrib.scikit-learn.org/category_encoders/"
,"Всем привет, не знаю отнести в эту категорию или нет, но всё же. Недавно начал анализировать log scale, появился вопрос: Какая польза будет/не будет оттого, что преобразованию подвергнется не только целевая переменная, но и остальные признаки? Помогите, пожалуйста","Если у тебя бустинг, лучше фичи готовить через https://contrib.scikit-learn.org/category_encoders/","Если линейные модели, то через https://pypi.org/project/autowoe/"
,,,"Смотря для чего
- Анализировать сильно смещенные распределения будет проще
- Линейной модели точно понравится
- Деревья и бустинги по идее сильно не заденет
- Всему,что обучается на градиентах, тоже кайф будет

Да и вообще хорошо стремиться к тому, чтобы все переменные были примерно одного масштаба"
,,"Смотря для чего
- Анализировать сильно смещенные распределения будет проще
- Линейной модели точно понравится
- Деревья и бустинги по идее сильно не заденет
- Всему,что обучается на градиентах, тоже кайф будет

Да и вообще хорошо стремиться к тому, чтобы все переменные были примерно одного масштаба","Временные ряды?)
Не суть. Преобразования нужны чтобы измерять все в наиболее подходящих друг к другу попугаях"
,,,"Привет ! 
Подскажите плиз, а что сейчас лучше всего генерит картинку содержащую текст в хорошем качестве ?"
,,"Привет ! 
Подскажите плиз, а что сейчас лучше всего генерит картинку содержащую текст в хорошем качестве ?",https://t.me/lovedeathtransformers/5979
,,,"Всем привет! Прошу совета у акул ML и пираний DS. Не знаю в какой профильный чат обратиться, так что пишу в welcome.

У нас на офисном nas'ике скопилось несколько ТБ сканов и фотогрфий всяких разных документов. 

Мне нужно как-то проиндексировать эти документы по тексту, чтобы можно было быстренько искать нужный документ в этой бессистемной многолетней куче.

Я хочу воспользоваться готовыми решениями, лучше каким-то прикладным ПО. Индексатор текстов планирую взять Archivarius 3000. А какой прогой лучше сделать OCR такого огромного количества файлов? Fine Reader на таких объёмах сходит с ума (+ почему-то не использует видеокарту, да и проц грузит по минимуму)."
,,"Всем привет! Прошу совета у акул ML и пираний DS. Не знаю в какой профильный чат обратиться, так что пишу в welcome.

У нас на офисном nas'ике скопилось несколько ТБ сканов и фотогрфий всяких разных документов. 

Мне нужно как-то проиндексировать эти документы по тексту, чтобы можно было быстренько искать нужный документ в этой бессистемной многолетней куче.

Я хочу воспользоваться готовыми решениями, лучше каким-то прикладным ПО. Индексатор текстов планирую взять Archivarius 3000. А какой прогой лучше сделать OCR такого огромного количества файлов? Fine Reader на таких объёмах сходит с ума (+ почему-то не использует видеокарту, да и проц грузит по минимуму).",А в чем проблема в канале про CV такое спрашивать?
,,,"Мне кажется можно воспользоваться ocr pytesseract (либо если есть другая схожая библиотека которая позволяет считать на gpu), а из индексатора документов weaviate
но лучше эти сообщения перенести в другой тред или вообще в лс)"
,,,"Всем привет. Когда-то слышал про соревнование на kaggle ""для детекции тюленей"" может кто поскидывать полезные материалы по этому соревнованию?"
,,"Всем привет. Когда-то слышал про соревнование на kaggle ""для детекции тюленей"" может кто поскидывать полезные материалы по этому соревнованию?",А можешь ссылку скинуть?
,,,у него и с weviate есть интеграция
,,у него и с weviate есть интеграция,"Текст лучше всего генерит IF от deepfloyd, картинки лучше всего генерит stable diffusion спустя месяц кусания кактуса опенсорсных интерфейсов к ним, в хорошем качестве генерит миджорни, то что тебе надо конкретно по твоему видению можно добиться стилизацией через контролнет во всех нейронках к которым его подтыкали и тренили."
,у него и с weviate есть интеграция,"Текст лучше всего генерит IF от deepfloyd, картинки лучше всего генерит stable diffusion спустя месяц кусания кактуса опенсорсных интерфейсов к ним, в хорошем качестве генерит миджорни, то что тебе надо конкретно по твоему видению можно добиться стилизацией через контролнет во всех нейронках к которым его подтыкали и тренили.",Спасибо !)
у него и с weviate есть интеграция,"Текст лучше всего генерит IF от deepfloyd, картинки лучше всего генерит stable diffusion спустя месяц кусания кактуса опенсорсных интерфейсов к ним, в хорошем качестве генерит миджорни, то что тебе надо конкретно по твоему видению можно добиться стилизацией через контролнет во всех нейронках к которым его подтыкали и тренили.",Спасибо !),да
,,,"Всем привет! Помогите понять. Я думаю, все видели как midjourney нагенерила Гарри Поттера в разных образах. Меня интересует, каким образом была сделана анимация. Это тоже какая-то моделька? Это же не сам миджорни делает?"
,,"Всем привет! Помогите понять. Я думаю, все видели как midjourney нагенерила Гарри Поттера в разных образах. Меня интересует, каким образом была сделана анимация. Это тоже какая-то моделька? Это же не сам миджорни делает?",https://www.youtube.com/watch?v=TGD8zKvRxc4
,,,"Если вдруг я не туда, прошу прощения"
,,"Если вдруг я не туда, прошу прощения","мем с баленсиагой васянят через D-ID сервис для создания говорящих голов из картинки. В стейбле для этого есть sadTalker экстеншен, но там конечно все значительно грустнее выглядит."
,,,"А, вот оно что. Этот сервис нашла. А есть инфа, что используется для анимации? Очень интересно, как это работает всё."
,,"А, вот оно что. Этот сервис нашла. А есть инфа, что используется для анимации? Очень интересно, как это работает всё.","в плане дипфейковых говорящих голов на гитхабе сейчас, откровенно говоря, неустоявшийся бардак.  Библиотеки есть, методы есть, сборки воедино будь добр сделай сам. 
насколько я понимаю там для мемного dame da ne метода подтыкается предзаписанная маска с артикуляцией и липсинком"
,"А, вот оно что. Этот сервис нашла. А есть инфа, что используется для анимации? Очень интересно, как это работает всё.","в плане дипфейковых говорящих голов на гитхабе сейчас, откровенно говоря, неустоявшийся бардак.  Библиотеки есть, методы есть, сборки воедино будь добр сделай сам. 
насколько я понимаю там для мемного dame da ne метода подтыкается предзаписанная маска с артикуляцией и липсинком",
,,,Поняла. Значит полезу в эти дебри. Спасибо!
,,,"А как работает такая прикольная анимация рта? Она прям идеально в звуки попадает. Я думала, что там генерится просто рандомное открытие и закрытие, хм"
,,"А как работает такая прикольная анимация рта? Она прям идеально в звуки попадает. Я думала, что там генерится просто рандомное открытие и закрытие, хм","https://github.com/OpenTalker/SadTalker самая трогаемая альтернатива
липсинк не ракетная наука"
,,,"А, вот эта. Хорошо, попробую. Спасибо!"
,,"А, вот эта. Хорошо, попробую. Спасибо!","Накидайте тг/yt/ medium каналов или других источников, с помощью которых вы следите за новинками в области CV. Интересует общий срез, а не конкретная специфичная область
Так же интересно, где искать статьи / обзоры, направленные на оптимальность модели? Я имею ввиду, что сота модельки по разным метрикам качества легко найти на paperswithcode, но часто они там больших размеров и / или заоверфичены под конкретный датасет. Где вы ищете модельки, которые имеют хороший трейдофф скорости / качества?"
,"А, вот эта. Хорошо, попробую. Спасибо!","Накидайте тг/yt/ medium каналов или других источников, с помощью которых вы следите за новинками в области CV. Интересует общий срез, а не конкретная специфичная область
Так же интересно, где искать статьи / обзоры, направленные на оптимальность модели? Я имею ввиду, что сота модельки по разным метрикам качества легко найти на paperswithcode, но часто они там больших размеров и / или заоверфичены под конкретный датасет. Где вы ищете модельки, которые имеют хороший трейдофф скорости / качества?","А есть кто шарит за Yandex Research ML Residency: какие  там условия, нагрузка, зп? Интересные ли проекты и нормально ли происходит взаимодействие с научником или для галочки?"
,,,Есть ли у Кандински какие-либо ограничения по использованию?
,,Есть ли у Кандински какие-либо ограничения по использованию?,"А какие интересуют? 
Т2и есть, и2и есть, инпеинт есть, вариации/смешивание есть, контролнет глубины есть, лицензия написана везде, инференс жирный но в колаб помещается"
,Есть ли у Кандински какие-либо ограничения по использованию?,"А какие интересуют? 
Т2и есть, и2и есть, инпеинт есть, вариации/смешивание есть, контролнет глубины есть, лицензия написана везде, инференс жирный но в колаб помещается",По количеству запросов - я про это
,,,"…трен лоры и текстовой инверсии есть

Бот в тг неограниченная халява как и fusionbrain или голососберомощники, но цензура и очереди"
,,"…трен лоры и текстовой инверсии есть

Бот в тг неограниченная халява как и fusionbrain или голососберомощники, но цензура и очереди","можете объяснить, что это?😁 ""трен лоры и текстовой инверсии есть"""
,"…трен лоры и текстовой инверсии есть

Бот в тг неограниченная халява как и fusionbrain или голососберомощники, но цензура и очереди","можете объяснить, что это?😁 ""трен лоры и текстовой инверсии есть""",можно натренировать конкретный стиль или концепцию в специальный файл-вставку и с его помощью надежно его вызывать
,,,">трен лоры и текстовой инверсии есть
там его нет -"
,,">трен лоры и текстовой инверсии есть
там его нет -",https://colab.research.google.com/drive/1lUWfe4CWhPJhUZYjMAE7g4ciHX4764rN?usp=sharing не трогал но есть же?
,,,в боте конечно нет
,,,"человек спросил про кандински ,я ответил про кандински в целом :3"
,,"человек спросил про кандински ,я ответил про кандински в целом :3",
,,,"всем привет, кто-нибудь знает кто давал название Kandinskiy?"
,,"всем привет, кто-нибудь знает кто давал название Kandinskiy?","Ну тут сидят ребята из команды могут ответить, но вообще в рамках Брейн шторма"
,"всем привет, кто-нибудь знает кто давал название Kandinskiy?","Ну тут сидят ребята из команды могут ответить, но вообще в рамках Брейн шторма","Да, только, не знаю кого пинговать, но хотел бы попросить от имени сообщества, коммьюнити поднять вопрос о переименовании"
"всем привет, кто-нибудь знает кто давал название Kandinskiy?","Ну тут сидят ребята из команды могут ответить, но вообще в рамках Брейн шторма","Да, только, не знаю кого пинговать, но хотел бы попросить от имени сообщества, коммьюнити поднять вопрос о переименовании",А зачем
,,,"С готовыми трекерами в opencv я пробовал, но думал может, уже есть что-то лучше?"
,,"С готовыми трекерами в opencv я пробовал, но думал может, уже есть что-то лучше?","У готовых из OpenCV самый классный - это на сиамских сетях. Если полегче, то Nano. Их пробовал?"
,"С готовыми трекерами в opencv я пробовал, но думал может, уже есть что-то лучше?","У готовых из OpenCV самый классный - это на сиамских сетях. Если полегче, то Nano. Их пробовал?","Вот сиамские нейросети не пробовал, а как называется трекер? Сходу не могу найти в opencv."
,,,ну на paperswithcode можно еще посмотреть
,,ну на paperswithcode можно еще посмотреть,"есть, но просизводительности Pi скорее всего не хватит
но можно добавить признаки, посчитанные какой-то лёгкой моделью"
,ну на paperswithcode можно еще посмотреть,"есть, но просизводительности Pi скорее всего не хватит
но можно добавить признаки, посчитанные какой-то лёгкой моделью","Если выберешь nano, то только v2, первый плоховат"
ну на paperswithcode можно еще посмотреть,"есть, но просизводительности Pi скорее всего не хватит
но можно добавить признаки, посчитанные какой-то лёгкой моделью","Если выберешь nano, то только v2, первый плоховат",Спасибо! Буду пробовать.
"есть, но просизводительности Pi скорее всего не хватит
но можно добавить признаки, посчитанные какой-то лёгкой моделью","Если выберешь nano, то только v2, первый плоховат",Спасибо! Буду пробовать.,Плюс один в диси)
"Если выберешь nano, то только v2, первый плоховат",Спасибо! Буду пробовать.,Плюс один в диси),"Всем привет! Не подскажете, где можно что-то почитать/посмотреть о таком:

Дано решение какой-нибудь задачи (по математике скажем), или код какой нибудь, и надо научиться проверять его, хотя бы находить огромные косяки, например неправильно подсчитанные выражения и тд."
,,,"Коллеги привет! Стоит задача — после диаризации аудиозаписи распознать спикеров по ФИО. Есть таймкоды начала/окончания разговора каждого спикера. Я хочу получить эмбеддинги всех фрагментов записи по каждому спикеру, после чего усреднить все полученные эмбеддинги по каждому спикеру и получить эталонный эмбеддинг голоса. Буду хранить его в базе (ФИО-эмбединг) и на следующих записях проверять косинусную близость между новыми голосами и теми что уже в базе. Вопрос - верный ли подход, и если да — какую посоветуете сетку для формирования эмбеддингов по аудиофрагменту? Важно ли чтобы сеть была обучена на русской речи?"
,,"Коллеги привет! Стоит задача — после диаризации аудиозаписи распознать спикеров по ФИО. Есть таймкоды начала/окончания разговора каждого спикера. Я хочу получить эмбеддинги всех фрагментов записи по каждому спикеру, после чего усреднить все полученные эмбеддинги по каждому спикеру и получить эталонный эмбеддинг голоса. Буду хранить его в базе (ФИО-эмбединг) и на следующих записях проверять косинусную близость между новыми голосами и теми что уже в базе. Вопрос - верный ли подход, и если да — какую посоветуете сетку для формирования эмбеддингов по аудиофрагменту? Важно ли чтобы сеть была обучена на русской речи?","Я бы массив держал из N элементов для каждого спикера, причём чтоб максимально эмбединги внутри были далекими. И потом искомый эмбединг сравнил бы с этим массивом"
,"Коллеги привет! Стоит задача — после диаризации аудиозаписи распознать спикеров по ФИО. Есть таймкоды начала/окончания разговора каждого спикера. Я хочу получить эмбеддинги всех фрагментов записи по каждому спикеру, после чего усреднить все полученные эмбеддинги по каждому спикеру и получить эталонный эмбеддинг голоса. Буду хранить его в базе (ФИО-эмбединг) и на следующих записях проверять косинусную близость между новыми голосами и теми что уже в базе. Вопрос - верный ли подход, и если да — какую посоветуете сетку для формирования эмбеддингов по аудиофрагменту? Важно ли чтобы сеть была обучена на русской речи?","Я бы массив держал из N элементов для каждого спикера, причём чтоб максимально эмбединги внутри были далекими. И потом искомый эмбединг сравнил бы с этим массивом",А чем эмбеддинги получать?
"Коллеги привет! Стоит задача — после диаризации аудиозаписи распознать спикеров по ФИО. Есть таймкоды начала/окончания разговора каждого спикера. Я хочу получить эмбеддинги всех фрагментов записи по каждому спикеру, после чего усреднить все полученные эмбеддинги по каждому спикеру и получить эталонный эмбеддинг голоса. Буду хранить его в базе (ФИО-эмбединг) и на следующих записях проверять косинусную близость между новыми голосами и теми что уже в базе. Вопрос - верный ли подход, и если да — какую посоветуете сетку для формирования эмбеддингов по аудиофрагменту? Важно ли чтобы сеть была обучена на русской речи?","Я бы массив держал из N элементов для каждого спикера, причём чтоб максимально эмбединги внутри были далекими. И потом искомый эмбединг сравнил бы с этим массивом",А чем эмбеддинги получать?,А как до этого хотел собрать записи одного спикера?
"Я бы массив держал из N элементов для каждого спикера, причём чтоб максимально эмбединги внутри были далекими. И потом искомый эмбединг сравнил бы с этим массивом",А чем эмбеддинги получать?,А как до этого хотел собрать записи одного спикера?,Pyanotte для диаризации использую.
,,,После диаризации появляется есть таблица спикер-начало-конец. Вырезаю из записи эти куски
,,После диаризации появляется есть таблица спикер-начало-конец. Вырезаю из записи эти куски,"Посмотри это https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/speaker_recognition/intro.html
И это еще https://github.com/idiap/bert-text-diarization-atc
Второй вариант еще учитывает текст. Идея в том, что когда человек говорит, есть слова и порядок слов, которые уникальны для спикера. 
Так же для разделения на спикеров может виспер диаризацию использовать, есть такой отдельный проект на гитхабе"
,,,"Нет, спасибо, посмотрю"
,,,"видос нет, но стажки в сбере местами норм, местами не очень. но в целом для первой стажи - пойдет"
,,"видос нет, но стажки в сбере местами норм, местами не очень. но в целом для первой стажи - пойдет",Спасибо!!!
,,,"Привет. Оцените, пожалуйста, CV) И, если не сложно - подскажите, что можно улучшить.
Ищу позицию Middle/Middle+ ML Ops или MLE (ввиду редкости позиций ML Ops)."
,,"Привет. Оцените, пожалуйста, CV) И, если не сложно - подскажите, что можно улучшить.
Ищу позицию Middle/Middle+ ML Ops или MLE (ввиду редкости позиций ML Ops).","Выглядит норм. Что можно улучшить - добавить гитхаб, ссылки на соревнования, если есть, добавить ссылки на продукты, которые ты делал, либо на сайты компаний, ссылки на статьи и выступления если есть."
,"Привет. Оцените, пожалуйста, CV) И, если не сложно - подскажите, что можно улучшить.
Ищу позицию Middle/Middle+ ML Ops или MLE (ввиду редкости позиций ML Ops).","Выглядит норм. Что можно улучшить - добавить гитхаб, ссылки на соревнования, если есть, добавить ссылки на продукты, которые ты делал, либо на сайты компаний, ссылки на статьи и выступления если есть.","Да, спасибо.
Выступлений и статей пока, увы, нет. Гитхаб надо б заполнить)

Имеет ли смысл туда заливать решение несложных задач, типа обёрнутого в Телеграм бота детектора?"
"Привет. Оцените, пожалуйста, CV) И, если не сложно - подскажите, что можно улучшить.
Ищу позицию Middle/Middle+ ML Ops или MLE (ввиду редкости позиций ML Ops).","Выглядит норм. Что можно улучшить - добавить гитхаб, ссылки на соревнования, если есть, добавить ссылки на продукты, которые ты делал, либо на сайты компаний, ссылки на статьи и выступления если есть.","Да, спасибо.
Выступлений и статей пока, увы, нет. Гитхаб надо б заполнить)

Имеет ли смысл туда заливать решение несложных задач, типа обёрнутого в Телеграм бота детектора?","Да, конечно имеет смысл. Понятно, что боевые задачи с работы никто не может показывать. Как раз всякие простые вещи показывают как человек пишет код"
,,,"По-моему норм. Не придирка, но рамка вокруг ссылки выглядит инородно... По опыту и все остальное 🆒"
,,"По-моему норм. Не придирка, но рамка вокруг ссылки выглядит инородно... По опыту и все остальное 🆒","Согласен, спасибо)"
,"По-моему норм. Не придирка, но рамка вокруг ссылки выглядит инородно... По опыту и все остальное 🆒","Согласен, спасибо)",Ну значит это было из разряда красного слоника?)
"По-моему норм. Не придирка, но рамка вокруг ссылки выглядит инородно... По опыту и все остальное 🆒","Согласен, спасибо)",Ну значит это было из разряда красного слоника?),"Нет. Просто я сомневался на этот счёт. С одной стороны - инородно, с другой стороны - всё-таки, подчёркивает, что это именно ссылка.
У меня, на самом деле, больше вопрос к разделителям ""|"" в пунктах по проектам. Я слил некоторые в один, чтобы по итогу всё влезло на одну страницу."
,,,иногда еще говорят собачки
,,,"Думаю, не упоролся ли я с одностраничностью)"
,,"Думаю, не упоролся ли я с одностраничностью)",Это вот как раз не напрасно
,,,Зачем в вакансиях на ML просят linux shell и что под этим подрузамевается?
,,Зачем в вакансиях на ML просят linux shell и что под этим подрузамевается?,"Добавлю еще, что хорошо бы иметь понимание про PATH, осознание какой питон запускается и туда ли ты поставил пакеты."
,,,"работа в командной строке - навигация, выводы, файлик открыть нано/вимом, команду какую-нить докеру отдать или переменную назначить)"
,,"работа в командной строке - навигация, выводы, файлик открыть нано/вимом, команду какую-нить докеру отдать или переменную назначить)","зачем, не скажу, а linux shell это наверняка команды в командной строке 
я бы посмотрел pwd, cd, ps auxw |grep имя процесса, top, htop, free -h, df -h, du -sh директория,
точка = текущая директория, ~ - домашняя директория
ssh, scp
это попробовать, остальное можно сказать, ""счас что-то не помню"" )
ну и логи читать tail -f"
,,Спасибо,"серверы (на *nix) в 99% случаев без графического интерфейса (не нужен он). И из управления там только консолька. Ну и исторически она может все то же что и графический интерфейс, и еще исторически много-много всего другого. Если быстро тыкаешь по кнопкам - то и быстрее"
,,,rm rf
,,rm rf,"perl .... | echo ""test test test...""

...

чему хорошему человека бы научил)

man vim

например"
,,,давать разрабам судо эт канеш особый вид извращения
,,давать разрабам судо эт канеш особый вид извращения,"Это совершенно _нормальная_ практика в DL командах, видел много где"
,давать разрабам судо эт канеш особый вид извращения,"Это совершенно _нормальная_ практика в DL командах, видел много где",надеюсь у них всё хорошо идёт
,,,pin version наверное надо использовать
,,,"контейнеры? не, не слышал"
,,"контейнеры? не, не слышал",Кееек. Настроить докер так чтобы разраб не мог сделать себе sudo надо постараться сильнее
,"контейнеры? не, не слышал",Кееек. Настроить докер так чтобы разраб не мог сделать себе sudo надо постараться сильнее,"лолшто, я к тому, что зачем давать судо в целом на сервере, если можно организовать всю работу в контейнерах и там юзать судо сколько хошь, ничего не поломает для других"
"контейнеры? не, не слышал",Кееек. Настроить докер так чтобы разраб не мог сделать себе sudo надо постараться сильнее,"лолшто, я к тому, что зачем давать судо в целом на сервере, если можно организовать всю работу в контейнерах и там юзать судо сколько хошь, ничего не поломает для других","тошто, у докера много приколов и сайд эффектов.
sudo-права на всю систему vs дать всем докер -- холивар, оба варианта с плюсами и минусами.
Зависит от того что важно и как работу организовать.

Если неорганизованно работать в докере, поломается в одном месте. Если со всеобщими судо-правами в другом."
,,,"Я конечно не шарю, но разве витуал енв не всегда прописывать нужно для своих проектов?"
,,"Я конечно не шарю, но разве витуал енв не всегда прописывать нужно для своих проектов?",тут не про пакеты питоновские а глобальные утилиты системы речь я так понимаю
,,,"Всем привет! Есть задача дообучить text-to-text модель, но никогда тюнингом не занимался. Если кто-то уже это делал, то можете подсказать"
,,"Всем привет! Есть задача дообучить text-to-text модель, но никогда тюнингом не занимался. Если кто-то уже это делал, то можете подсказать",а подсказать то что????????
,,,"Если дообучить, то есть готовая сетка, которая работает, но плохо?
Какой язык?
Есть датасет ""нужный текст на входе - нужный текст на выходе""?
Какой размер датасета?"
,,,"Статью, ноутбук что угодно.. (для русской речи)"
,,"Статью, ноутбук что угодно.. (для русской речи)",https://github.com/Den4ikAI/FRED-T5-Finetuning
,,,"если есть наглядный пример, то вообще супер
Спасибо👍"
,,,"Всем привет, какой бесплатный солвер посоветуете для MILP задачи, где много переменных и ограничений (целочисленные переменные бинарные)"
,,"Всем привет, какой бесплатный солвер посоветуете для MILP задачи, где много переменных и ограничений (целочисленные переменные бинарные)","не уверен что именно такая постановка есть там, но гляньте or-tools"
,,,"Всем привет, подскажите пожалуйста sota в классификации видео или в выделении эмбеддинга из всего видео"
,,,"Соту, прям соту, подсказать, конечно, не могу, но большинство  работ из топов paperswithcode юзают clip или xclip"
,,"Соту, прям соту, подсказать, конечно, не могу, но большинство  работ из топов paperswithcode юзают clip или xclip",Клипы для выделения ембедингов
,,,"кто-то из старого коллектива вероятно
до кандинского были модели с названиями в честь других художников
малевич тот же"
,,,"надо просто в какого-то нормального художника перименовать, масштаб модели не соответсвует масштабу художника"
,,"надо просто в какого-то нормального художника перименовать, масштаб модели не соответсвует масштабу художника",да на самом деле не стоило просто наследовать имя Кандинский
,,,"например?
(инб4 уууууххххх какой крутой художник Стабильная Диффузия, вечно соперничал с мадам Фаерфлай)"
,,"например?
(инб4 уууууххххх какой крутой художник Стабильная Диффузия, вечно соперничал с мадам Фаерфлай)",Как-то забыл уточнить
,"например?
(инб4 уууууххххх какой крутой художник Стабильная Диффузия, вечно соперничал с мадам Фаерфлай)",Как-то забыл уточнить,"Ну это понятно, есть DINO v2 тот же получше, но я имею в виду из видео как то достать один информативный вектор, а не список векторов"
"например?
(инб4 уууууххххх какой крутой художник Стабильная Диффузия, вечно соперничал с мадам Фаерфлай)",Как-то забыл уточнить,"Ну это понятно, есть DINO v2 тот же получше, но я имею в виду из видео как то достать один информативный вектор, а не список векторов","первый и второй совершенно разные проекты
куда более разные чем малевич и кандинский 1"
Как-то забыл уточнить,"Ну это понятно, есть DINO v2 тот же получше, но я имею в виду из видео как то достать один информативный вектор, а не список векторов","первый и второй совершенно разные проекты
куда более разные чем малевич и кандинский 1","Да, от имени сообщества это громко
скорее только от моего"
"Ну это понятно, есть DINO v2 тот же получше, но я имею в виду из видео как то достать один информативный вектор, а не список векторов","первый и второй совершенно разные проекты
куда более разные чем малевич и кандинский 1","Да, от имени сообщества это громко
скорее только от моего",Но зачем?..
"первый и второй совершенно разные проекты
куда более разные чем малевич и кандинский 1","Да, от имени сообщества это громко
скорее только от моего",Но зачем?..,"Как вариант можно извлекать эмбединги для всего видео, а дальше кластеризовать в какое-то фиксированное подпространство"
,,,"Всем привет! Может кто-то, пожалуйста, объяснить почему в этом примере ответ: 14.94 (несколько раз пересчитывал) или скинуть хорошую сетку(лучше сервис) для подсчёта."
,,"Всем привет! Может кто-то, пожалуйста, объяснить почему в этом примере ответ: 14.94 (несколько раз пересчитывал) или скинуть хорошую сетку(лучше сервис) для подсчёта.",На глаз целое число будет
,,,"А, не, третье слагаемое дробное"
,,"А, не, третье слагаемое дробное","привет, может кто знает хорошие веса Stable diffusion, которая генерит картинки на белом фоне/ или похожие на вектор/ даже лучше похожее на вектор и на белом фоне👨‍💻"
,,,"привет, может кто знает хорошие веса Stable diffusion, которая генерит картинки на белом фоне/ или похожие на вектор/ даже лучше похожее на вектор и на белом фоне👨‍💻"
,,"привет, может кто знает хорошие веса Stable diffusion, которая генерит картинки на белом фоне/ или похожие на вектор/ даже лучше похожее на вектор и на белом фоне👨‍💻",https://civitai.com/models/34739/logoarchive есть такое
,,,"Ребят, всем привет. Пытаюсь разобраться с этной и временными рядами . Подскажите, что я делаю не так в этом куске кода. Хочу помимо таргета закинуть ещё признаки, которые есть во временном ряде. Вроде бы в доке было написано, что это регрессионные признаки, но при попытке их добавить вылазит ошибка. Кажется, что что-то неправильно понимаю"
,,"Ребят, всем привет. Пытаюсь разобраться с этной и временными рядами . Подскажите, что я делаю не так в этом куске кода. Хочу помимо таргета закинуть ещё признаки, которые есть во временном ряде. Вроде бы в доке было написано, что это регрессионные признаки, но при попытке их добавить вылазит ошибка. Кажется, что что-то неправильно понимаю","Привет, у нас есть чат, можно туда писать https://t.me/etna_support )

По твоей ошибки, у нас ""регрессорами"" считаются признаки которые известны в будущем. Если они не известны, то можно от них сделать лаги. Но тогда не нужно ставить known_future для всех признаков изначально"
,"Ребят, всем привет. Пытаюсь разобраться с этной и временными рядами . Подскажите, что я делаю не так в этом куске кода. Хочу помимо таргета закинуть ещё признаки, которые есть во временном ряде. Вроде бы в доке было написано, что это регрессионные признаки, но при попытке их добавить вылазит ошибка. Кажется, что что-то неправильно понимаю","Привет, у нас есть чат, можно туда писать https://t.me/etna_support )

По твоей ошибки, у нас ""регрессорами"" считаются признаки которые известны в будущем. Если они не известны, то можно от них сделать лаги. Но тогда не нужно ставить known_future для всех признаков изначально","аа, понял. А если у меня фичи, которые приходят вместе с таргетом, то мне просто нужно для них также делать лаги, как для самого таргета? (как на картинке)"
,,,"вот ошибка
вот как выглядит датасет для ясности"
,,"вот ошибка
вот как выглядит датасет для ясности","Типа того, да"
,"вот ошибка
вот как выглядит датасет для ясности","Типа того, да","ещё один вопрос. Тогда нужно после добавления лагов удалять эти фичи или этна их учтет сама?
чтобы не было ликов"
,,,"В данном случае лучше дропнуть, да. Часть моделей сама дропнет. Модели которые умеют с нанами работать, катбуст например, попробует учесть эти признаки, но вряд-ли от них какой-то толк будет"
,,"В данном случае лучше дропнуть, да. Часть моделей сама дропнет. Модели которые умеют с нанами работать, катбуст например, попробует учесть эти признаки, но вряд-ли от них какой-то толк будет","я немного про другое. Я имею ввиду сами переменные. Типо если мы сдвинем Open, то появятся новые колонки с лагами опена, но сам open останется"
,,,и вот вопрос нужно ли его удалять
,,и вот вопрос нужно ли его удалять,"Да, я про то же вроде)

Фича Open останется. Потом она либо будет использоваться, либо нет - зависит от модели"
,,,"Привет NLP сообщество) подскажите какие модельки  🤗 попробовать для суммаризации новостей (русскоязычные) чтоб на выходе было не 2-3 предложения, ну а порядка 8-10"
,,"Привет NLP сообщество) подскажите какие модельки  🤗 попробовать для суммаризации новостей (русскоязычные) чтоб на выходе было не 2-3 предложения, ну а порядка 8-10","bert-extractive-summarizer. Предложения будут из текста, но количество задать можно .

Если англ, то повезло. Есть coreference"
,"Привет NLP сообщество) подскажите какие модельки  🤗 попробовать для суммаризации новостей (русскоязычные) чтоб на выходе было не 2-3 предложения, ну а порядка 8-10","bert-extractive-summarizer. Предложения будут из текста, но количество задать можно .

Если англ, то повезло. Есть coreference","Оке, тоже гляну) есть вариант перевести на английский сначала, а потом суммаризировать."
,,,"всё, наверное понял, спасибо большое)"
,,"всё, наверное понял, спасибо большое)",BaRT?
,,,"Тут есть Илья Гусев, он известный мастер : есть статьи и модели"
,,"Тут есть Илья Гусев, он известный мастер : есть статьи и модели","Ок, спасибки)"
,,,Поищи на HF
,,,"По моему опыту логарифмическое преобразование фичей почти не пригождается. Для деревянных моделей как писали выше пофиг. Линейные модели лучше учить на woe фичах

Единственное где это в моем опыте было полезно - при построении моделей эластичности. Когда по дизайну нужно построить простую линейную модель, где коэффициенты как раз показывают эластичность. В таком случае распределение цен логнормальное и мы используем лог лог модель."
,,"По моему опыту логарифмическое преобразование фичей почти не пригождается. Для деревянных моделей как писали выше пофиг. Линейные модели лучше учить на woe фичах

Единственное где это в моем опыте было полезно - при построении моделей эластичности. Когда по дизайну нужно построить простую линейную модель, где коэффициенты как раз показывают эластичность. В таком случае распределение цен логнормальное и мы используем лог лог модель.","Логарифмы в вашем опыте не пригождались, видимо потому что у вас были аддитивные зависимости в данных. 

Стоило бы там затесаться чему-то околоценовому, была бы другая история"
,"По моему опыту логарифмическое преобразование фичей почти не пригождается. Для деревянных моделей как писали выше пофиг. Линейные модели лучше учить на woe фичах

Единственное где это в моем опыте было полезно - при построении моделей эластичности. Когда по дизайну нужно построить простую линейную модель, где коэффициенты как раз показывают эластичность. В таком случае распределение цен логнормальное и мы используем лог лог модель.","Логарифмы в вашем опыте не пригождались, видимо потому что у вас были аддитивные зависимости в данных. 

Стоило бы там затесаться чему-то околоценовому, была бы другая история",Но вопрос как логарифмические преобразования качество моделей улучшают
"По моему опыту логарифмическое преобразование фичей почти не пригождается. Для деревянных моделей как писали выше пофиг. Линейные модели лучше учить на woe фичах

Единственное где это в моем опыте было полезно - при построении моделей эластичности. Когда по дизайну нужно построить простую линейную модель, где коэффициенты как раз показывают эластичность. В таком случае распределение цен логнормальное и мы используем лог лог модель.","Логарифмы в вашем опыте не пригождались, видимо потому что у вас были аддитивные зависимости в данных. 

Стоило бы там затесаться чему-то околоценовому, была бы другая история",Но вопрос как логарифмические преобразования качество моделей улучшают,"Вопрос хороший. Бывает, улучшают. Некоторые архитектуры , начиная от линейной, хорошо реагируют на замену умножения сложением"
,,,"Наверное для сеток будет полезно, где есть логнормальные фичи. Но я сам никогда сетки на табличных задачах в прод не катил. Мб кто-то тут эмбеддинги по пользователям обучал или что-то похожее делал, и отпишет тут свой опыт"
,,"Наверное для сеток будет полезно, где есть логнормальные фичи. Но я сам никогда сетки на табличных задачах в прод не катил. Мб кто-то тут эмбеддинги по пользователям обучал или что-то похожее делал, и отпишет тут свой опыт","Глупый может вопрос, а есть какой нибудь нормальный датасет с картинками и данными по ним по типу ava например,  только чтоб картинки уже скачанные были, вчера  пытался ava, но у нее ссылки на dp, и он напрямую картинки не отдает (html).
Из за слова non - это шум для модели."
,"Наверное для сеток будет полезно, где есть логнормальные фичи. Но я сам никогда сетки на табличных задачах в прод не катил. Мб кто-то тут эмбеддинги по пользователям обучал или что-то похожее делал, и отпишет тут свой опыт","Глупый может вопрос, а есть какой нибудь нормальный датасет с картинками и данными по ним по типу ava например,  только чтоб картинки уже скачанные были, вчера  пытался ava, но у нее ссылки на dp, и он напрямую картинки не отдает (html).
Из за слова non - это шум для модели.","Не претендую на истину, скорее привожу примеры rule of thumb"
,,,Эти условия тоже относятся к программистам (этой вакансии)? Это с сайта информация
,,Эти условия тоже относятся к программистам (этой вакансии)? Это с сайта информация,Рофл
,,,"Привет, хочу разобраться с генеративные моделями, диффузиями и LLM. Но кажется, что материала так много, что не понятно, с чего начать и что важно для собеседований и полезно понимать в целом.
Можете посоветовать, какой хороший разбор диффузий и LLM можно посмотреть и, может, какой-то план изучения тем посоветовать?"
,,"Привет, хочу разобраться с генеративные моделями, диффузиями и LLM. Но кажется, что материала так много, что не понятно, с чего начать и что важно для собеседований и полезно понимать в целом.
Можете посоветовать, какой хороший разбор диффузий и LLM можно посмотреть и, может, какой-то план изучения тем посоветовать?","про диффузии тут хорошо написано, можно стартовать

https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
,,,"Привет, такой вопрос, есть ли где-то сборник/топ самых важных статей как из мл в целом, так и по топикам? Чтобы иметь представление о ключевых работах в разных областях ( по типу  Attention в NLP и т. д)"
,,"Привет, такой вопрос, есть ли где-то сборник/топ самых важных статей как из мл в целом, так и по топикам? Чтобы иметь представление о ключевых работах в разных областях ( по типу  Attention в NLP и т. д)",Paper with code посмотри ресурс
,,,"работаем брат
а не забей она хуйню выдала"
,,,"всяких awesome на гитхабе полно.

Но вот вопрос, что значит ""ключевой"". Attention is all you need - он такой один.

Если что фронтир - это еще пока вязкое и непрогнозируемое, даже в обратную сторону"
,,"всяких awesome на гитхабе полно.

Но вот вопрос, что значит ""ключевой"". Attention is all you need - он такой один.

Если что фронтир - это еще пока вязкое и непрогнозируемое, даже в обратную сторону","Ну и кстати есть способ. Открыть huggingface, отсортировать модели в каждой задаче по скачиваниям (или лайкам, но вряд ли). Топ10 собрать пэйперы, посмотреть что общего разного.

Не благодарите)"
,,,"Заинтересовался ml. Хочу начать хорошо ориентироваться в нем.
Из того что понял, 
1) это суровые статистические модели, плюс какие-то современные методы работы с ними
2) нужен питон на уровне ниже среднего (вроде без фреймворков люди обходятся)
3) надо уметь готовить данные
4) надо уметь кастомизировать llm модели под себя (можно взять нейросеть и натренировать её под свои задачи).
И это собственно все умения, которые надо уметь уметь.

В чем я сильно не прав и какой роуд мап на пару лет для ""вжух и вхиро""?"
,,"Заинтересовался ml. Хочу начать хорошо ориентироваться в нем.
Из того что понял, 
1) это суровые статистические модели, плюс какие-то современные методы работы с ними
2) нужен питон на уровне ниже среднего (вроде без фреймворков люди обходятся)
3) надо уметь готовить данные
4) надо уметь кастомизировать llm модели под себя (можно взять нейросеть и натренировать её под свои задачи).
И это собственно все умения, которые надо уметь уметь.

В чем я сильно не прав и какой роуд мап на пару лет для ""вжух и вхиро""?",Я бы посоветовал ещё добавить пункт с участием в соревнованиях на каггле
,"Заинтересовался ml. Хочу начать хорошо ориентироваться в нем.
Из того что понял, 
1) это суровые статистические модели, плюс какие-то современные методы работы с ними
2) нужен питон на уровне ниже среднего (вроде без фреймворков люди обходятся)
3) надо уметь готовить данные
4) надо уметь кастомизировать llm модели под себя (можно взять нейросеть и натренировать её под свои задачи).
И это собственно все умения, которые надо уметь уметь.

В чем я сильно не прав и какой роуд мап на пару лет для ""вжух и вхиро""?",Я бы посоветовал ещё добавить пункт с участием в соревнованиях на каггле,Спасибо. Думал о таком тоже.
,,,"ну на питоне ниже среднего далеко не уедешь
желательно неплохо его знать + пару фреймворков"
,,"ну на питоне ниже среднего далеко не уедешь
желательно неплохо его знать + пару фреймворков",Как ml без фреймворков?)
,"ну на питоне ниже среднего далеко не уедешь
желательно неплохо его знать + пару фреймворков",Как ml без фреймворков?),О. А какие фреймвопки для ml?
"ну на питоне ниже среднего далеко не уедешь
желательно неплохо его знать + пару фреймворков",Как ml без фреймворков?),О. А какие фреймвопки для ml?,"А что Вы собирались писать без их испоьзования, просто интересно?"
,,,"Ну вот есть джанго. Даёт удобства всякие типа mtv. Понятно для чего. А в ml для чего (я просто не знаю, а из того что на утубе видел,  там просто библиотеки, в которых есть методы считать  статистические алгоритмы быстрее чем сам напишешь)"
,,"Ну вот есть джанго. Даёт удобства всякие типа mtv. Понятно для чего. А в ml для чего (я просто не знаю, а из того что на утубе видел,  там просто библиотеки, в которых есть методы считать  статистические алгоритмы быстрее чем сам напишешь)",PyTorch/tensorflow/scikit-learn всякие
,,,Если вы мне названия просто скажете фреймворков для мл я и сам чатгпт помучаю.
,,Если вы мне названия просто скажете фреймворков для мл я и сам чатгпт помучаю.,"Ахахаха, вот оно, будущее"
,Если вы мне названия просто скажете фреймворков для мл я и сам чатгпт помучаю.,"Ахахаха, вот оно, будущее",Разумеется :-). Вот кто в наше время от гугля откажется? В ии просто запросы другие немного и вид вывода (иногда удобнее его спросить)
,,,Я думал это библиотеки
,,Я думал это библиотеки,"На Вики вроде пишут фреймворк, но хозяин барин"
,Я думал это библиотеки,"На Вики вроде пишут фреймворк, но хозяин барин",Так а цель то конечная какая? Стать дс-ом\мл инженегром\просто потрогать интересное направление?
,,,"Конечная цель наверное пока потрогать интересное направление. Если заинтересует и продвинусь (субъективно), то может и перепрофилироваться в дс из - как сейчас - нагрузочного тестирования."
,,"Конечная цель наверное пока потрогать интересное направление. Если заинтересует и продвинусь (субъективно), то может и перепрофилироваться в дс из - как сейчас - нагрузочного тестирования.",Huggingface course рекомендую тогда
,,,"Никто не знает, что будет через пару лет, но думаю точно умение просто спрашивать ллмки и получать хорошие ответы станет чем-то вроде умения быстро гуглить (а хочется чего-то более низкоуровнего 😀
Спасибо!"
,,,"Всем ку, читал кто? Хочу обсудить с кем-нибудь шарящим статью эту"
,,"Всем ку, читал кто? Хочу обсудить с кем-нибудь шарящим статью эту",Привет
,,,"Выглядит недурно. Must read
Спасибо"
,,"Выглядит недурно. Must read
Спасибо",100% причём:)
,"Выглядит недурно. Must read
Спасибо",100% причём:),Благодарю от всей души)
"Выглядит недурно. Must read
Спасибо",100% причём:),Благодарю от всей души),Спасибо
100% причём:),Благодарю от всей души),Спасибо,"Про плаформы хз, можно чужие ноутбуки читать и запускать в колабе и на кагле. Или можешь деньги мне на карту перевести"
,,,"Все, посмеялись и хватит) я удаляю ) и спасибо за ответ)"
,,"Все, посмеялись и хватит) я удаляю ) и спасибо за ответ)",А удалять зачем? Может у кого-то есть тот же вопрос
,"Все, посмеялись и хватит) я удаляю ) и спасибо за ответ)",А удалять зачем? Может у кого-то есть тот же вопрос,Там скам был
,,,"Всем привет, кто-нибудь подскажет как к 60 фото в датасете применить аугментацию (какие методы) и превратить их в 1000? Задача Plant Detection"
,,"Всем привет, кто-нибудь подскажет как к 60 фото в датасете применить аугментацию (какие методы) и превратить их в 1000? Задача Plant Detection","чекни albumentations
я обычно бегал по файлам в папке и сохранял аугментированные с суффиксом типа filename_1
А про из 60 сделать 1000, ты конечно можешь, но после этого советую все их просмотреть, потому что может быть многовато мусора"
,,,"Можно не сохранять, только воспроизводить
Аугментации лучше всего делать те, которые физически реализуются в дикой природе..."
,,"Можно не сохранять, только воспроизводить
Аугментации лучше всего делать те, которые физически реализуются в дикой природе...","Не могу сказать, что я очень круто шарю, потому что я всё же не дата инженер
Посмотрел текст статьи, как обычно, обещание за месяц построить космическую ракету не соответствует действительности"
,,,"Например, когда речь идёт про обычные базы данных автор предлагает просто изучить SQL.Это фигня. Нужен нормальный полноценный курс по теории баз данных, где также будут разобраны хранилища данных."
,,"Например, когда речь идёт про обычные базы данных автор предлагает просто изучить SQL.Это фигня. Нужен нормальный полноценный курс по теории баз данных, где также будут разобраны хранилища данных.","Спасибо большое, а где можно поискать?"
,,,"Также смущает, что автор в тексте приравнивает ML инженера к дата инженеру. У каждой компании свои особенности, но в моём понимании, ML инженер занимается выкадкой в продакшн моделей, что требует дополнительных знаний, которые в статье никак не обозначены (kubernetes, kafka, docker etc)
От mail ru на ютубе лежит неплохой курс по базам данных
Хотя про нереляционные вещи там рассказано ужасно, и хадуп со спарком не покрыты"
,,,Почему у шедулеров lr уходит в 0? Там же в конце в основном weight decay работать будет
,,Почему у шедулеров lr уходит в 0? Там же в конце в основном weight decay работать будет,"Интуиция примерно такая:  если функция потерь U-shaped, то на ранних стадиях градиентного спуска мы хотим двигаться быстро (чтобы поскорее приползти в окрестность оптимума), а на поздних – медленно (чтобы не скакать вокруг этого оптимума, регулярно перепрыгивая через него). Но подбирать точные значения lr нам влом, поэтому будем просто плавно уменьшать его до нуля."
,Почему у шедулеров lr уходит в 0? Там же в конце в основном weight decay работать будет,"Интуиция примерно такая:  если функция потерь U-shaped, то на ранних стадиях градиентного спуска мы хотим двигаться быстро (чтобы поскорее приползти в окрестность оптимума), а на поздних – медленно (чтобы не скакать вокруг этого оптимума, регулярно перепрыгивая через него). Но подбирать точные значения lr нам влом, поэтому будем просто плавно уменьшать его до нуля.","Но у нас weight decay  будет все так же работать во всю силу когда lr будет около нулевой и чем ближе к нулю тем больше мы просто уменьшаем веса, без обновлений"
Почему у шедулеров lr уходит в 0? Там же в конце в основном weight decay работать будет,"Интуиция примерно такая:  если функция потерь U-shaped, то на ранних стадиях градиентного спуска мы хотим двигаться быстро (чтобы поскорее приползти в окрестность оптимума), а на поздних – медленно (чтобы не скакать вокруг этого оптимума, регулярно перепрыгивая через него). Но подбирать точные значения lr нам влом, поэтому будем просто плавно уменьшать его до нуля.","Но у нас weight decay  будет все так же работать во всю силу когда lr будет около нулевой и чем ближе к нулю тем больше мы просто уменьшаем веса, без обновлений","Weight decay обычно применяется с тем же самым learning rate, что и градиенты от лосса, и поэтому затухает по такому же расписанию.

Для примера можете почитать формулу торчовой имплементации AdamW: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"
"Интуиция примерно такая:  если функция потерь U-shaped, то на ранних стадиях градиентного спуска мы хотим двигаться быстро (чтобы поскорее приползти в окрестность оптимума), а на поздних – медленно (чтобы не скакать вокруг этого оптимума, регулярно перепрыгивая через него). Но подбирать точные значения lr нам влом, поэтому будем просто плавно уменьшать его до нуля.","Но у нас weight decay  будет все так же работать во всю силу когда lr будет около нулевой и чем ближе к нулю тем больше мы просто уменьшаем веса, без обновлений","Weight decay обычно применяется с тем же самым learning rate, что и градиенты от лосса, и поэтому затухает по такому же расписанию.

Для примера можете почитать формулу торчовой имплементации AdamW: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html","Сори, не увидел"
,,,"Тема с warmup ясна, а это не прнимаю"
,,,"Привет, что порекомендуете для быстрой детекции текста на изображениях? Хочется иметь как можно быстрый инференс, но на гпу"
,,"Привет, что порекомендуете для быстрой детекции текста на изображениях? Хочется иметь как можно быстрый инференс, но на гпу","Мне понравилась layoutLMV3, есть на huggingface. Её легче ставить и работает вроде сносно"
,,,"Добрый день! Можешь поделиться чуть более подробными описаниями проектов? Как попао на первую работу, было ли внятное порфолио?"
,,"Добрый день! Можешь поделиться чуть более подробными описаниями проектов? Как попао на первую работу, было ли внятное порфолио?","Добрый день, часть моих работ выложены на github, в портфолио указывал и другие достижения, в т.ч. серебро в соревновании на kaggle. О компании узнал от преподавателя , и как подкачал скилы попал к ним на собес и стажировку."
,"Добрый день! Можешь поделиться чуть более подробными описаниями проектов? Как попао на первую работу, было ли внятное порфолио?","Добрый день, часть моих работ выложены на github, в портфолио указывал и другие достижения, в т.ч. серебро в соревновании на kaggle. О компании узнал от преподавателя , и как подкачал скилы попал к ним на собес и стажировку.",С таким портфолио Вы получили позицию Middle?
"Добрый день! Можешь поделиться чуть более подробными описаниями проектов? Как попао на первую работу, было ли внятное порфолио?","Добрый день, часть моих работ выложены на github, в портфолио указывал и другие достижения, в т.ч. серебро в соревновании на kaggle. О компании узнал от преподавателя , и как подкачал скилы попал к ним на собес и стажировку.",С таким портфолио Вы получили позицию Middle?,"Нет, начал стажёром, сейчас джуниор. Без опыта работы стать мидлом непосильная задача"
"Добрый день, часть моих работ выложены на github, в портфолио указывал и другие достижения, в т.ч. серебро в соревновании на kaggle. О компании узнал от преподавателя , и как подкачал скилы попал к ним на собес и стажировку.",С таким портфолио Вы получили позицию Middle?,"Нет, начал стажёром, сейчас джуниор. Без опыта работы стать мидлом непосильная задача","Я опешила от того, что все это великолепие тянет только на стажера😊"
,,,"Всем привет! Возникла необходимость сделать инференс языковой модельки на C++. Саму модельку я могу в ONNX конвертнуть и там есть API для C++. А как быть с токенизатором?
Кто-нибудь сталкивался с похожей задачей?"
,,"Всем привет! Возникла необходимость сделать инференс языковой модельки на C++. Саму модельку я могу в ONNX конвертнуть и там есть API для C++. А как быть с токенизатором?
Кто-нибудь сталкивался с похожей задачей?",https://github.com/VKCOM/YouTokenToMe
,,,"Я думаю, что это мне не поможет. Я дообучил bert из HF, у которого токенизатор уже есть. И мне бы это на C++ реализацию перекинуть"
,,"Я думаю, что это мне не поможет. Я дообучил bert из HF, у которого токенизатор уже есть. И мне бы это на C++ реализацию перекинуть","Есть на Kotlin пример реализации. Я использовал его как есть и для берта работало.

https://github.com/pytorch/android-demo-app/blob/master/QuestionAnswering/app/src/main/java/org/pytorch/demo/questionanswering/MainActivity.kt#L110"
,"Я думаю, что это мне не поможет. Я дообучил bert из HF, у которого токенизатор уже есть. И мне бы это на C++ реализацию перекинуть","Есть на Kotlin пример реализации. Я использовал его как есть и для берта работало.

https://github.com/pytorch/android-demo-app/blob/master/QuestionAnswering/app/src/main/java/org/pytorch/demo/questionanswering/MainActivity.kt#L110","Спасибо, посмотрю."
,,,nopandas разработка??? Это как???
,,nopandas разработка??? Это как???,"@SovaSmeshnaya  Это чистый python, в продакшн разработке мы не используем pandas и другие подобные фреймворки 
 
Многие кандидаты, особенно в аналитике, в основном пишут код именно с использованием этого фреймворка и других тяжеловесных аналогов. Мы пишем на чистом языке и стараемся использовать только стандартные встроенные библиотеки"
,nopandas разработка??? Это как???,"@SovaSmeshnaya  Это чистый python, в продакшн разработке мы не используем pandas и другие подобные фреймворки 
 
Многие кандидаты, особенно в аналитике, в основном пишут код именно с использованием этого фреймворка и других тяжеловесных аналогов. Мы пишем на чистом языке и стараемся использовать только стандартные встроенные библиотеки","Интересно, если я правильно понял то pandas не устраивает потому что медленно. Допустим. Тогда два вопроса:
1. Допускаете ли pandas в EDA?
2. Что насчёт, например, двухмерных массивов numpy, которые во многом быстрее  и удобнее, чем городить огород из стандартных питоновских классов?"
nopandas разработка??? Это как???,"@SovaSmeshnaya  Это чистый python, в продакшн разработке мы не используем pandas и другие подобные фреймворки 
 
Многие кандидаты, особенно в аналитике, в основном пишут код именно с использованием этого фреймворка и других тяжеловесных аналогов. Мы пишем на чистом языке и стараемся использовать только стандартные встроенные библиотеки","Интересно, если я правильно понял то pandas не устраивает потому что медленно. Допустим. Тогда два вопроса:
1. Допускаете ли pandas в EDA?
2. Что насчёт, например, двухмерных массивов numpy, которые во многом быстрее  и удобнее, чем городить огород из стандартных питоновских классов?","@Millnesium Да, все верно, но  кроме этого он абсолютно не читаем на проде. 
1. при анализе данных, конечно. no pandas - только о комитах в репозиторий
2. np тоже используем, проблем нет. мы не фрики)"
"@SovaSmeshnaya  Это чистый python, в продакшн разработке мы не используем pandas и другие подобные фреймворки 
 
Многие кандидаты, особенно в аналитике, в основном пишут код именно с использованием этого фреймворка и других тяжеловесных аналогов. Мы пишем на чистом языке и стараемся использовать только стандартные встроенные библиотеки","Интересно, если я правильно понял то pandas не устраивает потому что медленно. Допустим. Тогда два вопроса:
1. Допускаете ли pandas в EDA?
2. Что насчёт, например, двухмерных массивов numpy, которые во многом быстрее  и удобнее, чем городить огород из стандартных питоновских классов?","@Millnesium Да, все верно, но  кроме этого он абсолютно не читаем на проде. 
1. при анализе данных, конечно. no pandas - только о комитах в репозиторий
2. np тоже используем, проблем нет. мы не фрики)","А почему не используете поверх pandas'а, который основан на numpy, numba?

Кажется, скорость разработки оставляет желать лучшего в таком случае? И на сколько бустится скорость обработки данных вашим подходом?"
"Интересно, если я правильно понял то pandas не устраивает потому что медленно. Допустим. Тогда два вопроса:
1. Допускаете ли pandas в EDA?
2. Что насчёт, например, двухмерных массивов numpy, которые во многом быстрее  и удобнее, чем городить огород из стандартных питоновских классов?","@Millnesium Да, все верно, но  кроме этого он абсолютно не читаем на проде. 
1. при анализе данных, конечно. no pandas - только о комитах в репозиторий
2. np тоже используем, проблем нет. мы не фрики)","А почему не используете поверх pandas'а, который основан на numpy, numba?

Кажется, скорость разработки оставляет желать лучшего в таком случае? И на сколько бустится скорость обработки данных вашим подходом?","Я тут левый чувак, но поделюсь своим опытом. Numba (без gpu) ускоряет обычный python код с кучей циклов и вызовов math до 100 раз. Если использовать его поверх np, то ускорение от 1.5 до 5 раз за счет отжора всего CPU.

При этом, разработка куска кода, который оборачивается в jit-компилятор замедляется в 2-3 раза, потому что numba капризная. Кроме того из такого куска кода приходится убирать все настройки над numpy типа scipy, sklearn и т.д., т.к. numba их не кушает. У нас был кейс при котором пишлось отказаться от библы bottleneck (там есть вычисление медианы путем сортировки только половины массива) и из-за этого мы не получили прироста скорости относительно сырого np вообще.

Так что не панацея)"
"@Millnesium Да, все верно, но  кроме этого он абсолютно не читаем на проде. 
1. при анализе данных, конечно. no pandas - только о комитах в репозиторий
2. np тоже используем, проблем нет. мы не фрики)","А почему не используете поверх pandas'а, который основан на numpy, numba?

Кажется, скорость разработки оставляет желать лучшего в таком случае? И на сколько бустится скорость обработки данных вашим подходом?","Я тут левый чувак, но поделюсь своим опытом. Numba (без gpu) ускоряет обычный python код с кучей циклов и вызовов math до 100 раз. Если использовать его поверх np, то ускорение от 1.5 до 5 раз за счет отжора всего CPU.

При этом, разработка куска кода, который оборачивается в jit-компилятор замедляется в 2-3 раза, потому что numba капризная. Кроме того из такого куска кода приходится убирать все настройки над numpy типа scipy, sklearn и т.д., т.к. numba их не кушает. У нас был кейс при котором пишлось отказаться от библы bottleneck (там есть вычисление медианы путем сортировки только половины массива) и из-за этого мы не получили прироста скорости относительно сырого np вообще.

Так что не панацея)","Вкину пару от себя. На одном особенно тяжелом пайплайне обучения довелось параллелить препроцессинг. Изначально был python+pandas без мультипроцесинга. В итоге сначала все обернул в мультипроц, потом пробовал менять весь pandas на polars и numpy, пытался декорировать функции на чистом numpy через JIT (пробовал numba и pypy) и дошло до того, что всю работу с таблицами вообще перенес на Rust и подкинул крейт как либу через maturin. В общем итоге быстрее всего сработало решение на Rust либе и на numpy, сравнительно одинаковые по скорости вышли решения. На numpy было чутка помедленнее т.к. там еще пару методов от чистого питона были. JIT вообще не помог, правильно пишут что он капризный, плюс его еще прогревать надо, на тот момент не стал погружаться, сроки горели. Как-то вот так.
Если что не пытаюсь доказать что что-то лучше, просто, так сказать, делюсь опытом ускорения работы с матрицами в препроцессинге"
,,,очевидный
,,,не фиксирован random
,,не фиксирован random,"хорошо если дело в рандоме

в первом случае модель не запускается в беспл колаб из-за нехватки памяти, вторая же запускается"
,,,"Всем привет, я делаю рекомендательную систему для активностей на основании отчётов пользователя о днях: каждый день юзер создаёт список задач, в конце дня отмечает выполненные и дает субъективные оценки по 10-бальной шкале: продуктивность, интерес, стресс, на основании этих данных делается предсказание топ n активностей на следующий, день максимизирующих целевую метрику с учётом отчетов за прошлые дни. Сейчас я пытаюсь найти хорошую архитектуру, которая будет учитывать временные зависимости, при этом обучаться на данных, собранных с одного пользователя - 260 отчетов по 4 активности в каждом. Очень хотелось бы услышать ваших советов и идей, как лучше решать такую задачу и что использовать без промт инжиниринга 

Пока на ум приходит юзать рекуррентную сеть для обработки истории пользователя и потом по косинусной близости отбирать активности"
,,"Всем привет, я делаю рекомендательную систему для активностей на основании отчётов пользователя о днях: каждый день юзер создаёт список задач, в конце дня отмечает выполненные и дает субъективные оценки по 10-бальной шкале: продуктивность, интерес, стресс, на основании этих данных делается предсказание топ n активностей на следующий, день максимизирующих целевую метрику с учётом отчетов за прошлые дни. Сейчас я пытаюсь найти хорошую архитектуру, которая будет учитывать временные зависимости, при этом обучаться на данных, собранных с одного пользователя - 260 отчетов по 4 активности в каждом. Очень хотелось бы услышать ваших советов и идей, как лучше решать такую задачу и что использовать без промт инжиниринга 

Пока на ум приходит юзать рекуррентную сеть для обработки истории пользователя и потом по косинусной близости отбирать активности","Привет. 
Из простых вариантов:  идея как в slim, только нужно вектора над активностями построить через какую-нибудь nlp  модельку, например, rubert (скорее всего без до обучения заведется). Бонус от подхода: интерпретируемый (близкие активности будут в slim получать близкие вектора) 
Из непростых вариантов: Tisarec какой-нибудь (модель как bert4rec, но ещё докинуты фичи времени наравне с позиционным энкодингом)"
,"Всем привет, я делаю рекомендательную систему для активностей на основании отчётов пользователя о днях: каждый день юзер создаёт список задач, в конце дня отмечает выполненные и дает субъективные оценки по 10-бальной шкале: продуктивность, интерес, стресс, на основании этих данных делается предсказание топ n активностей на следующий, день максимизирующих целевую метрику с учётом отчетов за прошлые дни. Сейчас я пытаюсь найти хорошую архитектуру, которая будет учитывать временные зависимости, при этом обучаться на данных, собранных с одного пользователя - 260 отчетов по 4 активности в каждом. Очень хотелось бы услышать ваших советов и идей, как лучше решать такую задачу и что использовать без промт инжиниринга 

Пока на ум приходит юзать рекуррентную сеть для обработки истории пользователя и потом по косинусной близости отбирать активности","Привет. 
Из простых вариантов:  идея как в slim, только нужно вектора над активностями построить через какую-нибудь nlp  модельку, например, rubert (скорее всего без до обучения заведется). Бонус от подхода: интерпретируемый (близкие активности будут в slim получать близкие вектора) 
Из непростых вариантов: Tisarec какой-нибудь (модель как bert4rec, но ещё докинуты фичи времени наравне с позиционным энкодингом)","А разве slim учитывает как-то временную зависимотсть? Насколько я понимаю, slim делает матричное разложение для user-item матрицы, у меня вместо user-item матрицы будет day-activity матрица но непонятно, как интерпретировать элементы матрицы: допустим есть какой-то день и несколько активностей, которые как положительно так и отрицательно влияли на состояние пользователя, но мы получается забиваем на это и всем активностям проставляем одно число - какую-нибудь взвешенную оценку дня, не знаю насколько это будет работать, возможно, за счет того, что одни и те же активности появляются в днях с разными оценками это как-то уравняется, но вот с временной зависимостью что делать так и непонятно"
"Всем привет, я делаю рекомендательную систему для активностей на основании отчётов пользователя о днях: каждый день юзер создаёт список задач, в конце дня отмечает выполненные и дает субъективные оценки по 10-бальной шкале: продуктивность, интерес, стресс, на основании этих данных делается предсказание топ n активностей на следующий, день максимизирующих целевую метрику с учётом отчетов за прошлые дни. Сейчас я пытаюсь найти хорошую архитектуру, которая будет учитывать временные зависимости, при этом обучаться на данных, собранных с одного пользователя - 260 отчетов по 4 активности в каждом. Очень хотелось бы услышать ваших советов и идей, как лучше решать такую задачу и что использовать без промт инжиниринга 

Пока на ум приходит юзать рекуррентную сеть для обработки истории пользователя и потом по косинусной близости отбирать активности","Привет. 
Из простых вариантов:  идея как в slim, только нужно вектора над активностями построить через какую-нибудь nlp  модельку, например, rubert (скорее всего без до обучения заведется). Бонус от подхода: интерпретируемый (близкие активности будут в slim получать близкие вектора) 
Из непростых вариантов: Tisarec какой-нибудь (модель как bert4rec, но ещё докинуты фичи времени наравне с позиционным энкодингом)","А разве slim учитывает как-то временную зависимотсть? Насколько я понимаю, slim делает матричное разложение для user-item матрицы, у меня вместо user-item матрицы будет day-activity матрица но непонятно, как интерпретировать элементы матрицы: допустим есть какой-то день и несколько активностей, которые как положительно так и отрицательно влияли на состояние пользователя, но мы получается забиваем на это и всем активностям проставляем одно число - какую-нибудь взвешенную оценку дня, не знаю насколько это будет работать, возможно, за счет того, что одни и те же активности появляются в днях с разными оценками это как-то уравняется, но вот с временной зависимостью что делать так и непонятно","Можно брать последние n item, как в YouTube recsys, их порядок вроде как учитывается"
,,,Всем привет! Кто-то знает сервера в Японии с возможностью арендовать пару сотен ip адресов?
,,Всем привет! Кто-то знает сервера в Японии с возможностью арендовать пару сотен ip адресов?,Для какой цели надо?
,Всем привет! Кто-то знает сервера в Японии с возможностью арендовать пару сотен ip адресов?,Для какой цели надо?,Торговля
Всем привет! Кто-то знает сервера в Японии с возможностью арендовать пару сотен ip адресов?,Для какой цели надо?,Торговля,"В общем напиши в саппорт, дадут сколько надо серваков, но могут затребовать  обоснование"
,,,"Что будет если при тесте модели с ohe кодированием встертится значение признака, которого не было на изучающей выборке?"
,,"Что будет если при тесте модели с ohe кодированием встертится значение признака, которого не было на изучающей выборке?",https://scikit-learn.org/stable/modules/preprocessing.html#encoder-infrequent-categories
,,,"будет мизматч размерностей, либо, если размерность сохранилась, неверное предсказание."
,,"будет мизматч размерностей, либо, если размерность сохранилась, неверное предсказание.","Все нормальные имплементации кэшируют и энкодер, и все предыдущие токены декодера, кроме последнего (только что добавленного)."
,"будет мизматч размерностей, либо, если размерность сохранилась, неверное предсказание.","Все нормальные имплементации кэшируют и энкодер, и все предыдущие токены декодера, кроме последнего (только что добавленного).","Перед тем как спросить заходил уже в документацию пацторча
Внесёт шум"
"будет мизматч размерностей, либо, если размерность сохранилась, неверное предсказание.","Все нормальные имплементации кэшируют и энкодер, и все предыдущие токены декодера, кроме последнего (только что добавленного).","Перед тем как спросить заходил уже в документацию пацторча
Внесёт шум","Ещё варианты :timesvd, lightfm реализации Сбера, там время докидываеься как фича"
,,,"Привет есть размеченный датасет, состоящий из большого текста (до 2048 токенов). Следует в тексте выделить важные части. Условно абзацы или предложение подчеркнуть (highlighting). Так сказать, почистить документ от не важной информации. Я думаю в трех направлениях:
1. Взять Т5 и зафайнтюнить ее. Как суммаризатор.
2. Свести это к задаче QA или token-classification.
3. Классификатор подобен BERT-Sum
Возможно, кто-то сталкивался с таким и может поделиться советами или идеями?"
,,"Привет есть размеченный датасет, состоящий из большого текста (до 2048 токенов). Следует в тексте выделить важные части. Условно абзацы или предложение подчеркнуть (highlighting). Так сказать, почистить документ от не важной информации. Я думаю в трех направлениях:
1. Взять Т5 и зафайнтюнить ее. Как суммаризатор.
2. Свести это к задаче QA или token-classification.
3. Классификатор подобен BERT-Sum
Возможно, кто-то сталкивался с таким и может поделиться советами или идеями?","Суммаризатор + классификатор мусор/важное - нормально сработал в пайплайне. Но у меня были диалоги, там легко сделать разметку.

Как с твоим датасетом будет - хз 🤷🏻‍♂️"
,"Привет есть размеченный датасет, состоящий из большого текста (до 2048 токенов). Следует в тексте выделить важные части. Условно абзацы или предложение подчеркнуть (highlighting). Так сказать, почистить документ от не важной информации. Я думаю в трех направлениях:
1. Взять Т5 и зафайнтюнить ее. Как суммаризатор.
2. Свести это к задаче QA или token-classification.
3. Классификатор подобен BERT-Sum
Возможно, кто-то сталкивался с таким и может поделиться советами или идеями?","Суммаризатор + классификатор мусор/важное - нормально сработал в пайплайне. Но у меня были диалоги, там легко сделать разметку.

Как с твоим датасетом будет - хз 🤷🏻‍♂️",а что использовал под суммаризатором? Какой подход? Extractive или Abstractive?
"Привет есть размеченный датасет, состоящий из большого текста (до 2048 токенов). Следует в тексте выделить важные части. Условно абзацы или предложение подчеркнуть (highlighting). Так сказать, почистить документ от не важной информации. Я думаю в трех направлениях:
1. Взять Т5 и зафайнтюнить ее. Как суммаризатор.
2. Свести это к задаче QA или token-classification.
3. Классификатор подобен BERT-Sum
Возможно, кто-то сталкивался с таким и может поделиться советами или идеями?","Суммаризатор + классификатор мусор/важное - нормально сработал в пайплайне. Но у меня были диалоги, там легко сделать разметку.

Как с твоим датасетом будет - хз 🤷🏻‍♂️",а что использовал под суммаризатором? Какой подход? Extractive или Abstractive?,"T5 на samsum доученная на своих данных.
Датасет формировали по аналогии с samsum, так что скорее extractive"
"Суммаризатор + классификатор мусор/важное - нормально сработал в пайплайне. Но у меня были диалоги, там легко сделать разметку.

Как с твоим датасетом будет - хз 🤷🏻‍♂️",а что использовал под суммаризатором? Какой подход? Extractive или Abstractive?,"T5 на samsum доученная на своих данных.
Датасет формировали по аналогии с samsum, так что скорее extractive",Спасибо большое
,,,"Сталкивался с таким в работе с более маленькими текстами (одно или несколько предложений), которые нужно было очистить от разных вводных фраз, хорошо сработал подход token classification."
,,"Сталкивался с таким в работе с более маленькими текстами (одно или несколько предложений), которые нужно было очистить от разных вводных фраз, хорошо сработал подход token classification.","а как, считаете, на больших текстах оно сработает или от большого количества текста Token Classification может просто размечать все подряд?"
,"Сталкивался с таким в работе с более маленькими текстами (одно или несколько предложений), которые нужно было очистить от разных вводных фраз, хорошо сработал подход token classification.","а как, считаете, на больших текстах оно сработает или от большого количества текста Token Classification может просто размечать все подряд?","Думаю, что сложность token classification от длины текста не очень зависит – а больше зависит от того, насколько разметка нетривиальная."
,,,"как написали выше, либо упадет с ошибкой по размеру, либо, если обрабатывается, то просто отсекается фича не из тренировочного набора в простом случае"
,,,Можно глянуть в сторону методов экстрактивной суммаризации
,,Можно глянуть в сторону методов экстрактивной суммаризации,Спасибо
,,,"Ну у меня текста примерно на одну - две страници А4. И в нем выделении предложения, абзацы. Тексти очень разние."
,,"Ну у меня текста примерно на одну - две страници А4. И в нем выделении предложения, абзацы. Тексти очень разние.","Зависит от того чем кодируете, короче :) 
У OHE аж 3 режима есть"
,"Ну у меня текста примерно на одну - две страници А4. И в нем выделении предложения, абзацы. Тексти очень разние.","Зависит от того чем кодируете, короче :) 
У OHE аж 3 режима есть","Почистил флуд, ребят"
,,,AWS
,,AWS,Там нельзя купить пару сотен ip адресов:(
,AWS,Там нельзя купить пару сотен ip адресов:(,"Там можно арендовать многг серваков, по крайней мере знакомого хакнули на aws) возможно майнили, точно не знаю"
,,,"Не верится)) 
Как тогда крупные компании пользуются AWS для своих сервисов?"
,,"Не верится)) 
Как тогда крупные компании пользуются AWS для своих сервисов?","Возможно можно получить уникальный тариф, если ты большая компания🤷‍♂️

Там есть elastic ip, но они могут поменяться после перезагрузки сервера, а мне нужны обыкновенные ip которые мне будут принадлежать на время аренды"
,"Не верится)) 
Как тогда крупные компании пользуются AWS для своих сервисов?","Возможно можно получить уникальный тариф, если ты большая компания🤷‍♂️

Там есть elastic ip, но они могут поменяться после перезагрузки сервера, а мне нужны обыкновенные ip которые мне будут принадлежать на время аренды",Так elastic как раз и не меняются же)
"Не верится)) 
Как тогда крупные компании пользуются AWS для своих сервисов?","Возможно можно получить уникальный тариф, если ты большая компания🤷‍♂️

Там есть elastic ip, но они могут поменяться после перезагрузки сервера, а мне нужны обыкновенные ip которые мне будут принадлежать на время аренды",Так elastic как раз и не меняются же),Повторный запуск остановленного экземпляра (или создание нового экземпляра после завершения другого экземпляра) приводит к возникновению нового IP-адреса.
"Возможно можно получить уникальный тариф, если ты большая компания🤷‍♂️

Там есть elastic ip, но они могут поменяться после перезагрузки сервера, а мне нужны обыкновенные ip которые мне будут принадлежать на время аренды",Так elastic как раз и не меняются же),Повторный запуск остановленного экземпляра (или создание нового экземпляра после завершения другого экземпляра) приводит к возникновению нового IP-адреса.,"это если без elastic ip. но в любом случае пару сотен ip мне кажется сейчас никто не продаст, их слишком мало"
,,,"В аренду взять нужно, а не купить"
,,"В аренду взять нужно, а не купить","По ipv6 есть доступ? Обычно дают сразу сеть /64, которой хватит с запасом."
,"В аренду взять нужно, а не купить","По ipv6 есть доступ? Обычно дают сразу сеть /64, которой хватит с запасом.",не катит ipv6 для бинанса
,,,"и в аренду не дадут. в aws вроде дефолтный лимит 5 elastic ip на аккаунт, чтобы повысили, надо прям сильные аргументы предоставить"
,,"и в аренду не дадут. в aws вроде дефолтный лимит 5 elastic ip на аккаунт, чтобы повысили, надо прям сильные аргументы предоставить","Подскажи, эластик ип лично мой или я его шарю с кем-то?"
,"и в аренду не дадут. в aws вроде дефолтный лимит 5 elastic ip на аккаунт, чтобы повысили, надо прям сильные аргументы предоставить","Подскажи, эластик ип лично мой или я его шарю с кем-то?",лично твой
,,,:(
,,:(,зачем вам вообще 200 публичных айпи?
,,,Ограничения на лимиты бинанс
,,Ограничения на лимиты бинанс,"хех, ну тогда специализированные сервисы нужны, прокси там и прочее"
,Ограничения на лимиты бинанс,"хех, ну тогда специализированные сервисы нужны, прокси там и прочее",Долго будет)) нужна задержка до 20мс
Ограничения на лимиты бинанс,"хех, ну тогда специализированные сервисы нужны, прокси там и прочее",Долго будет)) нужна задержка до 20мс,"в каком-нибудь brightdata прокси есть в любом регионе, только дорого"
"хех, ну тогда специализированные сервисы нужны, прокси там и прочее",Долго будет)) нужна задержка до 20мс,"в каком-нибудь brightdata прокси есть в любом регионе, только дорого","Не думаю что будет задержка 20мс с прокси, даже если брать и сервак и прокси в Японии"
,,,"Братиш, это не поможет, там не дураки))"
,,,а почему в японии?
,,а почему в японии?,"Задержка 15мс, эвропа 1000мс"
,,,"У тебя есть лимиты на аккаунте, безотносительно IP, с которого ты шлешь запрос)"
,,"У тебя есть лимиты на аккаунте, безотносительно IP, с которого ты шлешь запрос)",Разный аккаунт под каждый ип
,"У тебя есть лимиты на аккаунте, безотносительно IP, с которого ты шлешь запрос)",Разный аккаунт под каждый ип,Разные аккаунты или субаккаунты ?
"У тебя есть лимиты на аккаунте, безотносительно IP, с которого ты шлешь запрос)",Разный аккаунт под каждый ип,Разные аккаунты или субаккаунты ?,Разные аккаунты конечно
,,,Так что проблем не будет
,,Так что проблем не будет,Нужны просто сотни ип в Японии🙃
,,,Мож кому полезно будет 🤷‍♂️
,,Мож кому полезно будет 🤷‍♂️,"мда.. в Японии совсем грустно
в Европе спокойно дают пару сотен)"
,,,Кстати OVH давал раньше
,,Кстати OVH давал раньше,можно ссылку?
,Кстати OVH давал раньше,можно ссылку?,https://blog.ovhcloud.com/additional-ipv4-new-pricing/
Кстати OVH давал раньше,можно ссылку?,https://blog.ovhcloud.com/additional-ipv4-new-pricing/,"японии нет, индия или европа"
можно ссылку?,https://blog.ovhcloud.com/additional-ipv4-new-pricing/,"японии нет, индия или европа","Надо спрашивать, там всегда есть нюансы в каждом ДЦ."
https://blog.ovhcloud.com/additional-ipv4-new-pricing/,"японии нет, индия или европа","Надо спрашивать, там всегда есть нюансы в каждом ДЦ.",в японии нет дц у ovh
"японии нет, индия или европа","Надо спрашивать, там всегда есть нюансы в каждом ДЦ.",в японии нет дц у ovh,а это что https://www.ovhcloud.com/en/bare-metal/dedicated-server-japan/ ?
"Надо спрашивать, там всегда есть нюансы в каждом ДЦ.",в японии нет дц у ovh,а это что https://www.ovhcloud.com/en/bare-metal/dedicated-server-japan/ ?,
в японии нет дц у ovh,а это что https://www.ovhcloud.com/en/bare-metal/dedicated-server-japan/ ?,,"это единственный где дают свободно /24, хоть и не в Японии, но рядом"
а это что https://www.ovhcloud.com/en/bare-metal/dedicated-server-japan/ ?,,"это единственный где дают свободно /24, хоть и не в Японии, но рядом",так вам /24  или пара сотен адресов? второе думаю будет попроще
,"это единственный где дают свободно /24, хоть и не в Японии, но рядом",так вам /24  или пара сотен адресов? второе думаю будет попроще,/24 /25 есть
,,,"Всем привет. Подскажите молодому и неопытныму: стоит ли пользоваться историческими данными с бинанса для обучения? Они нормальные, реальности соответствуют?"
,,"Всем привет. Подскажите молодому и неопытныму: стоит ли пользоваться историческими данными с бинанса для обучения? Они нормальные, реальности соответствуют?",я думаю вопрос только к объемам
,,,Спрошу своих технарей.
,,Спрошу своих технарей.,cпасибо!!! гляну
,Спрошу своих технарей.,cпасибо!!! гляну,в azure смотрели?
,,,"Если хочется 20мс, то это только aws"
,,"Если хочется 20мс, то это только aws",почему? 20 мс это можно всю японию пролететь сверху донизу и обратно
,,,"Всем привет, знаете ли предтрененные на русском языке модели для определения sentence similarity?"
,,"Всем привет, знаете ли предтрененные на русском языке модели для определения sentence similarity?","E5, distiluse-multilingual-v1, sbert_synonymy"
,"Всем привет, знаете ли предтрененные на русском языке модели для определения sentence similarity?","E5, distiluse-multilingual-v1, sbert_synonymy",Этот distiluse до сих пор в проде норм крутится)
"Всем привет, знаете ли предтрененные на русском языке модели для определения sentence similarity?","E5, distiluse-multilingual-v1, sbert_synonymy",Этот distiluse до сих пор в проде норм крутится),Одна из самых качественных моделей. Именно v1
"E5, distiluse-multilingual-v1, sbert_synonymy",Этот distiluse до сих пор в проде норм крутится),Одна из самых качественных моделей. Именно v1,Угу. Мне тоже v2 не зашел и как-то удивило
Этот distiluse до сих пор в проде норм крутится),Одна из самых качественных моделей. Именно v1,Угу. Мне тоже v2 не зашел и как-то удивило,Ну на сберте вроде даже написано типа больше языков поддерживает но менее точный
,,,"тьху, точно, проглядел"
,,,попробуйте несколько аккаунтов зарегистрировать в aws и с каждого из них получать по 40 ip адресов
,,попробуйте несколько аккаунтов зарегистрировать в aws и с каждого из них получать по 40 ip адресов,Но с этим надо быть осторожным очень)
,,,"у IBM есть клауд в Токио. 8 IP дают точно, больше по запросу."
,,"у IBM есть клауд в Токио. 8 IP дают точно, больше по запросу.",думаю достаточно в одном городе захоститься
,"у IBM есть клауд в Токио. 8 IP дают точно, больше по запросу.",думаю достаточно в одном городе захоститься,"Зависит от того, на какой квантили 20 мс хочется)"
"у IBM есть клауд в Токио. 8 IP дают точно, больше по запросу.",думаю достаточно в одном городе захоститься,"Зависит от того, на какой квантили 20 мс хочется)",думаю примерно на 99й будет
,,,"У меня пока что для би-энкодера лучше всего работает intfloat/multilingual-e5-base
Чисто русскоязычные модели проигрывают, почему без понятия"
,,"У меня пока что для би-энкодера лучше всего работает intfloat/multilingual-e5-base
Чисто русскоязычные модели проигрывают, почему без понятия","Проигрывают скорее всего из-за особенностей датасетов. Плюс трансформеру не так важен язык, сколько структура (внимания) в нем"
,,,"спасибо всем за ответы, будем изучать все варианты"
,,"спасибо всем за ответы, будем изучать все варианты","а, ну 20 мс пинг или ожидание ответа от бинанса?)"
,"спасибо всем за ответы, будем изучать все варианты","а, ну 20 мс пинг или ожидание ответа от бинанса?)",у амазона обратите внимание есть дц в осаке и в токио
"спасибо всем за ответы, будем изучать все варианты","а, ну 20 мс пинг или ожидание ответа от бинанса?)",у амазона обратите внимание есть дц в осаке и в токио,V2 хуже
,,,"А кто-нибудь пробовал тюнить квантованные модели из под peft (lora)

С чистой лорой у меня модели дают как-бы больше ретрив точности, а если квантую их то получается сразу печальное зрелище

Так потому что теряется трансфер лернинг при таком подходе?"
,,"А кто-нибудь пробовал тюнить квантованные модели из под peft (lora)

С чистой лорой у меня модели дают как-бы больше ретрив точности, а если квантую их то получается сразу печальное зрелище

Так потому что теряется трансфер лернинг при таком подходе?","я грузила в 8bit и сверху лорой тюнила rugpt3.5
работает +- хорошо, но учится нестабильно"
,,,"Тормоза там знатные
Approximate trip times:
        Minimum = 230.266604ms, Maximum = 268.851698ms, Average = 248.81003ms"
,,"Тормоза там знатные
Approximate trip times:
        Minimum = 230.266604ms, Maximum = 268.851698ms, Average = 248.81003ms",Это ты про что?
,"Тормоза там знатные
Approximate trip times:
        Minimum = 230.266604ms, Maximum = 268.851698ms, Average = 248.81003ms",Это ты про что?,"это с EU до них...  tf-futures-prod-fapi-2-alb-2110254405.ap-northeast-1.elb.amazonaws.com
хостятся они сами в AWS"
,,,"Какой дц
aws, vultr дает 15-20мс
Европа да - очень долго
Не зависимо от дц"
,,"Какой дц
aws, vultr дает 15-20мс
Европа да - очень долго
Не зависимо от дц","Можно Канаду, как вариант, посмотреть."
,,,"Добрый день! Думаю, многие тут кэтбуст обучали. Подскажите, пожалуйста, при инференсе, когда прогоняешь через предикт всего одну последовательность, то результат один, а когда на целой истории в кучу последовательностей по очереди, то результат другой, в частности меняется вероятность. Кто-нибудь сталкивался с таким, и если да, то как это называется, иначе до Гугла достучаться не могу, чтобы выдал что-то похожее по теме."
,,"Добрый день! Думаю, многие тут кэтбуст обучали. Подскажите, пожалуйста, при инференсе, когда прогоняешь через предикт всего одну последовательность, то результат один, а когда на целой истории в кучу последовательностей по очереди, то результат другой, в частности меняется вероятность. Кто-нибудь сталкивался с таким, и если да, то как это называется, иначе до Гугла достучаться не могу, чтобы выдал что-то похожее по теме.","Если используются категориальные фичи, то проблема почти наверняка в них. Насколько знаю, в кэтбусте они немного странно преобразуются в числа, и,  как раз, зависят от входных данных"
,,,"Подозреваю, что нет таких. Мб мультимодальная гпт4, но ее нет в открытом доступе"
,,,тоже сталкивался с этим и не разобрался в чем прикол
,,тоже сталкивался с этим и не разобрался в чем прикол,"Мне как-то очень давно попадалось, еще до того, как начала юзать кэтбуст, что типа распределение весов как-то смещается или что-то типа того, но, блин, теперь ничего не могу найти на эту тему 😢"
,,,у меня было и без кат фич
,,у меня было и без кат фич,"Также, данные без категориальных фич"
,у меня было и без кат фич,"Также, данные без категориальных фич",Кто-нибудь работал с токенизацией изображений? Подскажете модели интересные?
,,,"Есть ли какой нибудь онлайн конвертер популярных моделей из одного формата в другой? Типа pytorch->tf->onnx->caffee->trt->vino, чтобы можно было указать веса, архитектуру, и откуда куда конвертнуть. Я знаю что есть mm утилиты, например, но проблема почти всех репозиториев что без костылей не работают, и авторы почти всегда забывают указывать конкретные версии пакетов, что приводит к потере куче времени на поиск совместимых решений."
,,"Есть ли какой нибудь онлайн конвертер популярных моделей из одного формата в другой? Типа pytorch->tf->onnx->caffee->trt->vino, чтобы можно было указать веса, архитектуру, и откуда куда конвертнуть. Я знаю что есть mm утилиты, например, но проблема почти всех репозиториев что без костылей не работают, и авторы почти всегда забывают указывать конкретные версии пакетов, что приводит к потере куче времени на поиск совместимых решений.","Универсальный вряд ли, там слишком неочевидно все"
,,,Справа до отпуска. Слева после 😀
,,,Оч на EulerА похоже как будто
,,Оч на EulerА похоже как будто,с ним тоже какой-то соевый
,,,"Всем привет, я вкатывальщик и свидетель секты святого дикого коня."
,,,"Понимаю, что были и другие причины, но скорость тут явно не ключевая - вариантов увеличить перфоманс очень много ведь"
,,"Понимаю, что были и другие причины, но скорость тут явно не ключевая - вариантов увеличить перфоманс очень много ведь","@MaximFN Если надо увеличить перфоманс, то можно написать на плюсах, но мы это не практикуем за редким исключением. Действительно, основная причина - нечитабельность кода при использовании фреймворков."
,,,А в КЗ та же вилка?
,,А в КЗ та же вилка?,Да
,А в КЗ та же вилка?,Да,Ну для КЗ прям сладко имхо
,,,все лучшие промпты — на aibooru в метадате к постам
,,,"Хотелось бы обсудить gradio, не в том смысле как его использовать, а в том смысле зачем он нужен, мне как человеку с фронтенд background очень больно смотреть на всякие *-webui на gradio (вот эти очереди  безумные невпопад), хотелось бы узнать о причинах популярности и может даже вписаться или инициировать проект который бы заменил этот проект, ну или какие-то лучшие практики разработать."
,,"Хотелось бы обсудить gradio, не в том смысле как его использовать, а в том смысле зачем он нужен, мне как человеку с фронтенд background очень больно смотреть на всякие *-webui на gradio (вот эти очереди  безумные невпопад), хотелось бы узнать о причинах популярности и может даже вписаться или инициировать проект который бы заменил этот проект, ну или какие-то лучшие практики разработать.",Имхо Streamlit куда лучше
,,,"А что с ним не так-то? Две строки и у тебя все работает. То, что фронтендерам бывает больно – это нормально же."
,,,"streamlit в плане дизайна (апи) чуток пободрее.

В целом претензия понятна, но не совсем обоснованна. Для прототипирования того что есть достаточно.

А в прод морды делать - страдания другого рода специалистов"
,,"streamlit в плане дизайна (апи) чуток пободрее.

В целом претензия понятна, но не совсем обоснованна. Для прототипирования того что есть достаточно.

А в прод морды делать - страдания другого рода специалистов","Ну вот мне интересно, как раз что двигает людьми когда они из этого большие комбайны собирают, эти очереди на скачивание при генерации и наоборот, кнопочка ""обновить список""  и прочее, может можно этим людям придумать такой же ненапряжный флоу, но с лучшими результатами ?"
,"streamlit в плане дизайна (апи) чуток пободрее.

В целом претензия понятна, но не совсем обоснованна. Для прототипирования того что есть достаточно.

А в прод морды делать - страдания другого рода специалистов","Ну вот мне интересно, как раз что двигает людьми когда они из этого большие комбайны собирают, эти очереди на скачивание при генерации и наоборот, кнопочка ""обновить список""  и прочее, может можно этим людям придумать такой же ненапряжный флоу, но с лучшими результатами ?",другие задачи... и рамки
,,,"К тому же проекты запускать это легче, чем (даже бестолково) сделать, и гораздо легче чем продвинуть в массы"
,,,Добрый день. Есть ли толковые способы угол обзора камеры по кадру определить без параметров самой камеры?
,,Добрый день. Есть ли толковые способы угол обзора камеры по кадру определить без параметров самой камеры?,"Возьми метровую линейку (метр для простоты). Поднести к ней камеру (лучше на штативе) так, чтобы центр линейки был в центре кадра, а края линейки по краям кадра. Измерь теперь расстояние от центра объектива до центра линейки. Далее минус, косинус, кунилингус и примерный  ответ готов."
,Добрый день. Есть ли толковые способы угол обзора камеры по кадру определить без параметров самой камеры?,"Возьми метровую линейку (метр для простоты). Поднести к ней камеру (лучше на штативе) так, чтобы центр линейки был в центре кадра, а края линейки по краям кадра. Измерь теперь расстояние от центра объектива до центра линейки. Далее минус, косинус, кунилингус и примерный  ответ готов.","Про этот способ знаю, но нежизнеспособен уже на сделанных фото, которые мне надо обрабатывать)"
,,,"толковых нет. opencv могет с шахматкой... на тоненького, особенно даже если ее натягивать на референсный объект

В такой постановке почти все способы провальные в универсальном плане"
,,"толковых нет. opencv могет с шахматкой... на тоненького, особенно даже если ее натягивать на референсный объект

В такой постановке почти все способы провальные в универсальном плане","я маслёнок пока, что имеется в виду под шахматкой?"
,,,"... если я вопрос понял правильно) может меня поправят
google opencv chessboard"
,,,Кто-нибудь сталкивался при работе с YOLOv8 object detection + tracking с проблемой частой смены id движущегося объекта?
,,Кто-нибудь сталкивался при работе с YOLOv8 object detection + tracking с проблемой частой смены id движущегося объекта?,Что за трекер?
,,,"Посмотрите его настройки в том числе
Скорее всего у вас медленно обрабатываются кадры
Прикольный способ. Не универсальный правда, тем не менее рабочий)"
,,,"Все привет! Возникла задача попиксельно определять ID материала на картинке.
Вход: RGB картинка
Выход: картинка где у каждого пикселя ID материала на этой картинке.

Если кто-то уже сталкивался с этой проблемой или есть идеи, подскажите куда начать копать 🙏

Есть возможность создавать синтетику в бледере.

Пока из моих вариантов FCN на чистой синтетике или сиамские сети для кластеризации. Но пока не придумал как прикрутить их к регресионной попиксельной задаче.

Заранее спасибо!"
,,"Все привет! Возникла задача попиксельно определять ID материала на картинке.
Вход: RGB картинка
Выход: картинка где у каждого пикселя ID материала на этой картинке.

Если кто-то уже сталкивался с этой проблемой или есть идеи, подскажите куда начать копать 🙏

Есть возможность создавать синтетику в бледере.

Пока из моих вариантов FCN на чистой синтетике или сиамские сети для кластеризации. Но пока не придумал как прикрутить их к регресионной попиксельной задаче.

Заранее спасибо!",segmentation models pytorch в pypi
,,,"Поняла, спасибо, попробую там узнать!"
,,"Поняла, спасибо, попробую там узнать!","Спасибо, очень полезно, знакомлюсь."
,"Поняла, спасибо, попробую там узнать!","Спасибо, очень полезно, знакомлюсь.",А параметры объектива и матрицы тоже никак не узнать?
,,,неа
,,неа,"Была какая-то база на python на гитхаб, база интринсиков по названию камеры"
,,,спасибо всем за ответы
,,,"Это ж опен сорс. Можно завести вопрос в issues, или pull request сделать. Я вот делал)"
,,"Это ж опен сорс. Можно завести вопрос в issues, или pull request сделать. Я вот делал)","Ну меня интересует что им поможет в общем, может стэйт машину завести, чтобы она этот градио сама апдейтила и за блокировками следила. Потому что сами то продукты классные и мне кажется какая то привычка простая может их сильно улучшить в плане юзабельности. Вот хотя бы теперь все рядом с листом модели ставят кнопочку обновить, раньше и этого не было, но хотелось бы чтоб кнопочка не нужна была"
,,,"Всем привет. Посоветует кто веб-приложение для визуализации изображений? Нужен следующий функционал:
- Отображение изображений, возможно с какой-то аннотацией и атрибутами
- Иерархичная структура датасетов, по которой можно передвигаться, хранение мета информации по каждому датасету. Пример: датасет1, датасет2/трейн и тд
- Добавление атрибутов к изображениям
- Сортировка, фильтрация по атрибутом, поиск по айди
- (optional) хранение атрибутов в датасетах в сжатом виде"
,,,Веб-сервис с возможностью деплоя на своём сервере. Есть какие-то такие решения? Заранее спасибо
,,Веб-сервис с возможностью деплоя на своём сервере. Есть какие-то такие решения? Заранее спасибо,label studio гляньте
,,,fiftyone?
,,,привет! а что сейчас есть по апишкам для последнего кандинского?
,,привет! а что сейчас есть по апишкам для последнего кандинского?,"Привет

По прежнему ничего, могу дать свою за мелкий прайс"
,,,"Не такой уж и жирный у кандинского инференс 
В порядке безумия можно попробовать собрать через автоматик1111"
,,"Не такой уж и жирный у кандинского инференс 
В порядке безумия можно попробовать собрать через автоматик1111",Уже есть
,"Не такой уж и жирный у кандинского инференс 
В порядке безумия можно попробовать собрать через автоматик1111",Уже есть,Я в смысле что это все еще требует пердолинга чтобы уместиться по памяти на среднее железо
,,,"Когда устраивались, наверное, у вас было не все, что сейчас есть на github?"
,,"Когда устраивались, наверное, у вас было не все, что сейчас есть на github?","Уже было, там не так уж много всего"
,"Когда устраивались, наверное, у вас было не все, что сейчас есть на github?","Уже было, там не так уж много всего",Ясно
,,,"Похоже на pytti
Но там в основе ганы, а не SD
VQGAN если быть точным"
,,,"Почему бы для демо retrieval augmentation не использовать? И в целом для поиска по своим данным, на мой взгляд, данный подход надежнее будет"
,,"Почему бы для демо retrieval augmentation не использовать? И в целом для поиска по своим данным, на мой взгляд, данный подход надежнее будет","Хмм, если я правильно понял, то это подход, который позволяет добавлять данные из базы знаний к ответам LLM. То есть использовать LLAMA 2 и retrieval augmentation.
Или можно использовать только standalone RAG модель?"
,,,"И в случае если llama-2 + rag уже не так важно количество данных для демо, верно?"
,,"И в случае если llama-2 + rag уже не так важно количество данных для демо, верно?","Ребят всем саламчик. Прошаренные, подскажите, как щас можно подписку на колаб оформить?"
,"И в случае если llama-2 + rag уже не так важно количество данных для демо, верно?","Ребят всем саламчик. Прошаренные, подскажите, как щас можно подписку на колаб оформить?","Rag это не отдельная модель, а просто метод улучшить ответы llm относительно своих данных (можно использовать совместно с файн тюнингом, можно отдельно). В векторной бд лежат все данные, которые могут пригодиться по определенной тематики. Не знаю, что требуется в демо, но полагаю, можно просто положить пару тем и по ним спрашивать модель"
,,,"Спасибо за разъяснение!
А можно какой-то пример реализации. Какие либы стоит попробовать для rag?
Или предлагается просто делать поиск информации и вручную подставлять ее к промпту llm?"
,,"Спасибо за разъяснение!
А можно какой-то пример реализации. Какие либы стоит попробовать для rag?
Или предлагается просто делать поиск информации и вручную подставлять ее к промпту llm?",LangChain неплохо справляется с такой задачей. Плюс еще LlamaIndex
,,,"Организовано через чатгпт, но концептуально то же самое для лламы"
,,"Организовано через чатгпт, но концептуально то же самое для лламы","Спасибо! Тоже наткнулся на него
О, ну это вообще готовое демо на русском"
,"Организовано через чатгпт, но концептуально то же самое для лламы","Спасибо! Тоже наткнулся на него
О, ну это вообще готовое демо на русском",Почему в один скалер несколько фичей - это не очень?
"Организовано через чатгпт, но концептуально то же самое для лламы","Спасибо! Тоже наткнулся на него
О, ну это вообще готовое демо на русском",Почему в один скалер несколько фичей - это не очень?,"ну чтобы их обратно перевести к нормальному масштабу после предсказаний нужно непонятно что туда передать, типо скалер то матрицу из 11ти столбцов переводит а там 1 будет
а хотя просто нулями залить остальное к примеру, но как-то костыльно выглядит"
"Спасибо! Тоже наткнулся на него
О, ну это вообще готовое демо на русском",Почему в один скалер несколько фичей - это не очень?,"ну чтобы их обратно перевести к нормальному масштабу после предсказаний нужно непонятно что туда передать, типо скалер то матрицу из 11ти столбцов переводит а там 1 будет
а хотя просто нулями залить остальное к примеру, но как-то костыльно выглядит","Скалер можешь применить либо на фичи, либо на таргет, и выход модели будет отнормирован также как и таргет при обучении"
,,,К каким фичам после предсказания нужно применять скалер не очень понимаю
,,К каким фичам после предсказания нужно применять скалер не очень понимаю,"ну он(inverse_transform) на вход ждет что-то 
типо (N, число фич) а не (N, 1)"
,К каким фичам после предсказания нужно применять скалер не очень понимаю,"ну он(inverse_transform) на вход ждет что-то 
типо (N, число фич) а не (N, 1)",Можно вытащить статистики для нужной фичи (среднее и ст отклонение для стандарт скалера например) и трансформировать самому
,,,"Я могу ответить как бэк, который использует Plotly Dash.

Мне нужен был инструмент , чтобы полностью меня избавить от написания JS кода, причем веб интерфейс я описываю сам, а именно на bootstrap.

Это прям очень резвый старт дает там, где нету пока ещё требования к качеству веб интерфейса. Есть требование к функциональности и наличию публичного интерфейса к бэку. В итоге все равно пришел к проблемам чисто интерфейсного характера.

Gradio часто вижу в публичных ноутбуках. Просто инструмент, который избавит дата саинтиста и прочих от изучения фронтенд технологий.
Очень полезно ещё для внутренних сервисов внутри компаний, где так же нету требования качества веб интерфейса, а главное функциональность. Проще говоря, современная админка с визуализацией(это конкретно про Plotly Dash)
Panel, на мой взгляд, не стоит рассматривать по причине того, что он - обертка над остальными самостоятельными решениями. Лучше потратить немного времени и выбрать один из исходных, чтобы в последствии не иметь дело с лишним слоем абстракций. Смотрел когда-то Panel."
,,,"Altair еще хорош, если надо декларативно описать веб интерфейс к данным, а он сам его построит"
,,"Altair еще хорош, если надо декларативно описать веб интерфейс к данным, а он сам его построит","Про такое не слышал, интересно, спасибо"
,,,"привет
а кто то может посоветовать сервис где люди картинки с инкорпорированным тестом генерируют
(пример из облаков надпись на картинке которую не сразу видно, недавно появилось)
не могу найти или нагуглить"
,,"привет
а кто то может посоветовать сервис где люди картинки с инкорпорированным тестом генерируют
(пример из облаков надпись на картинке которую не сразу видно, недавно появилось)
не могу найти или нагуглить",https://youtu.be/_6tXOARkue0
,,,"Посоветуйте впн сервис, нужно добавить айпишники в реестр
Плачу 150 рублей за айпишник"
,,"Посоветуйте впн сервис, нужно добавить айпишники в реестр
Плачу 150 рублей за айпишник",Очисти как в прошлый раз))
,"Посоветуйте впн сервис, нужно добавить айпишники в реестр
Плачу 150 рублей за айпишник",Очисти как в прошлый раз)),"Постарался оставить информативное, остальное дропнул"
,,,"Привет, где почитать, что использовать, чтобы быстро почистить текст от мусорных  слов по типу: «бесплатно», «скачать» ?"
,,"Привет, где почитать, что использовать, чтобы быстро почистить текст от мусорных  слов по типу: «бесплатно», «скачать» ?",классика типа stopwords + most_freq не подходит?
,,,"не пробовал так;
 думал сделать: стеминг -> удаление слова если оно в заданном списке stop_words; не хочется вручную вписывать все stop, возможно most_freq поможет; Но хотел уточнить мб есть способы поинтересней и удачней избавляться от мусорных слов"
,,"не пробовал так;
 думал сделать: стеминг -> удаление слова если оно в заданном списке stop_words; не хочется вручную вписывать все stop, возможно most_freq поможет; Но хотел уточнить мб есть способы поинтересней и удачней избавляться от мусорных слов","К сожалению, понятие «мусорности» не универсально, а зависит от задачи, которую вы решаете.
Например, для классификации спама слово «бесплатно» может быть важным признаком.

Поэтому два самых популярных решения – или вообще ничего не чистить, или делать стоплист специализированный под вашу задачу."
,"не пробовал так;
 думал сделать: стеминг -> удаление слова если оно в заданном списке stop_words; не хочется вручную вписывать все stop, возможно most_freq поможет; Но хотел уточнить мб есть способы поинтересней и удачней избавляться от мусорных слов","К сожалению, понятие «мусорности» не универсально, а зависит от задачи, которую вы решаете.
Например, для классификации спама слово «бесплатно» может быть важным признаком.

Поэтому два самых популярных решения – или вообще ничего не чистить, или делать стоплист специализированный под вашу задачу.",Спасибо ! Мне нужно почистить текстовые описания к картинками для text2img
"не пробовал так;
 думал сделать: стеминг -> удаление слова если оно в заданном списке stop_words; не хочется вручную вписывать все stop, возможно most_freq поможет; Но хотел уточнить мб есть способы поинтересней и удачней избавляться от мусорных слов","К сожалению, понятие «мусорности» не универсально, а зависит от задачи, которую вы решаете.
Например, для классификации спама слово «бесплатно» может быть важным признаком.

Поэтому два самых популярных решения – или вообще ничего не чистить, или делать стоплист специализированный под вашу задачу.",Спасибо ! Мне нужно почистить текстовые описания к картинками для text2img,"Возможно, для этой задачи чистка не нужна; модель сама научится игнорировать текст, не связанный с содержанием картинки"
"К сожалению, понятие «мусорности» не универсально, а зависит от задачи, которую вы решаете.
Например, для классификации спама слово «бесплатно» может быть важным признаком.

Поэтому два самых популярных решения – или вообще ничего не чистить, или делать стоплист специализированный под вашу задачу.",Спасибо ! Мне нужно почистить текстовые описания к картинками для text2img,"Возможно, для этой задачи чистка не нужна; модель сама научится игнорировать текст, не связанный с содержанием картинки","Да, но у меня есть опасения, не будет ли модель ждать в промт слов «скачать бесплатно» чтобы сгенерировать хорошую картинку"
Спасибо ! Мне нужно почистить текстовые описания к картинками для text2img,"Возможно, для этой задачи чистка не нужна; модель сама научится игнорировать текст, не связанный с содержанием картинки","Да, но у меня есть опасения, не будет ли модель ждать в промт слов «скачать бесплатно» чтобы сгенерировать хорошую картинку","Если эти слова являются признаками хороших картинок, то они тем более не мусорные 🙃"
,,,"Pointnet же, нет? =)"
,,"Pointnet же, нет? =)","Не знаю, не знаком =)

Пытаясь читать китти, даже не понимаю, как строится датасет)"
,,,"Всем привет! Кто-то встречал датасеты для детекции электросамокатов? Нашел один на roboflow, но там очень кривая разметка."
,,,"Привет всем, у меня вопрос касательно юридической составляющей нейронок в РФ (не нашел соответствующий тред)
Смотрите, если я возьму LLM из huggingface (с лицензией apache 2 или mit) и на основе этой нейронки сделаю проект, то смогу ли я зарегать его в реестре отечественного ПО и писать что-то вроде ""на основе разработанной нейросети бла-бла-бла"" ?
Где вообще проходит грань между ""собственной разработкой"" и ""спизжено у Васи""?
Можно ли считать ""собственной разработкой"", если просто дообучить на своих данных?

Или всё это серая зона и пока никак не формализовано и не контролируется?"
,,"Привет всем, у меня вопрос касательно юридической составляющей нейронок в РФ (не нашел соответствующий тред)
Смотрите, если я возьму LLM из huggingface (с лицензией apache 2 или mit) и на основе этой нейронки сделаю проект, то смогу ли я зарегать его в реестре отечественного ПО и писать что-то вроде ""на основе разработанной нейросети бла-бла-бла"" ?
Где вообще проходит грань между ""собственной разработкой"" и ""спизжено у Васи""?
Можно ли считать ""собственной разработкой"", если просто дообучить на своих данных?

Или всё это серая зона и пока никак не формализовано и не контролируется?","Модельку придется морозить, т.к. если поменяешь, то теоритически вылетишь из реестра"
,,,"при подаче заявки в реестр надо будет приложить описание всех используемых библиотек с указанием типа лицензий, если лицензия позволяет использование и у тебя всё развернуто внутри, независимо от ""недружественных стран"" и не требует обязательных обновлений из ""недружественных стран"", то скорее всего вопросов не будет"
,,"при подаче заявки в реестр надо будет приложить описание всех используемых библиотек с указанием типа лицензий, если лицензия позволяет использование и у тебя всё развернуто внутри, независимо от ""недружественных стран"" и не требует обязательных обновлений из ""недружественных стран"", то скорее всего вопросов не будет","Ага, понял, спасибо"
,,,"Заказчику надо, чтобы была возможность зарегать в реестре"
,,"Заказчику надо, чтобы была возможность зарегать в реестре","У минцифры довольно подробные инструкции по всему этому на сайте есть, есть видосики на ютуб от сколково. Прямо в коде вряд ли кто-то будет копаться, если ты за это переживаешь, но потом могут предъявить, как со всякими офисами было недавно=)."
,"Заказчику надо, чтобы была возможность зарегать в реестре","У минцифры довольно подробные инструкции по всему этому на сайте есть, есть видосики на ютуб от сколково. Прямо в коде вряд ли кто-то будет копаться, если ты за это переживаешь, но потом могут предъявить, как со всякими офисами было недавно=).",А какая версия торча?
,,,2.0.1
,,2.0.1,Работает?
,,,Ставь 1.13.1
,,,"Всем привет!
А какие трюки принято использовать для получения эмбедингов для длинных текстов (~5-12k токенов)? 
Как-то процессить по кускам используя sentence encoder насколько позволяет его контекстное окно? А потом складывать\усреднять?"
,,"Всем привет!
А какие трюки принято использовать для получения эмбедингов для длинных текстов (~5-12k токенов)? 
Как-то процессить по кускам используя sentence encoder насколько позволяет его контекстное окно? А потом складывать\усреднять?",Как вариант
,"Всем привет!
А какие трюки принято использовать для получения эмбедингов для длинных текстов (~5-12k токенов)? 
Как-то процессить по кускам используя sentence encoder насколько позволяет его контекстное окно? А потом складывать\усреднять?",Как вариант,"И шо это все до чего дошла наука 🧐?)
Или дальше NDA?))"
"Всем привет!
А какие трюки принято использовать для получения эмбедингов для длинных текстов (~5-12k токенов)? 
Как-то процессить по кускам используя sentence encoder насколько позволяет его контекстное окно? А потом складывать\усреднять?",Как вариант,"И шо это все до чего дошла наука 🧐?)
Или дальше NDA?))",Да не вон почитай mem transformer
Как вариант,"И шо это все до чего дошла наука 🧐?)
Или дальше NDA?))",Да не вон почитай mem transformer,"От Миши Бурцева, да?"
"И шо это все до чего дошла наука 🧐?)
Или дальше NDA?))",Да не вон почитай mem transformer,"От Миши Бурцева, да?","А можно ссылочку, пожалуйста))"
Да не вон почитай mem transformer,"От Миши Бурцева, да?","А можно ссылочку, пожалуйста))","https://arxiv.org/pdf/2006.11527.pdf
https://arxiv.org/pdf/2207.06881.pdf"
"От Миши Бурцева, да?","А можно ссылочку, пожалуйста))","https://arxiv.org/pdf/2006.11527.pdf
https://arxiv.org/pdf/2207.06881.pdf","К формированию второй, в идейном плане поучаствовать даже довелось"
,,,)
,,,"какой бы seqlen длинный не был у модели, когда-то придётся нарезать"
,,"какой бы seqlen длинный не был у модели, когда-то придётся нарезать",Справедливо
,,,"Mem tokens
И тп)
Mem - memory
Ага"
,,"Mem tokens
И тп)
Mem - memory
Ага",вот эти 2 работы нашел
,"Mem tokens
И тп)
Mem - memory
Ага",вот эти 2 работы нашел,"Оно оно
У нас синки бывают периодически"
,,,"Всем привет!
Хотел бы попросить поделиться контактами хорошего карьерного эксперта. 
Может есть кто на примете у Вас? :)"
,,"Всем привет!
Хотел бы попросить поделиться контактами хорошего карьерного эксперта. 
Может есть кто на примете у Вас? :)","Привет!
Я брала консультацию для редактирования моего резюме у этого HR эксперта. Советую 👍🏼

https://instagram.com/kristinahr_?igshid=NTc4MTIwNjQ2YQ=="
,"Всем привет!
Хотел бы попросить поделиться контактами хорошего карьерного эксперта. 
Может есть кто на примете у Вас? :)","Привет!
Я брала консультацию для редактирования моего резюме у этого HR эксперта. Советую 👍🏼

https://instagram.com/kristinahr_?igshid=NTc4MTIwNjQ2YQ==",Спасибо :)
,,,"Всем привет. Я с новым вопросом.

Можете методы определения заваленного горизонта на фото подсказать? Данные - фотографии комнат. Копал в сторону преобразования Хафа, чтобы выделять основные линии (стык между стенами, стык между стенами и потолком/полом), но не могу понять, как его настроить, чтоб другие линии не находил в кадре (ремонт, мебель и тд). И возможно ли это вообще?"
,,"Всем привет. Я с новым вопросом.

Можете методы определения заваленного горизонта на фото подсказать? Данные - фотографии комнат. Копал в сторону преобразования Хафа, чтобы выделять основные линии (стык между стенами, стык между стенами и потолком/полом), но не могу понять, как его настроить, чтоб другие линии не находил в кадре (ремонт, мебель и тд). И возможно ли это вообще?","https://jinlinyi.github.io/PerspectiveFields/

Запускаешь -> получаешь roll, pitch -> profit!"
,"Всем привет. Я с новым вопросом.

Можете методы определения заваленного горизонта на фото подсказать? Данные - фотографии комнат. Копал в сторону преобразования Хафа, чтобы выделять основные линии (стык между стенами, стык между стенами и потолком/полом), но не могу понять, как его настроить, чтоб другие линии не находил в кадре (ремонт, мебель и тд). И возможно ли это вообще?","https://jinlinyi.github.io/PerspectiveFields/

Запускаешь -> получаешь roll, pitch -> profit!",Ах ты ж блин крутяк
,,,А  можно примеры фотографий ? Так станет куда понятнее
,,А  можно примеры фотографий ? Так станет куда понятнее,
,,,обычные фотографии комнат
,,обычные фотографии комнат,Знакомые фотки компании Самолёт 😆
,,,"Хотя сорян, ошибаюсь. Уже везде мерещатся после того хакатона"
,,"Хотя сорян, ошибаюсь. Уже везде мерещатся после того хакатона","Кто в ЛЦТ участвовал, тот их будет везде видеть))
Я сам об этом же подумал"
,,,"Классификацию или инстанс сегментацию стен/потолка/полов, а потом искать углы между ними"
,,"Классификацию или инстанс сегментацию стен/потолка/полов, а потом искать углы между ними","а как классификацию применить, не понимаю? Что именно классифицировать?"
,"Классификацию или инстанс сегментацию стен/потолка/полов, а потом искать углы между ними","а как классификацию применить, не понимаю? Что именно классифицировать?",Тут разве не бинарная классификация ? Горизонт завален/нет
"Классификацию или инстанс сегментацию стен/потолка/полов, а потом искать углы между ними","а как классификацию применить, не понимаю? Что именно классифицировать?",Тут разве не бинарная классификация ? Горизонт завален/нет,Я так понял размеченного датасета нет.
"а как классификацию применить, не понимаю? Что именно классифицировать?",Тут разве не бинарная классификация ? Горизонт завален/нет,Я так понял размеченного датасета нет.,"пока нет, возможно и не будет"
Тут разве не бинарная классификация ? Горизонт завален/нет,Я так понял размеченного датасета нет.,"пока нет, возможно и не будет",В толоку на крайняк закинуть можно
,,,"по идее да, я просто не знаю, справится ли с этим сетка. Я пока маслёнок"
,,,Акк хакнули и арендовали 7568 серваков
,,Акк хакнули и арендовали 7568 серваков,Жесть…
,,,"Итого более $80k долг на него повесили, так что будьте внимательны к безопасности)"
,,"Итого более $80k долг на него повесили, так что будьте внимательны к безопасности)",F
,,,"Гайз. Нужны советы суровых инженеров с суровых заводов, но чтобы ML)))
Нужно детектить дефекты на полотне.
Дефектов штук 10 разных типов (и размеров), разметка боксами и разумеется плавает.
В итоге сеть может предсказать два дефекта одного типа одним боксом и наоборот.
Принципиально различать инстансы с точностью до 0.5 метра, скажем. То есть ответить есть/нет не достаточно.

В чем суть: ""на глаз"" модель отрабатывает хорошо, но метрики оценки (IoU + ConfusionMatrix) показывают непотребное.
Может кто-то сталкивался или знает хорошие способы оценки качества. Спасибо)"
,,"Гайз. Нужны советы суровых инженеров с суровых заводов, но чтобы ML)))
Нужно детектить дефекты на полотне.
Дефектов штук 10 разных типов (и размеров), разметка боксами и разумеется плавает.
В итоге сеть может предсказать два дефекта одного типа одним боксом и наоборот.
Принципиально различать инстансы с точностью до 0.5 метра, скажем. То есть ответить есть/нет не достаточно.

В чем суть: ""на глаз"" модель отрабатывает хорошо, но метрики оценки (IoU + ConfusionMatrix) показывают непотребное.
Может кто-то сталкивался или знает хорошие способы оценки качества. Спасибо)","Себе для оценки я сделал  утилиту, у которой на входе пачка обученных моделей и кусочек датасета корого не было в обучении. На выходе табличка, в которой поля, имя модели, сколько найдено, сколько пропущено, время работы, и т.п. То есть те вещи которые  реально мне важны в проде. И могу понять для себя какая наиболее подходит."
,"Гайз. Нужны советы суровых инженеров с суровых заводов, но чтобы ML)))
Нужно детектить дефекты на полотне.
Дефектов штук 10 разных типов (и размеров), разметка боксами и разумеется плавает.
В итоге сеть может предсказать два дефекта одного типа одним боксом и наоборот.
Принципиально различать инстансы с точностью до 0.5 метра, скажем. То есть ответить есть/нет не достаточно.

В чем суть: ""на глаз"" модель отрабатывает хорошо, но метрики оценки (IoU + ConfusionMatrix) показывают непотребное.
Может кто-то сталкивался или знает хорошие способы оценки качества. Спасибо)","Себе для оценки я сделал  утилиту, у которой на входе пачка обученных моделей и кусочек датасета корого не было в обучении. На выходе табличка, в которой поля, имя модели, сколько найдено, сколько пропущено, время работы, и т.п. То есть те вещи которые  реально мне важны в проде. И могу понять для себя какая наиболее подходит.","табличку и я собираю.
тут немного в другом вопрос.
Ладно, копаю weighted box fusion и agnostic nms, может что-то выйдет))
спасибо)"
,,,mAP?
,,mAP?,"Precision-Recall вроде тоже плывут.
Хотя я еще мало наигрался с сетом, чтобы судить, насколько мой mAP 0,73 отражает качество.
Плюс тут еще момент ""презентативности"", то бишь показать заказчику, что все хорошо."
,,,"можешь попробовать подобрать iou трешхолд для nms (или wbf)
а для случая ""наоборот"" есть agnostic nms"
,,"можешь попробовать подобрать iou трешхолд для nms (или wbf)
а для случая ""наоборот"" есть agnostic nms","nms? wbf?
Не, я то пойду гуглить, но в двух словах?)"
,"можешь попробовать подобрать iou трешхолд для nms (или wbf)
а для случая ""наоборот"" есть agnostic nms","nms? wbf?
Не, я то пойду гуглить, но в двух словах?)","алгоритм, который объединяет предсказанные боксы
non maximum supression - стандратный алгоритм, есть модификации в виде weighted box fusion

один из значимых параметров - iou_thresh - степень пересечения боксов для их слияния, грубо говоря"
"можешь попробовать подобрать iou трешхолд для nms (или wbf)
а для случая ""наоборот"" есть agnostic nms","nms? wbf?
Не, я то пойду гуглить, но в двух словах?)","алгоритм, который объединяет предсказанные боксы
non maximum supression - стандратный алгоритм, есть модификации в виде weighted box fusion

один из значимых параметров - iou_thresh - степень пересечения боксов для их слияния, грубо говоря","nms это не очень очевидное сокращение.
Он не поможет у нас он есть. 
Точнее, у меня бегает YOLO со своим, а на проде рукописный.
Но в потроха не залезал, может можно что-то подкрутить/переделать под задачу."
,,,non maximum supression
,,non maximum supression,Открыл резюме на хх ру и за сутки вообще никто не написал 🤨
,,,Два года назад сделал то же самое и мб человек 20 написали тут же
,,Два года назад сделал то же самое и мб человек 20 написали тут же,"Должность и зарплатные ожидания менял? Может, в этом дело?"
,Два года назад сделал то же самое и мб человек 20 написали тут же,"Должность и зарплатные ожидания менял? Может, в этом дело?","Зарплатные ожидания не указал, должность поставил просто синьор дс/мле"
,,,Интересно конечно
,,,"Всем привет. Меня зовут Настя. Я чувствую здесь себя немного самозванцем, но все равно представлюсь.

Я научный сотрудник в Университетской клинике Бонна, работаю в лаборатории клеточной и молекулярной биологии. 
Так получилось, что мы делали исследования РНК секвенирования, а опыта анализа данных ни у кого в команде не было. Я самостоятельно изучала R и меня затянуло: сейчас прохожу онлайн курсы по Data Science. Если буду достаточно успешной, то хочу сменить полностью деятельность."
,,"Всем привет. Меня зовут Настя. Я чувствую здесь себя немного самозванцем, но все равно представлюсь.

Я научный сотрудник в Университетской клинике Бонна, работаю в лаборатории клеточной и молекулярной биологии. 
Так получилось, что мы делали исследования РНК секвенирования, а опыта анализа данных ни у кого в команде не было. Я самостоятельно изучала R и меня затянуло: сейчас прохожу онлайн курсы по Data Science. Если буду достаточно успешной, то хочу сменить полностью деятельность.","Привет!
У меня похожее было: я занимался биофизикой, исследовал нейровоспаления, потом порядком надоело количество унылой ручной работы в этом всём, плюс тогда же начал погружаться в R, в итоге подтянул ещё и python, перекатился в биоинформатику, за два года там разобрался в ML и в итоге ушёл в обычный Data Science

Спустя три года никак не связанных с биологией ощущения следующие:
- отношение зарплаты к потраченным нервам существенно выросло (но надо учитывать, что наукой я пытался заниматься в России)
- новая работа позволила легко эмигрировать два года назад
- иногда действительно накатывает, что я занимаюсь какой-то бесполезной ерундой просто ради денег. периодически подумываю уйти в коммерческую биоинформатику, но обычно это проходит, когда на текущей работе получается сделать что-то клёвое)
- сильно больше ездить во время работы я не стал, может на две-три недели в год, но это скорее мой выбор, мне очень тяжело сосредоточиться вне офиса"
,"Всем привет. Меня зовут Настя. Я чувствую здесь себя немного самозванцем, но все равно представлюсь.

Я научный сотрудник в Университетской клинике Бонна, работаю в лаборатории клеточной и молекулярной биологии. 
Так получилось, что мы делали исследования РНК секвенирования, а опыта анализа данных ни у кого в команде не было. Я самостоятельно изучала R и меня затянуло: сейчас прохожу онлайн курсы по Data Science. Если буду достаточно успешной, то хочу сменить полностью деятельность.","Привет!
У меня похожее было: я занимался биофизикой, исследовал нейровоспаления, потом порядком надоело количество унылой ручной работы в этом всём, плюс тогда же начал погружаться в R, в итоге подтянул ещё и python, перекатился в биоинформатику, за два года там разобрался в ML и в итоге ушёл в обычный Data Science

Спустя три года никак не связанных с биологией ощущения следующие:
- отношение зарплаты к потраченным нервам существенно выросло (но надо учитывать, что наукой я пытался заниматься в России)
- новая работа позволила легко эмигрировать два года назад
- иногда действительно накатывает, что я занимаюсь какой-то бесполезной ерундой просто ради денег. периодически подумываю уйти в коммерческую биоинформатику, но обычно это проходит, когда на текущей работе получается сделать что-то клёвое)
- сильно больше ездить во время работы я не стал, может на две-три недели в год, но это скорее мой выбор, мне очень тяжело сосредоточиться вне офиса",Спасибо за то что поделился своим опытом :)
,,,"Всем привет. Хочу вкатиться в алгоритмичный трейдинг на крипте. Есть база мл хорошая и понимание как её применить. Но вот как прикрутить к бирже и данные получить не знаю. Посоветуйте, пожалуйста, материалы для изучения. Заранее спасибо!"
,,"Всем привет. Хочу вкатиться в алгоритмичный трейдинг на крипте. Есть база мл хорошая и понимание как её применить. Но вот как прикрутить к бирже и данные получить не знаю. Посоветуйте, пожалуйста, материалы для изучения. Заранее спасибо!",данные тут https://www.binance.com/en/landing/data
,,,Берешь апи бинанса и прикручиваешь и получаешь.
,,Берешь апи бинанса и прикручиваешь и получаешь.,"Там полкниги про пайтон
Откройте бумажный счет 
подключитесь, получите данные 
запустите индикаторы из книги
сделайте простую стратегию 
убедитесь что не работает
Вы готовы к большому пути :)"
,,,Хорошо) Спасибо!
,,Хорошо) Спасибо!,"Ещё можно с freqtrade начать, по нему много видео и гайдов"
,,,"это остатки сайта с полным курсом
домен уже, к сожалению, не отвечает
Твардовский, Ильинский - рекомендую категорически"
,,"это остатки сайта с полным курсом
домен уже, к сожалению, не отвечает
Твардовский, Ильинский - рекомендую категорически","Всем привет!
Кто-то работал с NVidia deep stream на Edge устройствах типа jetson?
Поделитесь, как оно? Насколько хорошая технология?"
,,,"Всем привет! В эту субботу в 14:00 МСК будет онлайн-лекция для Better Data Community, от Ильи Гусева, старшего инженера по машинному обучению в Букинге, автора Сайги. Лекция будет про архитектуры, альтерантивные трансформерам, а именно про линейные рекуррентные сети. Внутри будет куча крутых архитектур которые полезно знать MLE инженерам из топовых перцентилей!"
,,"Всем привет! В эту субботу в 14:00 МСК будет онлайн-лекция для Better Data Community, от Ильи Гусева, старшего инженера по машинному обучению в Букинге, автора Сайги. Лекция будет про архитектуры, альтерантивные трансформерам, а именно про линейные рекуррентные сети. Внутри будет куча крутых архитектур которые полезно знать MLE инженерам из топовых перцентилей!",Ребят запись то есть где или нет?
,"Всем привет! В эту субботу в 14:00 МСК будет онлайн-лекция для Better Data Community, от Ильи Гусева, старшего инженера по машинному обучению в Букинге, автора Сайги. Лекция будет про архитектуры, альтерантивные трансформерам, а именно про линейные рекуррентные сети. Внутри будет куча крутых архитектур которые полезно знать MLE инженерам из топовых перцентилей!",Ребят запись то есть где или нет?,Готовиться
"Всем привет! В эту субботу в 14:00 МСК будет онлайн-лекция для Better Data Community, от Ильи Гусева, старшего инженера по машинному обучению в Букинге, автора Сайги. Лекция будет про архитектуры, альтерантивные трансформерам, а именно про линейные рекуррентные сети. Внутри будет куча крутых архитектур которые полезно знать MLE инженерам из топовых перцентилей!",Ребят запись то есть где или нет?,Готовиться,Компилируется! 😏
Ребят запись то есть где или нет?,Готовиться,Компилируется! 😏,"Да там по-моему в презентации все здорово написано)) я кстати первые пять слайдов оказывается прозевал, весь доклад вспоминал что за long range arena 😂"
,,,"Всем привет! 
Вопрос максимально простой, но чет никак не могу решить: где в yolov8 менять аугментации на кастомные?"
,,"Всем привет! 
Вопрос максимально простой, но чет никак не могу решить: где в yolov8 менять аугментации на кастомные?",типо того
,,,но нужно библиотечку одноименную поставить
,,но нужно библиотечку одноименную поставить,"А, ну про нее я в курсе"
,,,Спасибо!!
,,Спасибо!!,Не надо)
,,,"а что побуждает к смене деятельности? зарплата? интерес к деятельности (просто мне кажется, что клеточная и молекулярная биология в разы интереснее датасаенса, но это лишь мои ощущения)?"
,,"а что побуждает к смене деятельности? зарплата? интерес к деятельности (просто мне кажется, что клеточная и молекулярная биология в разы интереснее датасаенса, но это лишь мои ощущения)?","Свобода перемещения ☺️ и возможность работать из разных мест. Когда работаешь в лаборатории, то особо не поездишь."
,"а что побуждает к смене деятельности? зарплата? интерес к деятельности (просто мне кажется, что клеточная и молекулярная биология в разы интереснее датасаенса, но это лишь мои ощущения)?","Свобода перемещения ☺️ и возможность работать из разных мест. Когда работаешь в лаборатории, то особо не поездишь.","Да и на удалёнке особо не поездить на самом деле. Нужно жить примерно в часовом поясе с рабочим часовым поясом, иначе придётся работать ночью, а спать днём. Почти все удалёнщики работают из дома, а не из Бали, попивая смузи"
"а что побуждает к смене деятельности? зарплата? интерес к деятельности (просто мне кажется, что клеточная и молекулярная биология в разы интереснее датасаенса, но это лишь мои ощущения)?","Свобода перемещения ☺️ и возможность работать из разных мест. Когда работаешь в лаборатории, то особо не поездишь.","Да и на удалёнке особо не поездить на самом деле. Нужно жить примерно в часовом поясе с рабочим часовым поясом, иначе придётся работать ночью, а спать днём. Почти все удалёнщики работают из дома, а не из Бали, попивая смузи",Маврикий.  Часовой пояс москва если что:-)
,,,Не уверен что оно того стоит. Дверь в лабораторию рекомендую оставить открытой и кругозор и знание трендов не теряйте в своей специальности
,,Не уверен что оно того стоит. Дверь в лабораторию рекомендую оставить открытой и кругозор и знание трендов не теряйте в своей специальности,а тут нужно смотреть как научная карьера складывается )
,Не уверен что оно того стоит. Дверь в лабораторию рекомендую оставить открытой и кругозор и знание трендов не теряйте в своей специальности,а тут нужно смотреть как научная карьера складывается ),"я не про карьеру говорил, а про мотив смены деятельности"
Не уверен что оно того стоит. Дверь в лабораторию рекомендую оставить открытой и кругозор и знание трендов не теряйте в своей специальности,а тут нужно смотреть как научная карьера складывается ),"я не про карьеру говорил, а про мотив смены деятельности","я понял. имел в виду, что неудовлетворительный карьерный трек в науке может быть мотивом смены деятельности."
а тут нужно смотреть как научная карьера складывается ),"я не про карьеру говорил, а про мотив смены деятельности","я понял. имел в виду, что неудовлетворительный карьерный трек в науке может быть мотивом смены деятельности.",а я про то что можно и в фарму пойти)
"я не про карьеру говорил, а про мотив смены деятельности","я понял. имел в виду, что неудовлетворительный карьерный трек в науке может быть мотивом смены деятельности.",а я про то что можно и в фарму пойти),аа ) справедливо.
,,,"Спасибо за совет. Если честно, я бы хотела совмещать :)"
,,"Спасибо за совет. Если честно, я бы хотела совмещать :)","Биоинформатика = Наука + Data Science для вас👍.

В чистый Data Science лезть не стоит. Она еще не сформировалась."
,"Спасибо за совет. Если честно, я бы хотела совмещать :)","Биоинформатика = Наука + Data Science для вас👍.

В чистый Data Science лезть не стоит. Она еще не сформировалась.","Спасибо за совет :)
Я возможно, пока не поздно, перенаправлю свои усилия в учебе на биоинформатику."
"Спасибо за совет. Если честно, я бы хотела совмещать :)","Биоинформатика = Наука + Data Science для вас👍.

В чистый Data Science лезть не стоит. Она еще не сформировалась.","Спасибо за совет :)
Я возможно, пока не поздно, перенаправлю свои усилия в учебе на биоинформатику.","+ биоинформатика мне кажется непаханым полем из-за высокого порога вхождения, чем и интереснее"
,,,"если рекорд не подразумевает, что после phd  или первого постдока ты станешь assistant/associate professor, то надо думать..."
,,,"Возможно мои иллюзии сильно разняться с действительностью.
Но, я подумала, что внутри часового пояса можно передвигаться в таком случае. 
А возможно у меня слишком высокие ожидания 🤔"
,,"Возможно мои иллюзии сильно разняться с действительностью.
Но, я подумала, что внутри часового пояса можно передвигаться в таком случае. 
А возможно у меня слишком высокие ожидания 🤔","Чем меньше ожиданий, тем меньше разочарований) 

Я лично не вижу причин менять науку на возможность считать цены на товары в каком-нибудь маркетплейсе или делать стопятсотый переведчик на берте, который лучше соты на 0.01%. Дата сайнс лучше всего совмещать с вашей научной деятельностью. Дата сайнс это не столько наука, сколько инструмент, как и математика. Как и писал человечек выше, можно на биоинформатику ориентироваться. Я бы сам занялся биоинформатикой, учитывая как сильно в школе нравилась биология."
,,,"Есть мысль, что тогда атеншн будет тригериться на некоторые шаблоны попавшие в окно."
,,"Есть мысль, что тогда атеншн будет тригериться на некоторые шаблоны попавшие в окно.",А в принципе это и есть цель
,"Есть мысль, что тогда атеншн будет тригериться на некоторые шаблоны попавшие в окно.",А в принципе это и есть цель,"Если вы хотите организовать это условно как ViT, то он будет смотреть на выборку как на одномерную картинку или как на последовательность слов, etc. Я имею в виду, что он будет смотреть на это как на упорядоченную последовательность, где сможет хайлайтить какие-то периоды в истории. В какой конфигурации и на каких данных это может быть полезно - вопрос открытый."
"Есть мысль, что тогда атеншн будет тригериться на некоторые шаблоны попавшие в окно.",А в принципе это и есть цель,"Если вы хотите организовать это условно как ViT, то он будет смотреть на выборку как на одномерную картинку или как на последовательность слов, etc. Я имею в виду, что он будет смотреть на это как на упорядоченную последовательность, где сможет хайлайтить какие-то периоды в истории. В какой конфигурации и на каких данных это может быть полезно - вопрос открытый.",Не одномерную в целом
А в принципе это и есть цель,"Если вы хотите организовать это условно как ViT, то он будет смотреть на выборку как на одномерную картинку или как на последовательность слов, etc. Я имею в виду, что он будет смотреть на это как на упорядоченную последовательность, где сможет хайлайтить какие-то периоды в истории. В какой конфигурации и на каких данных это может быть полезно - вопрос открытый.",Не одномерную в целом,"Концептуально это не так важно, просто вопрос в том, как организовать финансовые данные для того, чтобы по целой композиции (по аналогии картинке) делать ""точный"" предикт."
"Если вы хотите организовать это условно как ViT, то он будет смотреть на выборку как на одномерную картинку или как на последовательность слов, etc. Я имею в виду, что он будет смотреть на это как на упорядоченную последовательность, где сможет хайлайтить какие-то периоды в истории. В какой конфигурации и на каких данных это может быть полезно - вопрос открытый.",Не одномерную в целом,"Концептуально это не так важно, просто вопрос в том, как организовать финансовые данные для того, чтобы по целой композиции (по аналогии картинке) делать ""точный"" предикт.",Кормить подходящим образом другие серии. Макру ту же
,,,Вопрос нарезки данных
,,,"Всем привет, Не знаю в этот тред или нет, хотел совета.
Есть задача сделать предсказание количества звонков в колцентре интернет магазина, на следующий день, в перспективе предсказание количество звонков на следующий час.
Из исходных данных есть база звонков за несколько лет (дата звонка, направление, связанность с заказом, связанность с ЮЛ или Физ лицом)
Может у кого-то был подобный опыт и подскажите с чего правильней подойти к этой задаче?"
,,"Всем привет, Не знаю в этот тред или нет, хотел совета.
Есть задача сделать предсказание количества звонков в колцентре интернет магазина, на следующий день, в перспективе предсказание количество звонков на следующий час.
Из исходных данных есть база звонков за несколько лет (дата звонка, направление, связанность с заказом, связанность с ЮЛ или Физ лицом)
Может у кого-то был подобный опыт и подскажите с чего правильней подойти к этой задаче?","Если интернет магазин - надо сезонность учесть. И тренд. По временным рядам. Если данные за несколько лет, данных должно хватить."
,,,добавить в фичи действия на сайте
,,добавить в фичи действия на сайте,"какие например? историю просмотров, например какие товары смотрел?"
,добавить в фичи действия на сайте,"какие например? историю просмотров, например какие товары смотрел?","физику в данных выловите. Не вижу смысла здесь в prophet. Точнее вижу, но это слишком просто) я не для того чтобы усложнить предлагаю. А предлагаю вскрыть суть процесса"
,,,"Как бейслайн, сделать просто обычный time series forecasting xgboost'ом или чем-то подобным, где тайм сериес это количество звонков на день. Можно сделать это prophet'ом или этной от тиньки
Далее уже можно попробовать прикручивать разные фичи, если перфоманс будет неудовлетворительным"
,,"Как бейслайн, сделать просто обычный time series forecasting xgboost'ом или чем-то подобным, где тайм сериес это количество звонков на день. Можно сделать это prophet'ом или этной от тиньки
Далее уже можно попробовать прикручивать разные фичи, если перфоманс будет неудовлетворительным","Если кого заинтересует, тетрадку открою"
,,,"Добавить лаги вроде ""вчера"", ""неделю назад"", ""месяц назад"", ""год назад"". Но нужно смотреть, чтобы день недели был одинаковый, так как предполагаю, что от дня недели все сильно зависит"
,,"Добавить лаги вроде ""вчера"", ""неделю назад"", ""месяц назад"", ""год назад"". Но нужно смотреть, чтобы день недели был одинаковый, так как предполагаю, что от дня недели все сильно зависит","это да, думал про это тоже что бы инфа была не только по вчерашнему дню, но и по такому же дню неделю назад, месяц и год назад"
,"Добавить лаги вроде ""вчера"", ""неделю назад"", ""месяц назад"", ""год назад"". Но нужно смотреть, чтобы день недели был одинаковый, так как предполагаю, что от дня недели все сильно зависит","это да, думал про это тоже что бы инфа была не только по вчерашнему дню, но и по такому же дню неделю назад, месяц и год назад",correlation does not imply causation - завтра может рекламу запустят. И все бестолкк
,,,Так же добавить 0 или 1 для выходного дня
,,Так же добавить 0 или 1 для выходного дня,В Европе день раньше начинается
,Так же добавить 0 или 1 для выходного дня,В Европе день раньше начинается,"Ну для супербазовой модели лаг в один день и неделю плюс 0/1 в выходной будет достаточно. Такая штука пишется за час от силы, и мб метрика будет приличная
Потом уже можно почитать конкретно по теме и улучшать"
Так же добавить 0 или 1 для выходного дня,В Европе день раньше начинается,"Ну для супербазовой модели лаг в один день и неделю плюс 0/1 в выходной будет достаточно. Такая штука пишется за час от силы, и мб метрика будет приличная
Потом уже можно почитать конкретно по теме и улучшать",да ок... тут нечего возразить
В Европе день раньше начинается,"Ну для супербазовой модели лаг в один день и неделю плюс 0/1 в выходной будет достаточно. Такая штука пишется за час от силы, и мб метрика будет приличная
Потом уже можно почитать конкретно по теме и улучшать",да ок... тут нечего возразить,"тоже так думал, что начать с простого функционала, а потом на основе результатов смотреть в сторону улучшений и обрастанием учёта доп фич"
"Ну для супербазовой модели лаг в один день и неделю плюс 0/1 в выходной будет достаточно. Такая штука пишется за час от силы, и мб метрика будет приличная
Потом уже можно почитать конкретно по теме и улучшать",да ок... тут нечего возразить,"тоже так думал, что начать с простого функционала, а потом на основе результатов смотреть в сторону улучшений и обрастанием учёта доп фич","только может выясниться что на звонки вовсе не вращение небесных тел влияет. но сортировать гипотезы не мне, поэтому ладно)"
да ок... тут нечего возразить,"тоже так думал, что начать с простого функционала, а потом на основе результатов смотреть в сторону улучшений и обрастанием учёта доп фич","только может выясниться что на звонки вовсе не вращение небесных тел влияет. но сортировать гипотезы не мне, поэтому ладно)",ну да) потом вообще ещё придётся прикручивать учёт экономической и политической ситуации в регионе)
,,,Но для тайм сериес есть свои трансформеры
,,Но для тайм сериес есть свои трансформеры,с какими моделями посоветуете ознакомиться?
,,,Выше я написал про них)
,,Выше я написал про них),Там какие-то особые велосипеды есть
,Выше я написал про них),Там какие-то особые велосипеды есть,"Вот в этом пакете можно в них повкуривать. Но мысли там другие кмк
https://nixtla.github.io/neuralforecast/models.hint.html"
Выше я написал про них),Там какие-то особые велосипеды есть,"Вот в этом пакете можно в них повкуривать. Но мысли там другие кмк
https://nixtla.github.io/neuralforecast/models.hint.html","Спасибо за наводку, интересная вещь"
,,,Я бы рекомендовал тебе начать  с торговли руками и поиска стратегии. А уже дальше алгоритм перекладывать на  код...
,,Я бы рекомендовал тебе начать  с торговли руками и поиска стратегии. А уже дальше алгоритм перекладывать на  код...,Трансформеры кушают токены. По ссылке рецепт как серии в них обратить
,,,"Не в генеративном смысле, а в дискриминативном"
,,"Не в генеративном смысле, а в дискриминативном",Трансформеры умеют классифицировать так-то. Начиная от BERT
,,,или я не так понял?
,,или я не так понял?,Мне кажется специфика данных может сильно повлиять на свойства
,или я не так понял?,Мне кажется специфика данных может сильно повлиять на свойства,и в этом тоже предмет исследований
,,,На этом этапе начинается велосипедостроение
,,На этом этапе начинается велосипедостроение,"Когда-то был первый велосипед. И он был думаю одноколесный. А без него бы и двухколёсных не было, хз"
,,,"Чо теперь, сидеть ждать пока скептики не исчезнут? :)
Я хотел бы скорее на arxiv ссылку с чем-то подобным"
,,,похоже на state space models?
,,похоже на state space models?,"насколько я их помню, нет"
,,,Насколько релевантно использование spatial transformer для задач паттерн рекогнишн?
,,Насколько релевантно использование spatial transformer для задач паттерн рекогнишн?,ViT сам же упоминал
,Насколько релевантно использование spatial transformer для задач паттерн рекогнишн?,ViT сам же упоминал,"Это разные вещи. Spatial transformer вообще до атеншна появился, там сетка внутри может быть и не трансформер."
Насколько релевантно использование spatial transformer для задач паттерн рекогнишн?,ViT сам же упоминал,"Это разные вещи. Spatial transformer вообще до атеншна появился, там сетка внутри может быть и не трансформер.",тогда это тут не причем
,,,"О, го резерч и чатик по трансформерам в тайм сериес. Тоже интересует эта тема"
,,,"а какая глобально проблема решается, что на ивентах плохо работать? у меня в реальных случаях как раз ивентбэйзд входы (предикшоны какой-то другой модели для каждого события, fill’а, например) + аттеншен в качестве аггренейшн степа показывали себя лучше и робастнее всего, в отличие от подходов с нарезанием (что-то похожее на статью яндекса недавнюю)"
,,"а какая глобально проблема решается, что на ивентах плохо работать? у меня в реальных случаях как раз ивентбэйзд входы (предикшоны какой-то другой модели для каждого события, fill’а, например) + аттеншен в качестве аггренейшн степа показывали себя лучше и робастнее всего, в отличие от подходов с нарезанием (что-то похожее на статью яндекса недавнюю)",Что за статья?
,"а какая глобально проблема решается, что на ивентах плохо работать? у меня в реальных случаях как раз ивентбэйзд входы (предикшоны какой-то другой модели для каждого события, fill’а, например) + аттеншен в качестве аггренейшн степа показывали себя лучше и робастнее всего, в отличие от подходов с нарезанием (что-то похожее на статью яндекса недавнюю)",Что за статья?,https://arxiv.org/pdf/2307.14338.pdf
"а какая глобально проблема решается, что на ивентах плохо работать? у меня в реальных случаях как раз ивентбэйзд входы (предикшоны какой-то другой модели для каждого события, fill’а, например) + аттеншен в качестве аггренейшн степа показывали себя лучше и робастнее всего, в отличие от подходов с нарезанием (что-то похожее на статью яндекса недавнюю)",Что за статья?,https://arxiv.org/pdf/2307.14338.pdf,"А, это распеарили дай боже. Хорошая штука)"
,,,"Правильный вопрос!)))

Глобально решается создание базы не евентов, а структуры в них
бонусом можно кормить свой хвост, модель causal llm под это заточена из коробки
спасибо за ссылку! Вы про hrp?
У трансформеров хорошие кластеры лишь побочка..."
,,,"В статье несколько алгоритмов рассматривается, hrp вроде тоже был"
,,"В статье несколько алгоритмов рассматривается, hrp вроде тоже был","Посмотрел абстракт, там топят за motifs"
,,,"трансформеры их в состоянии находить...
потому что Тьюринг-полные"
,,,а запись будет?
,,а запись будет?,Офк
,,,"Добавил по ссылке в  комментариях ссылку на тетрадку.

Библиотека кривулек - она ручная, и составлена не из кусков серий.

Поэтому кодирование универсальное"
,,"Добавил по ссылке в  комментариях ссылку на тетрадку.

Библиотека кривулек - она ручная, и составлена не из кусков серий.

Поэтому кодирование универсальное",А где ссылка? Не могу найти
,,,"если вкратце, кодирование произвольных multidimensional timeseries как текста, а потом жах языковыми генераторами. Вся суть.

Примеры надо было сделать toy. Но в отпуске уже много других дел..."
,,,"Но я свою тему раньше начал, которая не собственная архитектура, а банальный трансформер"
,,"Но я свою тему раньше начал, которая не собственная архитектура, а банальный трансформер",Хотя это неважно
,,,"Всем привет, какие способы выкатывания модельки в прод существуют для такой задачи: есть модель и код для неё на Питоне, надо подвязать это к сервису, который работает на Go"
,,"Всем привет, какие способы выкатывания модельки в прод существуют для такой задачи: есть модель и код для неё на Питоне, надо подвязать это к сервису, который работает на Go","Есть еще вариант отдельный микросервис. А общаться они могут хоть по http, хоть named pipes, хоть shared memory"
,,,"Это если прям самый общий подход
У отдельно взятых либ можно сразу импортировать/экспортировать модельки в общем формате (у того же xgboost)"
,,,А находил кто-нибудь тетрадки по TabR?) Везде он ща
,,А находил кто-нибудь тетрадки по TabR?) Везде он ща,скажи если найдешь плиз
,А находил кто-нибудь тетрадки по TabR?) Везде он ща,скажи если найдешь плиз,"Да пока, кроме гита и этой статьи выше, ничего вообще нет. Один хайп будто"
,,,но пока есть слухи что авторы TabR сейчас умирают в нипс ребатле в неравном бою.
,,но пока есть слухи что авторы TabR сейчас умирают в нипс ребатле в неравном бою.,Так может у автора спросить?) Он сидит в этом канале
,,,"подскажите, пожалуйста хорошую статью о том, где систематизировано как развернуть пространство для разработки с использованием и тех продвинутых фич, которые используются для продакшина, например в tensorflow


    ConfusionMatrix for recognizing bad input data
    Automatical data labeling (but it is enough rare on practice, as I understand)
    Anomalies detection and validation of input data
    Features selection (specially by importance), transformation to use raw data directly to input.
    Autotuner
    Fairness detection
    Shapely would be usefull too in debugging, I think"
,,"подскажите, пожалуйста хорошую статью о том, где систематизировано как развернуть пространство для разработки с использованием и тех продвинутых фич, которые используются для продакшина, например в tensorflow


    ConfusionMatrix for recognizing bad input data
    Automatical data labeling (but it is enough rare on practice, as I understand)
    Anomalies detection and validation of input data
    Features selection (specially by importance), transformation to use raw data directly to input.
    Autotuner
    Fairness detection
    Shapely would be usefull too in debugging, I think","Если локально советую докер композер, просто ставишь туда образ nvidia , монтируешь volume как .:/app и работаешь спокойно., Можно ещё venv, тогда ещё и модeли будут там же.
по приколу выпросил точную реализацию у гпт :) https://chat.openai.com/share/d7a2151a-5e9b-4126-926b-5190302c6926"
,"подскажите, пожалуйста хорошую статью о том, где систематизировано как развернуть пространство для разработки с использованием и тех продвинутых фич, которые используются для продакшина, например в tensorflow


    ConfusionMatrix for recognizing bad input data
    Automatical data labeling (but it is enough rare on practice, as I understand)
    Anomalies detection and validation of input data
    Features selection (specially by importance), transformation to use raw data directly to input.
    Autotuner
    Fairness detection
    Shapely would be usefull too in debugging, I think","Если локально советую докер композер, просто ставишь туда образ nvidia , монтируешь volume как .:/app и работаешь спокойно., Можно ещё venv, тогда ещё и модeли будут там же.
по приколу выпросил точную реализацию у гпт :) https://chat.openai.com/share/d7a2151a-5e9b-4126-926b-5190302c6926","при чем тут среда в ОС? Я спрашивал про шаблон кода куда вставлять модель надо. Вот например про features engeneering, которую  перечислил

https://www.tensorflow.org/tfx/tutorials/tfx/penguin_tft"
,,,"Привет. Может кто-то решал подобную задачу и сможет подсказать. 

Дано: Есть тексты и неры из этих текстов от наташи по типу ""Медведев"", ""Дмитрий Анатольевич Медведев"", ""Дмитрий Медведев "", ""Андрей Медведев"", ""Даниил Медведев"" и т.д. 

Задача: Нужно линковать неры относительно их личностей. Т.е. если нер ""Медведев"" подразумевает премьер министра, то он должен линковаться с ""Дмитрий Анатольевич Медведев"" и с ""Дмитрий Медведев"", а если теннесиста, то с ""Даниил Медведев"".

Пробовал получать эмбединги от неров, текстов где употребились эти неры через e5-multilingual и совмещать их разными способами,  а потом кластеризовать. Что-то получилось, но не очень"
,,"Привет. Может кто-то решал подобную задачу и сможет подсказать. 

Дано: Есть тексты и неры из этих текстов от наташи по типу ""Медведев"", ""Дмитрий Анатольевич Медведев"", ""Дмитрий Медведев "", ""Андрей Медведев"", ""Даниил Медведев"" и т.д. 

Задача: Нужно линковать неры относительно их личностей. Т.е. если нер ""Медведев"" подразумевает премьер министра, то он должен линковаться с ""Дмитрий Анатольевич Медведев"" и с ""Дмитрий Медведев"", а если теннесиста, то с ""Даниил Медведев"".

Пробовал получать эмбединги от неров, текстов где употребились эти неры через e5-multilingual и совмещать их разными способами,  а потом кластеризовать. Что-то получилось, но не очень","Задача называется entity linking; у неё существуют более-менее типовые решения. 
Вот пример одного из решений от моих коллег из Меты; там есть мультиязычная версия, которая в том числе поддерживает и русский: https://github.com/facebookresearch/GENRE
 
P.S. У них есть ещё модель поновее и вроде как получше, но там код для запуска менее очевидный: https://github.com/facebookresearch/BELA"
,,,В комментах к статье. Пардон что не копипастю - только с бара пришёл
,,В комментах к статье. Пардон что не копипастю - только с бара пришёл,"Если у вас 4 детей, по статистике 5й будет китаец. Не удивляйтесь  😀"
,,,"Всем привет, интересует бектест на limit order book (тестовое в цмф 😁). Есть стакан, ордера и тикеры. 
Я так понял для симуляции я должен обновлять стакан по тикерам, такой вопрос, когда я тестирую стратегию, я предполагаю что мои ордера приходят после исторических ордеров или до? Или скажем с вероятностью p до?"
,,"Всем привет, интересует бектест на limit order book (тестовое в цмф 😁). Есть стакан, ордера и тикеры. 
Я так понял для симуляции я должен обновлять стакан по тикерам, такой вопрос, когда я тестирую стратегию, я предполагаю что мои ордера приходят после исторических ордеров или до? Или скажем с вероятностью p до?",в симуляцию обычно как раз добавляется параметр задержки
,"Всем привет, интересует бектест на limit order book (тестовое в цмф 😁). Есть стакан, ордера и тикеры. 
Я так понял для симуляции я должен обновлять стакан по тикерам, такой вопрос, когда я тестирую стратегию, я предполагаю что мои ордера приходят после исторических ордеров или до? Или скажем с вероятностью p до?",в симуляцию обычно как раз добавляется параметр задержки,А как учитывается задержка в более сложных моделях? Чисто путём симуляции и максимизации pnl скажем?
"Всем привет, интересует бектест на limit order book (тестовое в цмф 😁). Есть стакан, ордера и тикеры. 
Я так понял для симуляции я должен обновлять стакан по тикерам, такой вопрос, когда я тестирую стратегию, я предполагаю что мои ордера приходят после исторических ордеров или до? Или скажем с вероятностью p до?",в симуляцию обычно как раз добавляется параметр задержки,А как учитывается задержка в более сложных моделях? Чисто путём симуляции и максимизации pnl скажем?,"обычно есть параметры задержки явные, ваша задержка до биржи, внутренняя задержка мэтчера биржи"
,,,от вашего решение по обновлению бука выставить лимитку до выставления лимитки
,,от вашего решение по обновлению бука выставить лимитку до выставления лимитки,"под питон рекомендую посмотреть https://github.com/nkaz001/hftbacktest?ysclid=ll73qc612i588919746, сугубо в educational/ознакомительных целях, не для прод-рисёрча"
,от вашего решение по обновлению бука выставить лимитку до выставления лимитки,"под питон рекомендую посмотреть https://github.com/nkaz001/hftbacktest?ysclid=ll73qc612i588919746, сугубо в educational/ознакомительных целях, не для прод-рисёрча","Топчик, как раз думал что по-любому кто-то реализовал чтобы с 0 не писать 
Спасибо большое!"
от вашего решение по обновлению бука выставить лимитку до выставления лимитки,"под питон рекомендую посмотреть https://github.com/nkaz001/hftbacktest?ysclid=ll73qc612i588919746, сугубо в educational/ознакомительных целях, не для прод-рисёрча","Топчик, как раз думал что по-любому кто-то реализовал чтобы с 0 не писать 
Спасибо большое!","думаю там задание все таки с 0 написать хоть более простое, но это наверное можно для вдохновения"
,,,"про симуляцию и максимизацию не понял,  задержка — данность,её вряд ли оптимизируют в разработке стратегии
первое выставляют исходя из вашей инфры, второе сложнее)"
,,,Скорее индиец
,,Скорее индиец,Это четвертый
,,,3й ребенок чернокожий?
,,,"Всем привет! А что за видеочат сегодня?.. Какая-то тема, или так обо всем понемногу?"
,,"Всем привет! А что за видеочат сегодня?.. Какая-то тема, или так обо всем понемногу?",это к @alexnikosa
,"Всем привет! А что за видеочат сегодня?.. Какая-то тема, или так обо всем понемногу?",это к @alexnikosa,"А, понял, спасибо. Это на весь BDS видимо"
,,,"Всем добрый день!
подскажите пожалуйста, есть ли модели для распознавания русского языка жестов онлайн?"
,,"Всем добрый день!
подскажите пожалуйста, есть ли модели для распознавания русского языка жестов онлайн?","Привет, оно? https://github.com/hukenovs/slovo"
,,,"как вариант
спасибо большое)"
,,"как вариант
спасибо большое)",Спасибо за соучастие 🙃
,,,"Всем привет, можете подсказать
У меня есть 10М пар предложение 1, предложение 2 с бинарным таргетом - совпадают предложения или нет
Пары из разных областей, областей в каждой области средний таргет между 0.7 и 0.85
Есть область где примеров 60к, а есть где 1.5М
Как лучше с таким датасетом работать? 
Обучаю роберту"
,,"Всем привет, можете подсказать
У меня есть 10М пар предложение 1, предложение 2 с бинарным таргетом - совпадают предложения или нет
Пары из разных областей, областей в каждой области средний таргет между 0.7 и 0.85
Есть область где примеров 60к, а есть где 1.5М
Как лучше с таким датасетом работать? 
Обучаю роберту","Вариант 1: если области не сильно друг с другом конкурируют (в том смысле что обучение на категории 6 не приводит к сильному ухудшению работы на категории 20, и т.п.), можно работать с ним как есть, ничего специального не делая. 

Вариант 2: можно пересэмплить датасет, сделав распределение категорий более однородным. Как именно пересэмплить - обычно используют или ""Temperature-based sampling"", или более простой ""UniMax sampling"" (оба описаны в разделе 3 статьи про UMT5, например)."
,"Всем привет, можете подсказать
У меня есть 10М пар предложение 1, предложение 2 с бинарным таргетом - совпадают предложения или нет
Пары из разных областей, областей в каждой области средний таргет между 0.7 и 0.85
Есть область где примеров 60к, а есть где 1.5М
Как лучше с таким датасетом работать? 
Обучаю роберту","Вариант 1: если области не сильно друг с другом конкурируют (в том смысле что обучение на категории 6 не приводит к сильному ухудшению работы на категории 20, и т.п.), можно работать с ним как есть, ничего специального не делая. 

Вариант 2: можно пересэмплить датасет, сделав распределение категорий более однородным. Как именно пересэмплить - обычно используют или ""Temperature-based sampling"", или более простой ""UniMax sampling"" (оба описаны в разделе 3 статьи про UMT5, например).","Спасибо
А можешь подсказать, по поводу дисбаланса таргетов?
Я раньше приводил в каждой категории таргет до 0.5 даунсемплингом и обучался на датасете в 4М пар где-то
Вот думаю, для BCE такое соотношение сильно вредит, или можно оставить? А если можно исправить, то куда смотреть"
"Всем привет, можете подсказать
У меня есть 10М пар предложение 1, предложение 2 с бинарным таргетом - совпадают предложения или нет
Пары из разных областей, областей в каждой области средний таргет между 0.7 и 0.85
Есть область где примеров 60к, а есть где 1.5М
Как лучше с таким датасетом работать? 
Обучаю роберту","Вариант 1: если области не сильно друг с другом конкурируют (в том смысле что обучение на категории 6 не приводит к сильному ухудшению работы на категории 20, и т.п.), можно работать с ним как есть, ничего специального не делая. 

Вариант 2: можно пересэмплить датасет, сделав распределение категорий более однородным. Как именно пересэмплить - обычно используют или ""Temperature-based sampling"", или более простой ""UniMax sampling"" (оба описаны в разделе 3 статьи про UMT5, например).","Спасибо
А можешь подсказать, по поводу дисбаланса таргетов?
Я раньше приводил в каждой категории таргет до 0.5 даунсемплингом и обучался на датасете в 4М пар где-то
Вот думаю, для BCE такое соотношение сильно вредит, или можно оставить? А если можно исправить, то куда смотреть","Мне кажется, можно оставить. Но вообще лучше это проверить экспериментально)"
,,,Уже через несколько минут начнем!
,,Уже через несколько минут начнем!,микрофон включите
,Уже через несколько минут начнем!,микрофон включите,Как они от марковских цепей отличаются (или от простой авторегрессии)? Не оч понятно
Уже через несколько минут начнем!,микрофон включите,Как они от марковских цепей отличаются (или от простой авторегрессии)? Не оч понятно,"Есть ли преимущества в скорости?
Когда ждать возвращение к TF IDF? 😄
Развитие пошло в другом направление."
микрофон включите,Как они от марковских цепей отличаются (или от простой авторегрессии)? Не оч понятно,"Есть ли преимущества в скорости?
Когда ждать возвращение к TF IDF? 😄
Развитие пошло в другом направление.",Как эти модели ведут себя на небольших последовательностях?
Как они от марковских цепей отличаются (или от простой авторегрессии)? Не оч понятно,"Есть ли преимущества в скорости?
Когда ждать возвращение к TF IDF? 😄
Развитие пошло в другом направление.",Как эти модели ведут себя на небольших последовательностях?,"Вопросов нет, но..."
"Есть ли преимущества в скорости?
Когда ждать возвращение к TF IDF? 😄
Развитие пошло в другом направление.",Как эти модели ведут себя на небольших последовательностях?,"Вопросов нет, но...","Матрицу А диагонализируют все обучение (типа orthogonal в linear) или мы обучаем диагональку?
Так а что обучаем-то, если А фиксированная?"
Как эти модели ведут себя на небольших последовательностях?,"Вопросов нет, но...","Матрицу А диагонализируют все обучение (типа orthogonal в linear) или мы обучаем диагональку?
Так а что обучаем-то, если А фиксированная?",Какие размерности они берут для матриц?
"Вопросов нет, но...","Матрицу А диагонализируют все обучение (типа orthogonal в linear) или мы обучаем диагональку?
Так а что обучаем-то, если А фиксированная?",Какие размерности они берут для матриц?,Благодарю
"Матрицу А диагонализируют все обучение (типа orthogonal в linear) или мы обучаем диагональку?
Так а что обучаем-то, если А фиксированная?",Какие размерности они берут для матриц?,Благодарю,"Я правильно понял, что w - это один(!) обучаемый вектор весов прошлых токенов и его связь с нынешним токеном - это суммирование w + key?"
Какие размерности они берут для матриц?,Благодарю,"Я правильно понял, что w - это один(!) обучаемый вектор весов прошлых токенов и его связь с нынешним токеном - это суммирование w + key?",К текущему вопросу: можно ли делать semi-supervised?
Благодарю,"Я правильно понял, что w - это один(!) обучаемый вектор весов прошлых токенов и его связь с нынешним токеном - это суммирование w + key?",К текущему вопросу: можно ли делать semi-supervised?,"Какими мощностями нужно обладать чтобы повторить эксперименты из статей
В графике качества была модель MEGA в презентации нет информации, можно пару слов о ней"
"Я правильно понял, что w - это один(!) обучаемый вектор весов прошлых токенов и его связь с нынешним токеном - это суммирование w + key?",К текущему вопросу: можно ли делать semi-supervised?,"Какими мощностями нужно обладать чтобы повторить эксперименты из статей
В графике качества была модель MEGA в презентации нет информации, можно пару слов о ней","Последней модельки нет у Хуггингов? Вообще код есть? Вроде я видел репо, но точно не помню.. .
Нужна запись и материалы презентаций! 😅"
К текущему вопросу: можно ли делать semi-supervised?,"Какими мощностями нужно обладать чтобы повторить эксперименты из статей
В графике качества была модель MEGA в презентации нет информации, можно пару слов о ней","Последней модельки нет у Хуггингов? Вообще код есть? Вроде я видел репо, но точно не помню.. .
Нужна запись и материалы презентаций! 😅","завис
А можно статейки на то какую работу по обяснимости и всего такого сделали для трансформеров в последние годы и которые нужно сделать для этих моделей"
"Какими мощностями нужно обладать чтобы повторить эксперименты из статей
В графике качества была модель MEGA в презентации нет информации, можно пару слов о ней","Последней модельки нет у Хуггингов? Вообще код есть? Вроде я видел репо, но точно не помню.. .
Нужна запись и материалы презентаций! 😅","завис
А можно статейки на то какую работу по обяснимости и всего такого сделали для трансформеров в последние годы и которые нужно сделать для этих моделей","Вааащеее, спасибо тебе большое за лекцию, очень круто 🙂"
"Последней модельки нет у Хуггингов? Вообще код есть? Вроде я видел репо, но точно не помню.. .
Нужна запись и материалы презентаций! 😅","завис
А можно статейки на то какую работу по обяснимости и всего такого сделали для трансформеров в последние годы и которые нужно сделать для этих моделей","Вааащеее, спасибо тебе большое за лекцию, очень круто 🙂",Супер!
,,,"Привет всем! Только сейчас узнал об этом комунити. 

Меня зовут Андрей, я python разработчик. Так же интересуюсь NLP и ML в Музыке. Сейчас нахожусь в Астане, если есть оффлайн движухи, то с радостью присоединюсь."
,,"Привет всем! Только сейчас узнал об этом комунити. 

Меня зовут Андрей, я python разработчик. Так же интересуюсь NLP и ML в Музыке. Сейчас нахожусь в Астане, если есть оффлайн движухи, то с радостью присоединюсь.","Привет! ML в музыке – эт хорошо, наш человек. 😁"
,,,"Ассаламу алейкум, зовут антон, люблю пообучать сетки и сладко дунуть. Хочу перекатиться куда-то ближе к ресерчу, прощупываю почву"
,,"Ассаламу алейкум, зовут антон, люблю пообучать сетки и сладко дунуть. Хочу перекатиться куда-то ближе к ресерчу, прощупываю почву",Вы чат перепутали. Здесь не тусовка рэперов и гангста.
,"Ассаламу алейкум, зовут антон, люблю пообучать сетки и сладко дунуть. Хочу перекатиться куда-то ближе к ресерчу, прощупываю почву",Вы чат перепутали. Здесь не тусовка рэперов и гангста.,"Да? А я думал, здесь тусовка рэперов и гангста"
,,,"я не ресерчер, но мне кажется прощупывать почву вы не с того начали, Антон"
,,"я не ресерчер, но мне кажется прощупывать почву вы не с того начали, Антон","Так-так, а с чего стоит? Мб ты знаешь, как залететь в лабу?"
,"я не ресерчер, но мне кажется прощупывать почву вы не с того начали, Антон","Так-так, а с чего стоит? Мб ты знаешь, как залететь в лабу?","Например Шолле либу написал. Или Олах - крутые статьи. Не уверен что они на курении акцентировались в поиске работы.

Удивишь, если докажешь что я неправ"
"я не ресерчер, но мне кажется прощупывать почву вы не с того начали, Антон","Так-так, а с чего стоит? Мб ты знаешь, как залететь в лабу?","Например Шолле либу написал. Или Олах - крутые статьи. Не уверен что они на курении акцентировались в поиске работы.

Удивишь, если докажешь что я неправ","Так это понятно, а статьи как писать? Попасть к хорошему руководителю в пхд - оч сложно, а в хуйне говна получать - терять 4-5 лет фактически. В дискорде у Алексы гордича есть упоминания про ресерч без пхд, но там ссылки на какие-то мёртвые ресурсы, как мне показалось"
"Так-так, а с чего стоит? Мб ты знаешь, как залететь в лабу?","Например Шолле либу написал. Или Олах - крутые статьи. Не уверен что они на курении акцентировались в поиске работы.

Удивишь, если докажешь что я неправ","Так это понятно, а статьи как писать? Попасть к хорошему руководителю в пхд - оч сложно, а в хуйне говна получать - терять 4-5 лет фактически. В дискорде у Алексы гордича есть упоминания про ресерч без пхд, но там ссылки на какие-то мёртвые ресурсы, как мне показалось","у него где-то было подробное описание что он делал, чтобы попасть в deepmind. насколько я понял основную роль сыграло то, что у него была хорошая медийная составляющая и он наладил контакт кем-то внутри коллективна и его порекомендовали"
,,,"Жду запись с нетерпением, судя по презе все топ)"
,,,А как написать статью без пхд или позиции в Лабе?
,,А как написать статью без пхд или позиции в Лабе?,"самый простой способ - стать пхд. я например кандидатскую по экономике написал (не защищал), сдал кандитатский минимум, статьи публиковал в аспирантуре...

А не защищал потому что развёлся, уехал в другой город, а потом и вообще понял, что в бизнесе пхд нужны очень мало где"
,,,Точнее не написать даже а опубликовать на хорошей конфе
,,,"Ну вот и я про то, что всё дороги ведут на пхд. Другие пути кажутся маловероятными"
,,"Ну вот и я про то, что всё дороги ведут на пхд. Другие пути кажутся маловероятными",Я работаю рисечером в лабе без пхд. В Америке это точно реально. ( но планирую делать под все равно)
,"Ну вот и я про то, что всё дороги ведут на пхд. Другие пути кажутся маловероятными",Я работаю рисечером в лабе без пхд. В Америке это точно реально. ( но планирую делать под все равно),"Поделишься опытом, расскажешь про бэкграунд?"
"Ну вот и я про то, что всё дороги ведут на пхд. Другие пути кажутся маловероятными",Я работаю рисечером в лабе без пхд. В Америке это точно реально. ( но планирую делать под все равно),"Поделишься опытом, расскажешь про бэкграунд?","Мастер по computational neuroscience. В Европе найти работу без пхд показалось сложно, так как там каждая лаба легко может нанять пхд студента, и это будет дешевле и надолго. В Америке все пхд студенты идут через структурированные программы, поэтому лабы борются за студентов. Им гораздо проще нанять человека с бак/мастером напрямую. У нас в лабе 0 пхд студентов и 4 research scientist после бака/маги. Такая ситуация не только в моей лабе. Иная ситуация будет разве что в супер известных лабах"
Я работаю рисечером в лабе без пхд. В Америке это точно реально. ( но планирую делать под все равно),"Поделишься опытом, расскажешь про бэкграунд?","Мастер по computational neuroscience. В Европе найти работу без пхд показалось сложно, так как там каждая лаба легко может нанять пхд студента, и это будет дешевле и надолго. В Америке все пхд студенты идут через структурированные программы, поэтому лабы борются за студентов. Им гораздо проще нанять человека с бак/мастером напрямую. У нас в лабе 0 пхд студентов и 4 research scientist после бака/маги. Такая ситуация не только в моей лабе. Иная ситуация будет разве что в супер известных лабах","1. Расскажи, что за лаба и чем занимается твоя группа? Публикуетесь? 
2. Какие требования к кандидатам? Возможно ли стать условным инженером только с бизнес-бекграундом без публикаций? 
3. Неужели даж бакалавр может податься и его рассмотрят?"
"Поделишься опытом, расскажешь про бэкграунд?","Мастер по computational neuroscience. В Европе найти работу без пхд показалось сложно, так как там каждая лаба легко может нанять пхд студента, и это будет дешевле и надолго. В Америке все пхд студенты идут через структурированные программы, поэтому лабы борются за студентов. Им гораздо проще нанять человека с бак/мастером напрямую. У нас в лабе 0 пхд студентов и 4 research scientist после бака/маги. Такая ситуация не только в моей лабе. Иная ситуация будет разве что в супер известных лабах","1. Расскажи, что за лаба и чем занимается твоя группа? Публикуетесь? 
2. Какие требования к кандидатам? Возможно ли стать условным инженером только с бизнес-бекграундом без публикаций? 
3. Неужели даж бакалавр может податься и его рассмотрят?","Лаба занимается мультисенсорной интеграцией в мозге, собирает много фмрт, интракраниального ээг. Когда я нанималась, то разговоры шли про моделирование нейропроцессов нейросетями, но по факту лабе нужен был аналитик (больших) данных со знанием статистики. 
Да, публикуемся. Так как это не мл, то на статьи уходит больше времени.
Основные требования: питон, статистика. Меня нанимали из-за знание dl, но, как я уже сказала, это оказалось ненужным. На релевантный опыт, конечно смотрят. Я сомневаюсь, что кого-то с бизнес бэкграудом возьмут в чистое нейро или чистое мл, но можно пробовать идти в decision making and reinforcement learning. Везде в науке очень ценится искренний интерес к теме, и его надо подтвердить.
Да, у нас два студента после бака, но они оба заканчивали бак в Америке и они на opt. Нанимать их очень дешево и легко"
"Мастер по computational neuroscience. В Европе найти работу без пхд показалось сложно, так как там каждая лаба легко может нанять пхд студента, и это будет дешевле и надолго. В Америке все пхд студенты идут через структурированные программы, поэтому лабы борются за студентов. Им гораздо проще нанять человека с бак/мастером напрямую. У нас в лабе 0 пхд студентов и 4 research scientist после бака/маги. Такая ситуация не только в моей лабе. Иная ситуация будет разве что в супер известных лабах","1. Расскажи, что за лаба и чем занимается твоя группа? Публикуетесь? 
2. Какие требования к кандидатам? Возможно ли стать условным инженером только с бизнес-бекграундом без публикаций? 
3. Неужели даж бакалавр может податься и его рассмотрят?","Лаба занимается мультисенсорной интеграцией в мозге, собирает много фмрт, интракраниального ээг. Когда я нанималась, то разговоры шли про моделирование нейропроцессов нейросетями, но по факту лабе нужен был аналитик (больших) данных со знанием статистики. 
Да, публикуемся. Так как это не мл, то на статьи уходит больше времени.
Основные требования: питон, статистика. Меня нанимали из-за знание dl, но, как я уже сказала, это оказалось ненужным. На релевантный опыт, конечно смотрят. Я сомневаюсь, что кого-то с бизнес бэкграудом возьмут в чистое нейро или чистое мл, но можно пробовать идти в decision making and reinforcement learning. Везде в науке очень ценится искренний интерес к теме, и его надо подтвердить.
Да, у нас два студента после бака, но они оба заканчивали бак в Америке и они на opt. Нанимать их очень дешево и легко","но как получается релевантный опыт, если, чтоб попасть в лабу, нужен релевантный опыт? в маге какие-нить проектики/стажки?"
"1. Расскажи, что за лаба и чем занимается твоя группа? Публикуетесь? 
2. Какие требования к кандидатам? Возможно ли стать условным инженером только с бизнес-бекграундом без публикаций? 
3. Неужели даж бакалавр может податься и его рассмотрят?","Лаба занимается мультисенсорной интеграцией в мозге, собирает много фмрт, интракраниального ээг. Когда я нанималась, то разговоры шли про моделирование нейропроцессов нейросетями, но по факту лабе нужен был аналитик (больших) данных со знанием статистики. 
Да, публикуемся. Так как это не мл, то на статьи уходит больше времени.
Основные требования: питон, статистика. Меня нанимали из-за знание dl, но, как я уже сказала, это оказалось ненужным. На релевантный опыт, конечно смотрят. Я сомневаюсь, что кого-то с бизнес бэкграудом возьмут в чистое нейро или чистое мл, но можно пробовать идти в decision making and reinforcement learning. Везде в науке очень ценится искренний интерес к теме, и его надо подтвердить.
Да, у нас два студента после бака, но они оба заканчивали бак в Америке и они на opt. Нанимать их очень дешево и легко","но как получается релевантный опыт, если, чтоб попасть в лабу, нужен релевантный опыт? в маге какие-нить проектики/стажки?","В маге релевантный опыт получить просто (она для этого и сделана): работа в лабе (студентов нанимать очень просто), lab rotation, собственно сам магистерский тезис. Также куча стажировок есть, но туда можно и без маги идти"
"Лаба занимается мультисенсорной интеграцией в мозге, собирает много фмрт, интракраниального ээг. Когда я нанималась, то разговоры шли про моделирование нейропроцессов нейросетями, но по факту лабе нужен был аналитик (больших) данных со знанием статистики. 
Да, публикуемся. Так как это не мл, то на статьи уходит больше времени.
Основные требования: питон, статистика. Меня нанимали из-за знание dl, но, как я уже сказала, это оказалось ненужным. На релевантный опыт, конечно смотрят. Я сомневаюсь, что кого-то с бизнес бэкграудом возьмут в чистое нейро или чистое мл, но можно пробовать идти в decision making and reinforcement learning. Везде в науке очень ценится искренний интерес к теме, и его надо подтвердить.
Да, у нас два студента после бака, но они оба заканчивали бак в Америке и они на opt. Нанимать их очень дешево и легко","но как получается релевантный опыт, если, чтоб попасть в лабу, нужен релевантный опыт? в маге какие-нить проектики/стажки?","В маге релевантный опыт получить просто (она для этого и сделана): работа в лабе (студентов нанимать очень просто), lab rotation, собственно сам магистерский тезис. Также куча стажировок есть, но туда можно и без маги идти","Боюсь, стажки недоступны не-студентам)"
"но как получается релевантный опыт, если, чтоб попасть в лабу, нужен релевантный опыт? в маге какие-нить проектики/стажки?","В маге релевантный опыт получить просто (она для этого и сделана): работа в лабе (студентов нанимать очень просто), lab rotation, собственно сам магистерский тезис. Также куча стажировок есть, но туда можно и без маги идти","Боюсь, стажки недоступны не-студентам)","Может какие-то и недоступны, но я ездила на две стажировки в Германию и Японию не будучи студентов, плюс делала одну школу онлайн. Так что все возможно - надо просто искать"
"В маге релевантный опыт получить просто (она для этого и сделана): работа в лабе (студентов нанимать очень просто), lab rotation, собственно сам магистерский тезис. Также куча стажировок есть, но туда можно и без маги идти","Боюсь, стажки недоступны не-студентам)","Может какие-то и недоступны, но я ездила на две стажировки в Германию и Японию не будучи студентов, плюс делала одну школу онлайн. Так что все возможно - надо просто искать","Думаю, носителям паспорта РФ сейчас будет проблематично гонять по стажкам в недружественные страны, но это всё надо проверять, канеш. В целом, спасиб большое за инфу, будем копать!"
"Боюсь, стажки недоступны не-студентам)","Может какие-то и недоступны, но я ездила на две стажировки в Германию и Японию не будучи студентов, плюс делала одну школу онлайн. Так что все возможно - надо просто искать","Думаю, носителям паспорта РФ сейчас будет проблематично гонять по стажкам в недружественные страны, но это всё надо проверять, канеш. В целом, спасиб большое за инфу, будем копать!",Удачи
,,,"Получается, ты задал что-то вроде Фурье-базиса по-своему, а над ним накатил трансформер?
А почему именно трансформер?"
,,"Получается, ты задал что-то вроде Фурье-базиса по-своему, а над ним накатил трансформер?
А почему именно трансформер?","Фурье базис из функций, а к меня меня просто значения.

Трансформер потому что он натренирован ""кусать себя за хвост"". Изначально я это в gpt2 запихивал, но связанные с этим проблемы описал.

Трансформер спорно да, можно хоть бустинг. Но это та архитектура, которая нынче в состоянии справляться с 8192 классами за разумный вычислительный бюджет"
,,,"Коллеги, а кто сталкивался с нером, я правильно понимаю что если я готовлю датасет например по спанам, то это токены конкретного токенизатора и скорее всего для другой модели придется переразмечать?

Просто кажется такой подход топорноватым, кажется сейчас как-то попроще это должно решаться, есть какие-то бест практисы? Куда гуглить?"
,,"Коллеги, а кто сталкивался с нером, я правильно понимаю что если я готовлю датасет например по спанам, то это токены конкретного токенизатора и скорее всего для другой модели придется переразмечать?

Просто кажется такой подход топорноватым, кажется сейчас как-то попроще это должно решаться, есть какие-то бест практисы? Куда гуглить?","Ну вообще примерно так и есть, в хф даже есть функция  tokenize_and_align_labels для переноса меток на нужный токенизатор https://github.com/huggingface/transformers/blob/e42587f596181396e1c4b63660abf0c736b10dae/examples/pytorch/token-classification/run_ner.py#L425"
,,,"Нет, почему же, можно устроиться в лабу не будучи пхдшником. В мл по крайней мере так"
,,"Нет, почему же, можно устроиться в лабу не будучи пхдшником. В мл по крайней мере так","Удваиваю, реквестирую конкретные случаи работы в лабах без пхд"
,,,"не спорю, что можно. я бы послушал про конкретные кейсы: какая лаба, какая позиция и т.п. просто самого интересует эта тема, но для пхд уже староват)"
,,"не спорю, что можно. я бы послушал про конкретные кейсы: какая лаба, какая позиция и т.п. просто самого интересует эта тема, но для пхд уже староват)","*рекурсивные читай ""частично-рекурсивные"""
,,,а он не на ресерч позицию устроился а на инженерную
,,а он не на ресерч позицию устроился а на инженерную,Он был именно что ресерч инженером
,,,"ну да. но как я понимаю, это больше про код писать чем про исследования. исследователькие там research scientist называются"
,,"ну да. но как я понимаю, это больше про код писать чем про исследования. исследователькие там research scientist называются","Да, но они точно так же должгы шарить за всё, что в статьях происходит. И в написании статей инженеры участвуют"
,,,(ну и хард скилы разумеется)
,,,"я думаю, если есть четкое понимание, чего хочется и какой ресерч, можно написать прямо людям в лабах, которые его делают, и поинтересоваться у них, что нужно"
,,"я думаю, если есть четкое понимание, чего хочется и какой ресерч, можно написать прямо людям в лабах, которые его делают, и поинтересоваться у них, что нужно","Да, пробовал, кроме совета подаваться через обычные каналы, ничего не посоветовали :D"
,"я думаю, если есть четкое понимание, чего хочется и какой ресерч, можно написать прямо людям в лабах, которые его делают, и поинтересоваться у них, что нужно","Да, пробовал, кроме совета подаваться через обычные каналы, ничего не посоветовали :D",через обычные — через PhD всмысле?)
,,,"лично мне видится, что ресерч - это около ""дела жизни"", а не про, миль пардон, ""сексуальность карьеры"". 

вобщем надо не (просто) хотеть, а даже бухим (кому-то накуренным) лежать в направлении"
,,"лично мне видится, что ресерч - это около ""дела жизни"", а не про, миль пардон, ""сексуальность карьеры"". 

вобщем надо не (просто) хотеть, а даже бухим (кому-то накуренным) лежать в направлении","Да оно и понятно, что дело жизни. Сексуальность карьеры - совершенно иное, достичь её в мле достаточно просто(по крайней мере, сейчас) . Приколдес скорее в том, что, похоже, начать заниматься ресерчем в РФ сейчас сильно проще, чем за её пределами"
,"лично мне видится, что ресерч - это около ""дела жизни"", а не про, миль пардон, ""сексуальность карьеры"". 

вобщем надо не (просто) хотеть, а даже бухим (кому-то накуренным) лежать в направлении","Да оно и понятно, что дело жизни. Сексуальность карьеры - совершенно иное, достичь её в мле достаточно просто(по крайней мере, сейчас) . Приколдес скорее в том, что, похоже, начать заниматься ресерчем в РФ сейчас сильно проще, чем за её пределами","проще, но и качество ниже будет скорее всего"
"лично мне видится, что ресерч - это около ""дела жизни"", а не про, миль пардон, ""сексуальность карьеры"". 

вобщем надо не (просто) хотеть, а даже бухим (кому-то накуренным) лежать в направлении","Да оно и понятно, что дело жизни. Сексуальность карьеры - совершенно иное, достичь её в мле достаточно просто(по крайней мере, сейчас) . Приколдес скорее в том, что, похоже, начать заниматься ресерчем в РФ сейчас сильно проще, чем за её пределами","проще, но и качество ниже будет скорее всего",Базара зеро
,,,"Единственное — реалии таковы, что хорошим лабам приходят десятки+ писем в день от желающих ресерчить с ними. Если у тебя есть кто-то (преподаватель/научник/знакомый из лаборатории), кто мог бы тебя хорошо представить и при этом нет сложностей в начале работы с тобой (не требуется учебная/рабочая виза, тд) — то шансы на успех будут сильно выше.

И с твоей стороны должно быть четкое понимание, что ты хочешь делать и оно должно клеиться с тем, что уже делает группа.

Про дело жизни — не уверена, но в идеале это должен быть реальный интерес, иначе есть риск, что быстро сольешься"
,,"Единственное — реалии таковы, что хорошим лабам приходят десятки+ писем в день от желающих ресерчить с ними. Если у тебя есть кто-то (преподаватель/научник/знакомый из лаборатории), кто мог бы тебя хорошо представить и при этом нет сложностей в начале работы с тобой (не требуется учебная/рабочая виза, тд) — то шансы на успех будут сильно выше.

И с твоей стороны должно быть четкое понимание, что ты хочешь делать и оно должно клеиться с тем, что уже делает группа.

Про дело жизни — не уверена, но в идеале это должен быть реальный интерес, иначе есть риск, что быстро сольешься",Ты говоришь про университетские?
,"Единственное — реалии таковы, что хорошим лабам приходят десятки+ писем в день от желающих ресерчить с ними. Если у тебя есть кто-то (преподаватель/научник/знакомый из лаборатории), кто мог бы тебя хорошо представить и при этом нет сложностей в начале работы с тобой (не требуется учебная/рабочая виза, тд) — то шансы на успех будут сильно выше.

И с твоей стороны должно быть четкое понимание, что ты хочешь делать и оно должно клеиться с тем, что уже делает группа.

Про дело жизни — не уверена, но в идеале это должен быть реальный интерес, иначе есть риск, что быстро сольешься",Ты говоришь про университетские?,"В основном да.

Но к индустрии тоже применимо (речь про Европу по опыту себя и друзей) - там похоже и проще нанять местного пхд-студента задешево"
,,,Привет! А какие SOTA англоязычные или мультиязычные TTS на диффузионных моделях построены?
,,Привет! А какие SOTA англоязычные или мультиязычные TTS на диффузионных моделях построены?,У меня есть тоже белая кофта NASA)
,Привет! А какие SOTA англоязычные или мультиязычные TTS на диффузионных моделях построены?,У меня есть тоже белая кофта NASA),"О, жесть Егор.."
Привет! А какие SOTA англоязычные или мультиязычные TTS на диффузионных моделях построены?,У меня есть тоже белая кофта NASA),"О, жесть Егор..",rimworld становится интереснее )
,,,"Всем привет, подскажите плиз какие модели дают хорошие эмбеддинги для приближенного поиска документов в векторной базе. Документы на русском языке и побиты на куски, куски бывают довольно большие (до 1000 токенов).
Пробовал paraphrase-multilingual-mpnet-base-v2, вроде норм, но хочу узнать, может есть что-то лучше?"
,,"Всем привет, подскажите плиз какие модели дают хорошие эмбеддинги для приближенного поиска документов в векторной базе. Документы на русском языке и побиты на куски, куски бывают довольно большие (до 1000 токенов).
Пробовал paraphrase-multilingual-mpnet-base-v2, вроде норм, но хочу узнать, может есть что-то лучше?",Mmarco lm или e5 multilingual
,,,"Парни, а где будет ссылка на запись, когда/если будет? 😬 здесь ловить?"
,,"Парни, а где будет ссылка на запись, когда/если будет? 😬 здесь ловить?","Привет всем!
Подскажите, пожалуйста, какие есть инструменты для работы с записями видеорегистраторов? Нужно, чтобы инструмент позволял извлекать GPS координаты для каждого кадра"
,,,"Салют всем! 🏄‍♂
Кто сможет  подсказать нормальные языковые модели (doc. question answering, summarization, text2text), которые показывают себя хорошо в работе с мед. данными на русском языке, благодарю ¡"
,,"Салют всем! 🏄‍♂
Кто сможет  подсказать нормальные языковые модели (doc. question answering, summarization, text2text), которые показывают себя хорошо в работе с мед. данными на русском языке, благодарю ¡","Я сам не пробовал, но вот такое есть (в чате упоминались):
https://huggingface.co/DmitryPogrebnoy/MedRuRobertaLarge
https://huggingface.co/DmitryPogrebnoy/MedDistilBertBaseRuCased
https://huggingface.co/blanchefort/rubert-base-cased-sentiment-med
https://huggingface.co/anechaev/ru_med_gpt3sm_based_on_gpt2
https://huggingface.co/DmitryPogrebnoy/MedRuBertTiny2"
,,,"Кто-нибудь работал с поисковым движком Apache Solr? У меня 3 терабайта строк, по ним нужно делать поиск. В каком формате их удобнее хранить на диске и импортировать, и сколько места займет индекс?"
,,"Кто-нибудь работал с поисковым движком Apache Solr? У меня 3 терабайта строк, по ним нужно делать поиск. В каком формате их удобнее хранить на диске и импортировать, и сколько места займет индекс?","Bark?
Tam vnutri discord and github"
,,,"Ребят, недавно в телеграме
Как создаются в канале эти группы? Есть какой-то гайд или объясните как также создать?"
,,"Ребят, недавно в телеграме
Как создаются в канале эти группы? Есть какой-то гайд или объясните как также создать?",Галочка в настройках есть. У админов
,,,"Спасибо большое! Судя по описанию Bark, на cpu в realtime пока не умеет."
,,,"А есть ли готовые подходы, решения, инструменты по простановке ударений в словоформах? Понятно, что есть к примеру wiktionary, интересен подход для случаев, где ударение зависит от контекста."
,,"А есть ли готовые подходы, решения, инструменты по простановке ударений в словоформах? Понятно, что есть к примеру wiktionary, интересен подход для случаев, где ударение зависит от контекста.","Есть: https://github.com/MashaPo/russtress, но оно плохо работает. Я сейчас работаю в этом направлении, но высокого качества тоже ждать не стоит"
,,,"Всем здравствуйте! Интересует какими терминалам/инструментами пользуетесь для торговли на биржах. Quik, tslab, tiger, может кто-то сам реализовывал протоколы подключений. Как запускали алгоритмы, в целом может кто-то хочет поделиться своим стеком 😊?"
,,"Всем здравствуйте! Интересует какими терминалам/инструментами пользуетесь для торговли на биржах. Quik, tslab, tiger, может кто-то сам реализовывал протоколы подключений. Как запускали алгоритмы, в целом может кто-то хочет поделиться своим стеком 😊?","ninjatrader + matlab + python через webapi. 
вся та же связка, но с исходным фреймворком на tws api
экспериментировал с stocksharp, но от них отказался
Tws api сделали версию своего продукта на python, я ее пробовал, но довести ее нормального использования не получилось. Возможно на ней использование моделей можно сделать без web api"
,"Всем здравствуйте! Интересует какими терминалам/инструментами пользуетесь для торговли на биржах. Quik, tslab, tiger, может кто-то сам реализовывал протоколы подключений. Как запускали алгоритмы, в целом может кто-то хочет поделиться своим стеком 😊?","ninjatrader + matlab + python через webapi. 
вся та же связка, но с исходным фреймворком на tws api
экспериментировал с stocksharp, но от них отказался
Tws api сделали версию своего продукта на python, я ее пробовал, но довести ее нормального использования не получилось. Возможно на ней использование моделей можно сделать без web api","Мы по юзерам браузера,  просто ""неделю назад"" за каждые 5 мин,  брали данные и аппроксимировали их на ""уже прошедшее сегодня"", но у нас задача была простая очень да и точность не особо нужна была."
,,,"Всем привет. Есть тут классные дата аналитики? Есть датасет с тюленями для задачи Image Classification. Максимальный F1 вышел примерно 0.6. Может кто подсказать что можно сделать с картинкой, чтобы тюлени явно выделялись(как лучше подать в нейронку). Сэмпл из датасета ниже(тюлени около берега). В модель идёт разрешение 215 на 215. На входе в модель картинка на половину обрезается, чтобы не было видно чаек(они на других картинках есть)"
,,"Всем привет. Есть тут классные дата аналитики? Есть датасет с тюленями для задачи Image Classification. Максимальный F1 вышел примерно 0.6. Может кто подсказать что можно сделать с картинкой, чтобы тюлени явно выделялись(как лучше подать в нейронку). Сэмпл из датасета ниже(тюлени около берега). В модель идёт разрешение 215 на 215. На входе в модель картинка на половину обрезается, чтобы не было видно чаек(они на других картинках есть)","Соревнование на схожую тему, кажется 
https://www.kaggle.com/competitions/noaa-fisheries-steller-sea-lion-population-count"
,"Всем привет. Есть тут классные дата аналитики? Есть датасет с тюленями для задачи Image Classification. Максимальный F1 вышел примерно 0.6. Может кто подсказать что можно сделать с картинкой, чтобы тюлени явно выделялись(как лучше подать в нейронку). Сэмпл из датасета ниже(тюлени около берега). В модель идёт разрешение 215 на 215. На входе в модель картинка на половину обрезается, чтобы не было видно чаек(они на других картинках есть)","Соревнование на схожую тему, кажется 
https://www.kaggle.com/competitions/noaa-fisheries-steller-sea-lion-population-count","Забыл сказать, тема схожая, но эта задача binary classification и вид тюленей другой (цвета сильно различаются)"
"Всем привет. Есть тут классные дата аналитики? Есть датасет с тюленями для задачи Image Classification. Максимальный F1 вышел примерно 0.6. Может кто подсказать что можно сделать с картинкой, чтобы тюлени явно выделялись(как лучше подать в нейронку). Сэмпл из датасета ниже(тюлени около берега). В модель идёт разрешение 215 на 215. На входе в модель картинка на половину обрезается, чтобы не было видно чаек(они на других картинках есть)","Соревнование на схожую тему, кажется 
https://www.kaggle.com/competitions/noaa-fisheries-steller-sea-lion-population-count","Забыл сказать, тема схожая, но эта задача binary classification и вид тюленей другой (цвета сильно различаются)","другой вид тюленей...))

Базу эмбеддингов dinov2 шаблонов другого вида тюленей сделайте и косинусом до нее от текущего (без патчей). Тресхолд, понятно, подберете."
,,,А на этой картинке вообще есть тюлени?)
,,А на этой картинке вообще есть тюлени?),В этом то вся и проблема
,А на этой картинке вообще есть тюлени?),В этом то вся и проблема,"В модель подаешь куски этого семпла? Просто в твоем случае надо как будто разбить семпл на мелкие куски и их подавать. Причём аугументацию с зумом надо делать очень хитро. Я бы взял некие верхние и нижние границы зума, а так же поизучал датасет, всегда ли они рядом с водой и кучкой лежат. Если да, то это сохранил бы в аугументированных картинках"
,,,Слева на берегу лежат:))
,,Слева на берегу лежат:)),"Привет, подскажите пожалуйста, что стоит еще посмотреть или почитать после cs321n от стэнфорда?"
,Слева на берегу лежат:)),"Привет, подскажите пожалуйста, что стоит еще посмотреть или почитать после cs321n от стэнфорда?","Попробуйте dinov2, и целиком, и на патчах"
,,,"Всем привет ✋🏽. Вопрос по задачке Doc Classification. Сейчас у нас для классификации, скажем 7-12 классов (договора, акты, инвойсы и др.), используется Tf-IDf+RF+Regex. Порекомендуйте пож. более продвинутые методы хорошо работающие на реальных данных (шумы,  ошибки OCR)? Кол-во классов вероятно в скором времени будет ~100 и некоторые классы будут сильно коррелировать между собой.. Буду примного благодарен)"
,,"Всем привет ✋🏽. Вопрос по задачке Doc Classification. Сейчас у нас для классификации, скажем 7-12 классов (договора, акты, инвойсы и др.), используется Tf-IDf+RF+Regex. Порекомендуйте пож. более продвинутые методы хорошо работающие на реальных данных (шумы,  ошибки OCR)? Кол-во классов вероятно в скором времени будет ~100 и некоторые классы будут сильно коррелировать между собой.. Буду примного благодарен)","https://github.com/shabie/docformer если получится адекватный результат получить, отпишись, пжл))"
,"Всем привет ✋🏽. Вопрос по задачке Doc Classification. Сейчас у нас для классификации, скажем 7-12 классов (договора, акты, инвойсы и др.), используется Tf-IDf+RF+Regex. Порекомендуйте пож. более продвинутые методы хорошо работающие на реальных данных (шумы,  ошибки OCR)? Кол-во классов вероятно в скором времени будет ~100 и некоторые классы будут сильно коррелировать между собой.. Буду примного благодарен)","https://github.com/shabie/docformer если получится адекватный результат получить, отпишись, пжл))","ну раз пошла такая пьянка...))
https://github.com/deepdoctection/deepdoctection"
"Всем привет ✋🏽. Вопрос по задачке Doc Classification. Сейчас у нас для классификации, скажем 7-12 классов (договора, акты, инвойсы и др.), используется Tf-IDf+RF+Regex. Порекомендуйте пож. более продвинутые методы хорошо работающие на реальных данных (шумы,  ошибки OCR)? Кол-во классов вероятно в скором времени будет ~100 и некоторые классы будут сильно коррелировать между собой.. Буду примного благодарен)","https://github.com/shabie/docformer если получится адекватный результат получить, отпишись, пжл))","ну раз пошла такая пьянка...))
https://github.com/deepdoctection/deepdoctection",они чисто на визуале классифицируют же вроде. Есть еще https://github.com/PaddlePaddle/VIMER/tree/main/StrucTexT/v2 и у алибабы аналогичные подходы
"https://github.com/shabie/docformer если получится адекватный результат получить, отпишись, пжл))","ну раз пошла такая пьянка...))
https://github.com/deepdoctection/deepdoctection",они чисто на визуале классифицируют же вроде. Есть еще https://github.com/PaddlePaddle/VIMER/tree/main/StrucTexT/v2 и у алибабы аналогичные подходы,"Не, в текст проваливаются. Вроде тессерактом. Для документов он должен больмень работать"
,,,может будет полезно
,,,А как вообще вкатиться в DE из DS?
,,А как вообще вкатиться в DE из DS?,"1) работу с БД подтянуть мощно, научиться жсоны туда сюда складывать из базы и обратно, преобразовывать скриптами и так далее
2) почитать про проектирование хранилищ, нормализацию данных, чисто чтобы в грязь лицом на собесе не ударить
3) хотя бы потыкать airflow и spark, понимать основные концепции
4) вообще в целом чутка почитать про распределенные вычисления"
,А как вообще вкатиться в DE из DS?,"1) работу с БД подтянуть мощно, научиться жсоны туда сюда складывать из базы и обратно, преобразовывать скриптами и так далее
2) почитать про проектирование хранилищ, нормализацию данных, чисто чтобы в грязь лицом на собесе не ударить
3) хотя бы потыкать airflow и spark, понимать основные концепции
4) вообще в целом чутка почитать про распределенные вычисления","1)Ну а с чем? SQL?
3) Просто кажется что их тяжело потыкать на практике вне конторы потому что там же нужны шарды мощности и прочее"
,,,Если до этого ты чисто в ноутбуках чисто рисерчил чето учил
,,Если до этого ты чисто в ноутбуках чисто рисерчил чето учил,"ходишь на собеседования на DE, устраиваешься"
,Если до этого ты чисто в ноутбуках чисто рисерчил чето учил,"ходишь на собеседования на DE, устраиваешься","учишь петухон немножко получше чем требуется для ноутбуков и SQL

Плюс пару инструментов: Airfloiw + MPP (клик или гп)

Изи джун 200к"
,,,^полистать книгу с кабанчиком и потом ходить умничать
,,^полистать книгу с кабанчиком и потом ходить умничать,это на мидла
,,,С опытом DS нет смысла идти на джуна DE в общем-то
,,С опытом DS нет смысла идти на джуна DE в общем-то,?)
,,,По крайней мере попробовать можно
,,По крайней мере попробовать можно,"ну в смысле да, можно не на джуна, возможно
ну потыкать это именно потыкать, развернуть у себя и хоть простенькие джобы позапускать
spark поднять можно вполне, airflow тоже и настроить на них обработку данных
например сделай фичинжиниринг под какой-нибудь катбуст хоть раз на спарке

распределенные системы уже скорее самому не потыкаешь
а про первое да нет, не обязательно
например задачка с собеса - написать на питоне скрипт который перекладывает csv заданной структуры в postgres
причем желательно быстро, без считывания в память целиком и все вот это
ну и SQL да, база же"
,,,Перенёс
,,,А нейронки в DE нужны?
,,А нейронки в DE нужны?,кому?
,,,"Они против pandas, потому что хотят версионирования в git. И проще им писать без pandas, который хранит внутри магию. Я так понял. Но тогда, если им нужно версионирование, то могут юзать DVC."
,,"Они против pandas, потому что хотят версионирования в git. И проще им писать без pandas, который хранит внутри магию. Я так понял. Но тогда, если им нужно версионирование, то могут юзать DVC.",Причем тут pandas и версинионирование в git? Код написанный в pandas нельзя загрузить на git?
,"Они против pandas, потому что хотят версионирования в git. И проще им писать без pandas, который хранит внутри магию. Я так понял. Но тогда, если им нужно версионирование, то могут юзать DVC.",Причем тут pandas и версинионирование в git? Код написанный в pandas нельзя загрузить на git?,Спрашивайте у Насти и Сбер поддержка
,,,"Так а в чём проблема версионирования в гите с пандасом? 😢
Ну хорошо, может, пандас иногда убирают методы типа .append, но поларс-то гетеросексуальные разрабы пишут, там такого пока не было"
,,"Так а в чём проблема версионирования в гите с пандасом? 😢
Ну хорошо, может, пандас иногда убирают методы типа .append, но поларс-то гетеросексуальные разрабы пишут, там такого пока не было","Тут скорее вопрос в том, что человек умел не только pandas, но опыт MLOps для продакшна. То есть pandas ноутбук будет для research, а для прода будет REST API сервис. Мне так кажется."
,,,"Могу предположить по опыту, что из гита куда-то это клонится и запускается через условный papermill на ограниченных ресурсах, поэтому и без pandas, который жрёт кучу памяти
Вот pandas on spark - годная тема — почему ещё не упомянули непонятно"
,,"Могу предположить по опыту, что из гита куда-то это клонится и запускается через условный papermill на ограниченных ресурсах, поэтому и без pandas, который жрёт кучу памяти
Вот pandas on spark - годная тема — почему ещё не упомянули непонятно",Это к ней вопрос и был
,"Могу предположить по опыту, что из гита куда-то это клонится и запускается через условный papermill на ограниченных ресурсах, поэтому и без pandas, который жрёт кучу памяти
Вот pandas on spark - годная тема — почему ещё не упомянули непонятно",Это к ней вопрос и был,"вообще пересечений нет, если только DE не является еще и MLOps заодно"
,,,"nopandas в вакансии означает ""со своими skillbox-курсами идите лесом, мы делаем все по взрослому"""
,,"nopandas в вакансии означает ""со своими skillbox-курсами идите лесом, мы делаем все по взрослому""","Тоже не понятно,отдельно по pandas есть курсы?"
,"nopandas в вакансии означает ""со своими skillbox-курсами идите лесом, мы делаем все по взрослому""","Тоже не понятно,отдельно по pandas есть курсы?",На kaggle?
,,,"всем привет!
подскажите, пожалуйста, есть ли open source модели, которые хорошо генерируют вопросы по тексту?

например,  текст: ""Пицца - традиционное итальянское блюдо, изначально в виде круглой дрожжевой лепёшки, выпекаемой с уложенной сверху начинкой из томатного соуса, сыра и зачастую других ингредиентов, таких как мясо, овощи, грибы и прочие продукты."", хотелось бы получить вопрос ""Что такое пицца?"""
,,"всем привет!
подскажите, пожалуйста, есть ли open source модели, которые хорошо генерируют вопросы по тексту?

например,  текст: ""Пицца - традиционное итальянское блюдо, изначально в виде круглой дрожжевой лепёшки, выпекаемой с уложенной сверху начинкой из томатного соуса, сыра и зачастую других ингредиентов, таких как мясо, овощи, грибы и прочие продукты."", хотелось бы получить вопрос ""Что такое пицца?""",https://huggingface.co/doc2query/msmarco-russian-mt5-base-v1
,,,вы можете взять датасет типа sberquad и дообучить любую понравившуюся модель на текстах и вопросах от туда.
,,вы можете взять датасет типа sberquad и дообучить любую понравившуюся модель на текстах и вопросах от туда.,Взять любую open source llm и на вход подавать текст + запрос «сгенерируй вопросы по тексту» не вариант?
,вы можете взять датасет типа sberquad и дообучить любую понравившуюся модель на текстах и вопросах от туда.,Взять любую open source llm и на вход подавать текст + запрос «сгенерируй вопросы по тексту» не вариант?,спасибо
вы можете взять датасет типа sberquad и дообучить любую понравившуюся модель на текстах и вопросах от туда.,Взять любую open source llm и на вход подавать текст + запрос «сгенерируй вопросы по тексту» не вариант?,спасибо,"Вариант, нормально генерит вопросы stable beluga 2 например. Обычная не тюненая llama2 часто пишет то на русском то на аглийском. Лучше брать тюненую и подбирать на своём тексте где лучше будет генерировать вопросы"
Взять любую open source llm и на вход подавать текст + запрос «сгенерируй вопросы по тексту» не вариант?,спасибо,"Вариант, нормально генерит вопросы stable beluga 2 например. Обычная не тюненая llama2 часто пишет то на русском то на аглийском. Лучше брать тюненую и подбирать на своём тексте где лучше будет генерировать вопросы","топ, спасибо)"
спасибо,"Вариант, нормально генерит вопросы stable beluga 2 например. Обычная не тюненая llama2 часто пишет то на русском то на аглийском. Лучше брать тюненую и подбирать на своём тексте где лучше будет генерировать вопросы","топ, спасибо)",Или изобретение велосипедов
"Вариант, нормально генерит вопросы stable beluga 2 например. Обычная не тюненая llama2 часто пишет то на русском то на аглийском. Лучше брать тюненую и подбирать на своём тексте где лучше будет генерировать вопросы","топ, спасибо)",Или изобретение велосипедов,"Подскажите пж, правильно ли я понимаю, что 
1) - показывает вероятность того что как минимум (r) конкретных гостей взяли свою куртку, а
2) - показывает вероятность того что как минимум r гостей взяли свою куртку?"
"топ, спасибо)",Или изобретение велосипедов,"Подскажите пж, правильно ли я понимаю, что 
1) - показывает вероятность того что как минимум (r) конкретных гостей взяли свою куртку, а
2) - показывает вероятность того что как минимум r гостей взяли свою куртку?","Можно сначала удалить пакеты, потом заново установить"
Или изобретение велосипедов,"Подскажите пж, правильно ли я понимаю, что 
1) - показывает вероятность того что как минимум (r) конкретных гостей взяли свою куртку, а
2) - показывает вероятность того что как минимум r гостей взяли свою куртку?","Можно сначала удалить пакеты, потом заново установить",А там есть что курсить?
,,,"Я подобную задачу решал как NER, дообучая BERTForTokenClassification на самостоятельно размеченных текстах (приемлемое качество пошло где-то с сотни примеров).

Если хочется вообще без разметки, можно попробовать чей-нибудь BERTForQuestionAnswering запустить, подавая на вход вопрос типа «какой диагноз был поставлен?» и диалог, к которому задается вопрос, чтобы модель выделила нужную часть диалога.

Генеративные модели я бы поостерегся в такой чувствительной задаче использовать, ибо фантазия у них уж больно буйная."
,,"Я подобную задачу решал как NER, дообучая BERTForTokenClassification на самостоятельно размеченных текстах (приемлемое качество пошло где-то с сотни примеров).

Если хочется вообще без разметки, можно попробовать чей-нибудь BERTForQuestionAnswering запустить, подавая на вход вопрос типа «какой диагноз был поставлен?» и диалог, к которому задается вопрос, чтобы модель выделила нужную часть диалога.

Генеративные модели я бы поостерегся в такой чувствительной задаче использовать, ибо фантазия у них уж больно буйная.","Интересно 🤔
А классифицировать предложения не пробовали?"
,"Я подобную задачу решал как NER, дообучая BERTForTokenClassification на самостоятельно размеченных текстах (приемлемое качество пошло где-то с сотни примеров).

Если хочется вообще без разметки, можно попробовать чей-нибудь BERTForQuestionAnswering запустить, подавая на вход вопрос типа «какой диагноз был поставлен?» и диалог, к которому задается вопрос, чтобы модель выделила нужную часть диалога.

Генеративные модели я бы поостерегся в такой чувствительной задаче использовать, ибо фантазия у них уж больно буйная.","Интересно 🤔
А классифицировать предложения не пробовали?","В моем случае это были названия симптомов, диагноза и медикаментов – отдельные слова или словосочетания."
"Я подобную задачу решал как NER, дообучая BERTForTokenClassification на самостоятельно размеченных текстах (приемлемое качество пошло где-то с сотни примеров).

Если хочется вообще без разметки, можно попробовать чей-нибудь BERTForQuestionAnswering запустить, подавая на вход вопрос типа «какой диагноз был поставлен?» и диалог, к которому задается вопрос, чтобы модель выделила нужную часть диалога.

Генеративные модели я бы поостерегся в такой чувствительной задаче использовать, ибо фантазия у них уж больно буйная.","Интересно 🤔
А классифицировать предложения не пробовали?","В моем случае это были названия симптомов, диагноза и медикаментов – отдельные слова или словосочетания.","Но если у меня встречается диагноз, который озвучил пациент, но он таковым не является, тогда модель неправильно будет срабатывает в этих случаях?"
"Интересно 🤔
А классифицировать предложения не пробовали?","В моем случае это были названия симптомов, диагноза и медикаментов – отдельные слова или словосочетания.","Но если у меня встречается диагноз, который озвучил пациент, но он таковым не является, тогда модель неправильно будет срабатывает в этих случаях?","Если вам понятно, какие фразы принадлежат каждому из участников разговора, то ищите диагноз только во фразах врача, а симптомы - в словах пациента."
"В моем случае это были названия симптомов, диагноза и медикаментов – отдельные слова или словосочетания.","Но если у меня встречается диагноз, который озвучил пациент, но он таковым не является, тогда модель неправильно будет срабатывает в этих случаях?","Если вам понятно, какие фразы принадлежат каждому из участников разговора, то ищите диагноз только во фразах врача, а симптомы - в словах пациента.","Спасибо, идея интересная, но будут проблемы с реализацией, так как распределение ролей в диалоге пока не супер качественное, но в любом случае спасибо"
,,,"Полагаю, если в обучающей выборке будет достаточно таких примеров, правильно размеченных, модель может научиться их различать. 
(Но у меня самого подобного опыта не было, потому что я извлекал все это не из диалогов)"
,,"Полагаю, если в обучающей выборке будет достаточно таких примеров, правильно размеченных, модель может научиться их различать. 
(Но у меня самого подобного опыта не было, потому что я извлекал все это не из диалогов)","Хорошо, попробую этот вариант, а дальше уже буду смотреть стоит ли  дообучать. Спасибо большое 🙃"
,,,а причем здесь градкам? Запихиваете веса одной модели в объект другой
,,а причем здесь градкам? Запихиваете веса одной модели в объект другой,"Да, увидел уже, спасибо"
,,,"насколько помню efficientDet - это детектор, и для него gradcam работать не будет.

EfficientNet (классификатор) в pytorch hub есть, пошурудите в доках последнего"
,,"насколько помню efficientDet - это детектор, и для него gradcam работать не будет.

EfficientNet (классификатор) в pytorch hub есть, пошурудите в доках последнего",Тогда мне интересно чем отличается DE от MLOPSa?
,"насколько помню efficientDet - это детектор, и для него gradcam работать не будет.

EfficientNet (классификатор) в pytorch hub есть, пошурудите в доках последнего",Тогда мне интересно чем отличается DE от MLOPSa?,"всем привет, есть возможность в tsfresh функцию extract_features() в качестве набора признаков которые я хочу посчитать передавать не вложенные словари, а набор строк такого вида: '0__index_mass_quantile__q_0.1' ?"
,,,"Всем привет. Я не особо разбираюсь в GAN'ax, задачка такая: есть изображение (например, предмета одежды), нужно исправить дефекты, изменить форму и т.п., но при этом сохранить отличительные черты (например, надпись). Начал вникать в pix2pix, но у них ведь будут проблемы с изменением формы. Если будут идеи, а еще лучше ссылки - буду очень благодарен"
,,"Всем привет. Я не особо разбираюсь в GAN'ax, задачка такая: есть изображение (например, предмета одежды), нужно исправить дефекты, изменить форму и т.п., но при этом сохранить отличительные черты (например, надпись). Начал вникать в pix2pix, но у них ведь будут проблемы с изменением формы. Если будут идеи, а еще лучше ссылки - буду очень благодарен","посмотри GPFGAN. он конечно решает другую задачу, но по смыслу тебе подходит. там модель состоит из двух частей - первая генерит латентные вектора, вторая из них генерит картинку. можно написать свою архитектуру, а можно использовать их, но поправив код в месте генерации данных. 
причем можно сначала просто натренить GAN, а потом, заморозив его, тренить всю сетку."
,,,Как пример:
,,,"Спасибо, интересный пример. Вот только там на входе описание, а я получаю на входе только изображение. Ну может идеи получится оттуда взять"
,,"Спасибо, интересный пример. Вот только там на входе описание, а я получаю на входе только изображение. Ну может идеи получится оттуда взять","Там на вход идет картинка + описание. А задача подразумевает, что есть ограниченный и заранее определенный пул дефектов, которые нужно исправить? Просто как модель должна понять, что от нее хотят?"
,,,"Дефекты не факт что ограничены, но хотя бы чтобы некоторый набор типичных дефектов исправлялся, они могут быть в обучающей выборке"
,,"Дефекты не факт что ограничены, но хотя бы чтобы некоторый набор типичных дефектов исправлялся, они могут быть в обучающей выборке","изначально там решается задача энхансмента фотографий, но я решал другие задачи. некоторые успешно :)"
,,,"Спасибо, кажется это должно помочь"
,,"Спасибо, кажется это должно помочь","Расскажи потом, что получилось. По возможности конечно :)"
,"Спасибо, кажется это должно помочь","Расскажи потом, что получилось. По возможности конечно :)",Обязательно)
,,,"Всем привет 
Никто случайно не знает норм дешевого VPC-провайдера в Азии? Для аренды нескольких серверов на континенте, не принципиально важно в какой стране"
,,,"кода прилично. Баги могут быть много где. Как минимум 
а) в препроцессинге, особенно centercrop,
б) в том что у класса посередине, который без B4, у него какой-то слой есть, который вполне возможно нигде не инициализирован или не обучен"
,,"кода прилично. Баги могут быть много где. Как минимум 
а) в препроцессинге, особенно centercrop,
б) в том что у класса посередине, который без B4, у него какой-то слой есть, который вполне возможно нигде не инициализирован или не обучен","Понял, спасибо"
,,,"Коллеги, подскажите, насколько критично знание с++ для работы в сфере CV? Занимаюсь классическим дс, но хотел бы перекатиться, часто замечаю плюсы в вакансиях, появились сомнения"
,,"Коллеги, подскажите, насколько критично знание с++ для работы в сфере CV? Занимаюсь классическим дс, но хотел бы перекатиться, часто замечаю плюсы в вакансиях, появились сомнения",Не критично в общем случае. Очень полезно для общего понимания много чего.
,,,"C++ нужен не весь Страуструп. Достаточно того что есть в pytorch и opencv, а это наверное процентов 50 тех сложностей что есть в плюсах"
,,"C++ нужен не весь Страуструп. Достаточно того что есть в pytorch и opencv, а это наверное процентов 50 тех сложностей что есть в плюсах","Ну, в edge cv побольше и плюсов и других ( rust, go)"
,,,"Получается, что знание плюсов все же очень желательно. Хотя бы чтобы понимать, как написаны питоновские библы для cv？"
,,"Получается, что знание плюсов все же очень желательно. Хотя бы чтобы понимать, как написаны питоновские библы для cv？","да, желательно, потому что cv обычно рядом с производительным инференсом"
,,,"нет, не библы... треды в первую очередь, POSIX InterProcessCommunication... 

Ну и микроменеджмент памяти + перфоманс"
,,"нет, не библы... треды в первую очередь, POSIX InterProcessCommunication... 

Ну и микроменеджмент памяти + перфоманс","микроменеджмент не столь необходимость, сколько и необходимость и само следствие плюсов. Свой мир так скажем"
,,,"никакого ракетного знания не требуется, но минимальное рабочеее понимание очень ценно"
,,"никакого ракетного знания не требуется, но минимальное рабочеее понимание очень ценно","Понял, спасибо всем за ответы!"
,"никакого ракетного знания не требуется, но минимальное рабочеее понимание очень ценно","Понял, спасибо всем за ответы!","Сфера компьютерного зрения очень разнообразна
Знания языка помогает, например, залезть глубоко в исходники, если это необходимо
Верно говорили выше, что если это связано со встраиваемыми системами или встаёт вопрос производительности, то, конечно, знания С++ вам могут сильно пригодиться
В большинстве своём вы будете делать модельки на питоне, так что сильно переживать по этому поводу я бы не стал"
"никакого ракетного знания не требуется, но минимальное рабочеее понимание очень ценно","Понял, спасибо всем за ответы!","Сфера компьютерного зрения очень разнообразна
Знания языка помогает, например, залезть глубоко в исходники, если это необходимо
Верно говорили выше, что если это связано со встраиваемыми системами или встаёт вопрос производительности, то, конечно, знания С++ вам могут сильно пригодиться
В большинстве своём вы будете делать модельки на питоне, так что сильно переживать по этому поводу я бы не стал",да. Плюсы это больше про инференс
,,,"Всем, привет!👋
Стоит задача на основе реальных переписок(их 14 500) администратора и клиентов, научить модель вести диалог с клиентом(при помощи чат-бота). Так что бы он при общении с клиентами давал максимально близкие ответы к тем, которые давал бы администратор. Если кто то сталкивался с подобной задачей или знает какую модель лучше использовать подскажите как лучше сделать)
Буду очень признателен за любую идею, а то если честно уже не знаю как подступиться(
Всем заранее большое спасибо!"
,,"Всем, привет!👋
Стоит задача на основе реальных переписок(их 14 500) администратора и клиентов, научить модель вести диалог с клиентом(при помощи чат-бота). Так что бы он при общении с клиентами давал максимально близкие ответы к тем, которые давал бы администратор. Если кто то сталкивался с подобной задачей или знает какую модель лучше использовать подскажите как лучше сделать)
Буду очень признателен за любую идею, а то если честно уже не знаю как подступиться(
Всем заранее большое спасибо!",Я бы посмотрел просто мой доклад
,"Всем, привет!👋
Стоит задача на основе реальных переписок(их 14 500) администратора и клиентов, научить модель вести диалог с клиентом(при помощи чат-бота). Так что бы он при общении с клиентами давал максимально близкие ответы к тем, которые давал бы администратор. Если кто то сталкивался с подобной задачей или знает какую модель лучше использовать подскажите как лучше сделать)
Буду очень признателен за любую идею, а то если честно уже не знаю как подступиться(
Всем заранее большое спасибо!",Я бы посмотрел просто мой доклад,"Привет! Я бы посмотрел, а можно ссылку?)"
"Всем, привет!👋
Стоит задача на основе реальных переписок(их 14 500) администратора и клиентов, научить модель вести диалог с клиентом(при помощи чат-бота). Так что бы он при общении с клиентами давал максимально близкие ответы к тем, которые давал бы администратор. Если кто то сталкивался с подобной задачей или знает какую модель лучше использовать подскажите как лучше сделать)
Буду очень признателен за любую идею, а то если честно уже не знаю как подступиться(
Всем заранее большое спасибо!",Я бы посмотрел просто мой доклад,"Привет! Я бы посмотрел, а можно ссылку?)",https://youtu.be/eoo5Kom7FXE
Я бы посмотрел просто мой доклад,"Привет! Я бы посмотрел, а можно ссылку?)",https://youtu.be/eoo5Kom7FXE,не исчерпывающее видео
"Привет! Я бы посмотрел, а можно ссылку?)",https://youtu.be/eoo5Kom7FXE,не исчерпывающее видео,Что ещё не хватило? Отсыплю еще
https://youtu.be/eoo5Kom7FXE,не исчерпывающее видео,Что ещё не хватило? Отсыплю еще,Конкретно по вопросу Сергея. Модели бы хорошо ещё уметь задавать наводящие или уточняющие вопросы
не исчерпывающее видео,Что ещё не хватило? Отсыплю еще,Конкретно по вопросу Сергея. Модели бы хорошо ещё уметь задавать наводящие или уточняющие вопросы,"Это вопрос логики, какую ты реализуешь"
Что ещё не хватило? Отсыплю еще,Конкретно по вопросу Сергея. Модели бы хорошо ещё уметь задавать наводящие или уточняющие вопросы,"Это вопрос логики, какую ты реализуешь",так можно было ответить и на вопрос Сергея)
,,,"👋🏼👋🏼
Подскажите плиз у меня есть модель которая запускается через torchrun и он дает создает окружение для запуска модели, которая требует сразу два GPU. Как для такой модели написать api? Запуск сервера с torchrun не дает модели работать (возможно один из процессов блочится из за сокетов). Кто работал с таким? Заранее спасибо’"
,,"👋🏼👋🏼
Подскажите плиз у меня есть модель которая запускается через torchrun и он дает создает окружение для запуска модели, которая требует сразу два GPU. Как для такой модели написать api? Запуск сервера с torchrun не дает модели работать (возможно один из процессов блочится из за сокетов). Кто работал с таким? Заранее спасибо’","Раз есть диалоги, обратил внимание на наш подход"
,,,Можно конечно попытаться GPT тюн
,,Можно конечно попытаться GPT тюн,"Я попробовал, но вместо чёткого ответа на мой вопрос, выдает ответ и тут же  еще один ответ и вопрос и все это не очень связано между собой."
,Можно конечно попытаться GPT тюн,"Я попробовал, но вместо чёткого ответа на мой вопрос, выдает ответ и тут же  еще один ответ и вопрос и все это не очень связано между собой.",Ожидаемо)
,,,А можно подробней про оформление ответов в базу FAQ?
,,А можно подробней про оформление ответов в базу FAQ?,В видео как раз есть об этом
,А можно подробней про оформление ответов в базу FAQ?,В видео как раз есть об этом,Спасибо
,,,".
Ребят, ищу репетитора для подготовки в ШАД по математической части. Был бы благодарен любым предложениям."
,,,Ищу репетитора для подготовки в ШАД по математической части. Буду рад любым предложениям 🤝
,,Ищу репетитора для подготовки в ШАД по математической части. Буду рад любым предложениям 🤝,300кк/наносек готов?)
,Ищу репетитора для подготовки в ШАД по математической части. Буду рад любым предложениям 🤝,300кк/наносек готов?),Если в тенге то го
,,,Ищу репетитора для подготовки в ШАД. Буду рад любым предложениям
,,,Ищу репетитора для подготовки в ШАД. Буду рад любым предложениям.
,,Ищу репетитора для подготовки в ШАД. Буду рад любым предложениям.,"предлагаю заботать самому, очень мощным станешь"
,Ищу репетитора для подготовки в ШАД. Буду рад любым предложениям.,"предлагаю заботать самому, очень мощным станешь","ваша правда, но думаю попробовать с репетитором, может лучше получится. Не хотелось бы рисковать не поступить"
,,,🥴
,,🥴,Побываешь в Яндекс и тп поймёшь
,,,"А ты смотрел хоть? Слушал внимательно?
Если бы слушал - такой реакции на было бы"
,,,Это сетки сверху ОДНОЙ модельки
,,Это сетки сверху ОДНОЙ модельки,"я сразу и хотел спросить, почему не multi task)"
,,,Считай К голов
,,,это ты дальше рассказываешь
,,это ты дальше рассказываешь,"Потому, что далее смотреть)"
,,,"кажется что здесь ты вряд-ли найдешь, попробуй поискать консультации по каждой дисциплине отдельно при этом начав ""ботать"" эту тему самостоятельно
хотя мож тебе и повезет, найдешь прям репетитора репетитора"
,,"кажется что здесь ты вряд-ли найдешь, попробуй поискать консультации по каждой дисциплине отдельно при этом начав ""ботать"" эту тему самостоятельно
хотя мож тебе и повезет, найдешь прям репетитора репетитора","Спасибо за совет! Только начал поиски, на удивление люди отвечают, и даже советуют инфу полезную. Надеюсь все же найду репетитора"
,"кажется что здесь ты вряд-ли найдешь, попробуй поискать консультации по каждой дисциплине отдельно при этом начав ""ботать"" эту тему самостоятельно
хотя мож тебе и повезет, найдешь прям репетитора репетитора","Спасибо за совет! Только начал поиски, на удивление люди отвечают, и даже советуют инфу полезную. Надеюсь все же найду репетитора","Всем привет, есть здесь те, кто хочет поступить на магистратуру или учится на ней? 

Есть предложение по сотрудничеству с написанием статей для получения доп. баллов по конкурсу. Имеется опыт написания статей.

Есть также предложение совместно ботать материал по анализу данных и ML в небольшом комьюнити энтузиастов."
,,,"Есть у кого опыт Лоры для WizardCoder?

ну или куда смотреть? )"
,,"Есть у кого опыт Лоры для WizardCoder?

ну или куда смотреть? )",https://github.com/shibing624/CodeAssist/blob/main/codeassist/wizard_coder.py
,,,Хороший курс от одс по nlp?
,,Хороший курс от одс по nlp?,"ребят помогите пожалуйста
нужно купить подписку на колаб, как ее можно оплатить сейчас?"
,,,"Всем привет. Может кто посоветовать материалы для разработки NPC в играх с помощью Reinforcement Learning и т.д. Желательно курсы, но можно и учебники (язык не важен) Спасибо заранее"
,,"Всем привет. Может кто посоветовать материалы для разработки NPC в играх с помощью Reinforcement Learning и т.д. Желательно курсы, но можно и учебники (язык не важен) Спасибо заранее","Есть еще книга Саттон, Обучение с подкреплением. Сам не читал, знаю что знаковая, и знаю что не для начинающих"
,,,"на нашел ссылку на запись в чате, может кто поделится из добрых людей 🙏"
,,,"Ребят, а подскажите: есть ли коипарайтеры какие-нибудь (или это джуны?), которые могут помочь наполнить DS блог постами? (на англ) темы даже есть примерные

Как вообще к этому подступиться правильно?"
,,"Ребят, а подскажите: есть ли коипарайтеры какие-нибудь (или это джуны?), которые могут помочь наполнить DS блог постами? (на англ) темы даже есть примерные

Как вообще к этому подступиться правильно?",Parsing  medium + ChatGPT рерайт?
,,,"Ребят можете помочь, какие курсы посоветуете по ML?"
,,"Ребят можете помочь, какие курсы посоветуете по ML?",смотря какие предварительные знания и какие запросы/ожидания от курса (нужно больше конкретики)
,"Ребят можете помочь, какие курсы посоветуете по ML?",смотря какие предварительные знания и какие запросы/ожидания от курса (нужно больше конкретики),"Ожидания, научиться понимать какой алгоритм стоит использовать для определенной стратегии
И как в целом данные обрабатывать перед тем как засовывать в машинку"
"Ребят можете помочь, какие курсы посоветуете по ML?",смотря какие предварительные знания и какие запросы/ожидания от курса (нужно больше конкретики),"Ожидания, научиться понимать какой алгоритм стоит использовать для определенной стратегии
И как в целом данные обрабатывать перед тем как засовывать в машинку","ну про ""алгоритмы для определенной стратегии"" хз, у меня есть подозрение что открытых не булщитных курсов про мл в финансах нет, только если какие-то книжки/сборники статей. Если в целом про классический табличный мл с точки зрения сколько-нибудь прикладной теории, то людям с нормальной математической подготовкой я обычно советую курсы Воронцова или Соколова, там все есть. Но понимание, когда в практических задачах что юзать и что действительно хорошо работает/не работает в плане фича инжиниринга можно к сожалению почерпнуть только на практике (работа или каггл/любые другие контесты), я особо не видел открытых бесплатных курсов, в которых были бы какие-то похожие на боевые датасеты и задачи. Курсы это все ж больше про теорию + освоение какого-то базового практического инструментария и понимания что делать в основном нельзя, а что в основном можно"
смотря какие предварительные знания и какие запросы/ожидания от курса (нужно больше конкретики),"Ожидания, научиться понимать какой алгоритм стоит использовать для определенной стратегии
И как в целом данные обрабатывать перед тем как засовывать в машинку","ну про ""алгоритмы для определенной стратегии"" хз, у меня есть подозрение что открытых не булщитных курсов про мл в финансах нет, только если какие-то книжки/сборники статей. Если в целом про классический табличный мл с точки зрения сколько-нибудь прикладной теории, то людям с нормальной математической подготовкой я обычно советую курсы Воронцова или Соколова, там все есть. Но понимание, когда в практических задачах что юзать и что действительно хорошо работает/не работает в плане фича инжиниринга можно к сожалению почерпнуть только на практике (работа или каггл/любые другие контесты), я особо не видел открытых бесплатных курсов, в которых были бы какие-то похожие на боевые датасеты и задачи. Курсы это все ж больше про теорию + освоение какого-то базового практического инструментария и понимания что делать в основном нельзя, а что в основном можно","а, вспомнил, что-то похожее быть может это прикладной анализ данных дьяконова (на ютубе есть), у него оч своеобразный стиль изложения, но там как раз про все эти вещи которые традиционные курсы обычно игнорируют или упоминают вскользь"
"Ожидания, научиться понимать какой алгоритм стоит использовать для определенной стратегии
И как в целом данные обрабатывать перед тем как засовывать в машинку","ну про ""алгоритмы для определенной стратегии"" хз, у меня есть подозрение что открытых не булщитных курсов про мл в финансах нет, только если какие-то книжки/сборники статей. Если в целом про классический табличный мл с точки зрения сколько-нибудь прикладной теории, то людям с нормальной математической подготовкой я обычно советую курсы Воронцова или Соколова, там все есть. Но понимание, когда в практических задачах что юзать и что действительно хорошо работает/не работает в плане фича инжиниринга можно к сожалению почерпнуть только на практике (работа или каггл/любые другие контесты), я особо не видел открытых бесплатных курсов, в которых были бы какие-то похожие на боевые датасеты и задачи. Курсы это все ж больше про теорию + освоение какого-то базового практического инструментария и понимания что делать в основном нельзя, а что в основном можно","а, вспомнил, что-то похожее быть может это прикладной анализ данных дьяконова (на ютубе есть), у него оч своеобразный стиль изложения, но там как раз про все эти вещи которые традиционные курсы обычно игнорируют или упоминают вскользь","Понял, спасибо большое)"
,,,"Работаю стажером квантом в инвест фонде, знаю питончик (pandas, sklearn, matplotlib etc..) , sql, матанчик и немного статистики"
,,,"ну и в целом еще есть подозрение что ""для стратегий в инвест фонде"" стоит не мл курсы смотреть, а читать книжки по эконометрике и анализу временных рядов"
,,"ну и в целом еще есть подозрение что ""для стратегий в инвест фонде"" стоит не мл курсы смотреть, а читать книжки по эконометрике и анализу временных рядов","Можешь посоветовать книжечки, пожалуйста🥺"
,,,"Всем привет! Подскажите, пожалуйста, стоит ли добавлять в pipeline ocr сканов документов детекцию самого документа на фоне (обычно он белый, так как скан)? Или можно и так скармливать модельки сегментации? 
Вопрос возник по причине того, что  нужно делать ресайз скана для подачи в сегментацию, а там сам документ может лежать как угодно прозвольно и занимать разный масштаб от исходного фона."
,,,накидай вариантов
,,накидай вариантов,"Да самый простой если нужны уточнения, сделать Intent recognition. А там уже с ним работать на уровне rules"
,,,интересно
,,интересно,"Если хочется актов диалоговых, можно делать их тоже контекстными с аннотатором change topic/action+диалоговая моделька"
,интересно,"Если хочется актов диалоговых, можно делать их тоже контекстными с аннотатором change topic/action+диалоговая моделька","В каждой организации своё смысловое наполнение
У нас, например, есть отдельно Bi (de), а есть отдельно mlops
Первые занимаются:
1. ETL
2. Подключением разных баз данных к корпоративному хранилищу данных. В том числе подключают нереляционные базы
3. Сборкой объёмных и сложных витрин + написанием документации по ним и поддержанием SLA по ним
4. Проектированием инфологических схем для различных бизнес-сущностей
Mlops - немного другой вектор:
1. Помощь дата-сайентистам в выкатке моделей в продакшен
2. Поддержание работоспособности модели на протяжении всего её жизненного цикла, переобучение (для актуализации параметров), контроль работоспособности модели во времени
Вторые с точки зрения данных для моделек живут в основном на спарке, но это чисто наша корпоративная история
У первых ещё есть, как правило, проблема с качеством данных, не во всех компаниях есть фокус и проработанная политика по поддержанию качества данных
Первые, как правило, работают с широким спектром инструментов для создания бизнес-отчётности, в том числе olap-кубы, дашборды.
Что касается спарка, развёрнутого на хадупе, то его вместе с ETL поддерживает отдельная команда."
интересно,"Если хочется актов диалоговых, можно делать их тоже контекстными с аннотатором change topic/action+диалоговая моделька","В каждой организации своё смысловое наполнение
У нас, например, есть отдельно Bi (de), а есть отдельно mlops
Первые занимаются:
1. ETL
2. Подключением разных баз данных к корпоративному хранилищу данных. В том числе подключают нереляционные базы
3. Сборкой объёмных и сложных витрин + написанием документации по ним и поддержанием SLA по ним
4. Проектированием инфологических схем для различных бизнес-сущностей
Mlops - немного другой вектор:
1. Помощь дата-сайентистам в выкатке моделей в продакшен
2. Поддержание работоспособности модели на протяжении всего её жизненного цикла, переобучение (для актуализации параметров), контроль работоспособности модели во времени
Вторые с точки зрения данных для моделек живут в основном на спарке, но это чисто наша корпоративная история
У первых ещё есть, как правило, проблема с качеством данных, не во всех компаниях есть фокус и проработанная политика по поддержанию качества данных
Первые, как правило, работают с широким спектром инструментов для создания бизнес-отчётности, в том числе olap-кубы, дашборды.
Что касается спарка, развёрнутого на хадупе, то его вместе с ETL поддерживает отдельная команда.","Посмотрю на качество, спасибо)"
,,,"Привет! Может кто шарит за трекинг объектов при низкой частоте кадров? Необходимо затрекать дорожные знаки, но камера снимает около 5 кадров в секунду, вследствие чего iou боксов на соседних кадрах нулевое. Из всего что пробовал, более менее заработал костыльно-модифицированный SORT с искусственно увеличенным размером боксов. Работает, но не достаточно стабильно. Может кто сталкивался с похожей задачей? Желательно с реализацией на cpp."
,,"Привет! Может кто шарит за трекинг объектов при низкой частоте кадров? Необходимо затрекать дорожные знаки, но камера снимает около 5 кадров в секунду, вследствие чего iou боксов на соседних кадрах нулевое. Из всего что пробовал, более менее заработал костыльно-модифицированный SORT с искусственно увеличенным размером боксов. Работает, но не достаточно стабильно. Может кто сталкивался с похожей задачей? Желательно с реализацией на cpp.","Добавьте реализацию мэтчинга фичей из самой картинки как в deepsort
Я такую штуку для рук делал - работало"
,"Привет! Может кто шарит за трекинг объектов при низкой частоте кадров? Необходимо затрекать дорожные знаки, но камера снимает около 5 кадров в секунду, вследствие чего iou боксов на соседних кадрах нулевое. Из всего что пробовал, более менее заработал костыльно-модифицированный SORT с искусственно увеличенным размером боксов. Работает, но не достаточно стабильно. Может кто сталкивался с похожей задачей? Желательно с реализацией на cpp.","Добавьте реализацию мэтчинга фичей из самой картинки как в deepsort
Я такую штуку для рук делал - работало",А как считали метрики для фичей?
,,,"Думаю стоит посмотреть object centric сортеры. Они без Калмана, чисто на эмбеддингах объектов. Скорости не добавит конечно, но сортировать должно норм"
,,"Думаю стоит посмотреть object centric сортеры. Они без Калмана, чисто на эмбеддингах объектов. Скорости не добавит конечно, но сортировать должно норм",в плюсы потолкать через opencv dnn onnx можно помаяться технически
,,,"Смотри, SORT и иже с ним работает примерно так: детектирует объекты, сравнивает их со всеми предыдущими, из этих расстояний строит матрицу, которую отправляет в Венгерский алгоритм для поиска оптимальных паросочетаний (минимального потока в двудольном графе, где одна доля - детекции, а другая - прошлые треки).
Как формировать матрицу - это твоё дело, IOU лишь один из вариантов. Он удобен только для достаточно больших объектов, которые не сильно быстры относительно fps камеры.
Что ещё можно подставлять в матрицу расстояний вместо IoU:
- расстояние между центрами объектов (лучше нормировать);
- расстояние между прямоугольниками объектов;
- если была instance segmentation и форма объектов устойчива (а у знаков она устойчива), то расстояние между контурами объектов;
- идём глубже, а именно расстояние между эмбеддингами объектов.

Теперь усложняем, делаем расстояние в виде линейной комбинации других расстояний. Например, 0.5IoU + 0.5D(embeddings) = DeepSORT

По сути, всё просто"
,,"Смотри, SORT и иже с ним работает примерно так: детектирует объекты, сравнивает их со всеми предыдущими, из этих расстояний строит матрицу, которую отправляет в Венгерский алгоритм для поиска оптимальных паросочетаний (минимального потока в двудольном графе, где одна доля - детекции, а другая - прошлые треки).
Как формировать матрицу - это твоё дело, IOU лишь один из вариантов. Он удобен только для достаточно больших объектов, которые не сильно быстры относительно fps камеры.
Что ещё можно подставлять в матрицу расстояний вместо IoU:
- расстояние между центрами объектов (лучше нормировать);
- расстояние между прямоугольниками объектов;
- если была instance segmentation и форма объектов устойчива (а у знаков она устойчива), то расстояние между контурами объектов;
- идём глубже, а именно расстояние между эмбеддингами объектов.

Теперь усложняем, делаем расстояние в виде линейной комбинации других расстояний. Например, 0.5IoU + 0.5D(embeddings) = DeepSORT

По сути, всё просто","сейчас будет капитанство, но если тебе нужен репетитор для подготовки к шаду, то ты и так рискуешь не поступить"
,,,в телеге где-то были группы по (коллективной) подготовке к шаду
,,в телеге где-то были группы по (коллективной) подготовке к шаду,"был бы рад любой инфе, заранее благодарю!"
,,,"ой камон ребят, мне нужен, кому то нет, я школу давно закончил"
,,"ой камон ребят, мне нужен, кому то нет, я школу давно закончил","ну я про то, что зачем нести деньги кому-то, когда куча задачников с решениями и так в открытом доступе"
,"ой камон ребят, мне нужен, кому то нет, я школу давно закончил","ну я про то, что зачем нести деньги кому-то, когда куча задачников с решениями и так в открытом доступе","я по идее тоже думаю, зачем мне вообще репетитор, просто сиди и решай, но вот в голове сидит идея найти человека с которым быстрее и интереснее будет. Я просто хочу потеститься, надеюсь на хороший результат"
,,,"там еще периодически появляется человек, который как раз в шаде вел (мб ведет) курс по адаптационной математике и на фкне вышки и отвечает на вопросы (БЕСПЛАТНО)"
,,"там еще периодически появляется человек, который как раз в шаде вел (мб ведет) курс по адаптационной математике и на фкне вышки и отвечает на вопросы (БЕСПЛАТНО)","просто тут больше вопрос психологии, я перегорания боюсь, и плюс время ограниченно, да и опытный человек сможет объяснить моменты которые он уже знает, и уберечь от разных камней, и скажет что не учить"
,,,"из тех кто сейчас в интернете открыто продает курсы по подготовке к шад я бы не шел ни к одному человеку и советовать их тоже не буду посему. Вот Дима Трушин вышеупомянутый тоже как-то делал пробный платный курс по подготовке к шаду, но честно говорил, что если он нужен, то в шад поступить скорее всего не получится"
,,"из тех кто сейчас в интернете открыто продает курсы по подготовке к шад я бы не шел ни к одному человеку и советовать их тоже не буду посему. Вот Дима Трушин вышеупомянутый тоже как-то делал пробный платный курс по подготовке к шаду, но честно говорил, что если он нужен, то в шад поступить скорее всего не получится","ну я вообщем то согласен что мб не поступлю с первого, но не согласен что если сейчас ты слабый, но никогда не пытайся"
,,,"а я не говорю что никогда не пытайся, я ж выше написал, что не вижу смысла платить непонятно за что"
,,"а я не говорю что никогда не пытайся, я ж выше написал, что не вижу смысла платить непонятно за что","На самом деле это можно сравнить с менторством, а в том, чтобы платить ментору, чтобы он направлял и подсказывал, что важно, а что не важно для достижения цели конкретной, одни только плюсы)"
,"а я не говорю что никогда не пытайся, я ж выше написал, что не вижу смысла платить непонятно за что","На самом деле это можно сравнить с менторством, а в том, чтобы платить ментору, чтобы он направлял и подсказывал, что важно, а что не важно для достижения цели конкретной, одни только плюсы)",ChatGPT как репетитора можно использовать)
"а я не говорю что никогда не пытайся, я ж выше написал, что не вижу смысла платить непонятно за что","На самом деле это можно сравнить с менторством, а в том, чтобы платить ментору, чтобы он направлял и подсказывал, что важно, а что не важно для достижения цели конкретной, одни только плюсы)",ChatGPT как репетитора можно использовать),"ChatGPT не сказать, чтобы сильно хорош
в этом деле"
"На самом деле это можно сравнить с менторством, а в том, чтобы платить ментору, чтобы он направлял и подсказывал, что важно, а что не важно для достижения цели конкретной, одни только плюсы)",ChatGPT как репетитора можно использовать),"ChatGPT не сказать, чтобы сильно хорош
в этом деле","Насколько я знаю, достаточно хорошо. А если хочется что-нибудь поновее - claude 2 еще лучше будет"
,,,"ну плане решения задач хз, разве что как википедия сойдет, имхо"
,,"ну плане решения задач хз, разве что как википедия сойдет, имхо",и то wolframalpha в этом плане поинтереснее)
,,,"Всем привет! Тут недавно было выступление Ильи Гусева, говорили вроде что будет запись. Я хотел бы посмотреть. Может есть у кого ссылочка?"
,,,"Ребят всем привет. Помогите пожалуйста, как сейчас можно оплатить подписку на колаб?"
,,"Ребят всем привет. Помогите пожалуйста, как сейчас можно оплатить подписку на колаб?",Возьми лучше крипту и vast.ai он дешевле
,,,"Насколько я понял, в deepsort использовали cosine distance"
,,"Насколько я понял, в deepsort использовали cosine distance","Да, тоже использовал cos sim
В качестве функции потерь пробовал ArcFace, но что-то с ним  обучалось
Тогда перешёл к Triplet Loss и всё заработало 
Вам в качестве датасета нужен где-то 1 к классов (для проверки гипотезы о том, что это вообще будет работать у вас)
Каждый класс - несколько фотографий одного и того же знака (хотя бы около 10), снятые на разных участках дороги (в разных условиях)"
,"Насколько я понял, в deepsort использовали cosine distance","Да, тоже использовал cos sim
В качестве функции потерь пробовал ArcFace, но что-то с ним  обучалось
Тогда перешёл к Triplet Loss и всё заработало 
Вам в качестве датасета нужен где-то 1 к классов (для проверки гипотезы о том, что это вообще будет работать у вас)
Каждый класс - несколько фотографий одного и того же знака (хотя бы около 10), снятые на разных участках дороги (в разных условиях)","А если могут быть одни и те же знаки подряд, но немного поменять стратегию сбора, но суть остаётся
Ещё вариант - если знаки никогда не повторяются, то сделать мэтчинг через класс объекта
Для каждого знака будет отдельный класс, вопрос лишь в том, насколько универсальным будет ваше решение"
,,,"3. Взять готовое? Intel TBB, OpenCV GAPI, Intel OneAPI - вот это всё как раз про параллельную обработку."
,,,"Подскажите, какие есть открытые решения text2emoji. Есть ли что-то открытое для русского языка?"
,,"Подскажите, какие есть открытые решения text2emoji. Есть ли что-то открытое для русского языка?","А что это за задача?... Не по типу?..
https://modelize.ru/title-sketch/"
,"Подскажите, какие есть открытые решения text2emoji. Есть ли что-то открытое для русского языка?","А что это за задача?... Не по типу?..
https://modelize.ru/title-sketch/","Задача как либо перевести текст именно в текстовые эмоджи (в любые эмоджи, не только эмоджи лиц, которые показывают эмоции). Условно как в переводчике яндекса."
,,,Открытых моделек для перевода в широкий словарь эмоджи не нашел
,,Открытых моделек для перевода в широкий словарь эмоджи не нашел,"Картой банка вне РФ, найди знакомого, сейчас много у кого карты есть"
,,,через казахстан можно?
,,через казахстан можно?,Да вроде
,,,спасибо большое
,,спасибо большое,"Там только надо будет отследить момент, когда тебе больше не надо будет, и остановить подписку"
,,,"Всем привет!
Не нашёл подходящий топик, поэтому пишу в общий. Возникла довольно интересная проблема (во всяком случае раньше я такого не встречал) — нейросети обучаются крайне медленно на машине с 64-мя ядрами CPU и 150 гб RAM. Для сравнения: обучение простенькой fc сети на датасете в 1,3 мил. строчек заняло 4 минуты, тем временем та же нейросеть на локальной машине (4 ядра CPU, 16 гб RAM)  обучилась за 9 секунд. И там и там в цикле train было 10 эпох.
При этом gradboost отработал на сервере за 800 ms, а на локалке за 2,3 сек. 
Подскажите, в чём теоретически может быть проблема? Что можно проверить? Что можно исправить?
Дам ещё немного контекстуальной информации:
На локалке стоит python3.11, на серваке 3.8;
На локалке винда, на сервере ubuntu;
Нейросеть написана на pytorch;
Попробав запустить несколько раз одну и ту же ячейку с трейном на сервере, заметил ещё одно забавное свойство — оно может за 3 секунды крутануть эпоху, а следующую выполнять 15 секунд, следующую 50 секунд, потом 20... и так далее. Очень хаотично. Если одновременно с этим отслеживать нагруженность ядер, то в тех случаях, когда эпоха выполняется быстро, загруженность всех ядер под 100%, и чем медленее проходит эпоха, тем меньше загруженность."
,,"Всем привет!
Не нашёл подходящий топик, поэтому пишу в общий. Возникла довольно интересная проблема (во всяком случае раньше я такого не встречал) — нейросети обучаются крайне медленно на машине с 64-мя ядрами CPU и 150 гб RAM. Для сравнения: обучение простенькой fc сети на датасете в 1,3 мил. строчек заняло 4 минуты, тем временем та же нейросеть на локальной машине (4 ядра CPU, 16 гб RAM)  обучилась за 9 секунд. И там и там в цикле train было 10 эпох.
При этом gradboost отработал на сервере за 800 ms, а на локалке за 2,3 сек. 
Подскажите, в чём теоретически может быть проблема? Что можно проверить? Что можно исправить?
Дам ещё немного контекстуальной информации:
На локалке стоит python3.11, на серваке 3.8;
На локалке винда, на сервере ubuntu;
Нейросеть написана на pytorch;
Попробав запустить несколько раз одну и ту же ячейку с трейном на сервере, заметил ещё одно забавное свойство — оно может за 3 секунды крутануть эпоху, а следующую выполнять 15 секунд, следующую 50 секунд, потом 20... и так далее. Очень хаотично. Если одновременно с этим отслеживать нагруженность ядер, то в тех случаях, когда эпоха выполняется быстро, загруженность всех ядер под 100%, и чем медленее проходит эпоха, тем меньше загруженность.",Рамы хватает? Там может ботлнек в виде hdd
,"Всем привет!
Не нашёл подходящий топик, поэтому пишу в общий. Возникла довольно интересная проблема (во всяком случае раньше я такого не встречал) — нейросети обучаются крайне медленно на машине с 64-мя ядрами CPU и 150 гб RAM. Для сравнения: обучение простенькой fc сети на датасете в 1,3 мил. строчек заняло 4 минуты, тем временем та же нейросеть на локальной машине (4 ядра CPU, 16 гб RAM)  обучилась за 9 секунд. И там и там в цикле train было 10 эпох.
При этом gradboost отработал на сервере за 800 ms, а на локалке за 2,3 сек. 
Подскажите, в чём теоретически может быть проблема? Что можно проверить? Что можно исправить?
Дам ещё немного контекстуальной информации:
На локалке стоит python3.11, на серваке 3.8;
На локалке винда, на сервере ubuntu;
Нейросеть написана на pytorch;
Попробав запустить несколько раз одну и ту же ячейку с трейном на сервере, заметил ещё одно забавное свойство — оно может за 3 секунды крутануть эпоху, а следующую выполнять 15 секунд, следующую 50 секунд, потом 20... и так далее. Очень хаотично. Если одновременно с этим отслеживать нагруженность ядер, то в тех случаях, когда эпоха выполняется быстро, загруженность всех ядер под 100%, и чем медленее проходит эпоха, тем меньше загруженность.",Рамы хватает? Там может ботлнек в виде hdd,"За глаза, на локалке hdd стоит"
,,,"Я такое встречал, когда на сервере выкручивал количество воркеров в даталоадере. Если его используете — проверьте количество воркеров, не ставьте бездумно все доступные."
,,"Я такое встречал, когда на сервере выкручивал количество воркеров в даталоадере. Если его используете — проверьте количество воркеров, не ставьте бездумно все доступные.","Поигрался с num_workers, вроде никак не меняется ситуация. Но хаотичность, справедливости ради, ушла. Теперь стабильно по 30-35 секунд одна эпоха. Но в сумме всё равно то же самое по времени выходит."
,,,"Ну локально же летает, так что скорее всего не в раме дело. Кстати да, мб на локале ssd, на серваке hdd и как-то это влияет. Но не знаю, тестить надо)"
,,,Время с одним воркером == время с 6 воркерами? Проверьте на локалке
,,Время с одним воркером == время с 6 воркерами? Проверьте на локалке,А на локалке узание кол-ва воркеров приводит к ошибке
,Время с одним воркером == время с 6 воркерами? Проверьте на локалке,А на локалке узание кол-ва воркеров приводит к ошибке,Потому что виндовс
Время с одним воркером == время с 6 воркерами? Проверьте на локалке,А на локалке узание кол-ва воркеров приводит к ошибке,Потому что виндовс,А какой профит нативно в винде запускать ?(vs wsl+docker)
А на локалке узание кол-ва воркеров приводит к ошибке,Потому что виндовс,А какой профит нативно в винде запускать ?(vs wsl+docker),А зачем с такими костылями тогда вообще винда
Потому что виндовс,А какой профит нативно в винде запускать ?(vs wsl+docker),А зачем с такими костылями тогда вообще винда,"а в чем костыли ? в линуксе только wsl бы у меня не было в стандартном тулките, но его не сложно использовать и запускать, просто винда нужна для других задач, на десктопе то :) А нативно - это потонуть в собственном мусоре из пакетов когда то поставленных и конфликтящих, venv и pyenv и прочие как раз костыли для изоляции (ну это с моей т.з. т.к. я давний адепт контейнероной виртуализации, где то с 2003), чисто на wsl неудобно (тоже можно делать контенеры отдельные так то), т.к. не всё собирается да и докер и линукс в нем понятнее просто."
А какой профит нативно в винде запускать ?(vs wsl+docker),А зачем с такими костылями тогда вообще винда,"а в чем костыли ? в линуксе только wsl бы у меня не было в стандартном тулките, но его не сложно использовать и запускать, просто винда нужна для других задач, на десктопе то :) А нативно - это потонуть в собственном мусоре из пакетов когда то поставленных и конфликтящих, venv и pyenv и прочие как раз костыли для изоляции (ну это с моей т.з. т.к. я давний адепт контейнероной виртуализации, где то с 2003), чисто на wsl неудобно (тоже можно делать контенеры отдельные так то), т.к. не всё собирается да и докер и линукс в нем понятнее просто.","а как ты работаешь в этой связке, маунтишь какие-то папки в докере что бы можно было сохранять код?"
А зачем с такими костылями тогда вообще винда,"а в чем костыли ? в линуксе только wsl бы у меня не было в стандартном тулките, но его не сложно использовать и запускать, просто винда нужна для других задач, на десктопе то :) А нативно - это потонуть в собственном мусоре из пакетов когда то поставленных и конфликтящих, venv и pyenv и прочие как раз костыли для изоляции (ну это с моей т.з. т.к. я давний адепт контейнероной виртуализации, где то с 2003), чисто на wsl неудобно (тоже можно делать контенеры отдельные так то), т.к. не всё собирается да и докер и линукс в нем понятнее просто.","а как ты работаешь в этой связке, маунтишь какие-то папки в докере что бы можно было сохранять код?","ну прям в рабочем коде я просто . (текущая) директорию маунчу в /app и /root/.cache локально
если что-то стороннее запустить - клонирую в сборке и маунчу всякие дата и конфиг директории и файлы, через композер, не докерфайл, ещё экономия получается, потому что эти образы все почти одинаковые

# Use the official image as a parent image
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# Set the working directory in the container
WORKDIR /app

# Install Python and pip
RUN --mount=type=cache,target=/var/cache/apt     apt-get update && apt-get install -y \
    python3 \
    python-is-python3 \
    python3-pip \
    python3-dev \
    python3-venv \
    build-essential \
    wget \
    unzip \
    git \
    ffmpeg \ 
    && rm -rf /var/lib/apt/lists/* 

# Upgrade setuptools
RUN --mount=type=cache,target=/root/.cache/pip pip3 install --upgrade setuptools

# Install setuptools and wheel
RUN --mount=type=cache,target=/root/.cache/pip pip3 install setuptools wheel
COPY ./requirements.txt .
RUN --mount=type=cache,target=/root/.cache/pip pip3 install -r requirements.txt
COPY ./cuda_quant_requirements.txt .
ENV NVIDIA_VISIBLE_DEVICES=ALL
ENV TORCH_CUDA_ARCH_LIST=8.6+PTX
RUN --mount=type=cache,target=/root/.cache/pip pip install -r cuda_quant_requirements.txt

composer

version: '3.8'
services:
  app:
    build: .
    volumes:
      - .:/app
      - ./.container.cache:/root/.cache
      - ../models:/models
      - ./lora-output:/app/lora-output
      - ../data/:/data
    command: ""/app/run.sh""
    env_file:
      - .env
    ports:
      - 7860:7860
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]

это и в виде и в линухе одинаково работает"
,,,"RuntimeError: DataLoader worker (pid(s) 14440) exited unexpectedly
в зависимости от кол-ва воркеров растёт количество чисел pid
Окей, попробую. В любом случае спасибо большое! Есть куда думать хотя бы"
,,,"разница между виндой и линуксом в распределении вычислений по ядрам кроется в такой штуковине как scheduler процессов. 

Если на венде вы админ, прочитайте, нет ли чего фонового в линухах?

В целом при прочих равных дело не в том, что венда или линух. Блокирующие примитивы и там и там сравнимы. Возможно у вас Линукс под виртуальной машиной, а там могут быть свои политики, и это будет основной причиной"
,,"разница между виндой и линуксом в распределении вычислений по ядрам кроется в такой штуковине как scheduler процессов. 

Если на венде вы админ, прочитайте, нет ли чего фонового в линухах?

В целом при прочих равных дело не в том, что венда или линух. Блокирующие примитивы и там и там сравнимы. Возможно у вас Линукс под виртуальной машиной, а там могут быть свои политики, и это будет основной причиной","В линуксе были проблемы с шедуллером, громкий стон стоял годами, но толи шедулер починили, толи ssd и ddr5 стерли проблему, сейчас не слышно почти."
,,,Лучше sympy
,,,"Привет всем
Хотел узнать, реально ли засунуть торчовую модель сегментации в 4 Гб для андроид?
Видел где-то, что есть ограничение в 2ГБ по памяти в pytorch и tf приложух, но нормальной инфы не нашел."
,,"Привет всем
Хотел узнать, реально ли засунуть торчовую модель сегментации в 4 Гб для андроид?
Видел где-то, что есть ограничение в 2ГБ по памяти в pytorch и tf приложух, но нормальной инфы не нашел.","По памяти оперативной или физической (на устройстве)? 
В любом случае, должно хватить"
,,,"в целом да, зависит от модели и твоих ограничений"
,,,"Все так восхваляют матан в универе, когда сами учились через вольфрам и матпрофи за ночь  перед экзаменом. А после универа такие Господа💪
Да, матан нужен и т.д.🤣"
,,"Все так восхваляют матан в универе, когда сами учились через вольфрам и матпрофи за ночь  перед экзаменом. А после универа такие Господа💪
Да, матан нужен и т.д.🤣",я по Демидовичу (задачнику) учил. В интернете тогда еще ajax не работал. В умелых руках матан творит чудеса
,"Все так восхваляют матан в универе, когда сами учились через вольфрам и матпрофи за ночь  перед экзаменом. А после универа такие Господа💪
Да, матан нужен и т.д.🤣",я по Демидовичу (задачнику) учил. В интернете тогда еще ajax не работал. В умелых руках матан творит чудеса,"Матан и физика всего лишь фильтры для очистки (отчислений)😀
После 2 курса уже легче."
"Все так восхваляют матан в универе, когда сами учились через вольфрам и матпрофи за ночь  перед экзаменом. А после универа такие Господа💪
Да, матан нужен и т.д.🤣",я по Демидовичу (задачнику) учил. В интернете тогда еще ajax не работал. В умелых руках матан творит чудеса,"Матан и физика всего лишь фильтры для очистки (отчислений)😀
После 2 курса уже легче.","у нас фильтром был теор. вер. и мат. стат. На 3 курсе. Как после него осталось процентов 70 народу, так все и дошли уже"
,,,Есть кто-то на Кипре?
,,,"Всем привет, подскажите, пожалуйста, какую модель можно обучить с нуля (или для дообучения) для задачи перевода со специфического языка (татарского) на русский и наоборот? В распоряжении имеется одна V100 и около миллиона примеров для обучения."
,,"Всем привет, подскажите, пожалуйста, какую модель можно обучить с нуля (или для дообучения) для задачи перевода со специфического языка (татарского) на русский и наоборот? В распоряжении имеется одна V100 и около миллиона примеров для обучения.","HF показывает несколько разных моделей для перевода, уже предобученных на русском и татарском, но самый очевидный вариант - это NLLB-200. Например, её стандартный «маленький» чекпойнт на 600М параметров."
,,,E5
,,E5,Jupiter ai - искусственный интеллект в любимых блокнотиках. Статья с Медиума с переводом на русский
,,,"Всем привет. Хз в какой чат писать, поэтому спрошу здесь. При изучении backprop'а я обратил внимание, что PyTorch явно отделяет его от gradient descent'а через явные вызовы loss.backward() и optim.step() соответственно. Следовательно вопрос, почему нельзя в целях экономии памяти применять спуск сразу после нахождения градиентов по слою, а не хранить их всех до получения градиента по первому слою? В других фреймворках так же?"
,,"Всем привет. Хз в какой чат писать, поэтому спрошу здесь. При изучении backprop'а я обратил внимание, что PyTorch явно отделяет его от gradient descent'а через явные вызовы loss.backward() и optim.step() соответственно. Следовательно вопрос, почему нельзя в целях экономии памяти применять спуск сразу после нахождения градиентов по слою, а не хранить их всех до получения градиента по первому слою? В других фреймворках так же?","Память особо экономится не будет, значение градиента в тензоре это всего одна переменная, большая часть памяти уходит на построение вычислительного графа для расчета градиентов"
,"Всем привет. Хз в какой чат писать, поэтому спрошу здесь. При изучении backprop'а я обратил внимание, что PyTorch явно отделяет его от gradient descent'а через явные вызовы loss.backward() и optim.step() соответственно. Следовательно вопрос, почему нельзя в целях экономии памяти применять спуск сразу после нахождения градиентов по слою, а не хранить их всех до получения градиента по первому слою? В других фреймворках так же?","Память особо экономится не будет, значение градиента в тензоре это всего одна переменная, большая часть памяти уходит на построение вычислительного графа для расчета градиентов",Считай ещё одну модельку хранить
"Всем привет. Хз в какой чат писать, поэтому спрошу здесь. При изучении backprop'а я обратил внимание, что PyTorch явно отделяет его от gradient descent'а через явные вызовы loss.backward() и optim.step() соответственно. Следовательно вопрос, почему нельзя в целях экономии памяти применять спуск сразу после нахождения градиентов по слою, а не хранить их всех до получения градиента по первому слою? В других фреймворках так же?","Память особо экономится не будет, значение градиента в тензоре это всего одна переменная, большая часть памяти уходит на построение вычислительного графа для расчета градиентов",Считай ещё одну модельку хранить,Ну второй вычислительный граф для градиента получается по весу как вторая моделька
,,,"Если резюмировать, то дело в гибкости?"
,,"Если резюмировать, то дело в гибкости?","нее... ну почти) разница что если граф динамический, то градиенты это числа, а не заранее вычисленная функция"
,"Если резюмировать, то дело в гибкости?","нее... ну почти) разница что если граф динамический, то градиенты это числа, а не заранее вычисленная функция","Я не совсем понимаю, как природа этих чисел мешает нам вычитать их от параметров по ходу их нахождения"
"Если резюмировать, то дело в гибкости?","нее... ну почти) разница что если граф динамический, то градиенты это числа, а не заранее вычисленная функция","Я не совсем понимаю, как природа этих чисел мешает нам вычитать их от параметров по ходу их нахождения",параметры могут использоваться не один раз и градиент тогда нужно сначала просуммировать пр всем вхождениям
"нее... ну почти) разница что если граф динамический, то градиенты это числа, а не заранее вычисленная функция","Я не совсем понимаю, как природа этих чисел мешает нам вычитать их от параметров по ходу их нахождения",параметры могут использоваться не один раз и градиент тогда нужно сначала просуммировать пр всем вхождениям,Ну так не проблема
,,,"по идее не мешает. Но и не обязывает. Во-первых градиенты можно считать и без оптимизации мало ли в каких целях (я например экспериментировал с поиском равновесия по Нэшу), во-вторых, оптимизатор дизайн апи торча следует парадигме ""прогноз-сравнение-обучение"". То есть сначала считаем прогноз, потом ошибку, потом правим веса. На каждом шаге могут быть свои кастомизации. И выигрыш по памяти может быть конечно заметным если это LLM, ... , но и там скорее применяют gradient accumulation. Шаг оптимизатора не самая тяжелая процедура из 3х"
,,"по идее не мешает. Но и не обязывает. Во-первых градиенты можно считать и без оптимизации мало ли в каких целях (я например экспериментировал с поиском равновесия по Нэшу), во-вторых, оптимизатор дизайн апи торча следует парадигме ""прогноз-сравнение-обучение"". То есть сначала считаем прогноз, потом ошибку, потом правим веса. На каждом шаге могут быть свои кастомизации. И выигрыш по памяти может быть конечно заметным если это LLM, ... , но и там скорее применяют gradient accumulation. Шаг оптимизатора не самая тяжелая процедура из 3х","Ок, круто"
,,,"Да и кстати, если править веса в моменте, цепное правило сломается же"
,,"Да и кстати, если править веса в моменте, цепное правило сломается же","Разве? Нам же нужен на (n-k)-ом слое градиент со слоя n-k+1, а что до этого было уже не важно. Только если это не какой-нибудь resnet и ему подобные архитектуры"
,"Да и кстати, если править веса в моменте, цепное правило сломается же","Разве? Нам же нужен на (n-k)-ом слое градиент со слоя n-k+1, а что до этого было уже не важно. Только если это не какой-нибудь resnet и ему подобные архитектуры",Для произвольного графа должно ломаться...
"Да и кстати, если править веса в моменте, цепное правило сломается же","Разве? Нам же нужен на (n-k)-ом слое градиент со слоя n-k+1, а что до этого было уже не важно. Только если это не какой-нибудь resnet и ему подобные архитектуры",Для произвольного графа должно ломаться...,"Я написал предложенный мною подход для MLP, результаты backprop'а до оптимизации и после (train, validation loss) равны. Что касается гонки за памятью, то по крайней мере для малых моделей это не имеет смысла вовсе:

Before backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8432kB
Maximum allocated memory: 15745kB

After backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8380kB
Maximum allocated memory: 15606kB"
"Разве? Нам же нужен на (n-k)-ом слое градиент со слоя n-k+1, а что до этого было уже не важно. Только если это не какой-нибудь resnet и ему подобные архитектуры",Для произвольного графа должно ломаться...,"Я написал предложенный мною подход для MLP, результаты backprop'а до оптимизации и после (train, validation loss) равны. Что касается гонки за памятью, то по крайней мере для малых моделей это не имеет смысла вовсе:

Before backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8432kB
Maximum allocated memory: 15745kB

After backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8380kB
Maximum allocated memory: 15606kB","Очень полезно ковырять потроха, я без сарказма. Но вы и сами правильно написали - для всяких residual-connections это работать не будет... А это все трансформеры.

Конечно, для блоков можно сделать свои предрасчеты. Тогда, если это будет более-менее универсально, делайте либу или pull request. Или issue с вопросом для начала. 

Однако , помните о парадигмах) хотите неплохую книжку на тему?.. ""Грокаем глубокое обучение"""
Для произвольного графа должно ломаться...,"Я написал предложенный мною подход для MLP, результаты backprop'а до оптимизации и после (train, validation loss) равны. Что касается гонки за памятью, то по крайней мере для малых моделей это не имеет смысла вовсе:

Before backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8432kB
Maximum allocated memory: 15745kB

After backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8380kB
Maximum allocated memory: 15606kB","Очень полезно ковырять потроха, я без сарказма. Но вы и сами правильно написали - для всяких residual-connections это работать не будет... А это все трансформеры.

Конечно, для блоков можно сделать свои предрасчеты. Тогда, если это будет более-менее универсально, делайте либу или pull request. Или issue с вопросом для начала. 

Однако , помните о парадигмах) хотите неплохую книжку на тему?.. ""Грокаем глубокое обучение""","Я уже нашёл аргументы для себя, почему так делать не надо. Поэтому и продолжать эту тему больше нигде не буду)

Спасибо за совет книги"
"Я написал предложенный мною подход для MLP, результаты backprop'а до оптимизации и после (train, validation loss) равны. Что касается гонки за памятью, то по крайней мере для малых моделей это не имеет смысла вовсе:

Before backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8432kB
Maximum allocated memory: 15745kB

After backprop optimization
Dataset memory usage: 7130kB
Parameters number: 12297
Model parameters memory usage: 50kB
Intermediate tensors (forward pass): 8380kB
Maximum allocated memory: 15606kB","Очень полезно ковырять потроха, я без сарказма. Но вы и сами правильно написали - для всяких residual-connections это работать не будет... А это все трансформеры.

Конечно, для блоков можно сделать свои предрасчеты. Тогда, если это будет более-менее универсально, делайте либу или pull request. Или issue с вопросом для начала. 

Однако , помните о парадигмах) хотите неплохую книжку на тему?.. ""Грокаем глубокое обучение""","Я уже нашёл аргументы для себя, почему так делать не надо. Поэтому и продолжать эту тему больше нигде не буду)

Спасибо за совет книги","поделитесь, все свои)"
"Очень полезно ковырять потроха, я без сарказма. Но вы и сами правильно написали - для всяких residual-connections это работать не будет... А это все трансформеры.

Конечно, для блоков можно сделать свои предрасчеты. Тогда, если это будет более-менее универсально, делайте либу или pull request. Или issue с вопросом для начала. 

Однако , помните о парадигмах) хотите неплохую книжку на тему?.. ""Грокаем глубокое обучение""","Я уже нашёл аргументы для себя, почему так делать не надо. Поэтому и продолжать эту тему больше нигде не буду)

Спасибо за совет книги","поделитесь, все свои)",Аргументами или ноутбуком?
"Я уже нашёл аргументы для себя, почему так делать не надо. Поэтому и продолжать эту тему больше нигде не буду)

Спасибо за совет книги","поделитесь, все свои)",Аргументами или ноутбуком?,Аргументами
"поделитесь, все свои)",Аргументами или ноутбуком?,Аргументами,"По большей части это всё вместе собранное из написанного выше:

1.  Выигрыш не велик
2.  Плохая обобщаемость (ResNet, U-Net)
3.  Большая сложность поддержки кода и его меньшая гибкость"
,,,Ладно. Спасибо большое
,,Ладно. Спасибо большое,"да не за что. На самом деле вопрос непростой... Я ответил в духе ""преждевременная оптимизация корень всех бед"", но по идее тут проблема не столько в памяти, а сколько в самой процедуре оптимизации. Условно, знай мы рельеф лосс-функции полностью, или обладай он хорошими свойствами изначально (выпуклостью например), итеративные все эти приседания были бы не нужны"
,Ладно. Спасибо большое,"да не за что. На самом деле вопрос непростой... Я ответил в духе ""преждевременная оптимизация корень всех бед"", но по идее тут проблема не столько в памяти, а сколько в самой процедуре оптимизации. Условно, знай мы рельеф лосс-функции полностью, или обладай он хорошими свойствами изначально (выпуклостью например), итеративные все эти приседания были бы не нужны",Ну да
,,,"Звучит сложно - определить (класс же?) проекции по фото. Для (почти произвольных) объектов...

Да, текст должен помочь. CLIP тюнить самый вариант имхо"
,,"Звучит сложно - определить (класс же?) проекции по фото. Для (почти произвольных) объектов...

Да, текст должен помочь. CLIP тюнить самый вариант имхо","Ну да, 6 классов. Точный OOBB не нужен."
,,,А ведь действительно
,,А ведь действительно,"Там к основному графу второй достраивается, на нем считаются градиенты"
,,,"Собственно тензор градиента в ноды изначального вычислительного графа не копируется, а передается по ссылке должно быть"
,,"Собственно тензор градиента в ноды изначального вычислительного графа не копируется, а передается по ссылке должно быть","Копия уже происходит когда оптимайзер отнимает градиент и она нигде не хранится, это и экономит память"
,,,"это все следствия же, оптимизация на уровне кода"
,,"это все следствия же, оптимизация на уровне кода",Ну это просто логика построения абстрактного вычислительного графа
,"это все следствия же, оптимизация на уровне кода",Ну это просто логика построения абстрактного вычислительного графа,так вот же альтернативу предложили выше) я думаю есть еще варианты. В Байесовском выводе вообще можно без графов (если меня память не подводит)
"это все следствия же, оптимизация на уровне кода",Ну это просто логика построения абстрактного вычислительного графа,так вот же альтернативу предложили выше) я думаю есть еще варианты. В Байесовском выводе вообще можно без графов (если меня память не подводит),"Как градиенты рассчитывать без второго графа, если мы оптимизируемся спуском?"
,,,... память подводит. Без градиентов
,,... память подводит. Без градиентов,"Изменения памяти после каждой строки кода в обратном проходе. Первый график - после оптимизации, второй - до."
,,,"Я использовал SGD. Следовательно для оптимизаторов, которые аккумулируют моменты градиентов, относительная разница будет ещё меньше"
,,"Я использовал SGD. Следовательно для оптимизаторов, которые аккумулируют моменты градиентов, относительная разница будет ещё меньше",А что за модельку вы обучаете?
,"Я использовал SGD. Следовательно для оптимизаторов, которые аккумулируют моменты градиентов, относительная разница будет ещё меньше",А что за модельку вы обучаете?,"Из этого ноутбука 
https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjAxdmZFMzREQnloNHhoUzJBZzEwcWVaNjNqd3xBQ3Jtc0tuRWswVDAwX0llN0htaU1GR01VZ3RKRnRPeVBBVlpsNENobGt3WnpOWnRpYWtoaXBfQkFPaWVNYXBHcDVaa2cwdHNwVFhrX005LVFTd3haN21DTGJQcVR4YVhFd2NabjRwS0x2NmNKVnhPVlVRMVNhdw&q=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1WV2oi2fh9XXyldh02wupFQX0wh5ZC-z-%3Fusp%3Dsharing&v=q8SA3rM6ckI"
,,,"Сорян, увидел"
,,"Сорян, увидел",Там embedding и batchnorm в придачу
,,,"Всем добрый день! Покритикуйте CV, пожалуйста.

Работу менять не планирую, просто актуализирую сивишку, чтобы всегда была наготове)

UPD: в личку еще написали идею уменьшить разнообразие шрифтов — согласна, убрала все курсивы"
,,"Всем добрый день! Покритикуйте CV, пожалуйста.

Работу менять не планирую, просто актуализирую сивишку, чтобы всегда была наготове)

UPD: в личку еще написали идею уменьшить разнообразие шрифтов — согласна, убрала все курсивы","https://www-career.notion.site/Part-1-e6fb6d8271594097a4aec5612f220e61

Пройдись по этому чеклесту, его ребята из букинга делали, выглядит хорошо 🙂 

В МТС и лабе опыт надо раскрыть подробнее, по буллпойнтам должно быть видно что ты делала и насколько ты крутая. 

Формулируй их либо в виде какой-то выкатки либо в виде какой-то метрики, которую ты вырастила, если у тебя есть примерная цифра. Эти пойнты это самое важное что есть у тебя в резюме, так как они в первую очередь говорят про твои навыки, а не раздел скиллс. Его можно сильно порезать в пользу пойнтов 🙂"
,"Всем добрый день! Покритикуйте CV, пожалуйста.

Работу менять не планирую, просто актуализирую сивишку, чтобы всегда была наготове)

UPD: в личку еще написали идею уменьшить разнообразие шрифтов — согласна, убрала все курсивы","https://www-career.notion.site/Part-1-e6fb6d8271594097a4aec5612f220e61

Пройдись по этому чеклесту, его ребята из букинга делали, выглядит хорошо 🙂 

В МТС и лабе опыт надо раскрыть подробнее, по буллпойнтам должно быть видно что ты делала и насколько ты крутая. 

Формулируй их либо в виде какой-то выкатки либо в виде какой-то метрики, которую ты вырастила, если у тебя есть примерная цифра. Эти пойнты это самое важное что есть у тебя в резюме, так как они в первую очередь говорят про твои навыки, а не раздел скиллс. Его можно сильно порезать в пользу пойнтов 🙂","Спасибо большое, очень полезно!

Прям сильный затык с тем, чтобы переформулировать опыт в достижения в цифрах, т.к. все-таки nda, да и метрики в генеративных задачах штука не очень надежная) Но буду думать))"
,,,Публекейшены повыше мб?
,,Публекейшены повыше мб?,"Думала) Но она старенькая и только с классическим мл, то есть не особо отражает мой актуальный стек, в отличие от разделов со скиллами и курсами😁 Пока решилась, что как сделаю что-то свежее, подниму этот раздел"
,,,"- если работу не собираетесь менять, зачем на англ.?..
- достаточно узкий круг интересов обозначен, даже по меркам относительно широкой области NLP"
,,"- если работу не собираетесь менять, зачем на англ.?..
- достаточно узкий круг интересов обозначен, даже по меркам относительно широкой области NLP","На русском смысла особо делать cv нет, на англе примут в любой норм компании + ты себя не будешь ограничивать рынком российским, в международке куча стартапов с русскоязычными основателями, но другой юрисдикцией вроде всяких миро, индрайвера и тп 

В них даже при плохом знании языка можно залететь и там подтянуть."
,,,"привет, кто нить заводил SD на Jetson Orin NX?"
,,,"- Ну как-то английский уже default choice лично в моей голове, чтобы говорить о работе) Думаете, лучше для русскоговорящих читателей CV сделать русскую версию? Была мысль второй страницей вставить полную копию на русском, но может это оверкилл...
- Это читается так, будто я кроме это задачи ничего не знаю? Лучше добавить что-то еще что теоретически интересно, или этот пункт пошире назвать? Ну, скажем, NLP generative applications?"
,,"- Ну как-то английский уже default choice лично в моей голове, чтобы говорить о работе) Думаете, лучше для русскоговорящих читателей CV сделать русскую версию? Была мысль второй страницей вставить полную копию на русском, но может это оверкилл...
- Это читается так, будто я кроме это задачи ничего не знаю? Лучше добавить что-то еще что теоретически интересно, или этот пункт пошире назвать? Ну, скажем, NLP generative applications?","- просто определяет ЦА
- не совсем так. Область интересов для HR как красная тряпка. Чуть в сторону - отложат в сторонку...

экзерсис 🔥"
,"- Ну как-то английский уже default choice лично в моей голове, чтобы говорить о работе) Думаете, лучше для русскоговорящих читателей CV сделать русскую версию? Была мысль второй страницей вставить полную копию на русском, но может это оверкилл...
- Это читается так, будто я кроме это задачи ничего не знаю? Лучше добавить что-то еще что теоретически интересно, или этот пункт пошире назвать? Ну, скажем, NLP generative applications?","- просто определяет ЦА
- не совсем так. Область интересов для HR как красная тряпка. Чуть в сторону - отложат в сторонку...

экзерсис 🔥","Спасибо! Подумаю про второй пункт, чтобы поинтереснее выглядело"
,,,и вот ваши скип коннекты работают на примере лламы
,,и вот ваши скип коннекты работают на примере лламы,как работают?.. Не открываицо 😢
,,,попробуй впн)
,,,выключить или включить
,,выключить или включить,"давно выключил. ладно, на gh залезу"
,выключить или включить,"давно выключил. ладно, на gh залезу",Не полностью прогрузил
,,,"Наоборот, включите
У меня последние месяца 2 не получается на сайт pl войти без впн"
,,"Наоборот, включите
У меня последние месяца 2 не получается на сайт pl войти без впн","да я им и не пользуюсь, лайтнингом. Если не повезет - skorch)"
,,,с мобилы нихера не нашел...на gh. VPN у меня нет... Можно ссылку на код или текст в репо ?
,,с мобилы нихера не нашел...на gh. VPN у меня нет... Можно ссылку на код или текст в репо ?,)
,,,короче то что веса после процедуры те же сравнения я что-то не нашел
,,короче то что веса после процедуры те же сравнения я что-то не нашел,"Так запусти MLP, расскажешь нам потом"
,короче то что веса после процедуры те же сравнения я что-то не нашел,"Так запусти MLP, расскажешь нам потом",я себе в to-do на сегодня писал чекнуть fdsp на skip connections но теперь не буду
,,,"Ребята, посоветуйте чем можно определить координаты деревьев на спутниковых снимках типа таких:"
,,"Ребята, посоветуйте чем можно определить координаты деревьев на спутниковых снимках типа таких:",yolo?
,,,наверное что-то unet-like мне видится
,,наверное что-то unet-like мне видится,"Да, через heat map prediction

Размечаешь центры. Затем сглаживаешь с помощью Гаусса и предсказываешь

Мы так центры растений определяли, работало хорошо!"
,,,"Вау, спасибо за такой развернутый разбор!!!"
,,,"Стоит ли вообще перечислять архитектуры трансформеров BERT, RoBERTa, и т.д.?"
,,"Стоит ли вообще перечислять архитектуры трансформеров BERT, RoBERTa, и т.д.?","Да, иногда может помочь на скрининге"
,,,"Парочку можно, хуже не будет для этого резюме. А когда опыт вырастет — резюме пойдет на стадию «чего бы лишнего выкинуть?» 🙂"
,,"Парочку можно, хуже не будет для этого резюме. А когда опыт вырастет — резюме пойдет на стадию «чего бы лишнего выкинуть?» 🙂","Резюме эйчары смотрят, разве они поймут?"
,,,MLP ?)
,,MLP ?),Multilayer perceptron
,,,И residual connection добавь
,,И residual connection добавь,сам добавь 🤷‍♂
,И residual connection добавь,сам добавь 🤷‍♂,
И residual connection добавь,сам добавь 🤷‍♂,,"В colab не запускается *fsdp_overlap_step_with_backward*, и походу это не обойти. Так что я точно не проверю"
,,,"Всем привет!
Как поменять количество каналов в сети из TFOD? В конфигурационном файле YOLO, например, есть прям строчка num_channels = 3. А как в Tensorflow это сделать разобраться не могу("
,,"Всем привет!
Как поменять количество каналов в сети из TFOD? В конфигурационном файле YOLO, например, есть прям строчка num_channels = 3. А как в Tensorflow это сделать разобраться не могу(",а зачем нужно менять число каналов?
,"Всем привет!
Как поменять количество каналов в сети из TFOD? В конфигурационном файле YOLO, например, есть прям строчка num_channels = 3. А как в Tensorflow это сделать разобраться не могу(",а зачем нужно менять число каналов?,Мб у человека одноканальные изображения
"Всем привет!
Как поменять количество каналов в сети из TFOD? В конфигурационном файле YOLO, например, есть прям строчка num_channels = 3. А как в Tensorflow это сделать разобраться не могу(",а зачем нужно менять число каналов?,Мб у человека одноканальные изображения,"Если так, то можно просто подавать как rgb"
а зачем нужно менять число каналов?,Мб у человека одноканальные изображения,"Если так, то можно просто подавать как rgb","можно, но очень нежелательно"
,,,"Друзья, если хочу лламу задоменадаптить, могу ли просто побить пополам неразмеченные сиквенсы через ### Response, это может сработать?"
,,"Друзья, если хочу лламу задоменадаптить, могу ли просто побить пополам неразмеченные сиквенсы через ### Response, это может сработать?","А не проще ли сначала на текстах неразмеченных отфайнтюнить, а потом на размеченных?"
,,,"Всем привет!
Мы организуем хакатоны по искусственному интеллекту.

Ищем техэкспертов по NLP на хакатон в Санкт-Петербурге на 25-26 августа. Участие онлайн.
Пишите в личку🙂
Всем привет!
Мы организуем хакатоны по искусственному интеллекту.

Ищем техэкспертов по Computer Vision на хакатон в Санкт-Петербурге на 25-26 августа. Участие онлайн.
Пишите в личку 🙂"
,,,А про какие еще экспериментальные фичи говорите кроме pytorch 2.0?
,,А про какие еще экспериментальные фичи говорите кроме pytorch 2.0?,А вы пользуетесь этой оберткой?
,А про какие еще экспериментальные фичи говорите кроме pytorch 2.0?,А вы пользуетесь этой оберткой?,Оберткой compile?
А про какие еще экспериментальные фичи говорите кроме pytorch 2.0?,А вы пользуетесь этой оберткой?,Оберткой compile?,fsdp_overlap_step_with_backward - тут про это сейчас обсуждение
А вы пользуетесь этой оберткой?,Оберткой compile?,fsdp_overlap_step_with_backward - тут про это сейчас обсуждение,Сейчас нет
Оберткой compile?,fsdp_overlap_step_with_backward - тут про это сейчас обсуждение,Сейчас нет,"Если ранее был опыт, было бы интересно ознакомиться. И почему сейчас нет"
,,,"Со времен до 2.0?
В целом мой лично опыт с lightning очень быстро сошел на нет по двум причинам:
1. часто меняется api, постоянно код переписывать неинтересно,
2. очень много неинтуитивностей и багов"
,,,"всем привет, есть такая проблема, модель небольшая, и данных немного, но почему то заполняется всё gpu и kernel died, в чем может быть проблема?"
,,"всем привет, есть такая проблема, модель небольшая, и данных немного, но почему то заполняется всё gpu и kernel died, в чем может быть проблема?",batch size большой?...
,,,"тоже уменьшил, также использовал Mixed Precision, архитектура unet. картинки весят мало, ограничил искусственно до 4 картинок и такая же беда, параметров меньше 2 лямов, могу архитектуру закинуть"
,,"тоже уменьшил, также использовал Mixed Precision, архитектура unet. картинки весят мало, ограничил искусственно до 4 картинок и такая же беда, параметров меньше 2 лямов, могу архитектуру закинуть",Давайте скорее код train-процедуры
,"тоже уменьшил, также использовал Mixed Precision, архитектура unet. картинки весят мало, ограничил искусственно до 4 картинок и такая же беда, параметров меньше 2 лямов, могу архитектуру закинуть",Давайте скорее код train-процедуры,"import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout

def double_input_unet(input_shape, dropout_rate=0.2):
    input1 = Input(shape=input_shape)
    input2 = Input(shape=input_shape)

    concatenated_inputs = Concatenate(axis=-1)([input1, input2])

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(concatenated_inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Decoder
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    conv3 = Dropout(dropout_rate)(conv3)
    up1 = UpSampling2D(size=(2, 2))(conv3)
    up1 = Conv2D(128, 2, activation='relu', padding='same')(up1)
    merge1 = Concatenate(axis=3)([conv2, up1])

    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge1)
    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)
    conv4 = Dropout(dropout_rate)(conv4)
    up2 = UpSampling2D(size=(2, 2))(conv4)
    up2 = Conv2D(64, 2, activation='relu', padding='same')(up2)
    merge2 = Concatenate(axis=3)([conv1, up2])

    # Output layers
    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge2)
    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)

    output1 = Conv2D(1, (1, 1), activation='sigmoid', name=""output1"")(conv5)
    output2 = Conv2D(1, (1, 1), activation='sigmoid', name=""output2"")(conv5)

    model = Model(inputs=[input1, input2], outputs=[output1, output2])
    return model

# Создаем модель 
input_shape = (640, 480, 3)
model = double_input_unet(input_shape, dropout_rate=0.2)
model.summary()"
,,,"ну тогда гиперпараметры и параметры железа в студию пожалуйста)

kernel died может быть не только из-за out of memory на GPU конечно, хотя и причина самая частая

как вариант, могут версии чего-нибудь не совпадать"
,,"ну тогда гиперпараметры и параметры железа в студию пожалуйста)

kernel died может быть не только из-за out of memory на GPU конечно, хотя и причина самая частая

как вариант, могут версии чего-нибудь не совпадать",вообще обычно об аут оф мемори тот же торч сообщает явным образом (тензорфлоу вроде тоже)
,,,Хм
,,Хм,"если просто кернел умер из воздуха, то вряд ли причина в памяти"
,,,"А и еще. Может тетрадку давно не перезапускали? 

torch.cuda.empty_cache()?"
,,"А и еще. Может тетрадку давно не перезапускали? 

torch.cuda.empty_cache()?","да перезапускал, не помогло"
,,,"я бы для чистоты запустил не в тетрадке, а .py скриптом (на моем опыте тетрадки периодически что-то необъяснимым образом ломают)"
,,"я бы для чистоты запустил не в тетрадке, а .py скриптом (на моем опыте тетрадки периодически что-то необъяснимым образом ломают)","запускал через скрипт в pycharm отдельно и cmd не помогло
он просто застревал на первой эпохе"
,"я бы для чистоты запустил не в тетрадке, а .py скриптом (на моем опыте тетрадки периодически что-то необъяснимым образом ломают)","запускал через скрипт в pycharm отдельно и cmd не помогло
он просто застревал на первой эпохе","С tensorflow давно не работал... Помню были проблемы из-за дров Nvidia, всяких avx-инструкций у процессора...

Может чекнуть совместимость версий tf, Nvidia cuda/cudnn, и харда?

GPU крутая. Вряд ли в compute capability проблемы... у меня из-за него в основном ранее были"
,,,"на мнисте чекал, всё училось, по документации тоже всё ок версии сходятся"
,,"на мнисте чекал, всё училось, по документации тоже всё ок версии сходятся","проблема решилась, если вдруг кто столкнется с той же ситуацией проверьте в папке CUDA/vXX.X/bin наличие файла  zlibwapi.dll"
,,,может есть команда которая ограничивает потребление памяти на tf?
,,,"всем привет, скажите, пожалуйста, есть какие-то не нейро подходы по детекции движения в кадре (есть нет), кроме cv2.absdiff?"
,,"всем привет, скажите, пожалуйста, есть какие-то не нейро подходы по детекции движения в кадре (есть нет), кроме cv2.absdiff?","Нейроподходов тоже вагон и маленькая тележка. И они уже по качеству гораздо лучше того, что перечислили выше из классики. Классика всё ещё не сильно устойчива к небольшой тряске камеры, листьям деревьев, жёстким теням и т.д.
Например, обзор двухлетней давности:
https://arxiv.org/abs/2105.01342"
,"всем привет, скажите, пожалуйста, есть какие-то не нейро подходы по детекции движения в кадре (есть нет), кроме cv2.absdiff?","Нейроподходов тоже вагон и маленькая тележка. И они уже по качеству гораздо лучше того, что перечислили выше из классики. Классика всё ещё не сильно устойчива к небольшой тряске камеры, листьям деревьев, жёстким теням и т.д.
Например, обзор двухлетней давности:
https://arxiv.org/abs/2105.01342",ну впервую очередь классику хочу потому что есть ограничения по железу
,,,opencv background subtraction из классики
,,,"Модель движения на основе гауссиан, статистик"
,,"Модель движения на основе гауссиан, статистик",?
,"Модель движения на основе гауссиан, статистик",?,Да
,,,мерси всем поразбираюсь
,,,"Доброго утра. 

Кто-нибудь пробовал ли выделять буквы (teserract почти не работает, в eаsyocr вообще нет выделения букв, только слова, ещё думаю попробовать craft, который часть easyocr или самому поразмечать и детектор сделать) и получать, к какому шрифту они принадлежат? 🤔"
,,"Доброго утра. 

Кто-нибудь пробовал ли выделять буквы (teserract почти не работает, в eаsyocr вообще нет выделения букв, только слова, ещё думаю попробовать craft, который часть easyocr или самому поразмечать и детектор сделать) и получать, к какому шрифту они принадлежат? 🤔","а точно по буквам надо? Я бы решал так: нагенерил бы синтетики, и отучил бы классификатор. Для детекции текста на сцене при инференсе есть mmocr"
,,,"Ребят, всем привет. Хотел бы получить советы, как получить удаленную работу с заграничными компаниями (вне СНГ), где искать, на что лучше делать упор (я мидл ML инженер со стажем), и сколько времени может на это уйти? Заранее спасибо 😊"
,,"Ребят, всем привет. Хотел бы получить советы, как получить удаленную работу с заграничными компаниями (вне СНГ), где искать, на что лучше делать упор (я мидл ML инженер со стажем), и сколько времени может на это уйти? Заранее спасибо 😊",https://www-career.notion.site/IT-153c3d7531df42be94524d5eceee3f17
,"Ребят, всем привет. Хотел бы получить советы, как получить удаленную работу с заграничными компаниями (вне СНГ), где искать, на что лучше делать упор (я мидл ML инженер со стажем), и сколько времени может на это уйти? Заранее спасибо 😊",https://www-career.notion.site/IT-153c3d7531df42be94524d5eceee3f17,Лучший
,,,"Здравствуйте, могу ли кого-то спросить на тему решения задачи сегментации ?"
,,"Здравствуйте, могу ли кого-то спросить на тему решения задачи сегментации ?",здесь можно спросить) многие в теме) коллективный разум мощнее. Конную полицию же не зря придумали [шутка если что]
,,,"Отлично, Я бы хотел спросить следующее. Хочу свой БПЛА научить определять свои координаты по изображению. Норм идея обучить YOLO для детектирования на изображении, потом с помощью неё подготовить датасет для сегментации , например, для той же Unet ? Или есть более адекватные варианты ? Нейронка в данном случае сверяет картинку с картой, на которую была обучена"
,,"Отлично, Я бы хотел спросить следующее. Хочу свой БПЛА научить определять свои координаты по изображению. Норм идея обучить YOLO для детектирования на изображении, потом с помощью неё подготовить датасет для сегментации , например, для той же Unet ? Или есть более адекватные варианты ? Нейронка в данном случае сверяет картинку с картой, на которую была обучена","Ещё можно вот эту статью посмотреть, должно быть полезно"
,,,"Вариант выглядит как over engineered. Чтобы сопоставить карту со снимком... Сложно конечно. Я не спец, наверняка тут умелые есть.

Во-первых карту надо будет развернуть по компасу. Во-вторых надо будет размыть сильно снимок, и карту (до суперпикселей что ли), а потом сматчить..

Ну и от высоты масштаб же менять надо. Хотя и не самолет конечно, но важно +/- от ландшафта.

В итоге моя рекомендация погуглить, уверен что-то как минимум полуготовое уже должно быть"
,,,"SLAM - simultaneous localization and mapping
типа это?"
,,"SLAM - simultaneous localization and mapping
типа это?",а по-моему не совсем
,,,"Посмотрите в сторону нейросетевого определения кейпойинтов/дескрипторов + матчинг 
Как SOTA есть SuperPoint + SuperGlue или LOFTR
По найденной гомографии между снимком и геопривязанной подложке можно определить координаты (или можно находить координаты каждого кейпоинта)"
,,,"Добрый день.

Впервые столкнулся с задачей ocr.

Необходимо распознавать на структурированном документе только два поля. Будет ли правильным подход обучить модельку сегментации на два класса (на каждое поле). Или нужно делать сегментацию всего текста, а потом думать как баундбокс нужный находить?"
,,"Добрый день.

Впервые столкнулся с задачей ocr.

Необходимо распознавать на структурированном документе только два поля. Будет ли правильным подход обучить модельку сегментации на два класса (на каждое поле). Или нужно делать сегментацию всего текста, а потом думать как баундбокс нужный находить?",А пробовал классикой убирать весь текст кроме нужных тебе полей? Морфологическими операциями
,"Добрый день.

Впервые столкнулся с задачей ocr.

Необходимо распознавать на структурированном документе только два поля. Будет ли правильным подход обучить модельку сегментации на два класса (на каждое поле). Или нужно делать сегментацию всего текста, а потом думать как баундбокс нужный находить?",А пробовал классикой убирать весь текст кроме нужных тебе полей? Морфологическими операциями,"Не пробовал, кажется, что классика много крайних случаев не обработает, хочется что-то более универсальное"
"Добрый день.

Впервые столкнулся с задачей ocr.

Необходимо распознавать на структурированном документе только два поля. Будет ли правильным подход обучить модельку сегментации на два класса (на каждое поле). Или нужно делать сегментацию всего текста, а потом думать как баундбокс нужный находить?",А пробовал классикой убирать весь текст кроме нужных тебе полей? Морфологическими операциями,"Не пробовал, кажется, что классика много крайних случаев не обработает, хочется что-то более универсальное","Стоит попробовать тем не менее, особенно если ожидается что все документы будут одинаковыми по структуре.
Вообще гораздо легче сначала распознать бокс, а потом осr.
А какой язык распознавания?"
А пробовал классикой убирать весь текст кроме нужных тебе полей? Морфологическими операциями,"Не пробовал, кажется, что классика много крайних случаев не обработает, хочется что-то более универсальное","Стоит попробовать тем не менее, особенно если ожидается что все документы будут одинаковыми по структуре.
Вообще гораздо легче сначала распознать бокс, а потом осr.
А какой язык распознавания?","Русский, инн обычные"
"Не пробовал, кажется, что классика много крайних случаев не обработает, хочется что-то более универсальное","Стоит попробовать тем не менее, особенно если ожидается что все документы будут одинаковыми по структуре.
Вообще гораздо легче сначала распознать бокс, а потом осr.
А какой язык распознавания?","Русский, инн обычные","Если нужна помощь го в личку, я постараюсь подсказать что использовать"
"Стоит попробовать тем не менее, особенно если ожидается что все документы будут одинаковыми по структуре.
Вообще гораздо легче сначала распознать бокс, а потом осr.
А какой язык распознавания?","Русский, инн обычные","Если нужна помощь го в личку, я постараюсь подсказать что использовать",Спасибо) чуть позже отпишусь
,,,"И если сегментация на классы допустима, то можно брать стандартные сетки: unet, fpn. Или искать модельки именно для текстов?"
,,"И если сегментация на классы допустима, то можно брать стандартные сетки: unet, fpn. Или искать модельки именно для текстов?","цифра из метрики должна быть понятна простому смертному, это не должен быть рост какого-нибудь рок-аука, она должна быть про бизнес"
,,,Нужно на cpu всю распознавалку в пром запихивать и нагрузка большая ожидается. Что-то легковесное ищу
,,Нужно на cpu всю распознавалку в пром запихивать и нагрузка большая ожидается. Что-то легковесное ищу,">пром
Сбер?"
,Нужно на cpu всю распознавалку в пром запихивать и нагрузка большая ожидается. Что-то легковесное ищу,">пром
Сбер?","нет, у нас технологии idp нет, думаю, в сбере эти вопросы решены)"
,,,"Хорошо, всем спасибо!"
,,,"Берешь и ищешь, если нужна обычная работа то можно найти может за месяц-полтора,
искать можно
- тут
- в сингулярисе
- на hh (меньше шансов)
- пачки каналов в тг(тут надо самому искать)

Поправь cv, поготовься к собесу, эээ пройди и получи оффер?)"
,,"Берешь и ищешь, если нужна обычная работа то можно найти может за месяц-полтора,
искать можно
- тут
- в сингулярисе
- на hh (меньше шансов)
- пачки каналов в тг(тут надо самому искать)

Поправь cv, поготовься к собесу, эээ пройди и получи оффер?)",пасиб)
,,,"Зависит от того, насколько эти два поля отличаются друг от друга по содержанию и расположению от всего остального на документе.
В теории, можно обойтись обычным детектором который забайесится на их положение.
Но обычно решается двухстадийно - детектор + классификатор полей"
,,"Зависит от того, насколько эти два поля отличаются друг от друга по содержанию и расположению от всего остального на документе.
В теории, можно обойтись обычным детектором который забайесится на их положение.
Но обычно решается двухстадийно - детектор + классификатор полей","спасибо, а детектор любой подойдет? или есть что-то общепринятое?"
,"Зависит от того, насколько эти два поля отличаются друг от друга по содержанию и расположению от всего остального на документе.
В теории, можно обойтись обычным детектором который забайесится на их положение.
Но обычно решается двухстадийно - детектор + классификатор полей","спасибо, а детектор любой подойдет? или есть что-то общепринятое?","https://github.com/PaddlePaddle/PaddleOCR
Ищите тут)"
"Зависит от того, насколько эти два поля отличаются друг от друга по содержанию и расположению от всего остального на документе.
В теории, можно обойтись обычным детектором который забайесится на их положение.
Но обычно решается двухстадийно - детектор + классификатор полей","спасибо, а детектор любой подойдет? или есть что-то общепринятое?","https://github.com/PaddlePaddle/PaddleOCR
Ищите тут)",Спасибо!
,,,"Можно ли как нибудь в тексте выделять слова, которые больше повлияли на классификацию текста?

использую keras для бинарной классификации"
,,"Можно ли как нибудь в тексте выделять слова, которые больше повлияли на классификацию текста?

использую keras для бинарной классификации","Я использовала упомянутый в предыдущем комментарии lime алгоритм. Из этой библиотеки: https://github.com/marcotcr/lime

По этой же ссылке в репозитории есть примеры использования и туториалы. Однако нужно иметь ввиду, что этот алгоритм апроксимирует до линейной модели и поэтому может быть неточным и не ко всем случаям подходит (почитать про плебсы и минусы данного алгоритма можно тут: https://www.finalyse.com/blog/machine-learning-model-explainability-why-is-it-important-and-methods-to-achieve-it)"
,,,"Eli5
Lime
Shap
Тут есть прям примеры
Выбирай"
,,"Eli5
Lime
Shap
Тут есть прям примеры
Выбирай","чтобы NDA не нарушить не говори про абсолютные значения, а во сколько раз или на сколько процентов улучшение было в каком-то бейзлайне"
,,,Вот такие картинки получились:
,,Вот такие картинки получились:,База
,,,"Ну я учился на мехмате, тервер, булинский, короч занимаюсь теперь ML, люблю плавать и ковыряться в больших языковых моделях"
,,,"Привет всем, 
я абсолютный новичок в данной сфере, а тут задачка прилетела: есть несколько БД, надо визуализировать: по совпадающим полям данных построить граф (ну рисовать думаю dash_cytoscape)
Беда в том, что названия полей могут отличаться, порядок оформления их содержания - тоже (например, пользователь может указать адрес, начиная с области, или не указывать ее или использовать специфические сокращения...) Подскажите, пожалуйста, с чего начать, какие ресурсы можно посмотреть?"
,,"Привет всем, 
я абсолютный новичок в данной сфере, а тут задачка прилетела: есть несколько БД, надо визуализировать: по совпадающим полям данных построить граф (ну рисовать думаю dash_cytoscape)
Беда в том, что названия полей могут отличаться, порядок оформления их содержания - тоже (например, пользователь может указать адрес, начиная с области, или не указывать ее или использовать специфические сокращения...) Подскажите, пожалуйста, с чего начать, какие ресурсы можно посмотреть?","Какие-то тулзы строят красивые графы по бд со связями между таблицами, первчичыми и форин ключами. Может dbeaver умеет даже."
,"Привет всем, 
я абсолютный новичок в данной сфере, а тут задачка прилетела: есть несколько БД, надо визуализировать: по совпадающим полям данных построить граф (ну рисовать думаю dash_cytoscape)
Беда в том, что названия полей могут отличаться, порядок оформления их содержания - тоже (например, пользователь может указать адрес, начиная с области, или не указывать ее или использовать специфические сокращения...) Подскажите, пожалуйста, с чего начать, какие ресурсы можно посмотреть?","Какие-то тулзы строят красивые графы по бд со связями между таблицами, первчичыми и форин ключами. Может dbeaver умеет даже.","dbeaver может, но вроде ж не по данным, а по полям"
,,,"Кажется, что как-то метаданные записать надо, но пока не знаю, как
Там ещё ключевой момент в скорости, думал регулярки попробовать, но говорят ооочень медленно получится"
,,"Кажется, что как-то метаданные записать надо, но пока не знаю, как
Там ещё ключевой момент в скорости, думал регулярки попробовать, но говорят ооочень медленно получится","а блин, граф прочитал как ""графику"". Смотрите neo4j например"
,"Кажется, что как-то метаданные записать надо, но пока не знаю, как
Там ещё ключевой момент в скорости, думал регулярки попробовать, но говорят ооочень медленно получится","а блин, граф прочитал как ""графику"". Смотрите neo4j например","А что значит по данным?
Ууиды одинаковые, но не является парой перв ключ, форин ки?
И да, тулзы, конечно смотрят на запросы create table и рисуют свои красоты"
,,,"Там скорее uid разные, но есть совпадающие поля (но совпадающие по смыслу, не обязательно одинаковые) типа (""село Иваново, Ивановская область"" ->  ""обл. Ивановская, с. Иваново"" )"
,,"Там скорее uid разные, но есть совпадающие поля (но совпадающие по смыслу, не обязательно одинаковые) типа (""село Иваново, Ивановская область"" ->  ""обл. Ивановская, с. Иваново"" )","вот тут подстава. геокодинг нужен, в координаты. А потом матчить по маленькому радиусу. Это могут postgres/postgis, MySQL с геометрией тоже"
,"Там скорее uid разные, но есть совпадающие поля (но совпадающие по смыслу, не обязательно одинаковые) типа (""село Иваново, Ивановская область"" ->  ""обл. Ивановская, с. Иваново"" )","вот тут подстава. геокодинг нужен, в координаты. А потом матчить по маленькому радиусу. Это могут postgres/postgis, MySQL с геометрией тоже","Но тоже самое может быть и с другими полями, например, если пользователи пожелали оставить свой номер телефона и он в разных форматах и т.п."
"Там скорее uid разные, но есть совпадающие поля (но совпадающие по смыслу, не обязательно одинаковые) типа (""село Иваново, Ивановская область"" ->  ""обл. Ивановская, с. Иваново"" )","вот тут подстава. геокодинг нужен, в координаты. А потом матчить по маленькому радиусу. Это могут postgres/postgis, MySQL с геометрией тоже","Но тоже самое может быть и с другими полями, например, если пользователи пожелали оставить свой номер телефона и он в разных форматах и т.п.","Привет cosine distance тогда) можно сразу в ембеддинги. Поможет или typesense, или elasticsearch"
,,,"Спасибо за советы, посмотрю сейчас
Возможно"
,,,"Ну как вариант, только там же тогда порог дистанции надо будет задать?"
,,"Ну как вариант, только там же тогда порог дистанции надо будет задать?","да, но по идее первый ближайший можно забрать, если в выдаче есть выше порога. Тут уже статистику надо наводить"
,,,"Понял, спасибо за совет"
,,"Понял, спасибо за совет","да если честно, cosine distance не фонтан. Это последняя надежда, если уж на то пошло. Если возможно, лучше подходящими эвристиками.

Но и косинус получше чем поди туда не знаю куда, найди то не знаю что..."
,,,"ну да
Буду все пробовать.."
,,,"А не подскажете еще, может есть фпеймворк на python для сопоставления полей, если все таки одинаковые будут?"
,,"А не подскажете еще, может есть фпеймворк на python для сопоставления полей, если все таки одинаковые будут?","то есть сопоставления?.. если значения совпадают, сильно производительнее все делать в sql"
,,,"ок, спасибо"
,,"ок, спасибо",Чем-то может посодействовать для обобщения задачи sqlalchemy orm
,,,"Я хочу сделать на первый взгляд простой таск. 

Просто классифицировать входящие и исходящие сообщения из мессенджера на те, что содержать конфиденциальную информацию и те, что не содержат. Это:

1. Упоминание имен партнеров
2. Упоминание их контактов
3. Любые ссылки помимо тех, что были добавлены в исключения

Думал банальный таск, и смогу сделать с помощью Naive Bayes. Но основную трудность, которую я вижу, что сложно, например, распознавать разные форматы контактов. Телефон могут по-разному писать, имена на разных языках да и вообще кучу вариантов можно придумать, как обойти систему. На картинке, например, могут написать, но пока что я думаю, что с картинками можно не заморачиваться. 

Правильно ли я понимаю, что Naive Bayes уже не подходит? 😢"
,,"Я хочу сделать на первый взгляд простой таск. 

Просто классифицировать входящие и исходящие сообщения из мессенджера на те, что содержать конфиденциальную информацию и те, что не содержат. Это:

1. Упоминание имен партнеров
2. Упоминание их контактов
3. Любые ссылки помимо тех, что были добавлены в исключения

Думал банальный таск, и смогу сделать с помощью Naive Bayes. Но основную трудность, которую я вижу, что сложно, например, распознавать разные форматы контактов. Телефон могут по-разному писать, имена на разных языках да и вообще кучу вариантов можно придумать, как обойти систему. На картинке, например, могут написать, но пока что я думаю, что с картинками можно не заморачиваться. 

Правильно ли я понимаю, что Naive Bayes уже не подходит? 😢","У вас только эти три пункта показывают на то, что сообщение конф?"
,"Я хочу сделать на первый взгляд простой таск. 

Просто классифицировать входящие и исходящие сообщения из мессенджера на те, что содержать конфиденциальную информацию и те, что не содержат. Это:

1. Упоминание имен партнеров
2. Упоминание их контактов
3. Любые ссылки помимо тех, что были добавлены в исключения

Думал банальный таск, и смогу сделать с помощью Naive Bayes. Но основную трудность, которую я вижу, что сложно, например, распознавать разные форматы контактов. Телефон могут по-разному писать, имена на разных языках да и вообще кучу вариантов можно придумать, как обойти систему. На картинке, например, могут написать, но пока что я думаю, что с картинками можно не заморачиваться. 

Правильно ли я понимаю, что Naive Bayes уже не подходит? 😢","У вас только эти три пункта показывают на то, что сообщение конф?",в целом да. Больше идей не приходило.
"Я хочу сделать на первый взгляд простой таск. 

Просто классифицировать входящие и исходящие сообщения из мессенджера на те, что содержать конфиденциальную информацию и те, что не содержат. Это:

1. Упоминание имен партнеров
2. Упоминание их контактов
3. Любые ссылки помимо тех, что были добавлены в исключения

Думал банальный таск, и смогу сделать с помощью Naive Bayes. Но основную трудность, которую я вижу, что сложно, например, распознавать разные форматы контактов. Телефон могут по-разному писать, имена на разных языках да и вообще кучу вариантов можно придумать, как обойти систему. На картинке, например, могут написать, но пока что я думаю, что с картинками можно не заморачиваться. 

Правильно ли я понимаю, что Naive Bayes уже не подходит? 😢","У вас только эти три пункта показывают на то, что сообщение конф?",в целом да. Больше идей не приходило.,"Просто если это именно идея описания класса - это одно, тогда можете учить классификацию и не париться. А вот партнеры это, например, уже ner задача на мой взгляд. 

Но я бы сначала регулярками прошлась, если почты, номера и тд это единственный признак; чтобы не делать overkill."
"У вас только эти три пункта показывают на то, что сообщение конф?",в целом да. Больше идей не приходило.,"Просто если это именно идея описания класса - это одно, тогда можете учить классификацию и не париться. А вот партнеры это, например, уже ner задача на мой взгляд. 

Но я бы сначала регулярками прошлась, если почты, номера и тд это единственный признак; чтобы не делать overkill.","не понял про партнеров. Регулярки вряд ли помогут. Вот, например, если на другом языке напишут имя какого-то партнера. Они полезны довольно в узких рамках. 

И правильно ли я понял, что вы одобряете идею с Naive Bayes?"
в целом да. Больше идей не приходило.,"Просто если это именно идея описания класса - это одно, тогда можете учить классификацию и не париться. А вот партнеры это, например, уже ner задача на мой взгляд. 

Но я бы сначала регулярками прошлась, если почты, номера и тд это единственный признак; чтобы не делать overkill.","не понял про партнеров. Регулярки вряд ли помогут. Вот, например, если на другом языке напишут имя какого-то партнера. Они полезны довольно в узких рамках. 

И правильно ли я понял, что вы одобряете идею с Naive Bayes?","Я про регулярки скорее для номеров и тд. 

Если у вас простые тексты, то можете начать и с naive bayes) Нельзя же сказать, что нельзя вообще пробовать, naive bayes вы быстро и напишите, и обучите."
,,,"я бы вел отдельную базу документов с грифом (точнее хватит одних только эмбеддингов), и по ней бы матчил по наличию в ней"
,,"я бы вел отдельную базу документов с грифом (точнее хватит одних только эмбеддингов), и по ней бы матчил по наличию в ней",каких документов с грифом? что вы имели ввиду?
,,,"документом могут быть и контакты
naive bayes далеко не самая негодная вещь) у меня в проде бодрее TabPFN (на трансформерах) перформит"
,,,"Ясно. Я, наверное, действительно тогда попробую начать с naive bayes, а потом видимо лучше подсобрать данных, где умышленно постараются хакнуть мою систему. И под каждый кейс видимо придется сделать отдельное дополнение. Как бы вы это видели, кстати? 

Вот, например, само собой разумеющееся, что на другом языке bayes не распознает, т.к. я не забивал эту информацию в словарь вероятностей. 

Получается, это нужно будет поднять нейронку, обученную находить что-то похожее на те слова, которые были занесены в словарь вероятностей? Ну и потом перемножить вероятность того, что это была аналогичная фраза с вероятностью того, что предложение имеет информацию о контакте (как будто бы если слово встретилось в исходном виде, как в словаре вероятностей)?"
,,"Ясно. Я, наверное, действительно тогда попробую начать с naive bayes, а потом видимо лучше подсобрать данных, где умышленно постараются хакнуть мою систему. И под каждый кейс видимо придется сделать отдельное дополнение. Как бы вы это видели, кстати? 

Вот, например, само собой разумеющееся, что на другом языке bayes не распознает, т.к. я не забивал эту информацию в словарь вероятностей. 

Получается, это нужно будет поднять нейронку, обученную находить что-то похожее на те слова, которые были занесены в словарь вероятностей? Ну и потом перемножить вероятность того, что это была аналогичная фраза с вероятностью того, что предложение имеет информацию о контакте (как будто бы если слово встретилось в исходном виде, как в словаре вероятностей)?","давайте вернемся к нашей теме. Как бы вы видели дополнение модели, основанной на naive bayes?"
,"Ясно. Я, наверное, действительно тогда попробую начать с naive bayes, а потом видимо лучше подсобрать данных, где умышленно постараются хакнуть мою систему. И под каждый кейс видимо придется сделать отдельное дополнение. Как бы вы это видели, кстати? 

Вот, например, само собой разумеющееся, что на другом языке bayes не распознает, т.к. я не забивал эту информацию в словарь вероятностей. 

Получается, это нужно будет поднять нейронку, обученную находить что-то похожее на те слова, которые были занесены в словарь вероятностей? Ну и потом перемножить вероятность того, что это была аналогичная фраза с вероятностью того, что предложение имеет информацию о контакте (как будто бы если слово встретилось в исходном виде, как в словаре вероятностей)?","давайте вернемся к нашей теме. Как бы вы видели дополнение модели, основанной на naive bayes?","naive bayes это классификатор, и ему нужна разметка. классика. Вместо naive bayes можно подставить технически любой другой классификатор. 

Так что если сведете задачу к классической, дело в кармане, все стандартные практики будут работать.

Что представляет задача конкретно в вашем случае, лучше вас никто не знает"
"Ясно. Я, наверное, действительно тогда попробую начать с naive bayes, а потом видимо лучше подсобрать данных, где умышленно постараются хакнуть мою систему. И под каждый кейс видимо придется сделать отдельное дополнение. Как бы вы это видели, кстати? 

Вот, например, само собой разумеющееся, что на другом языке bayes не распознает, т.к. я не забивал эту информацию в словарь вероятностей. 

Получается, это нужно будет поднять нейронку, обученную находить что-то похожее на те слова, которые были занесены в словарь вероятностей? Ну и потом перемножить вероятность того, что это была аналогичная фраза с вероятностью того, что предложение имеет информацию о контакте (как будто бы если слово встретилось в исходном виде, как в словаре вероятностей)?","давайте вернемся к нашей теме. Как бы вы видели дополнение модели, основанной на naive bayes?","naive bayes это классификатор, и ему нужна разметка. классика. Вместо naive bayes можно подставить технически любой другой классификатор. 

Так что если сведете задачу к классической, дело в кармане, все стандартные практики будут работать.

Что представляет задача конкретно в вашем случае, лучше вас никто не знает","то, что можно подставить это непременно. Более того, я могу его изначально даже не использовать. Я всего лишь спрашивал, что если мне будет недостаточно bayes, то как можно было бы тогда дополнить его функционал? Например, для номеров телефона в разных форматах, переведенные имена партнеров и т.п. 


Или же вы сразу рекомендуете поднимать Siamise Network или NER?"
,,,"ща дам гайд
развлекайся 🙂"
,,"ща дам гайд
развлекайся 🙂",Спасибо✊🏻
,,,"я, наверное, даже полагаю, что с этим прекрасно и chatgpt справится, если его подключить через апи? А регулярки в любом случае неточны будут. Что там, кстати, по тарифам, это же не бесплатное удовольствие будет, на сколько я понимаю?"
,,"я, наверное, даже полагаю, что с этим прекрасно и chatgpt справится, если его подключить через апи? А регулярки в любом случае неточны будут. Что там, кстати, по тарифам, это же не бесплатное удовольствие будет, на сколько я понимаю?","ну... чатГПТ все ваши конфиденциальные данные отдаст microsoft.

посмотрите разделы сайта sbert.net"
,"я, наверное, даже полагаю, что с этим прекрасно и chatgpt справится, если его подключить через апи? А регулярки в любом случае неточны будут. Что там, кстати, по тарифам, это же не бесплатное удовольствие будет, на сколько я понимаю?","ну... чатГПТ все ваши конфиденциальные данные отдаст microsoft.

посмотрите разделы сайта sbert.net","да, точняк, Siamese Network может быть весьма кстати. Но выглядит слегка избыточно для моей таски. Он же всё таки больше заточен под похожесть смыслов больших текстов. А у меня весьма примитивный таск в этом плане. Не больше 5 слов ему нужно охватить. 

Хотя, может я преувеличиваю  полновесность этой сети?"
"я, наверное, даже полагаю, что с этим прекрасно и chatgpt справится, если его подключить через апи? А регулярки в любом случае неточны будут. Что там, кстати, по тарифам, это же не бесплатное удовольствие будет, на сколько я понимаю?","ну... чатГПТ все ваши конфиденциальные данные отдаст microsoft.

посмотрите разделы сайта sbert.net","да, точняк, Siamese Network может быть весьма кстати. Но выглядит слегка избыточно для моей таски. Он же всё таки больше заточен под похожесть смыслов больших текстов. А у меня весьма примитивный таск в этом плане. Не больше 5 слов ему нужно охватить. 

Хотя, может я преувеличиваю  полновесность этой сети?","Ваша задача для читающих со стороны как в тумане. Давайте я вам предложу, если есть время, какую книжку почитать"
,,,Siamese?... я такого не предлагал...
,,Siamese?... я такого не предлагал...,
,Siamese?... я такого не предлагал...,,"боже мои, той статье 5+ лет"
Siamese?... я такого не предлагал...,,"боже мои, той статье 5+ лет","ну это по той ссылке, что вы дали sbert.net"
,"боже мои, той статье 5+ лет","ну это по той ссылке, что вы дали sbert.net",да я понял... )
,,,"полагаю, что какие-то общие слова про нейронные сети. У меня есть представление о них. Как это связано с моей задачей?"
,,"полагаю, что какие-то общие слова про нейронные сети. У меня есть представление о них. Как это связано с моей задачей?",общее представление проще сделать частным
,"полагаю, что какие-то общие слова про нейронные сети. У меня есть представление о них. Как это связано с моей задачей?",общее представление проще сделать частным,лично у меня с представлением о нейронных сетях более ли менее...
,,,"Всем привет, нужна программа строить схемы, была такая где они как будто от руки нарисованы, но я не помню название, может кто подскажет"
,,"Всем привет, нужна программа строить схемы, была такая где они как будто от руки нарисованы, но я не помню название, может кто подскажет","https://www.unisender.com/ru/blog/idei/navesti-poryadok-v-golove-i-ne-tolko-10-luchshih-servisov-dlya-sozdaniya-intellektualnyh-kart/

вот тут прям список большой"
,"Всем привет, нужна программа строить схемы, была такая где они как будто от руки нарисованы, но я не помню название, может кто подскажет","https://www.unisender.com/ru/blog/idei/navesti-poryadok-v-golove-i-ne-tolko-10-luchshih-servisov-dlya-sozdaniya-intellektualnyh-kart/

вот тут прям список большой",CEO полезных списков
"Всем привет, нужна программа строить схемы, была такая где они как будто от руки нарисованы, но я не помню название, может кто подскажет","https://www.unisender.com/ru/blog/idei/navesti-poryadok-v-golove-i-ne-tolko-10-luchshih-servisov-dlya-sozdaniya-intellektualnyh-kart/

вот тут прям список большой",CEO полезных списков,сам в шоке
,,,with plt.xkcd()?
,,with plt.xkcd()?,"Да, но нет) Имею в виду онлайн платформу где можно рисовать блок схемы в похожем стиле
О спасибо! Выглядит как то, что надо"
,with plt.xkcd()?,"Да, но нет) Имею в виду онлайн платформу где можно рисовать блок схемы в похожем стиле
О спасибо! Выглядит как то, что надо","мб чего приглянется
правда там автор немножк кринжово эти схемы использует, прям полный аджайл"
,,,а ты хорош
,,а ты хорош,"Я выложил фото этого чувака, поэтому закидайте ему лайки"
,,,чет ору со своего лица на заднем фоне 😂
,,,"Всем привет! Появилась задача, суть которой в фильтрации точек с земли для данных с лидара (.pcap формат), т.е. планируется сегментировать дорогу и убирать найденные точки. Есть ли какие-то простые готовые решения для этого? Из state-of-the-art нашел трансформер SphereFormer, но хотелось бы что-то попроще, с чего бы следовало начать, чтобы погружаться в тему постепенно (с PC до этого никогда не работал)"
,,"Всем привет! Появилась задача, суть которой в фильтрации точек с земли для данных с лидара (.pcap формат), т.е. планируется сегментировать дорогу и убирать найденные точки. Есть ли какие-то простые готовые решения для этого? Из state-of-the-art нашел трансформер SphereFormer, но хотелось бы что-то попроще, с чего бы следовало начать, чтобы погружаться в тему постепенно (с PC до этого никогда не работал)",Как вариант - находить плоскости ransac'ом и уже с ними работать
,"Всем привет! Появилась задача, суть которой в фильтрации точек с земли для данных с лидара (.pcap формат), т.е. планируется сегментировать дорогу и убирать найденные точки. Есть ли какие-то простые готовые решения для этого? Из state-of-the-art нашел трансформер SphereFormer, но хотелось бы что-то попроще, с чего бы следовало начать, чтобы погружаться в тему постепенно (с PC до этого никогда не работал)",Как вариант - находить плоскости ransac'ом и уже с ними работать,"Думал про него, но если имеются наклоны, то возможны проблемы"
"Всем привет! Появилась задача, суть которой в фильтрации точек с земли для данных с лидара (.pcap формат), т.е. планируется сегментировать дорогу и убирать найденные точки. Есть ли какие-то простые готовые решения для этого? Из state-of-the-art нашел трансформер SphereFormer, но хотелось бы что-то попроще, с чего бы следовало начать, чтобы погружаться в тему постепенно (с PC до этого никогда не работал)",Как вариант - находить плоскости ransac'ом и уже с ними работать,"Думал про него, но если имеются наклоны, то возможны проблемы","вроде ничего страшного, лишь будут плоскости наклоненные"
Как вариант - находить плоскости ransac'ом и уже с ними работать,"Думал про него, но если имеются наклоны, то возможны проблемы","вроде ничего страшного, лишь будут плоскости наклоненные","Хотя нет, я был неправ, можно ransac-ом решать и для случаев с наклоном - https://www.researchgate.net/publication/329612826_A_Slope-robust_Cascaded_Ground_Segmentation_in_3D_Point_Cloud_for_Autonomous_Vehicles"
,,,"Как можно через whisper получить 1-2 сек интервалы? Например, 00:00:53,000 --> 00:00:59,000
From its earliest days, Washington, D.C., the nation's capital, has preserved the history of our frontiers.

00:00:53,000 --> 00:00:55,000
From its earliest days,
00:00:55,000 --> 00:00:57,000
Washington, D.C., the nation's capital
00:00:57,000 --> 00:00:59,000"
,,"Как можно через whisper получить 1-2 сек интервалы? Например, 00:00:53,000 --> 00:00:59,000
From its earliest days, Washington, D.C., the nation's capital, has preserved the history of our frontiers.

00:00:53,000 --> 00:00:55,000
From its earliest days,
00:00:55,000 --> 00:00:57,000
Washington, D.C., the nation's capital
00:00:57,000 --> 00:00:59,000",https://github.com/m-bain/whisperX
,,,"всем привет товарищи DLEшники, есть тут кто баловался по полной с эмбеддингами (в частности с CLIP’овскими) и готов ответить на каверзные вопросы?"
,,,"1. куда направлен эмбеддинг? Что это под собой подразумевает геометрически?

2. что происходит если я растягиваю эмбеддинг, умножив например на какое-нибудь число в пространстве? 

3. допустим я поверну эмбеддинг на какой-нибудь угол, что это поменяет теоретически? 

Благодарю, и да, у гпт спрашивал, он несёт ахинею"
,,"1. куда направлен эмбеддинг? Что это под собой подразумевает геометрически?

2. что происходит если я растягиваю эмбеддинг, умножив например на какое-нибудь число в пространстве? 

3. допустим я поверну эмбеддинг на какой-нибудь угол, что это поменяет теоретически? 

Благодарю, и да, у гпт спрашивал, он несёт ахинею","2. если cos sim считать и дальше будет, то ничего не произойдёт"
,"1. куда направлен эмбеддинг? Что это под собой подразумевает геометрически?

2. что происходит если я растягиваю эмбеддинг, умножив например на какое-нибудь число в пространстве? 

3. допустим я поверну эмбеддинг на какой-нибудь угол, что это поменяет теоретически? 

Благодарю, и да, у гпт спрашивал, он несёт ахинею","2. если cos sim считать и дальше будет, то ничего не произойдёт","Я понимаю, равно как и если растянуть его. Вопрос в том почему это так работает"
"1. куда направлен эмбеддинг? Что это под собой подразумевает геометрически?

2. что происходит если я растягиваю эмбеддинг, умножив например на какое-нибудь число в пространстве? 

3. допустим я поверну эмбеддинг на какой-нибудь угол, что это поменяет теоретически? 

Благодарю, и да, у гпт спрашивал, он несёт ахинею","2. если cos sim считать и дальше будет, то ничего не произойдёт","Я понимаю, равно как и если растянуть его. Вопрос в том почему это так работает","потому что угол считаем между векторами, модуль тут не играет разницы"
"2. если cos sim считать и дальше будет, то ничего не произойдёт","Я понимаю, равно как и если растянуть его. Вопрос в том почему это так работает","потому что угол считаем между векторами, модуль тут не играет разницы",При чем тут подсчет угла между векторами? Я говорю про матрицы поворотов условные или кватернионы
,,,это вопросы с какого-то тестового задания\домашки что ли?
,,это вопросы с какого-то тестового задания\домашки что ли?,"эм, нет"
,,,"вот dot product из атеншена уже бы разный скор от такого дал
ты сказал умножить эмбединг на число :<
вот я и подумал"
,,"вот dot product из атеншена уже бы разный скор от такого дал
ты сказал умножить эмбединг на число :<
вот я и подумал","Ну, давай забудем про это на сейчас, не понял тебя, извиняй
что происходит с эмбеддингом если его поверну в пространстве?"
,,,"наверное не до конца понимаю, что ты имеешь в виду. Ну он обретёт иной смысл"
,,"наверное не до конца понимаю, что ты имеешь в виду. Ну он обретёт иной смысл","Да, вопрос в том какой)"
,,,"вектор всегда имеет направление, кроме нулевого, эмбеддинг как я понимаю тоже имеет направление но судя по информации что я знаю это не играет абсолютно никакой роли"
,,"вектор всегда имеет направление, кроме нулевого, эмбеддинг как я понимаю тоже имеет направление но судя по информации что я знаю это не играет абсолютно никакой роли",в некоторых архитекутрах и лоссах очень важную роль играет
,"вектор всегда имеет направление, кроме нулевого, эмбеддинг как я понимаю тоже имеет направление но судя по информации что я знаю это не играет абсолютно никакой роли",в некоторых архитекутрах и лоссах очень важную роль играет,"отлично, уже мне нравится направление нашего диалога) Ну вот собсна и возникает вопрос а что будет если я буду поворачивать эмбеддинг, что это изменит в контексте например диффузий. Если вы знаете ссылки на ресурсы где могут дать такие ответы был бы очень благодарен"
,,,но я не уверен правда ли это
,,но я не уверен правда ли это,ты наивный пример из word2vec видимо пропустил
,,,"где из вектора короля вычитают вектор мужчины, добавляют женщину и получают королеву"
,,"где из вектора короля вычитают вектор мужчины, добавляют женщину и получают королеву",да
,,,"типо ArcFace
там лосс задрочен как раз для того что бы у вектров правильные направления были"
,,,просто допустим я игрался с эмбеддингом в диффузии и умножал на константу
,,просто допустим я игрался с эмбеддингом в диффузии и умножал на константу,текстового промта?
,просто допустим я игрался с эмбеддингом в диффузии и умножал на константу,текстового промта?,"CLIP, image encoder ViT"
,,,"но это ничего визуально не меняет
я не понимаю это просто не имеет смысла или что-то там хитрее работает"
,,,"если следовать наивной логике и запихнуть противоположный вектор промта, то должно получиться с точностью да нооборот)"
,,"если следовать наивной логике и запихнуть противоположный вектор промта, то должно получиться с точностью да нооборот)","нет, если бы)"
,,,"получается месиво)
а стоп, вру, там был текстовый энкодер где я получил месиво развернув вектор"
,,,"не знаю что там у диффузий, но вроде там атеншен картинки по тексту, а там dot product считается, и умножение на константу должно было бы изменить результаты"
,,"не знаю что там у диффузий, но вроде там атеншен картинки по тексту, а там dot product считается, и умножение на константу должно было бы изменить результаты",Вот я и не понимаю почему
,,,"ну они меняются конечно, но я бы не сказал что прям кардинально
могу лишь сказать что нулевой вектор выдает совсем другое совершенно несвязанное с промптом что логично, если вектор направить в обратное направление все ломается, а вот растяжение можно проводить условно до огромных значений но это результат не меняет"
,,,"знает ли кто ли инструмен для разметки, задача классификации изображения, выбираю несколько изображений - а инструмент сортирует остальные неразмеченные картинки по похожести - чтобы было легче найти все картинки этого класса?"
,,"знает ли кто ли инструмен для разметки, задача классификации изображения, выбираю несколько изображений - а инструмент сортирует остальные неразмеченные картинки по похожести - чтобы было легче найти все картинки этого класса?",только учти что CLIP не умеет работать с конкретными задачами / абстрактными задачами
,"знает ли кто ли инструмен для разметки, задача классификации изображения, выбираю несколько изображений - а инструмент сортирует остальные неразмеченные картинки по похожести - чтобы было легче найти все картинки этого класса?",только учти что CLIP не умеет работать с конкретными задачами / абстрактными задачами,"хех, а с какими тогда умеет?"
"знает ли кто ли инструмен для разметки, задача классификации изображения, выбираю несколько изображений - а инструмент сортирует остальные неразмеченные картинки по похожести - чтобы было легче найти все картинки этого класса?",только учти что CLIP не умеет работать с конкретными задачами / абстрактными задачами,"хех, а с какими тогда умеет?","CLIP не умеет отвечать на вопросы например сколько инстансов класса на фото, или например какой марки эта машина"
,,,там есть gui который сортирует картинки по похожести?
,,там есть gui который сортирует картинки по похожести?,"Это модель, твою задачу с ней можно решить в строк 30
Да, unicorn тут мб даже лучше, если описание класса не используешь"
,,,"если самому писать, что лучше подойдет? пока только streamlit в голову приходит
самому на html/js писать как-то зашкварно"
,,"если самому писать, что лучше подойдет? пока только streamlit в голову приходит
самому на html/js писать как-то зашкварно","Gradio можешь глянуть, но стримлит лучше будет здесь"
,,,Классификацию на streamlit получится. Что-то другое - как вы говорите - зашкварно
,,,"всем привет!
как думаете лосс здоровый?"
,,"всем привет!
как думаете лосс здоровый?",Выглядит допустимо. Что на тесте?
,"всем привет!
как думаете лосс здоровый?",Выглядит допустимо. Что на тесте?,"я пока без теста запустил
трейн 1кк строк"
"всем привет!
как думаете лосс здоровый?",Выглядит допустимо. Что на тесте?,"я пока без теста запустил
трейн 1кк строк","Ну варианты два:
- все данные ценные и у тебя все обучилось, на всплесках аномалии, которыми можно будет принебречь, к тому же лосс на них снижается
- ценные моменты именно на всплесках, модель переобучилась или обучилась плохо
Наверняка можно будет понять на тестовой выборке"
Выглядит допустимо. Что на тесте?,"я пока без теста запустил
трейн 1кк строк","Ну варианты два:
- все данные ценные и у тебя все обучилось, на всплесках аномалии, которыми можно будет принебречь, к тому же лосс на них снижается
- ценные моменты именно на всплесках, модель переобучилась или обучилась плохо
Наверняка можно будет понять на тестовой выборке",у меня датасет на ~70к классов
,,,обучаю триплет
,,,ок спасибо!
,,ок спасибо!,Dist это единица минус косинус?
,ок спасибо!,Dist это единица минус косинус?,но можно и так
,,,"Если будем ехать по мосту, то, возможно, описать плоскостью будет сложнее"
,,,"Тут пример сортировки через миниатюры, но я чаще интерактивной работой с embedding space пользуюсь для похожих задач"
,,"Тут пример сортировки через миниатюры, но я чаще интерактивной работой с embedding space пользуюсь для похожих задач",https://docs.voxel51.com/tutorials/image_embeddings.html
,,,"выглядит интересно, надо пробовать"
,,,странно что трейн лосс == 0
,,странно что трейн лосс == 0,"loss = max(0, triplet_loss)
triplet_loss = (dist(anchor, pos) - dist(anchor, neg) + margin)"
,,,"Насколько я помню, для триплета это ок, если у тебя positive ближе к anchor чем negative (без учета margin)"
,,"Насколько я помню, для триплета это ок, если у тебя positive ближе к anchor чем negative (без учета margin)","Подскажите, пожалуйста, где можно было бы найти базу данных, где можно найти написание телефонов в любых форматах по миру? Так же интересуют емейлы, адреса и ссылки. 

Пытаюсь тут пробить. Пока что лучшее  что я находил это просто набор цифр. Без +7, например."
,,,"!pip install git+https://github.com/huggingface/optimum.git
from optimum.gptq import GPTQQuantizer, load_quantized_model

Попробуйте ставить optimum вот так"
,,"!pip install git+https://github.com/huggingface/optimum.git
from optimum.gptq import GPTQQuantizer, load_quantized_model

Попробуйте ставить optimum вот так","Спасибо. 
Отдельно действительно сработало. Однако при добавлении auto-gptq в данный процесс, как это показано в туториале, все снова падает, но уже с другой ошибкой: 

cannot import name 'autogptq_post_init' from 'auto_gptq.modeling._utils' (/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_utils.py)"
,"!pip install git+https://github.com/huggingface/optimum.git
from optimum.gptq import GPTQQuantizer, load_quantized_model

Попробуйте ставить optimum вот так","Спасибо. 
Отдельно действительно сработало. Однако при добавлении auto-gptq в данный процесс, как это показано в туториале, все снова падает, но уже с другой ошибкой: 

cannot import name 'autogptq_post_init' from 'auto_gptq.modeling._utils' (/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_utils.py)","Попробуйте и auto-gptq так поставить, но видите, у вас они стоят в очереди сначала auto-gptq, потом optimum. Часто с версиями что-то не так, это нормально."
,,,Имею в виду текст на каком языке
,,,Рукописные/печатные?
,,Рукописные/печатные?,Печатные
,Рукописные/печатные?,Печатные,"Должны быть готовые решения ocr тогда, это точно, но я бы попробовала классику для выделения боксов."
,,,"Да, это я понимаю. Вопрос как подобрать правильную версию."
,,"Да, это я понимаю. Вопрос как подобрать правильную версию.","Вообще у них наверху еще предупреждение висит, что все нужно с source ставить, если нужная stable версия - по линке  туториал"
,,,Да. Я это тоже заметил. Сейчас пытаюсь подобрать нужную комбинацию
,,Да. Я это тоже заметил. Сейчас пытаюсь подобрать нужную комбинацию,"Чекните в репозитории под разные версии cuda еще, мб в этом проблема 🤷🏻‍♀️"
,Да. Я это тоже заметил. Сейчас пытаюсь подобрать нужную комбинацию,"Чекните в репозитории под разные версии cuda еще, мб в этом проблема 🤷🏻‍♀️","Спасибо вам большое! В итоге удалось запустить. Установка auto-gptq непосредственно с гита помогла. 
Правда протестить работу загруженной модели пока не смог, из-за ошибки переопределения методов в тестовом классе, но она хотя бы грузится! С этим уже можно работать."
,,,"Ой не туда, с другим дс чатом перепутал"
,,"Ой не туда, с другим дс чатом перепутал","поэтому 0 когда dist1<< dist2
нет, я эвклидовую считаю"
,"Ой не туда, с другим дс чатом перепутал","поэтому 0 когда dist1<< dist2
нет, я эвклидовую считаю","Доброго времени суток!
Подскажите пожалуйста. Для теста модели пишу свой простенький консольный чат, для чего наследую  BaseChatModel из langchain.chat_models.base. Это требует переопределения метода _llm_type. 
Я не нашел его в документации и переопределил просто как пустой, возвращающий None. Вроде все работает 
Однако меня одолевают смутные сомнения, что он наверняка для чего-то нужен. 
Что должен возвращать метод _llm_type (очевидно, что тип модели, но только ли), и для чего он нужен?

В некоторых решениях просто возвращается строка ""custom"" или еще какой-то текст. 
Вероятнее всего вопрос можно снять."
,,,"Всем снова привет. Вопрос, наверное, глупый, но Я не дотягиваю до джуна, поэтому не обессудьте. Если изначальная Yolo была обучена на детекцию, то можно ли переквалифицировать её на задачу сегментации, лишь заменив веса модели ? Маски есть, конечно"
,,"Всем снова привет. Вопрос, наверное, глупый, но Я не дотягиваю до джуна, поэтому не обессудьте. Если изначальная Yolo была обучена на детекцию, то можно ли переквалифицировать её на задачу сегментации, лишь заменив веса модели ? Маски есть, конечно","тебе не веса надо менять, а блок который будет декодить твои фичур мапы полученные от энкодера, следовательно тебе нужно переобучать будет декодер слой"
,,,"Детекция от сегментации не сильно отличается. Но нужно будет поменять ""голову"". Можно даже обучать только новую ""голову"", оставив зафиксированными остальные слои."
,,,"Понял, спасибо"
,,"Понял, спасибо",У yolo есть в v8 модели сегментации
,,,"А зачем так делать? Почему не использовать сетку для сегментации сразу? У йоло прост голова, специфическая для детекции, если выдрать бэкбон, вряд ли он будет лучше какого-либо предтренированного"
,,"А зачем так делать? Почему не использовать сетку для сегментации сразу? У йоло прост голова, специфическая для детекции, если выдрать бэкбон, вряд ли он будет лучше какого-либо предтренированного","То есть просто изменяю один параметр в свойствах класса на сегментацию, меняю веса и всё?"
,,,"Вопрос, кстати, очень интересный.
Сегментация уже прилично работает и на оч. простых сетках. Известны ли примеры/метрики перехода с детекции на сегментацию, только переобучением головы? Может на любой другой архитектуре кто-то уже делал и статью написал?"
,,"Вопрос, кстати, очень интересный.
Сегментация уже прилично работает и на оч. простых сетках. Известны ли примеры/метрики перехода с детекции на сегментацию, только переобучением головы? Может на любой другой архитектуре кто-то уже делал и статью написал?","А что значит ""переобучение головы""? В тех же yolo сегментация появляется вместе с новыми модулями протомасок в головах - обычная yolo просто не способна выдавать выходы для сегментации"
,"Вопрос, кстати, очень интересный.
Сегментация уже прилично работает и на оч. простых сетках. Известны ли примеры/метрики перехода с детекции на сегментацию, только переобучением головы? Может на любой другой архитектуре кто-то уже делал и статью написал?","А что значит ""переобучение головы""? В тех же yolo сегментация появляется вместе с новыми модулями протомасок в головах - обычная yolo просто не способна выдавать выходы для сегментации","Хз, что за модуль протомаски, это тип anchor? Там сегментация прост как доп. Голова работает?"
"Вопрос, кстати, очень интересный.
Сегментация уже прилично работает и на оч. простых сетках. Известны ли примеры/метрики перехода с детекции на сегментацию, только переобучением головы? Может на любой другой архитектуре кто-то уже делал и статью написал?","А что значит ""переобучение головы""? В тех же yolo сегментация появляется вместе с новыми модулями протомасок в головах - обычная yolo просто не способна выдавать выходы для сегментации","Хз, что за модуль протомаски, это тип anchor? Там сегментация прост как доп. Голова работает?",https://arxiv.org/pdf/1904.02689.pdf
"А что значит ""переобучение головы""? В тех же yolo сегментация появляется вместе с новыми модулями протомасок в головах - обычная yolo просто не способна выдавать выходы для сегментации","Хз, что за модуль протомаски, это тип anchor? Там сегментация прост как доп. Голова работает?",https://arxiv.org/pdf/1904.02689.pdf,"Пасиб за папиру, не до конца понял, как градиент протекает. Лосс считается как для обычной сегментации, но зануляются все пиксели вне gt bbox?"
"Хз, что за модуль протомаски, это тип anchor? Там сегментация прост как доп. Голова работает?",https://arxiv.org/pdf/1904.02689.pdf,"Пасиб за папиру, не до конца понял, как градиент протекает. Лосс считается как для обычной сегментации, но зануляются все пиксели вне gt bbox?",Предикт кропается по gt и по кропу считается лосс
https://arxiv.org/pdf/1904.02689.pdf,"Пасиб за папиру, не до конца понял, как градиент протекает. Лосс считается как для обычной сегментации, но зануляются все пиксели вне gt bbox?",Предикт кропается по gt и по кропу считается лосс,"Да, но как оно в коде трейна реализовано?) они прям после инференса кропают картинку физически? Или же просто зануляют пиксели вокруг бокса? И если кропают физически, оно бэкпроп не ломает?"
"Пасиб за папиру, не до конца понял, как градиент протекает. Лосс считается как для обычной сегментации, но зануляются все пиксели вне gt bbox?",Предикт кропается по gt и по кропу считается лосс,"Да, но как оно в коде трейна реализовано?) они прям после инференса кропают картинку физически? Или же просто зануляют пиксели вокруг бокса? И если кропают физически, оно бэкпроп не ломает?","не знаю что делают они, но чтобы бэкпроп не ломать, есть вкусная штука kornia"
,,,"Можно переформулировать: если оставим готовые свёрточные слои от детекции, и начнём обучать ещё одну голову, то получится сегментация или нет. Известны ли работы на эту тему?"
,,"Можно переформулировать: если оставим готовые свёрточные слои от детекции, и начнём обучать ещё одну голову, то получится сегментация или нет. Известны ли работы на эту тему?",так это так всегда и работает? Тебе нужно оставить слой энкодера а дальше уже делай чё хочешь в декодере
,,,"Ну это примерно то, что в статье выше происходит"
,,"Ну это примерно то, что в статье выше происходит","да, интересный подход"
,,,"Есть три типа сегментации:

семантическая (semantic) - каждому пикселю изображения мы присваиваем класс. Нам могут быть интересны не все точки, поэтому у нас отдельным классом идёт ""фон""(""background"")

экземплярная(instance), где фона нет, а нас интересуют объекты - мы не размечаем каждый пиксель изображения, а смотрим, относится ли он к объекту одного из классов, причём, к какому именно. Это задача, родственная детекции, а потому детекторы можно допилить до её решения. Последние версия YOLO это умеют.

паноптическая(panoptic) - смесь двух предыдущих: непрерывные объекты вроде травы или неба сложно рассматривать как объекты, поэтому для них всегда только один экземпляр класса, т. е. семантическая сегментация, а машины или люди - понятные разделимые объекты, поэтому для них применяем instance segmentation. Получается каждый пиксель принадлежит или непрерывному классу, или объекту одного из классов.

Понятно, что YOLO хорошо решать только instance segmentation."
,,"Есть три типа сегментации:

семантическая (semantic) - каждому пикселю изображения мы присваиваем класс. Нам могут быть интересны не все точки, поэтому у нас отдельным классом идёт ""фон""(""background"")

экземплярная(instance), где фона нет, а нас интересуют объекты - мы не размечаем каждый пиксель изображения, а смотрим, относится ли он к объекту одного из классов, причём, к какому именно. Это задача, родственная детекции, а потому детекторы можно допилить до её решения. Последние версия YOLO это умеют.

паноптическая(panoptic) - смесь двух предыдущих: непрерывные объекты вроде травы или неба сложно рассматривать как объекты, поэтому для них всегда только один экземпляр класса, т. е. семантическая сегментация, а машины или люди - понятные разделимые объекты, поэтому для них применяем instance segmentation. Получается каждый пиксель принадлежит или непрерывному классу, или объекту одного из классов.

Понятно, что YOLO хорошо решать только instance segmentation.",Они пошли самым простым путём: заменили прямоугольник более точным контуром.
,"Есть три типа сегментации:

семантическая (semantic) - каждому пикселю изображения мы присваиваем класс. Нам могут быть интересны не все точки, поэтому у нас отдельным классом идёт ""фон""(""background"")

экземплярная(instance), где фона нет, а нас интересуют объекты - мы не размечаем каждый пиксель изображения, а смотрим, относится ли он к объекту одного из классов, причём, к какому именно. Это задача, родственная детекции, а потому детекторы можно допилить до её решения. Последние версия YOLO это умеют.

паноптическая(panoptic) - смесь двух предыдущих: непрерывные объекты вроде травы или неба сложно рассматривать как объекты, поэтому для них всегда только один экземпляр класса, т. е. семантическая сегментация, а машины или люди - понятные разделимые объекты, поэтому для них применяем instance segmentation. Получается каждый пиксель принадлежит или непрерывному классу, или объекту одного из классов.

Понятно, что YOLO хорошо решать только instance segmentation.",Они пошли самым простым путём: заменили прямоугольник более точным контуром.,"в U-Net можно заменить слой энкодера на любой другой, главное чтобы совпадал по размерам с энкодером и всё"
"Есть три типа сегментации:

семантическая (semantic) - каждому пикселю изображения мы присваиваем класс. Нам могут быть интересны не все точки, поэтому у нас отдельным классом идёт ""фон""(""background"")

экземплярная(instance), где фона нет, а нас интересуют объекты - мы не размечаем каждый пиксель изображения, а смотрим, относится ли он к объекту одного из классов, причём, к какому именно. Это задача, родственная детекции, а потому детекторы можно допилить до её решения. Последние версия YOLO это умеют.

паноптическая(panoptic) - смесь двух предыдущих: непрерывные объекты вроде травы или неба сложно рассматривать как объекты, поэтому для них всегда только один экземпляр класса, т. е. семантическая сегментация, а машины или люди - понятные разделимые объекты, поэтому для них применяем instance segmentation. Получается каждый пиксель принадлежит или непрерывному классу, или объекту одного из классов.

Понятно, что YOLO хорошо решать только instance segmentation.",Они пошли самым простым путём: заменили прямоугольник более точным контуром.,"в U-Net можно заменить слой энкодера на любой другой, главное чтобы совпадал по размерам с энкодером и всё","эт да, blip умеет
иногда даже слишком
но мне нужны эмбединги, сейчас unicom для этого использую"
Они пошли самым простым путём: заменили прямоугольник более точным контуром.,"в U-Net можно заменить слой энкодера на любой другой, главное чтобы совпадал по размерам с энкодером и всё","эт да, blip умеет
иногда даже слишком
но мне нужны эмбединги, сейчас unicom для этого использую","а что у BLIP'а там? Там нет эмбеддингов?
Мне кажется там такой же трансформер должен быть
вроде бы ничего подозрительного"
,,,"Коллеги, а по файнтюну Лламы вопрос:
Есть у меня инпут и необходимый аутпут
Если я токенайзю аутпут и просто даю его как лейблы, это легально?
Выглядит как-будто она в любом случае выдает инпут в начале ответа и пока не ясно, хорошая ли это идея
В кукбуке у фейсбука они вроде лейблы -100 забивают на тех позициях где промпт

Есть какие-то мысли?"
,,"Коллеги, а по файнтюну Лламы вопрос:
Есть у меня инпут и необходимый аутпут
Если я токенайзю аутпут и просто даю его как лейблы, это легально?
Выглядит как-будто она в любом случае выдает инпут в начале ответа и пока не ясно, хорошая ли это идея
В кукбуке у фейсбука они вроде лейблы -100 забивают на тех позициях где промпт

Есть какие-то мысли?","это decoder-only модель с авторегрессионной генерацией, есть ровно ноль смысла иметь разные вещи на входе и на выходе"
,"Коллеги, а по файнтюну Лламы вопрос:
Есть у меня инпут и необходимый аутпут
Если я токенайзю аутпут и просто даю его как лейблы, это легально?
Выглядит как-будто она в любом случае выдает инпут в начале ответа и пока не ясно, хорошая ли это идея
В кукбуке у фейсбука они вроде лейблы -100 забивают на тех позициях где промпт

Есть какие-то мысли?","это decoder-only модель с авторегрессионной генерацией, есть ровно ноль смысла иметь разные вещи на входе и на выходе","Спасибо, понял"
,,,"Всем привет, подскажите пожалуйста, как запустить torch модельку на котлине без боли? Надо запустить yolov8n и модель на классификацию на мобилке, бэк написан на котлине"
,,"Всем привет, подскажите пожалуйста, как запустить torch модельку на котлине без боли? Надо запустить yolov8n и модель на классификацию на мобилке, бэк написан на котлине","Вынести в отдельный сервис, в котлине оставить обращения к API"
,,,Мб все-таки тензорфлоу? Там tflite есть
,,,"Это нормально когда работодатель просит чтобы я сам позвонил, да ещё и именно сегодня?"
,,"Это нормально когда работодатель просит чтобы я сам позвонил, да ещё и именно сегодня?",Только если ты уже трудоустроен)
,,,звучит как скам)
,,звучит как скам),Ладно
,звучит как скам),Ладно,дичь
звучит как скам),Ладно,дичь,кто ранил инференс whisper на multiple gpu? напишите пожалуйста
